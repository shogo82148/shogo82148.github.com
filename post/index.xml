<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Shogo&#39;s Blog</title>
    <link>https://shogo82148.github.io/post/</link>
    <description>Recent content in Posts on Shogo&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <lastBuildDate>Mon, 09 Dec 2024 22:37:00 +0900</lastBuildDate>
    <atom:link href="https://shogo82148.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Perl 5.41から、UTF-8で書かれたソースコードにはuse utf8が必須になります</title>
      <link>https://shogo82148.github.io/blog/2024/12/09/perl-requires-use-utf8/</link>
      <pubDate>Mon, 09 Dec 2024 22:37:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2024/12/09/perl-requires-use-utf8/</guid>
      <description>この記事は、Perl Advent Calendar 2024 9日目の記事（穴埋め）です。 8日目は@xtetsuji(Tetsuji OGATA)で「時間を毎秒カウント出力するシェルスクリプトの遅れの考察」でした。
Perl 5.41.2（開発版）から source::encodingプラグマが追加されました。 このプラグマの追加により、UTF-8で書かれたソースコードでは use utf8 が必須になります。
TL;DR ソースコードの先頭に use utf8 って書いておけばOK。
use utf8の必須化 たとえば以下のコードにはUTF-8の文字列が含まれていますが、 use utf8 の指定がありません。
use v5.41; # こんにちは世界 このコードをPerl 5.41.2（開発版）で実行すると以下のようなエラーを吐いて終了します。
Use of non-ASCII character 0xE3 illegal when &amp;#39;use source::encoding &amp;#34;ascii&amp;#34;&amp;#39; is in effect at hoge.pl line 3, at end of line Execution of hoge.pl aborted due to compilation errors. コメントアウトしてあっても日本語は使えないんですね。
正しく実行するには use utf8 を明示し、ソースコードがUTF-8で書かれていることを示す必要があります。
use v5.41; use utf8; # こんにちは世界 これは use utf8 をうっかり書き忘れることを防ぐための処置だそうです。</description>
    </item>
    <item>
      <title>Perl 5.40に真偽値の排他的論理和を表す新しい演算子が導入されました</title>
      <link>https://shogo82148.github.io/blog/2024/12/05/perl-logical-xor-operator/</link>
      <pubDate>Thu, 05 Dec 2024 21:24:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2024/12/05/perl-logical-xor-operator/</guid>
      <description>この記事は、Perl Advent Calendar 2024 5日目の記事（穴埋め）です。 4日目は@shogo82148で「Perl 5.40でtry/catch機能が安定版になりました」でした。
Perl 5.40.0 から、真偽値の排他的論理和を表す ^^ 演算子が導入されました。
背景 Perl には「コンテキスト（文脈）」と呼ばれる概念があります。 Perlはプログラム内の文脈によって、今扱っているデータをどんな種類（数値なのか文字列なのか）で解釈するかを決定します。
たとえば $x + $y は数値加算の演算子であり、$x や $y は数値コンテキストで解釈されます。 数値コンテキストではデータは数値として評価されます。 もし $x や $y に文字列が入っていた場合は、一度数値に変換してから演算が行われます。
そして、Perlにはコンテキスト毎に異なった演算子が存在します。 たとえば、「論理積」を表す演算子の場合、 「整数の論理積」「文字列の論理積」「真偽値の論理積（優先度高）」「真偽値の論理積（優先度低）」の4種類の演算子があります。 「論理和」や「排他的論理和」を加えて表にまとめてみると以下のようになります。
コンテキスト 論理積 論理和 排他的論理和 数値 &amp;amp; | ^ 文字列 &amp;amp;. |. ^. 真偽値(優先度高) &amp;amp;&amp;amp; || 真偽値(優先度低) and or xor さて、この表をよく見ると「真偽値の排他的論理和」の部分にひとつだけ空白があります。 「この空白を埋めよう！」というモチベーションで追加されたのが ^^ 演算子です。 ^^ は両辺の真偽値コンテキストで評価し、その排他的論理和を計算します。
試してみた 実際に試してみました。
use v5.40; sub say_bool($v) { say $v ? &amp;#34;true&amp;#34; : &amp;#34;false&amp;#34;; } say_bool false ^^ false; say_bool false ^^ true; say_bool true ^^ false; say_bool true ^^ true; Perl 5.</description>
    </item>
    <item>
      <title>Perl 5.40でtry/catch機能が安定版になりました</title>
      <link>https://shogo82148.github.io/blog/2024/12/04/try-feature-is-no-longer-experimental/</link>
      <pubDate>Wed, 04 Dec 2024 00:00:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2024/12/04/try-feature-is-no-longer-experimental/</guid>
      <description>この記事は、Perl Advent Calendar 2024 4日目の記事（代打）です。 3日目は@kfly8で「Perlの型ライブラリのkuraと組み込みのclassを一緒に利用できるようになりました」でした。
Perl 5.34.0 で導入されたtry/catch機能でしたが、今までは実験的機能の扱いでした。 しかし、Perl 5.40.0でついに正式な言語機能として扱われることになりました！
Perl 5.40.0のtry/catch機能 :5.40 feature bundle にも try feature が追加されました。 use v5.40 するだけで使えます。
use v5.40; try { die &amp;#34;dead&amp;#34;; } catch($e) { print &amp;#34;catch: $e&amp;#34;; } 実行結果は以下の通りです。
catch: dead at try-catch.pl line 4. まとめ Perl 5.40 で try/catch が使えるようになりました。
Perl 5.38 までの try/catch については以下の記事を参照。
Perl 5.34.0 の try-catch を触ってみる 新しい風が吹く、Perlの空に
tryとcatchで一筋の光
例外処理が簡単に
バグも恐れず、コードも輝く
未来を照らす、5.40
by CodeRabbit
明日5日目は@shogo82148で「Perl 5.40に真偽値の排他的論理和を表す新しい演算子が導入されました」です。 お楽しみに！
参考 Perl 5.</description>
    </item>
    <item>
      <title>LEFT JOINとFOR UPDATEを同時に使うのはやめよう</title>
      <link>https://shogo82148.github.io/blog/2024/11/11/do-not-use-left-join-with-for-update/</link>
      <pubDate>Mon, 11 Nov 2024 22:02:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2024/11/11/do-not-use-left-join-with-for-update/</guid>
      <description>LEFT JOIN を何度も繰り返し、さらに FOR UPDATE しているMySQLのクエリーを見かけました。 毎回似たようなコメントをするのも面倒なので、そのようなクエリーの問題点をまとめておきます。 たとえばこんな感じのクエリーです。
SELECT * FROM `user` LEFT JOIN `user_prefecture` USING (`user_id`) LEFT JOIN `prefecture` USING (`prefecture_id`) WHERE `user`.`user_id` = 1 FOR UPDATE; TL;DR 以下の理由から、LEFT JOINとFOR UPDATEを同時に使うのはやめたほうがよい。
そもそもロックの範囲を間違えている可能性が高い デッドロックの危険性が高まる ギャップロックの可能性がある FOR UPDATE はロックの獲得のみに使用し、関連する情報を取得するのは別クエリーに分けよう。
LEFT JOINとFOR UPDATEを同時に使うのはやめよう 検証用に簡単なテーブルを作ってみます。
ユーザーは自分の居住地（都道府県）を設定できます。 自分の居住地を明かしたくないユーザーは、居住地を設定を省略することも可能です。 このような要件をもとに以下のようなテーブルを定義してみました。
-- ユーザー CREATE TABLE `user` ( `user_id` BIGINT PRIMARY KEY AUTO_INCREMENT, `name` VARCHAR(191) ); -- 都道府県のマスターデータ CREATE TABLE `prefecture` ( `prefecture_id` INTEGER PRIMARY KEY, `name` VARCHAR(191) ); -- ユーザーと都道府県の関連テーブル CREATE TABLE `user_prefecture` ( `user_id` BIGINT PRIMARY KEY, `prefecture_id` INTEGER, CONSTRAINT `user_prefecture_user` FOREIGN KEY (`user_id`) REFERENCES `user` (`user_id`), CONSTRAINT `user_prefecture_prefecture` FOREIGN KEY (`prefecture_id`) REFERENCES `prefecture` (`prefecture_id`) ); -- 初期データ INSERT INTO `user` (`name`) VALUES (&amp;#34;Ichinose&amp;#34;), (&amp;#34;Furusawa&amp;#34;), (&amp;#34;Inoriko&amp;#34;), (&amp;#34;Izu&amp;#34;); INSERT INTO `prefecture` (`prefecture_id`, `name`) VALUES (15, &amp;#34;新潟&amp;#34;); INSERT INTO `user_prefecture` (`user_id`, `prefecture_id`) VALUES (1, 15), (2, 15); 以下の初期データを投入してあります。</description>
    </item>
    <item>
      <title>AWS::LambdaがAWS Asia Pacific (Malaysia) Regionで利用可能になりました</title>
      <link>https://shogo82148.github.io/blog/2024/08/30/p5-aws-lambda-is-available-on-ap-southeast-5/</link>
      <pubDate>Fri, 30 Aug 2024 20:56:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2024/08/30/p5-aws-lambda-is-available-on-ap-southeast-5/</guid>
      <description>AWSでアジアパシフィック（マレーシア）リージョンが利用可能になりました！
Now open — AWS Asia Pacific (Malaysia) Region ついにオープン – AWS アジアパシフィック (マレーシア) リージョン それに合わせて p5-aws-lambda のビルド済みレイヤーも公開しました！
Perl本体（x64）: arn:aws:lambda:ap-southeast-5:445285296882:layer:perl-5-40-runtime-al2023-x86_64:1 Perl本体（arm64）: arn:aws:lambda:ap-southeast-5:445285296882:layer:perl-5-40-runtime-al2023-arm64:1 Paws（x64）: arn:aws:lambda:ap-southeast-5:445285296882:layer:perl-5-38-paws-al2023-x86_64:1 Paws（arm64）: arn:aws:lambda:ap-southeast-5:445285296882:layer:perl-5-38-paws-al2023-arm64:1 🐰新しい地域に、喜びの声、
AWS Lambda、広がる希望。
マレーシアの空に、夢が舞う、
みんなで使おう、楽しいクラウド！
うさぎも跳ねて、嬉しさ満点、
これからの未来、共に進もう！ 🌟
by CodeRabbit
参考 Now open — AWS Asia Pacific (Malaysia) Region ついにオープン – AWS アジアパシフィック (マレーシア) リージョン shogo82148/p5-aws-lambda AWS::Lambda </description>
    </item>
    <item>
      <title>Structured Field Values のパーサーを書いた</title>
      <link>https://shogo82148.github.io/blog/2024/08/13/structured-field-values/</link>
      <pubDate>Tue, 13 Aug 2024 00:33:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2024/08/13/structured-field-values/</guid>
      <description>GoとTypeScriptで Structured Field Values のパーサーを書きました。
github.com/shogo82148/go-sfv: Go版実装 github.com/shogo82148/sfvjs: TypeScript版実装 背景 そもそも Structured Field Values (SFV) とはなにか、なぜ登場したのか、という背景はこちらの記事をどうぞ。
Structured Field Values による Header Field の構造化 HTTP APIを開発していると、アプリケーション独自のHTTPフィールドを定義することがあります。 そういうときに、標準にしたがっておいたほうが何かと楽だろう、ということでSFVを採用しました。
しかしいい感じのSFVのパーサーがなかなか見つからなかったので、自作することにした、というわけです。
Go実装 Go のモジュールとして公開されているので、いつものように go get してきましょう。
go get github.com/shogo82148/go-sfv GoでSFVをパースする DecodeItem、DecodeList、 DecodeDictionary を使います。
net/http.Header.Valuesの戻り値を直接受け取れるよう、 各関数は []string を受け取るようにしました。
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;net/http&amp;#34; &amp;#34;github.com/shogo82148/go-sfv&amp;#34; ) func main() { h := make(http.Header) h.Add(&amp;#34;Example&amp;#34;, `2; foourl=&amp;#34;https://foo.example.com/&amp;#34;`) item, err := sfv.DecodeItem(h.Values(&amp;#34;Example&amp;#34;)) if err != nil { panic(err) } fmt.</description>
    </item>
    <item>
      <title>denoland/dntがerror TS2304: Cannot find name &#39;ErrorOptions&#39;で失敗する</title>
      <link>https://shogo82148.github.io/blog/2024/08/13/denoland-dnt-cannot-find-error-options/</link>
      <pubDate>Tue, 13 Aug 2024 00:30:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2024/08/13/denoland-dnt-cannot-find-error-options/</guid>
      <description>先日npmへのパッケージ公開にチャレンジしてみました。
npmとjsrにパッケージを公開してみた (認証バッジ付) しかし2か月も経たないうちにビルドに失敗するようになってしまいました・・・。 何もしていないのに壊れた。
% deno run -A scripts/build_npm.ts [dnt] Transforming... [dnt] Running npm install... added 7 packages, and audited 8 packages in 4s found 0 vulnerabilities [dnt] Building project... [dnt] Type checking ESM... src/deps/jsr.io/@std/assert/1.0.2/assertion_error.ts:27:42 - error TS2304: Cannot find name &amp;#39;ErrorOptions&amp;#39;. 27 constructor(message: string, options?: ErrorOptions) { ~~~~~~~~~~~~ src/deps/jsr.io/@std/assert/1.0.2/assertion_error.ts:27:42 - error TS4063: Parameter &amp;#39;options&amp;#39; of constructor from exported class has or is using private name &amp;#39;ErrorOptions&amp;#39;. 27 constructor(message: string, options?</description>
    </item>
    <item>
      <title>Go言語の定数演算の精度が限界突破していた件</title>
      <link>https://shogo82148.github.io/blog/2024/08/12/golang-const/</link>
      <pubDate>Mon, 12 Aug 2024 18:39:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2024/08/12/golang-const/</guid>
      <description>元ネタ:
[JavaScriptの問題]
var a = 0.3 - 0.2;
var b = 0.2 - 0.1;
var c = a==b;
cの中身はどれ？
&amp;mdash; RAO(らお)@けもケP-31 (@RIORAO) 2017年10月24日 正確な実数計算をやらされるJavaScriptくん #擬竜戯画 pic.twitter.com/ipE56C2YbV
&amp;mdash; RAO(らお)@けもケP-31 (@RIORAO) 2017年10月26日 この件に関して、以下のような記事を書きました。
Go言語の浮動小数点数のお話 この記事のなかで「Goの定数は512bitの精度で計算されている」「有限精度のため、数学的な答えとは一致するとは限らない」というお話をしました。 しかし某電柱様から「記事中のコードを最新のGoで実行すると、記事の内容とは異なった結果が得られる」という情報を得ました。
問題のコード 動作が異なると報告があったのは以下のコードです。
package main import ( &amp;#34;fmt&amp;#34; ) func main() { const a = 0.3 - 0.2 const b = 0.2 - 0.1 var c = a == b fmt.Println(c) fmt.Printf(&amp;#34;%e\n&amp;#34;, float64(a-b)) } 数学的には 0.3 - 0.</description>
    </item>
    <item>
      <title>Firebase Functionsがデプロイできなくなった話</title>
      <link>https://shogo82148.github.io/blog/2024/07/16/2024-07-16-cannot-deploy-firebase-function/</link>
      <pubDate>Tue, 16 Jul 2024 10:33:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2024/07/16/2024-07-16-cannot-deploy-firebase-function/</guid>
      <description>新規に立ち上げたプロジェクトで firebase deploy を実行したところ、以下のエラーを吐いて失敗してしまいました。
Build failed: failed to Fetch: failed to download archive gs://gcf-sources-PROJECT_NUMBER-asia-northeast1/createUserOnUserCreate-5fd201fd-4b54-42b8-af5c-c3ca68fe3560/version-1/function-source.zip: Access to bucket gcf-sources-PROJECT_NUMBER-asia-northeast1 denied. You must grant Storage Object Viewer permission to PROJECT_NUMBER-compute@developer.gserviceaccount.com.
TL;DR 以下の設定を行います。
サービスアカウント PROJECT_NUMBER-compute@developer.gserviceaccount.com に「Cloud Build サービス アカウント（roles/cloudbuild.builds.builder）」のロールを付与 サービスアカウント PROJECT_NAME@appspot.gserviceaccount.com に「Firebase 管理者（roles/firebase.admin）」「サービス アカウント ユーザー（roles/iam.serviceAccountUser）」を付与 原因 原因は「Code Buildのサービスアカウントの仕様が変更になった」ことと「デフォルトのサービスアカウントへの自動的なロール付与を無効にする設定になっていた」ことでした。
Code Buildのサービスアカウントの仕様が変更になった 今まではサービスアカウント PROJECT_NUMBER@cloudbuild.gserviceaccount.com の権限を使用してビルドしていたのが、 サービスアカウント PROJECT_NUMBER-compute@developer.gserviceaccount.com に変更になりました。
Cloud Buildサービスアカウントが仕様変更（2024年4月29日から） デフォルトのサービスアカウントへの自動的なロール付与を無効にする設定になっていた 一部のGoogle Cloudサービスでは、APIを有効化したときにデフォルトのサービスアカウントが自動的に生成されます。 このとき生成されるサービスアカウントには編集者（roles/editor）が付与されます。
しかし、今回問題になったプロジェクトでは、組織ポリシーでロール付与が無効になっていました。
デフォルトのサービス アカウントへの自動的なロール付与を無効にする この設定の影響で、サービスアカウント PROJECT_NUMBER-compute@developer.gserviceaccount.com に一切権限がない状態でした。
また、Firebase Functionsを実行するためのサービスアカウントにも一切権限がありませんでした。
対策 各サービスアカウントに適切な権限を付与します。
具体的には以下の権限を付与しました。</description>
    </item>
    <item>
      <title>MySQL8.0で近傍検索</title>
      <link>https://shogo82148.github.io/blog/2024/07/16/2024-07-16-mysq8.0-gis/</link>
      <pubDate>Tue, 16 Jul 2024 07:33:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2024/07/16/2024-07-16-mysq8.0-gis/</guid>
      <description>「Redis、PostgreSQL、MySQLで近傍検索」を公開した当時は、 MySQL 5.7 で検証を行いました。 「MySQL 8.0 ではGIS関連も強化されているぞ！」という話を聞いていたので、MySQL 8.0でも検証してみます。 （MySQL 8.0リリースから何年経ってるんだよというツッコミは置いておく）
検証環境 検証環境はDocker上で起動しました。 バージョンは2024-07-16時点で8.0系列最新の8.0.38です。
mysql&amp;gt; SELECT VERSION(); +-----------+ | VERSION() | +-----------+ | 8.0.38 | +-----------+ 1 row in set (0.01 sec) 最新LTSの8.4.1がリリースされていますが、Amazon RDSでは未サポートです。 マネージドサービスを利用したいので、ひとまず8.0で検証を行います。
テーブルの準備 スキーマ定義でSRIDを指定できるようになりました。 何が嬉しいかというと MySQL が「地球は丸い」ということを理解してくれます！
CREATE DATABASE test; USE test; CREATE TABLE IF NOT EXISTS `geotable` ( `id` int(10) UNSIGNED NOT NULL AUTO_INCREMENT, `name` VARCHAR (255) NOT NULL, `geom` POINT NOT NULL SRID 4326, PRIMARY KEY (`id`), SPATIAL KEY `geom` (`geom`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; SRIDは省略可能ですが、インデックスを利用するためには必須です。 忘れずに指定しましょう。</description>
    </item>
    <item>
      <title>GitHub Artifact Attestations を試してみた</title>
      <link>https://shogo82148.github.io/blog/2024/06/30/2024-06-30-try-artifact-attestations/</link>
      <pubDate>Sun, 30 Jun 2024 14:36:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2024/06/30/2024-06-30-try-artifact-attestations/</guid>
      <description>GitHub Artifact Attestations が正式リリースされました。
GitHub Artifact Attestations is generally available ベータ公開 から2カ月足らずでの正式リリースです。 早いですね。それだけ力を入れているということでしょうか。
なんか難しい単語（attestations とか provenanceとか）が並んでいて正直良くわからんのですが、とりあえず試してみましょう。
署名してみる 「S3からファイルを落とすだけのツールを作った」で作成した、 s3cli-mini で試してみます。
s3cli-miniのリリース処理は GitHub Actions 上で実行しています。 ビルドしたバイナリーは以下のリンクからダウンロード可能です。
v0.0.15 - GitHub Releases しかしこのバイナリーは本当に GitHub Actions 上でビルドしたものでしょうか？ リリースバイナリーはあとから差し替えも可能です。僕が悪意のあるコードを密かに忍ばせ、再ビルドし、上書きしているかもしれません。 僕に悪意がなくとも、僕がうっかりクレデンシャルを流出させてしまい、悪意のある第三者によって上書きされるかもしれません。
そんな心配を解決するのが Artifact Attestations です。
使い方は簡単で、リリースのワークフローに actions/attest-build-provenance を呼ぶステップを追加するだけです。
diff --git a/.github/workflows/release.yml b/.github/workflows/release.yml index b5b65f4..31f2d6c 100644 --- a/.github/workflows/release.yml +++ b/.github/workflows/release.yml @@ -10,6 +10,7 @@ jobs: permissions: contents: write id-token: write + attestations: write runs-on: ubuntu-latest steps: @@ -35,3 +36,14 @@ jobs: args: release --clean env: GITHUB_TOKEN: ${{ secrets.</description>
    </item>
    <item>
      <title>go-retry v2 リリースのお知らせ</title>
      <link>https://shogo82148.github.io/blog/2024/06/25/2024-06-25-go-retry-v2/</link>
      <pubDate>Tue, 25 Jun 2024 23:03:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2024/06/25/2024-06-25-go-retry-v2/</guid>
      <description>shogo82148/go-retry は指数的バックオフを行ってくれるライブラリです。
Goで指数的バックオフをやってくれるgo-retryを書いた v2へメジャーバージョンアップをリリースしました。 破壊的な変更が入っているのでお知らせします。
エラーのTemporaryメソッドをチェックしなくなりました DoメソッドやDoValue関数のエラーハンドリングの挙動が変更になります。
v1 までの挙動 v1のDoメソッドは戻り値のエラーが Temporary メソッドを実装している場合、 その実行結果によってリトライの挙動を変えていました。 Temporary メソッドが true を返した場合はリトライを続行します。 false を返した場合はそれ以上のリトライは無意味と判断し、リトライ処理を中断します。
この挙動は net.Error を参考に実装したものでした。 ネットワーク処理中に回復不可能なエラーが発生した場合に、リトライが自動的に中断されることを期待して実装しました。
v2 からの挙動 しかし、残念ながら Go 1.18 から Temporary メソッドは非推奨になってしまいました。 Temporaryの意味はあいまいで、利用者の意図した通りの結果を得られるとは限りません。 実際に「リトライして欲しいときにリトライしてくれない」という報告を受けました。
そういうわけで、エラーのTemporaryメソッドの戻り値は信用せず、呼ばないよう変更しました。
v1からv2への移行 多くのケースでは、インポートパスを github.com/shogo82148/go-retry から github.com/shogo82148/go-retry/v2 に変更するだけでOKなはずです。
万が一v1と同じ挙動を維持したい場合は、以下のように書き換えてください。
// v1 code policy.Do(func() error { return DoSomething() }) // v2 code policy.Do(func() error { err := DoSomething() interface temporary { Temporary() bool } var tmp temporary if errors.As(err, &amp;amp;tmp) &amp;amp;&amp;amp; !</description>
    </item>
    <item>
      <title>npmとjsrにパッケージを公開してみた (認証バッジ付)</title>
      <link>https://shogo82148.github.io/blog/2024/06/23/2024-06-23-publish-to-npm-and-jsr/</link>
      <pubDate>Sun, 23 Jun 2024 16:12:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2024/06/23/2024-06-23-publish-to-npm-and-jsr/</guid>
      <description>先日、同時実行数を制限しながら並行実行する関数を書きました。
TypeScriptで同時実行数を制限しながら並行実行する 便利関数を作ったら他のプロジェクトから参照したいですよね。 そこでパッケージレジストリに登録してみました。
正直コピペで実装で十分なのでは？という分量ですが、パッケージ公開の練習です。
ソースコードを準備する まずは公開するソースコードを準備していきましょう。 ソースコードはGitHubで公開しました。
shogo82148/limit-concurrency - GitHub Denoの開発環境を整える TypeScriptの開発環境を整えたいのですが、Node+TypeScriptの組み合わせはプロジェクトの立ち上げは意外と面倒です。 そこで今回は Deno を使ってみることにしました。 DenoはTypeScriptの実行ランタイムとして開発されており、特別な設定なしでTypeScriptを実行できます。 Brewでインストールしました。
brew install deno 僕は最近エディターには VS Code を使っているので、Deno用の拡張機能をインストールしました。
denoland/vscode_deno インストールしただけでは有効化されません。 ワークスペースの設定ファイル .vscode/settings.json を編集して、明示的に有効化します。
{ &amp;#34;deno.enable&amp;#34;: true, &amp;#34;deno.lint&amp;#34;: true, &amp;#34;editor.formatOnSave&amp;#34;: true, &amp;#34;editor.defaultFormatter&amp;#34;: &amp;#34;denoland.vscode-deno&amp;#34;, &amp;#34;[typescript]&amp;#34;: { &amp;#34;editor.defaultFormatter&amp;#34;: &amp;#34;denoland.vscode-deno&amp;#34; }, } 開発環境が整ったらパッケージ本体のソースコードを書いていきます。
GitHub Actionsでテストを実行する パッケージとして公開するのであれば、テストを書いて、CIを回しておきたいですよね。 Deno公式がセットアップするためのアクションを公開しているので、これを利用します。
denoland/setup-deno あとは deno test コマンドを実行するだけです。
on: push: pull_request: jobs: deno: runs-on: ubuntu-latest steps: - uses: actions/checkout@v4 - uses: denoland/setup-deno@v1 with: deno-version: v1.</description>
    </item>
    <item>
      <title>TypeScriptで同時実行数を制限しながら並行実行する</title>
      <link>https://shogo82148.github.io/blog/2024/06/22/2024-06-22-limit-concurrency-in-typescript/</link>
      <pubDate>Sat, 22 Jun 2024 11:01:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2024/06/22/2024-06-22-limit-concurrency-in-typescript/</guid>
      <description>タスクがたくさんあって並行実行することを考えます。 何も考えずにすべてのタスクを並行実行すると負荷が高すぎるので、 同時実行数を制限したいことがありました。
ググってみるといくつか実装例が見つかりますが、その多くは配列を受け入れるものです。 AsyncIterator を受け入れるバージョンが欲しいなと思い、 他の人の記事を参考に実装してみました。
IteratorまたはIterableを受け入れる版 いきなりAsyncIterator版を実装するのは大変なので、Iterator版で練習してみました。 以下の関数 limitConcurrency は、タスクのIteratorまたはIterableを受け取って、並行実行します。
async function limitConcurrency&amp;lt;T&amp;gt;( iter: Iterator&amp;lt;() =&amp;gt; Promise&amp;lt;T&amp;gt;&amp;gt; | Iterable&amp;lt;() =&amp;gt; Promise&amp;lt;T&amp;gt;&amp;gt;, limit: number ) { const iterator = Symbol.iterator in iter ? iter[Symbol.iterator]() : iter; async function runNext(): Promise&amp;lt;void&amp;gt; { for (;;) { const { value: task, done } = iterator.next(); if (done) { return; } await task(); } } try { const initialTasks: Promise&amp;lt;void&amp;gt;[] = []; for (let i = 0; i &amp;lt; limit; i++) { initialTasks.</description>
    </item>
    <item>
      <title>鍵生成には暗号論的に安全な乱数を使おう</title>
      <link>https://shogo82148.github.io/blog/2024/03/27/2024-03-27-use-cryptographically-secure-random/</link>
      <pubDate>Wed, 27 Mar 2024 21:24:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2024/03/27/2024-03-27-use-cryptographically-secure-random/</guid>
      <description>SSHの鍵生成には暗号論的に安全な疑似乱数を使おうという話。 暗号論的に安全ではない疑似乱数がどれだけ危険かというのを、簡単なCTFを解くことで検証してみました。
背景 SSH公開鍵に自分の好きな文字列を入れる、という記事を読みました。
かっこいいSSH鍵が欲しい 例えばこのSSH公開鍵、末尾に私の名前(akiym)が入っています。
ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIFC90x6FIu8iKzJzvGOYOn2WIrCPTbUYOE+eGi/akiym そんなかっこいいssh鍵が欲しいと思いませんか？
かっこいい！真似してみたい！
そこまではいいんですが、問題は実装です。
秘密鍵を生成する際の乱数生成には高速化のために Goのmath/randを使っていますが、乱数が用いられるのは公開しない秘密鍵自体であり、このアルゴリズム自体はLagged Fibonacci generatorのようなので変に乱数に偏りがない限りは大丈夫だろうと思います(追記: これは乱数予測を主とした話)。 (強調 は筆者によるもの)
おっとそれはまずい。 Goの math/rand パッケージは暗号論的に安全な疑似乱数 ではありません 。 SSH秘密鍵のようなセキュリティーが重要な場面では使用してはいけません。
Capture the Flag Challenge ブログ記事の筆者も math/rand を使ったらまずいことは認識したようで、 かっこいいSSH鍵生成プログラムのREADMEに以下のような追記がありました。
A Small CTF Challenge This is a joke software, but there was a serious bug in commit 7db96da05684a86bdbea18319ecc39097d0320d4.
Can you recover the private key generated by the following command? Of course, it can be recovered in about an hour.</description>
    </item>
    <item>
      <title>GoでMySQLを使ったテストを書くときにつかうユーティリティーライブラリを作った</title>
      <link>https://shogo82148.github.io/blog/2024/03/20/2024-03-20-go-mysql-pool/</link>
      <pubDate>Wed, 20 Mar 2024 21:24:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2024/03/20/2024-03-20-go-mysql-pool/</guid>
      <description>GoでMySQLを使ったテストを書く場合、MySQLのデータベースを初期化する処理や、使い終わったデータベースを削除する処理が必要になります。 毎回似たような処理を書いているので、そろそろライブラリとして切り出せそうだなと思って書いてみました。
shogo82148/go-mysql-pool 背景 弊社ではデータベースに関連したテストを書く場合、ローカルでMySQLを起動し、実際にMySQLへ接続する手法を取っています。 SQLの文法エラーを検知するには、実際にMySQLで処理するのが手っ取り早いからです。
この方法を採用する場合、次の問題は「いつMySQLのデータベースを初期化するか」です。 Goでは TestMain 関数を用意することで、テストの開始前の処理、テストの終了後の処理を書けます。 初期化しているコードは CREATE DATABASE するだけの単純なものです。 そんな分量もないので、プロジェクト毎にコピー＆ペーストして使っていました。
// こんな感じのイメージ。 // 実際に使っているコードとは異なります。 package example_test import ( &amp;#34;database/sql&amp;#34; &amp;#34;testing&amp;#34; ) // 各ユニットテストで使い回す var db *sql.DB func TestMain(m *testing.M) { var cleanup func() db, cleanup = setup() defer cleanup() m.Run() } func setup() (*sql.DB, func()) { // MySQLに接続して新しいデータベースを作る db0, err := sql.Open(&amp;#34;mysql&amp;#34;, &amp;#34;user:password@/&amp;#34;) if err != nil { panic(err) } _, err = db0.Exec(&amp;#34;CREATE DATABASE dbname&amp;#34;) if err !</description>
    </item>
    <item>
      <title>GoのMySQLドライバーを使うときはmysql.NewConnectorとsql.OpenDBを使おう</title>
      <link>https://shogo82148.github.io/blog/2024/03/12/2024-03-12-use-mysql-new-connector-and-sql-open-db/</link>
      <pubDate>Tue, 12 Mar 2024 23:07:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2024/03/12/2024-03-12-use-mysql-new-connector-and-sql-open-db/</guid>
      <description>これから新規に書くコードでは mysql.NewConnector と sql.OpenDBを使ったほうが良さそう、という話。
昔からある書き方 go-sql-driver/mysql のDSNを文字列結合で実現するのは意外と大変なので、 某所ではDSN(Data Source Name)の生成を mysql.Config を使って行っています。
// DSNの生成 cfg := mysql.NewConfig() cfg.User = &amp;#34;user&amp;#34; cfg.Passwd = &amp;#34;password&amp;#34; cfg.DBName = &amp;#34;dbname&amp;#34; dsn := cfg.FormatDSN() // 接続 db, err := sql.Open(&amp;#34;mysql&amp;#34;, dsn) if err != nil { panic(err) } 新しい書き方 実はDSNを生成しなくとも、 mysql.Configから *sql.DB を取得できます。
cfg := mysql.NewConfig() cfg.User = &amp;#34;user&amp;#34; cfg.Passwd = &amp;#34;password&amp;#34; cfg.DBName = &amp;#34;dbname&amp;#34; // *mysql.Config を直接渡す conn, err := mysql.NewConnector(cfg) if err != nil { panic(err) } db := sql.</description>
    </item>
    <item>
      <title>GoのMySQLドライバーにBeforeConnectが追加されました</title>
      <link>https://shogo82148.github.io/blog/2024/03/11/2024-03-11-before-connect-of-mysql-driver/</link>
      <pubDate>Mon, 11 Mar 2024 22:47:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2024/03/11/2024-03-11-before-connect-of-mysql-driver/</guid>
      <description>先日 go-sql-driver/mysql v1.8.0 がリリースされ、 いくつかのオプションが追加されました。 その中からひとつ BeforeConnect を紹介したいと思います。
Add BeforeConnect callback to configuration object #1469 何が嬉しいの？ パスワード以外の方法で MySQL にログインするのが簡単になります。
BeforeConnect を使わない従来の方法 たとえば、AWS では IAM 認証を使ってログインする方法を提供しています。 IAM の情報を使って短期間だけ有効なトークンを発行し、そのトークンを使ってログインします。
MariaDB、MySQL、および PostgreSQL の IAM データベース認証 トークンの有効期限は短いので、接続を開始する直前にトークンを発行し接続設定を書き換えなければいけません。 しかし、Go はコネクションプールを採用しているため、実際に接続を開始するタイミングを知るのは意外と難しいです。
頑張ってそれを実現するためにわざわざドライバーを書いたこともありました。
IAM 認証で AWS RDS へ接続する MySQL ドライバを作った shogo82148/rdsmysql BeforeConnect を使った方法 BeforeConnect は、接続を開始する直前に接続設定を書き換える機能です。 shogo82148/rdsmysql を使用せずとも、簡単に IAM 認証を実現できます。
package main import ( &amp;#34;context&amp;#34; &amp;#34;github.com/aws/aws-sdk-go-v2/config&amp;#34; &amp;#34;github.com/aws/aws-sdk-go-v2/feature/rds/auth&amp;#34; &amp;#34;github.com/go-sql-driver/mysql&amp;#34; ) func main() { mycnf := mysql.NewConfig() mycnf.TLSConfig = &amp;#34;true&amp;#34; mycnf.</description>
    </item>
    <item>
      <title>AWS Lambda Function URLsのイベントをnet/httpで扱えるridgenativeとlambtripを書いた</title>
      <link>https://shogo82148.github.io/blog/2024/02/06/2024-02-06-introduce-ridgenative-and-lambtrip/</link>
      <pubDate>Tue, 06 Feb 2024 00:14:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2024/02/06/2024-02-06-introduce-ridgenative-and-lambtrip/</guid>
      <description>AWS Lambda関数をGoの標準ライブラリのインターフェイスに変換するライブラリを作りました。
http.Handler 実装: shogo82148/ridgenative http.RoundTripper 実装: shogo82148/lambtrip ridgenative Lambda Function URLsではリクエストとレスポンスがJSON形式になって渡ってきます。 これらをGo標準ライブラリの net/http.Request と net/http.ResponseWriter で扱えるように書いたアダプターが shogo82148/ridgenativeです。
同じコードをHTTPサーバーやAWS Lambda上で動かす これのうれしいポイントは net/http.Handler の実装をひとつ用意すれば、 普通のHTTPサーバーとしても、AWS Lambda上でも動かすことができるという点です。
たとえば以下のコードは go run main.go のように実行すると、 8080ポート上で動く普通のHTTPサーバーになります。
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;net/http&amp;#34; &amp;#34;github.com/shogo82148/ridgenative&amp;#34; ) func main() { http.HandleFunc(&amp;#34;/hello&amp;#34;, handleRoot) // httpの代わりにridgenativeを呼び出す ridgenative.ListenAndServe(&amp;#34;:8080&amp;#34;, nil) } func handleRoot(w http.ResponseWriter, r *http.Request) { w.Header().Set(&amp;#34;Content-Type&amp;#34;, &amp;#34;text/plain&amp;#34;) fmt.Fprintln(w, &amp;#34;Hello World&amp;#34;) } bootstrap という名前でコンパイルして、zipで固めてアップロードすれば、 Lambda Function URLsやAPI Gatewayで動くHTTP APIの完成です。
GOOS=linux GOARCH=arm64 CGOENABLED=0 go build -o bootstrap main.</description>
    </item>
    <item>
      <title>actions-setup-mysqlとactions-setup-redisがApple M1上で動くようになりました</title>
      <link>https://shogo82148.github.io/blog/2024/02/04/2024-02-04-actions-setup-mysql-and-actions-setup-redis-now-work-on-macos14/</link>
      <pubDate>Sun, 04 Feb 2024 12:35:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2024/02/04/2024-02-04-actions-setup-mysql-and-actions-setup-redis-now-work-on-macos14/</guid>
      <description>GitHub Actions に　Apple Silicon がやってきました！
GitHub Actions: Introducing the new M1 macOS runner available to open source! GitHub Actions: macOS 14 (Sonoma) is now available 先日Perlをビルドして遊んでみました。
actions-setup-perlがApple M1上で動くようになりました 今回はMySQLとRedisをビルドしてみたお話です。
shogo82148/actions-setup-mysql shogo82148/actions-setup-redis actions-setup-mysql v1.31.0, actions-setup-redis リリースのお知らせ actions-setup-mysql v1.31.0, actions-setup-redis v1.33.0 から M1 macOS に対応しています。 runs-on: キーに macos-14 を指定すると M1 を利用できます。
jobs: build: runs-on: macos-14 steps: - uses: actions/checkout@v4 - name: Set up MySQL uses: shogo82148/actions-setup-mysql@v1.31.0 M1による高速化 今日現在（2024-02-04）のMySQL最新安定版リリースは 8.0.36 です。 MySQL 8.</description>
    </item>
    <item>
      <title>actions-setup-perlがApple M1上で動くようになりました</title>
      <link>https://shogo82148.github.io/blog/2024/02/01/2024-02-01-actions-setup-perl-now-works-on-macos14/</link>
      <pubDate>Thu, 01 Feb 2024 20:50:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2024/02/01/2024-02-01-actions-setup-perl-now-works-on-macos14/</guid>
      <description>GitHub Actions に　Apple Silicon がやってきました！
GitHub Actions: Introducing the new M1 macOS runner available to open source! GitHub Actions: macOS 14 (Sonoma) is now available 新しいコンピューティング環境がでてやることといえばアレですよね。 Perlのビルド。 というわけでやっていきましょう。
actions-setup-perl v1.28.0 リリースのお知らせ actions-setup-perl v1.28.0 から M1 macOS に対応しています。 runs-on: キーに macos-14 を指定すると M1 を利用できます。
jobs: build: runs-on: macos-14 steps: - uses: actions/checkout@v4 - name: Set up perl uses: shogo82148/actions-setup-perl@v1.28.0 M1による高速化 今回のリリースにあたり、バージョン違いコンパイルオプション違いの 全148種類 のPerlバイナリを再ビルドしました！ Perl 5.38.2 のビルド時間で比較すると、x64では 11m 27s かかっていたビルドが、M1では 4m 6s へと大きく改善しました。 64.</description>
    </item>
    <item>
      <title>GoでForwarded Headerのパーサーを作った</title>
      <link>https://shogo82148.github.io/blog/2024/01/11/2024-01-11-go-forwarded-header/</link>
      <pubDate>Thu, 11 Jan 2024 23:03:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2024/01/11/2024-01-11-go-forwarded-header/</guid>
      <description>ちょっとした用事で Forwarded ヘッダーの解析をしたくなったので、解析ライブラリを書いてみました。
shogo82148/forwarded-header 背景 Amazon API GatewayのHTTP Proxy Integrationを利用しているプロジェクトで、 クライアントのIPアドレスを知りたい用件がありました。
リバースプロキシの運用に慣れている人なら、「クライアントのIPアドレスを取得したい」と聞いて真っ先に思いつくのは X-Forwarded-For ヘッダーでしょう。 しかし、HTTP Proxy Integrationはこのヘッダーを付与しません。
なんとかIPアドレスを取得できないかと調べてみると、HTTP Proxy IntegrationはForwardedヘッダーを付与することがわかりました。
Amazon API Gateway: Explaining HTTP Proxy in HTTP API Forwardedヘッダーは RFC 7239 で標準化されているヘッダーです。 リバースプロキシによって失われてしまう情報を補完するために利用します。
RFC 7239: Forwarded HTTP Extension RFC 7239: Forwarded HTTP拡張 Forwarded - MDN Forwardedヘッダーを見ればクライアントのIPアドレスもわかります。 たとえば以下の例では 192.0.2.60 がクライアントのIPアドレスです。
Forwarded: for=192.0.2.60; proto=http; by=203.0.113.43 X-Forwarded-Forヘッダーは単純なカンマ区切りのテキストだったので、Split関数で十分でした。 一方Forwardedヘッダーは構造化されているため、パーサーが必要です。 そこまで複雑ではないので、実装してみました。
使い方 解析は Parse関数を呼び出すだけです。
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;net/http&amp;#34; &amp;#34;os&amp;#34; forwardedheader &amp;#34;github.com/shogo82148/forwarded-header&amp;#34; ) func main() { header := make(http.</description>
    </item>
    <item>
      <title>AWS SDK for Go v2にnot found ResolveEndpointV2と起こられたときの解決策</title>
      <link>https://shogo82148.github.io/blog/2024/01/11/2024-01-11-not-found-resolve-endpoint-v2/</link>
      <pubDate>Thu, 11 Jan 2024 15:05:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2024/01/11/2024-01-11-not-found-resolve-endpoint-v2/</guid>
      <description>AWS SDK for Go v2を使っているプロジェクトで、以下のようなエラーが発生しました。
{&amp;#34;time&amp;#34;:&amp;#34;2024-01-09T06:45:00.239872&amp;#34;,&amp;#34;level&amp;#34;:&amp;#34;fatal&amp;#34;,&amp;#34;message&amp;#34;:&amp;#34;not found, ResolveEndpointV2&amp;#34;} 解決策 github.com/aws/aws-sdk-go-v2 名前空間の下にあるモジュールをすべて最新版にアップデートしましょう。
go get -u &amp;#34;github.com/aws/aws-sdk-go-v2/...&amp;#34; 原因 AWS SDK for Go v2 v1.23.0 (2023-11-15) で入った以下の変更が原因です。
Feature: BREAKING CHANGE: V2 endpoint resolution middleware has changed steps from Serialize to Finalize. Middleware that indexes off of this field will need to be updated accordingly.
特徴: 重大な変更: V2エンドポイント解決ミドルウェアは、SerializeからFinalizeへのステップが変更されました。このフィールドをベースにインデックスを付けるミドルウェアは、それに応じて更新する必要があります。（ChatGPTによる和訳）
なんでこんなひどいことするの 😭（1年3か月ぶり、2回目）
前回壊れたとき（参考：AWS SDK v2 for Goが壊れた、Googleお前もか）はコンパイルエラーで気がつけたのですが、今回のエラーは実行してみないとわかりません。 マイナーアップデートで入れるのはやめてくれ・・・。
参考 Release (2023-11-15) [SOLUTION IN THREAD] &amp;ldquo;not found, ResolveEndpointV2&amp;rdquo; service modules released on or after 11/15/23 are incompatible against previous runtimes (and vice versa) #2370 SOLUTIONが書かれたコメント AWS SDK v2 for Goが壊れた、Googleお前もか </description>
    </item>
    <item>
      <title>go-retry v1.2.0 リリースのお知らせ、ジェネリクスがやってきた</title>
      <link>https://shogo82148.github.io/blog/2023/12/29/2023-12-29-go-retry-meets-generics/</link>
      <pubDate>Fri, 29 Dec 2023 22:04:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/12/29/2023-12-29-go-retry-meets-generics/</guid>
      <description>shogo82148/go-retry は指数的バックオフを行ってくれるライブラリです。
Goで指数的バックオフをやってくれるgo-retryを書いた v1.2.0 でジェネリクスを導入した新しいインターフェイスを追加しました。
新インターフェイス Goで指数的バックオフをやってくれるgo-retryを書いたの最後のまとめで、僕らのやりたいことを全部詰め込んだこんなコードを書きました。
func DoSomethingWithRetry(ctx context.Context) (Result, error) { var res Result var err error policy.Do(ctx, func() error { ctx, cancel := context.WithTimeout(ctx, time.Second) defer cancel() res, err = DoSomething(ctx) return err }) return res, err } これが以下のようにちょっとシンプルになります。
func DoSomethingWithRetry(ctx context.Context) (Result, error) { return retry.DoValue(ctx, policy, func() (Result, error) { ctx, cancel := context.WithTimeout(ctx, time.Second) defer cancel() return DoSomething(ctx) }) } math/randの実装変更に合わせた最適化 math/randパッケージ には Int, Intn などトップレベルに関数があります。 Go 1.</description>
    </item>
    <item>
      <title>AWS::LambdaがCanada West (Calgary) Regionで利用可能になりました</title>
      <link>https://shogo82148.github.io/blog/2023/12/29/2023-12-29-p5-aws-lambda-is-available-on-ca-east-1/</link>
      <pubDate>Fri, 29 Dec 2023 16:38:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/12/29/2023-12-29-p5-aws-lambda-is-available-on-ca-east-1/</guid>
      <description>この記事は、Perl Advent Calendar 2023 25日目の記事（代打）です。 24日目は@shogo842148で「PerlにClass構文がやってきた」でした。
AWSでカナダ（カルガリー）リージョンが利用可能になりました！
The AWS Canada West (Calgary) Region is now available それに合わせて p5-aws-lambda のビルド済みレイヤーも公開しました！
Perl本体: arn:aws:lambda:ca-central-1:445285296882:layer:perl-5-38-runtime-al2023-x86_64:3 Paws: arn:aws:lambda:ca-central-1:445285296882:layer:perl-5-38-paws-al2023-x86_64:4 参考 The AWS Canada West (Calgary) Region is now available shogo82148/p5-aws-lambda AWS::Lambda </description>
    </item>
    <item>
      <title>PerlにClass構文がやってきた</title>
      <link>https://shogo82148.github.io/blog/2023/12/29/2023-12-29-perl-class/</link>
      <pubDate>Fri, 29 Dec 2023 16:37:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/12/29/2023-12-29-perl-class/</guid>
      <description>この記事は、Perl Advent Calendar 2023 24日目の記事（代打）です。 23日目は@doikojiで「【さらばpptxよ】perlとJavaScriptとHTMLで超手軽にスライドを作る」でした。
今年のPerlの重大ニュースといえば 「PerlにClass構文がやってきた」 ことですよね[要出典]。 （※ただしExperimental） Advent Calendar でClassをメインに取り上げることなかったなと思ったので、ちょっと触ってみました。
とりあえず動かしてみる perlclassの例です。 警告が出ないように no warnings &#39;experimental::class&#39; で抑制だけしました。
use v5.38; use feature &amp;#39;class&amp;#39;; no warnings &amp;#39;experimental::class&amp;#39;; class My::Example 1.234 { field $x; ADJUST { $x = &amp;#34;Hello, world&amp;#34;; } method print_message { say $x; } } My::Example-&amp;gt;new-&amp;gt;print_message; 実行すると Hello, world と出力されます。
Hello, world newの引数を受け取る My::Example-&amp;gt;new には引数を渡すことができます。 Perl 5.38時点では :param field属性を使って、フィールドを初期化できるようです。
use v5.38; use feature &amp;#39;class&amp;#39;; no warnings &amp;#39;experimental::class&amp;#39;; class My::Example 1.</description>
    </item>
    <item>
      <title>PerlのHTTP::Tinyがv0.083からデフォルトでTLSの証明書を検証するようになった件</title>
      <link>https://shogo82148.github.io/blog/2023/12/27/2023-12-27-perl-http-tiny-now-verify-tls/</link>
      <pubDate>Wed, 27 Dec 2023 00:16:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/12/27/2023-12-27-perl-http-tiny-now-verify-tls/</guid>
      <description>この記事は、Perl Advent Calendar 2023 22日目の記事（代打）です。 21日目は@shogo82148で「5.36以降でのサブルーチンプロトタイプを復習する」でした。
万策尽きたいっちーです。 そういえば今年こんなこともあったなーと思い出したので、メモとして残しておきます。
HTTP::Tiny 0.083からデフォルトでTLSの証明書を検証するようになりました 今年の6月11日リリースの HTTP::Tiny 0.083 からデフォルトで TLSの証明書を検証するようになりました！
検証してみた HTTP::TinyはPerlのコアモジュールに含まれている、超有名HTTPクライアントです。 「えっ、むしろ今まで検証してなかったの？」って思いますよね。
僕もそう思いました。というわけで証明書の検証していないことの検証してみましょう。
まずはお手元に古いHTTP::Tinyを用意します。
cpanm HTTP::Tiny@0.082 検証には不正な証明書を返すサーバーが必要です。 今回は badssl.com を利用しました。 有効期限の切れたサイトへのアクセスを試してみます。
# get.pl use v5.38; use HTTP::Tiny; my $response = HTTP::Tiny-&amp;gt;new-&amp;gt;get(&amp;#39;https://expired.badssl.com/&amp;#39;); die &amp;#34;Failed!\n&amp;#34; unless $response-&amp;gt;{success}; say $response-&amp;gt;{content}; 実行してみると・・・
% perl get.pl &amp;lt;!DOCTYPE html&amp;gt; &amp;lt;html&amp;gt; &amp;lt;head&amp;gt; &amp;lt;meta charset=&amp;#34;utf-8&amp;#34;&amp;gt; &amp;lt;meta name=&amp;#34;viewport&amp;#34; content=&amp;#34;width=device-width, initial-scale=1&amp;#34;&amp;gt; &amp;lt;link rel=&amp;#34;shortcut icon&amp;#34; href=&amp;#34;/icons/favicon-red.ico&amp;#34;/&amp;gt; &amp;lt;link rel=&amp;#34;apple-touch-icon&amp;#34; href=&amp;#34;/icons/icon-red.png&amp;#34;/&amp;gt; &amp;lt;title&amp;gt;expired.badssl.com&amp;lt;/title&amp;gt; &amp;lt;link rel=&amp;#34;stylesheet&amp;#34; href=&amp;#34;/style.css&amp;#34;&amp;gt; &amp;lt;style&amp;gt;body { background: red; }&amp;lt;/style&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;body&amp;gt; &amp;lt;div id=&amp;#34;content&amp;#34;&amp;gt; &amp;lt;h1 style=&amp;#34;font-size: 12vw;&amp;#34;&amp;gt; expired.</description>
    </item>
    <item>
      <title>5.36以降でのサブルーチンプロトタイプを復習する</title>
      <link>https://shogo82148.github.io/blog/2023/12/24/2023-12-24-perl-prototype/</link>
      <pubDate>Sun, 24 Dec 2023 22:13:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/12/24/2023-12-24-perl-prototype/</guid>
      <description>この記事は、Perl Advent Calendar 2023 21日目の記事（代打）です。 20日目は@doikojiで「低レベルperlスクリプトのススメ（その２）」でした。
いよいよネタが尽きて途方にくれているいっちーです。 ネタも尽きてn番煎じな気はしますが、サブルーチンプロトタイプの書き方について復習です。
プロトタイプ サブルーチンプロトタイプとは一言でいうと、引数パーサーの挙動をカスタマイズする仕組みです。 たとえば、Perlの組み込み関数 push は第一引数の配列に要素を追加する関数ですが、 これと同じものを普通は定義できません。
sub my_push { # TODO: 中身を実装する } my @hoge = (1, 2); my_push @hoge, 3, 4, 5; # my_push 1, 2, 3, 4, 5; と配列が展開されてしまって、 `@hoge` にはアクセスできない 「Perlのサブルーチンプロトタイプについて」から自作pushの例を引用します。
sub my_push(\@@){ my ($arr_ref, @arr) = @_; for(@arr){ $$arr_ref[$#$arr_ref+1] = $_; } } my @hoge = (1, 2); my_push @hoge, 3, 4, 5; # my_push \@hoge, 3, 4, 5; と解釈される Perl 5.</description>
    </item>
    <item>
      <title>Perlで超簡易アセンブラーを書いた話</title>
      <link>https://shogo82148.github.io/blog/2023/12/21/2023-12-21-perl-asm/</link>
      <pubDate>Thu, 21 Dec 2023 00:57:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/12/21/2023-12-21-perl-asm/</guid>
      <description>この記事は、Perl Advent Calendar 2023 18日目の記事（代打）です。 17日目は@tecklで「Perlのレガシーシステムを少し更新した話」でした。
背景 最小のELFを作る記事を見かけて、「自分もやってみよう！」と思ってやってみました。
最小限のELF ただ、僕はバイナリーエディターとはあまりお友達になれていないので、 ELFを出力するPerlスクリプトを書くことにしました。 そうしたらPerl製のアセンブラーっぽいものができた、というお話です。
shogo82148/minimum-elf Minimum ELF ELFとして実行できるだけの必要最低限の機能しか実装していないので、 プログラムの終了処理を書く以外、大したことはできません。 それでも実行可能なバイナリーを吐くので、 「これはアセンブラーだ！」 と言い張ることにします。
完成したELFファイルはDockerイメージに焼き込み、 GitHub Container Registry にあげてあるので、 docker pull で完成品をダウンロードできます。
$ docker pull ghcr.io/shogo82148/minimum-elf:latest $ docker images ghcr.io/shogo82148/minimum-elf:latest REPOSITORY TAG IMAGE ID CREATED SIZE ghcr.io/shogo82148/minimum-elf latest cd926faef0a2 13 days ago 188B わずか188バイト！
もちろん docker run で実行できます。 x86_64, arm64 どちらでも動くはずです。
実装 NASM っぽい構文を PerlのDSLとして実装し、ELFファイルを書き出しています。 たとえばELFのヘッダーを書き出す部分は以下のようになっています。
label($elf_start); my $elf_size = $elf_end - $elf_start; db 0x7F, &amp;#34;ELF&amp;#34;; # e_ident db 2; # 64-bit architecture.</description>
    </item>
    <item>
      <title>PythonのitertoolsをGoに移植してみた</title>
      <link>https://shogo82148.github.io/blog/2023/12/19/2023-12-19-itertools-on-golang/</link>
      <pubDate>Tue, 19 Dec 2023 00:57:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/12/19/2023-12-19-itertools-on-golang/</guid>
      <description>Go 1.22 に試験的に導入される予定の range over func で遊んでみました。 お題はPythonのitertoolsの移植です。
shogo82148/hi 背景 Go 1.22 では range over func と呼ばれる機能が試験的に導入されます。
spec: add range over int, range over func #61405 range over func が導入される背景については以下の記事がわかりやすかったです。
Go 1.22で追加予定のrange over intと、GOEXPERIMENT入り予定のrange over funcを触ってみる 大雑把にまとめると「Goにもイテレーターの標準を導入しよう」という話です。
Pythonを触っていた時期もあったので、自分はイテレーターと聞いて itertools がパッと思い浮かびました。 ということでこれを題材に遊んでみることにしました。
動かし方 2023-12-19現在、Go 1.22は未リリースなので、試すにはいくつか手順が必要です。
まずはGo本体。masterブランチの最新版をダウンロードしましょう。
go install golang.org/dl/gotip@latest gotip download shogo82148/hi はみんなに使ってほしいので、 Go 1.21で動くようになっています。 そのため、そのままでは Go 1.22 の最新機能が使えません。go.mod ファイルの go ディレクティブを書き換える必要があります。 さらに実験的機能を使っているので、実行には GOEXPERIMENT=rangefunc 環境変数が必要です。
git clone git@github.com:shogo82148/hi.git cd hi gotip mod edit -go=1.</description>
    </item>
    <item>
      <title>Perl 5.38 の「シグネチャのデフォルト式の定義性論理和と論理和」を試してみた</title>
      <link>https://shogo82148.github.io/blog/2023/12/12/2023-12-12-or-assignment-default-expressions-in-signatures/</link>
      <pubDate>Tue, 12 Dec 2023 21:55:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/12/12/2023-12-12-or-assignment-default-expressions-in-signatures/</guid>
      <description>この記事は、Perl Advent Calendar 2023 12日目の記事です。 11日目は@shogo82148で「ExifToolがすごいという話」でした。
アドベントカレンダーのネタを探してperldeltaをさまよい歩くいっちーです。
Perl 5.38.0 から、「シグネチャーのデフォルト式に定義性論理和と論理和が使えるようになった」という記載を見つけたので試してみます。
定義性論理和と論理和 「定義性論理和と論理和」と聞いてもピンとこなかったので、一応おさらい。 いわゆる // 演算子と || 演算子のことです（発音できない）。 英語で defined-or, logical-or と言ったほうが馴染み深い人も多いかもしれません。
「定義性論理和」の和訳は &amp;lt;perldoc.jp&amp;gt; を参考にしました。 perlop の担当をしたひとも 日本訳に相当苦労したことでしょう・・・。
論理和 論理和はどちらか一方が真ならば真を、それ以外の場合は偽を返す演算子です。 これは他のプログラミング言語と同じなので、みなさんおなじみだと思います。
Perlがおもしろいのは true, false というキーワードが（まだ）ないということですね。 0, &amp;quot;0&amp;quot;, undef は真、それ以外はすべて偽として認識されます。
true, false の代わりに 1, 0 を使って、 || の挙動を確かめてみましょう。
use 5.38.0; say 0 || 0; # 0 say 0 || 1; # 1 say 1 || 0; # 1 say 1 || 1; # 1 論理和の短絡評価 || 演算子は短絡評価を行います。 たとえば 1 || $a という式があったら、$a にどんな値が入っていても真なので、$aの評価を行いません。</description>
    </item>
    <item>
      <title>ExifToolがすごいという話</title>
      <link>https://shogo82148.github.io/blog/2023/12/11/2023-12-11-introduce-exiftool/</link>
      <pubDate>Mon, 11 Dec 2023 21:20:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/12/11/2023-12-11-introduce-exiftool/</guid>
      <description>この記事は、Perl Advent Calendar 2023 11日目の記事です。 10日目はid:papixで「Perlの｢後置if｣について」でした。
ふと「Exifの中身を確認したいな」と思ったときに ExifToolというツールの存在を知りました。 これがなかなか便利だったので紹介します。
Exif Exifは画像のメタデータのデファクトスタンダードです。 みなさんがスマホで撮った写真にはたいていExifが埋め込まれています。 「何時何分に撮ったか」という情報はもちろん、F値やシャッタースピードなどの細かい撮影条件などが含まれています。
一番注意が必要なのは「位置情報」ですね。今どきのスマホにはGPSが積まれているので、かなり正確な位置情報がExifに記録されます。 SNSなどに公開するときは要注意です。 事前にどんな情報が書き込まれているかチェックするべきでしょう。
そんなとき活躍するのがExifTool。 Exifを確認したり編集したりするためのツールです。
ExifToolはPerl製！！ なぜPerlアドベントカレンダーでExifToolを取り上げるかというと、ExifToolはPerl製 なんですね。
CPANにも上がっているので、cpanm でインストール可能です。
cpanm Image::ExifTool exiftool というコマンドがインストールされるので、適当な画像ファイルを渡すとメタデータを解析してくれます。 試しに 今年もアドベントカレンダー（物理）買いました で撮影した画像を読み込ませてみます。
$ exiftool 2023-12-06-advent-calendar1.jpeg ExifTool Version Number : 12.70 File Name : 2023-12-06-advent-calendar1.jpeg Directory : . File Size : 191 kB File Modification Date/Time : 2023:12:06 21:56:11+09:00 File Access Date/Time : 2023:12:06 21:56:18+09:00 File Inode Change Date/Time : 2023:12:06 21:56:17+09:00 File Permissions : -rw------- File Type : JPEG File Type Extension : jpg MIME Type : image/jpeg JFIF Version : 1.</description>
    </item>
    <item>
      <title>今年もアドベントカレンダー（物理）買いました</title>
      <link>https://shogo82148.github.io/blog/2023/12/06/2023-12-06-advent-calendar/</link>
      <pubDate>Wed, 06 Dec 2023 10:52:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/12/06/2023-12-06-advent-calendar/</guid>
      <description>この記事は、フラー株式会社 Advent Calendar 2023 の6日目の記事です。
さて、昨年は「ラバーダックデバッグのすゝめ」と題して、 アヒルちゃんアドベントカレンダー（物理）を買いました。
ところでそもそもアドベントカレンダーって何だか知ってますか？ エンジニアが日替わりでブログを書くイベント・・・ではありません。 クリスマスまでの日数をカウントダウンする「アドベントカレンダー（物理）」が元ネタです。 カレンダーの日付部分が蓋になっていて、開けるとお菓子やおもちゃなどが出てくる仕掛けになっています。 クリスマスを待ちきれない子供がクリスマスまでの期間を楽しむためのアイテムなのです。
インターネットではお菓子やおもちゃは配れないので、代わりにブログ記事を投稿するようになったのが、 今のアドベントカレンダーの始まりです。
でもやっぱり（物理）欲しくないですか？？？？ というわけで買っちゃいました！
しかし、中途半端に安物を買ったせいで、届いたカレンダーは梱包が雑！配送中にどこかにぶつかったのかボロボロになった状態で届きました。ネット通販で買い物すると「これって過剰包装では？」というような梱包で届きますが、あれにはちゃんと意味があったんですね。
去年の記事のまとめでは、「TODO: 来年はもうちょっと良いやつを買う」と誓ったのでした。
そしてやってきました 2023年。 紙製のアドベントカレンダーはボロボロになると学んだので、MDF（木材を合成樹脂で固めたもの）製のアドベントカレンダーにしました。
本の形になっていて、開けるとカレンダーが現れます。
何が出てくるかは開けてからのお楽しみ！ 引き出しを開けた後は裏返しにして戻してください。 おしゃれなイラストがクリスマスの雰囲気を盛り上げてくれます。
明日7日は @kod-sourceで「SQLアンチパターンの本を読んだので、アウトプットする」です。お楽しみに！
参考 ツクロウ 木製ブック型アドベントカレンダー クリスマス カウントダウン アドベントカレンダー プレゼント </description>
    </item>
    <item>
      <title>Amazon Linux 2023ベースのAWS Lambda Perl Runtimeを公開しました</title>
      <link>https://shogo82148.github.io/blog/2023/12/05/2023-12-05-al2023-based-perl-runtime-is-available/</link>
      <pubDate>Tue, 05 Dec 2023 21:00:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/12/05/2023-12-05-al2023-based-perl-runtime-is-available/</guid>
      <description>この記事は、Perl Advent Calendar 2023 5日目の記事です。 4日目は@doikojiで「ChatGPTとperl：古のCGIスクリプトを現代的な環境に合わせて再生させようとした話」でした。
AWS LambdaにAmazon Linux 2023ベースのカスタムランタイムが追加されました。 これはつまり・・・
Perlを…ビルドせねば…https://t.co/akYtrs3qXM
&amp;mdash; f96fd3a0-bdb9-4f10-b69f-8f765c1d341c ICHINOSEShogo (@shogo82148) November 10, 2023 ということでPerlをビルドしました。
AWS::Lambda v0.4.1 使い方はPerl Hackers Hubをどうぞ。
Perl Hackers Hub 第75回 AWS Lambda入門 サーバレスでもPerlを活用しよう！（1） Perl Hackers Hub 第75回 AWS Lambda入門 サーバレスでもPerlを活用しよう！（2） ビルド済み公開 Perl Runtime Layer いつも通りビルド済みのレイヤーを公開しています。
x86_64 architecture arn:aws:lambda:af-south-1:445285296882:layer:perl-5-38-runtime-al2023-x86_64:2 arn:aws:lambda:ap-east-1:445285296882:layer:perl-5-38-runtime-al2023-x86_64:2 arn:aws:lambda:ap-northeast-1:445285296882:layer:perl-5-38-runtime-al2023-x86_64:2 arn:aws:lambda:ap-northeast-2:445285296882:layer:perl-5-38-runtime-al2023-x86_64:2 arn:aws:lambda:ap-northeast-3:445285296882:layer:perl-5-38-runtime-al2023-x86_64:2 arn:aws:lambda:ap-south-1:445285296882:layer:perl-5-38-runtime-al2023-x86_64:2 arn:aws:lambda:ap-south-2:445285296882:layer:perl-5-38-runtime-al2023-x86_64:2 arn:aws:lambda:ap-southeast-1:445285296882:layer:perl-5-38-runtime-al2023-x86_64:2 arn:aws:lambda:ap-southeast-2:445285296882:layer:perl-5-38-runtime-al2023-x86_64:2 arn:aws:lambda:ap-southeast-3:445285296882:layer:perl-5-38-runtime-al2023-x86_64:2 arn:aws:lambda:ap-southeast-4:445285296882:layer:perl-5-38-runtime-al2023-x86_64:2 arn:aws:lambda:ca-central-1:445285296882:layer:perl-5-38-runtime-al2023-x86_64:2 arn:aws:lambda:eu-central-1:445285296882:layer:perl-5-38-runtime-al2023-x86_64:2 arn:aws:lambda:eu-central-2:445285296882:layer:perl-5-38-runtime-al2023-x86_64:2 arn:aws:lambda:eu-north-1:445285296882:layer:perl-5-38-runtime-al2023-x86_64:2 arn:aws:lambda:eu-south-1:445285296882:layer:perl-5-38-runtime-al2023-x86_64:2 arn:aws:lambda:eu-south-2:445285296882:layer:perl-5-38-runtime-al2023-x86_64:2 arn:aws:lambda:eu-west-1:445285296882:layer:perl-5-38-runtime-al2023-x86_64:2 arn:aws:lambda:eu-west-2:445285296882:layer:perl-5-38-runtime-al2023-x86_64:2 arn:aws:lambda:eu-west-3:445285296882:layer:perl-5-38-runtime-al2023-x86_64:2 arn:aws:lambda:il-central-1:445285296882:layer:perl-5-38-runtime-al2023-x86_64:2 arn:aws:lambda:me-central-1:445285296882:layer:perl-5-38-runtime-al2023-x86_64:2 arn:aws:lambda:me-south-1:445285296882:layer:perl-5-38-runtime-al2023-x86_64:2 arn:aws:lambda:sa-east-1:445285296882:layer:perl-5-38-runtime-al2023-x86_64:2 arn:aws:lambda:us-east-1:445285296882:layer:perl-5-38-runtime-al2023-x86_64:2 arn:aws:lambda:us-east-2:445285296882:layer:perl-5-38-runtime-al2023-x86_64:2 arn:aws:lambda:us-west-1:445285296882:layer:perl-5-38-runtime-al2023-x86_64:2 arn:aws:lambda:us-west-2:445285296882:layer:perl-5-38-runtime-al2023-x86_64:2 arm64 architecture arn:aws:lambda:af-south-1:445285296882:layer:perl-5-38-runtime-al2023-arm64:2 arn:aws:lambda:ap-east-1:445285296882:layer:perl-5-38-runtime-al2023-arm64:2 arn:aws:lambda:ap-northeast-1:445285296882:layer:perl-5-38-runtime-al2023-arm64:2 arn:aws:lambda:ap-northeast-2:445285296882:layer:perl-5-38-runtime-al2023-arm64:2 arn:aws:lambda:ap-northeast-3:445285296882:layer:perl-5-38-runtime-al2023-arm64:2 arn:aws:lambda:ap-south-1:445285296882:layer:perl-5-38-runtime-al2023-arm64:2 arn:aws:lambda:ap-south-2:445285296882:layer:perl-5-38-runtime-al2023-arm64:2 arn:aws:lambda:ap-southeast-1:445285296882:layer:perl-5-38-runtime-al2023-arm64:2 arn:aws:lambda:ap-southeast-2:445285296882:layer:perl-5-38-runtime-al2023-arm64:2 arn:aws:lambda:ap-southeast-3:445285296882:layer:perl-5-38-runtime-al2023-arm64:2 arn:aws:lambda:ap-southeast-4:445285296882:layer:perl-5-38-runtime-al2023-arm64:2 arn:aws:lambda:ca-central-1:445285296882:layer:perl-5-38-runtime-al2023-arm64:2 arn:aws:lambda:eu-central-1:445285296882:layer:perl-5-38-runtime-al2023-arm64:2 arn:aws:lambda:eu-central-2:445285296882:layer:perl-5-38-runtime-al2023-arm64:2 arn:aws:lambda:eu-north-1:445285296882:layer:perl-5-38-runtime-al2023-arm64:2 arn:aws:lambda:eu-south-1:445285296882:layer:perl-5-38-runtime-al2023-arm64:2 arn:aws:lambda:eu-south-2:445285296882:layer:perl-5-38-runtime-al2023-arm64:2 arn:aws:lambda:eu-west-1:445285296882:layer:perl-5-38-runtime-al2023-arm64:2 arn:aws:lambda:eu-west-2:445285296882:layer:perl-5-38-runtime-al2023-arm64:2 arn:aws:lambda:eu-west-3:445285296882:layer:perl-5-38-runtime-al2023-arm64:2 arn:aws:lambda:il-central-1:445285296882:layer:perl-5-38-runtime-al2023-arm64:2 arn:aws:lambda:me-central-1:445285296882:layer:perl-5-38-runtime-al2023-arm64:2 arn:aws:lambda:me-south-1:445285296882:layer:perl-5-38-runtime-al2023-arm64:2 arn:aws:lambda:sa-east-1:445285296882:layer:perl-5-38-runtime-al2023-arm64:2 arn:aws:lambda:us-east-1:445285296882:layer:perl-5-38-runtime-al2023-arm64:2 arn:aws:lambda:us-east-2:445285296882:layer:perl-5-38-runtime-al2023-arm64:2 arn:aws:lambda:us-west-1:445285296882:layer:perl-5-38-runtime-al2023-arm64:2 arn:aws:lambda:us-west-2:445285296882:layer:perl-5-38-runtime-al2023-arm64:2 ビルド済み公開 Paws Layer x86_64 architecture arn:aws:lambda:af-south-1:445285296882:layer:perl-5-38-runtime-paws-x86_64:3 arn:aws:lambda:ap-east-1:445285296882:layer:perl-5-38-runtime-paws-x86_64:3 arn:aws:lambda:ap-northeast-1:445285296882:layer:perl-5-38-runtime-paws-x86_64:3 arn:aws:lambda:ap-northeast-2:445285296882:layer:perl-5-38-runtime-paws-x86_64:3 arn:aws:lambda:ap-northeast-3:445285296882:layer:perl-5-38-runtime-paws-x86_64:3 arn:aws:lambda:ap-south-1:445285296882:layer:perl-5-38-runtime-paws-x86_64:3 arn:aws:lambda:ap-south-2:445285296882:layer:perl-5-38-runtime-paws-x86_64:3 arn:aws:lambda:ap-southeast-1:445285296882:layer:perl-5-38-runtime-paws-x86_64:3 arn:aws:lambda:ap-southeast-2:445285296882:layer:perl-5-38-runtime-paws-x86_64:3 arn:aws:lambda:ap-southeast-3:445285296882:layer:perl-5-38-runtime-paws-x86_64:3 arn:aws:lambda:ap-southeast-4:445285296882:layer:perl-5-38-runtime-paws-x86_64:3 arn:aws:lambda:ca-central-1:445285296882:layer:perl-5-38-runtime-paws-x86_64:3 arn:aws:lambda:eu-central-1:445285296882:layer:perl-5-38-runtime-paws-x86_64:3 arn:aws:lambda:eu-central-2:445285296882:layer:perl-5-38-runtime-paws-x86_64:3 arn:aws:lambda:eu-north-1:445285296882:layer:perl-5-38-runtime-paws-x86_64:3 arn:aws:lambda:eu-south-1:445285296882:layer:perl-5-38-runtime-paws-x86_64:3 arn:aws:lambda:eu-south-2:445285296882:layer:perl-5-38-runtime-paws-x86_64:3 arn:aws:lambda:eu-west-1:445285296882:layer:perl-5-38-runtime-paws-x86_64:3 arn:aws:lambda:eu-west-2:445285296882:layer:perl-5-38-runtime-paws-x86_64:3 arn:aws:lambda:eu-west-3:445285296882:layer:perl-5-38-runtime-paws-x86_64:3 arn:aws:lambda:il-central-1:445285296882:layer:perl-5-38-runtime-paws-x86_64:3 arn:aws:lambda:me-central-1:445285296882:layer:perl-5-38-runtime-paws-x86_64:3 arn:aws:lambda:me-south-1:445285296882:layer:perl-5-38-runtime-paws-x86_64:3 arn:aws:lambda:sa-east-1:445285296882:layer:perl-5-38-runtime-paws-x86_64:3 arn:aws:lambda:us-east-1:445285296882:layer:perl-5-38-runtime-paws-x86_64:3 arn:aws:lambda:us-east-2:445285296882:layer:perl-5-38-runtime-paws-x86_64:3 arn:aws:lambda:us-west-1:445285296882:layer:perl-5-38-runtime-paws-x86_64:3 arn:aws:lambda:us-west-2:445285296882:layer:perl-5-38-runtime-paws-x86_64:3 arm64 architecture arn:aws:lambda:af-south-1:445285296882:layer:perl-5-38-runtime-paws-arm64:1 arn:aws:lambda:ap-east-1:445285296882:layer:perl-5-38-runtime-paws-arm64:1 arn:aws:lambda:ap-northeast-1:445285296882:layer:perl-5-38-runtime-paws-arm64:1 arn:aws:lambda:ap-northeast-2:445285296882:layer:perl-5-38-runtime-paws-arm64:1 arn:aws:lambda:ap-northeast-3:445285296882:layer:perl-5-38-runtime-paws-arm64:1 arn:aws:lambda:ap-south-1:445285296882:layer:perl-5-38-runtime-paws-arm64:1 arn:aws:lambda:ap-south-2:445285296882:layer:perl-5-38-runtime-paws-arm64:1 arn:aws:lambda:ap-southeast-1:445285296882:layer:perl-5-38-runtime-paws-arm64:1 arn:aws:lambda:ap-southeast-2:445285296882:layer:perl-5-38-runtime-paws-arm64:1 arn:aws:lambda:ap-southeast-3:445285296882:layer:perl-5-38-runtime-paws-arm64:1 arn:aws:lambda:ap-southeast-4:445285296882:layer:perl-5-38-runtime-paws-arm64:1 arn:aws:lambda:ca-central-1:445285296882:layer:perl-5-38-runtime-paws-arm64:1 arn:aws:lambda:eu-central-1:445285296882:layer:perl-5-38-runtime-paws-arm64:1 arn:aws:lambda:eu-central-2:445285296882:layer:perl-5-38-runtime-paws-arm64:1 arn:aws:lambda:eu-north-1:445285296882:layer:perl-5-38-runtime-paws-arm64:1 arn:aws:lambda:eu-south-1:445285296882:layer:perl-5-38-runtime-paws-arm64:1 arn:aws:lambda:eu-south-2:445285296882:layer:perl-5-38-runtime-paws-arm64:1 arn:aws:lambda:eu-west-1:445285296882:layer:perl-5-38-runtime-paws-arm64:1 arn:aws:lambda:eu-west-2:445285296882:layer:perl-5-38-runtime-paws-arm64:1 arn:aws:lambda:eu-west-3:445285296882:layer:perl-5-38-runtime-paws-arm64:1 arn:aws:lambda:il-central-1:445285296882:layer:perl-5-38-runtime-paws-arm64:1 arn:aws:lambda:me-central-1:445285296882:layer:perl-5-38-runtime-paws-arm64:1 arn:aws:lambda:me-south-1:445285296882:layer:perl-5-38-runtime-paws-arm64:1 arn:aws:lambda:sa-east-1:445285296882:layer:perl-5-38-runtime-paws-arm64:1 arn:aws:lambda:us-east-1:445285296882:layer:perl-5-38-runtime-paws-arm64:1 arn:aws:lambda:us-east-2:445285296882:layer:perl-5-38-runtime-paws-arm64:1 arn:aws:lambda:us-west-1:445285296882:layer:perl-5-38-runtime-paws-arm64:1 arn:aws:lambda:us-west-2:445285296882:layer:perl-5-38-runtime-paws-arm64:1 al2023の注意点 詳細は公式のアナウンスを確認してほしいのですが、al2023ランタイムを使うに当たっていくつか注意点があります。</description>
    </item>
    <item>
      <title>URL圧縮サイトを作ってみた</title>
      <link>https://shogo82148.github.io/blog/2023/11/18/2023-11-18-url-compressor-for-qr-code/</link>
      <pubDate>Sat, 18 Nov 2023 17:11:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/11/18/2023-11-18-url-compressor-for-qr-code/</guid>
      <description>QRコードへの埋め込みを前提としたURLの圧縮サービスを作ってみました。
https://c.shogo82148.com/ ソースコードはこちら。
https://github.com/shogo82148/url-compressor 背景 短縮URLを利用している企業から「短縮URLから不正サイトへ誘導される」として注意喚起のお知らせがありました。
「いなげや」QRコードから不正サイトに誘導、カード情報抜き取られる被害 原因は「短縮URL」か？　QRコードから不正サイトへ誘導される事例が相次ぐ　オートバックスセブン、学習院大学も 短縮URLサービス利用時に表示された悪質な広告についてまとめてみた QRコードに短縮URLが使われるのは、以下のような理由からバージョン（QRコードの大きさの）の小さいQRコードの需要があるためです。
QRコードの印刷品質や読み取り性能が低くても、確実に読み取れるようにしたい 流入元計測のための情報をURLに載せるため、URLは長くなりがち 一方で短縮URLには以下のような問題が指摘されています。
短縮URLだけではどこに飛ぶかわからない 短縮URLのサービス終了してしまうと、リンク切れになる 目的 「元のURLの情報を圧縮してURLに詰め込めばすべて解決するのでは？」と考えて作ってみました。
名付けて 「圧縮URL」 。 以下の特徴を持ったURLの作成を目的とします。
QRコードでの共有に特化する 短縮URL自体から情報を取り出せる 短縮URLのサービスが終了しても、元のURLがわかるので安心 デモ 僕のブログ記事の中でももっとも長い、以下のURLを圧縮してみます。
https://shogo82148.github.io/blog/2023/07/02/2023-07-02-update-aws-sdk-v2-with-grouped-version-updates-for-dependabot/ 圧縮すると以下のようになります。
HTTPS://C.SHOGO82148.COM/0-SLNDB9IQ9IIU.HOR1NB0QGEF7$F2QD2$9V8ONQ9V:U.D-NQ.EVYALL.H74.HID9DLHT2QV5RHV-5P-CFW7.H.DF5NU1U5M30C.AF.CP7.C.A1QXA4-DU5 Google Chart APIを使って、それぞれURLをQRコードに変換してみます。
圧縮前： 圧縮後： 小さなバージョン（QRコードの大きさ）のQRコードが生成されたのがわかると思います。
変換方法 変換方法を見ていきましょう。この手順にしたがって変換すれば、オフラインでも圧縮URLを作成できます。
例として https://example.com を圧縮します。
プロトコル部分を取り除く URLにはかならず https:// か http:// が付きます。 7〜8バイトを使うのは大きなオーバーヘッドです。
今どきHTTPS通信は当たり前なので https:// 以外は対応しないこととし、 先頭の https:// は削除します。
https://example.com → example.com ハフマン符号化を行う ハフマン符号化を使って、ビット列に符号化します。 ハフマン符号化のテーブルはちょっと長いので、付録Aとして記事の末尾に記載しました。
e: 0011 x: 100001101 a: 0000 m: 00100 p: 100110 l: 01011 e: 0011 .</description>
    </item>
    <item>
      <title>Amazon Linux 2023でMySQLをパッケージングする</title>
      <link>https://shogo82148.github.io/blog/2023/11/09/2023-11-09-build-mysql-rpm/</link>
      <pubDate>Thu, 09 Nov 2023 21:00:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/11/09/2023-11-09-build-mysql-rpm/</guid>
      <description>Amazon Linux 2023でMySQLをビルドして、RPMとしてパッケージングしたというお話です。
shogo82148/mysql-rpm-for-amazonlinux2023 背景 普段僕はAWS上での開発をメインにしているため、いろいろな場面でAmazon Linux 2023のお世話になります。 「サーバーレス」「NoSQL」なんて言葉を聞くようになって久しいですが、なんだかんだ言って踏み台サーバーのLinux環境からMySQLに接続することが多いです。
さて、そうなると問題になってくるのが「どうやってAmazon Linux 2023にMySQLをインストールするか」です。
MySQLのビルド済みのバイナリはMySQL Community DownloadsでYUMレポジトリが提供されています。 しかし、2023-11-09現在提供されているのはOracle Linux 9, 8, 7, 6、Fedora 39, 38, 37 です。 Amazon Linux向けには提供されていません。
Amazon Linux 2 ではEPEL(Extra Packages for Enterprise Linux)パッケージが提供されており、 MySQLはEPELがインストールできました。 しかしAmazon Linux 2023ではEPELのサポートはありません。
Amazon Linux 2023はFedoraベースであることが明言されていますが、 その一方で「特定のFedoraのリリースと互換性がある、というわけではない」とも説明されています。
Relationship to Fedora The Generally Available (GA) version of AL2023 isn&amp;rsquo;t directly comparable to any specific Fedora release. The AL2023 GA version includes components from Fedora 34, 35, and 36.</description>
    </item>
    <item>
      <title>1Passwordで管理しているシークレットを各種サービスに同期するプログラムを書いた</title>
      <link>https://shogo82148.github.io/blog/2023/10/21/2023-10-21-op-sync/</link>
      <pubDate>Sat, 21 Oct 2023 17:44:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/10/21/2023-10-21-op-sync/</guid>
      <description>弊社では各種シークレットは1Passwordで管理しています。 シークレットの棚卸し作業をしていて不便を感じたので、 1Passwordで管理しているシークレットを各種サービスに同期するプログラムを書いてみました。
shogo82148/op-sync 背景 何が困るって、シークレットの出処がわからないこと。
たとえばCI/CDサービスのシークレット管理機能にシークレットが登録されている場合、 ヒントが FIREBASE_SECRET という名前だけ、ということがよくあります。 このヒントだけだと、Firebaseで使われていそうなのはわかる・・・でもFirebaseのプロジェクトたくさんあるんだよな、どれだろう・・・ってなります。 プロジェクト名やサービスアカウント名までわからないと、シークレットの出処を特定できません。
1Passwordにはシークレットの出処をメモとして残しておけるので、 せめて「このシークレットは、1Passwordのこの項目と対応しています」という情報が分かれば特定が簡単になります。
「シークレットと1Passwordの項目の対応付け」、ちょっとしたテキストを書くだけで十分なんですが、それができないのが人間というもの・・・。 そこでさらに推し進めて「シークレットと1Passwordの項目の対応付け」を機械可読な形式にして、「1Passwordの項目からシークレットの自動反映」を行います。 普段から自動反映する習慣をつけておけば、対応付けが漏れる心配はありません。
使い方 1Passwordとの連携には1Password CLIを使用しています。 あらかじめインストールしておいてください。
シークレットをファイルに書き出す Private Vaultに入っている、Testという名前のアイテムを読み出す設定例です。
# .op-sync.yml secrets: MyPassword: type: template output: .envrc template: | MY_PASSWORD={{ op://Private/Test/password }} 1Password CLIでサインインして、 op-sync コマンドを叩けば 1Password からパスワードを引っ張ってきてファイルに書き出してくれます。
$ eval $(op signin) Enter the password for shogo82148@gmail.com at my.1password.com: $ op-sync 2023/10/21 16:58:32 INFO 1password user information url=https://my.1password.com email=shogo82148@gmail.com The following changes will be applied: file &amp;#34;.</description>
    </item>
    <item>
      <title>半精度浮動小数点数をあつかうGoのライブラリを書いた</title>
      <link>https://shogo82148.github.io/blog/2023/10/15/2023-10-15-float16/</link>
      <pubDate>Sun, 15 Oct 2023 23:32:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/10/15/2023-10-15-float16/</guid>
      <description>半精度浮動小数点数をあつかうGoのライブラリを書いてみました。
shogo82148/float16 背景 なぜ書いたかというと、半精度浮動小数点数について勉強するためです。
最近のAIブームでビット数の少ない浮動小数点数が注目されていて興味を持ったため 最近の研究で、有効桁数はそこまで重要でないことがわかってきた パラメーターの数が膨大なので、少しでもモデルを圧縮したい CBORの実装読んでいたら、仕様の一部に半精度浮動小数点数が出てきたため 使い方 FromFloat64で倍精度浮動小数点型から半精度浮動小数点数へ変換できます。
import &amp;#34;github.com/shogo82148/float16&amp;#34; func main() { a := float16.FromFloat64(1.0) fmt.Printf(&amp;#34;%04x&amp;#34;, a.Bits()) } Float16.Bitsで内部表現を取得できるので、 この結果をシリアライズに使うのが主な使い方になると思います。
一応四則演算も実装してあります。
import &amp;#34;github.com/shogo82148/float16&amp;#34; func main() { a := float16.FromFloat64(1.0) b := float16.FromFloat64(2.0) fmt.Printf(&amp;#34;%f + %f = %f&amp;#34;, a.Add(b)) fmt.Printf(&amp;#34;%f - %f = %f&amp;#34;, a.Sub(b)) fmt.Printf(&amp;#34;%f * %f = %f&amp;#34;, a.Mul(b)) fmt.Printf(&amp;#34;%f / %f = %f&amp;#34;, a.Div(b)) } ただし（自分で書いておいてなんですが）あまり実用性はないです。 というのも半精度浮動小数点数同士の演算結果は float64 型で正確に表現できます。 そのため float64 型で計算したあと半精度浮動小数点数に戻せば、まったく同じ計算ができます。
import &amp;#34;github.com/shogo82148/float16&amp;#34; func main() { a := float16.</description>
    </item>
    <item>
      <title>Slack Incoming Webhook を GitHub Actions Secrets へ突っ込むのに疲れた俺達は</title>
      <link>https://shogo82148.github.io/blog/2023/10/01/2023-10-01-github-actions-notify-slack/</link>
      <pubDate>Sun, 01 Oct 2023 00:05:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/10/01/2023-10-01-github-actions-notify-slack/</guid>
      <description>GitHub ActionsからSlackへ通知したいとき、一番お手軽なのはSlack Incoming Webhookです。 直接curlで叩いてもいいですし、マーケットプレイスにも通知用のアクションがたくさんあります。
しかし、Incoming Webhookは一般公開してはいけないシークレットです。 迂闊にレポジトリにコミットしてはいけません。 GitHub Actions Secrets へ突っ込む等して、適切に管理する必要があります。 一個や二個ならまだしも、いくつもレポジトリがあると管理が大変です。
そういうわけで、OIDCを使ってSlackへの通知を行うアクションを書きました。
actions-notify-slack 使い方 gha-notify.shogo82148.com へアクセスします。 「Add to Slack」をクリックして、アプリをSlackにインストールします。 @actions-notify-slack というボットが追加されるので、こいつを通知を流したいチャンネルに招待します。 投稿先のチャンネルで /gha-notify allow ORG/REPO スラッシュコマンドを実行します。これにより ORG/REPO からの投稿が許可されます。 ワークフローにアクションを追加して完成！　- uses: shogo82148/actions-notify-slack@v0 with: team-id: T3G1HAY66 # 自分のチームIDに置き換え channel-id: C3GMGG162 # 自分のチャンネルIDに置き換え payload: &amp;#39;{&amp;#34;text&amp;#34;: &amp;#34;hello world&amp;#34;}&amp;#39; 仕組み 早い話が、過去 GitHub や AWS 向けに作ったアクションを Slack 向けに焼き直したものです。
actions-github-app-tokenの紹介 AWS_SECRET_ACCESS_KEY を GitHub Actions secrets へ突っ込むのに疲れた俺達は GitHub Actions は直接 Slack とやり取りするかわりに、中継サーバーにリクエストを投げます。 中継サーバーは、OIDC ID Tokenを検証し、Slackへの投稿権限をチェックします。 権限を確認できたら、ボットユーザーとして投稿する、という流れです。</description>
    </item>
    <item>
      <title>actions-github-app-tokenの紹介</title>
      <link>https://shogo82148.github.io/blog/2023/09/26/2023-09-26-actions-github-app-token/</link>
      <pubDate>Tue, 26 Sep 2023 23:30:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/09/26/2023-09-26-actions-github-app-token/</guid>
      <description>GitHub App Tokenを発行するための actions-github-app-token という GitHub アクションを書きました。
実験的なアクションだったので、マーケットには公開していませんでした。 最近になって「安定して動作しているし、マーケットに公開するか！」という気持ちになったので、 改めてご紹介です。
背景 GitHub Actionsのワークフローから、GitHub APIを叩きたいこと、よくありますよね？
GITHUB_TOKEN そんなとき第一候補に挙がるのは secrets.GITHUB_TOKEN です。
Automatic token authentication 特段複雑な設定をせずとも使えるのでお手軽です。 しかし、 secrets.GITHUB_TOKEN には大きな制限があります。 それは「他のGitHub Actions Workflowを起動できない」ということ。 これは無限ループで大量のジョブが投入されるのを防ぐための制限です。 理由もはっきりしていて妥当な制限だとは思うのですが、 必要なワークフローが起動しなくて困ることがときどきあります。
PAT (Personal Access Token) (Classic) 「他のGitHub Actions Workflowを起動できない」制限を回避する簡単な方法は、 Personal Access Token を使うことです。 このトークンにはこの制限はありません。
ただし、トークンを発行したユーザーの権限でAPIを叩くので、権限の範囲が広すぎる、という問題があります。 実行できるアクションは制限できるのですが、レポジトリの範囲までは調整できません。
また、トークンは「ユーザー」に紐づきます。 個人のレポジトリならまだいいんですが、Organization管理のレポジトリ困ることがあります。 一番のあるあるは「トークンを発行したユーザーがOrganizationを抜けるとワークフローが止まる」ですかね。 属人化が進み、健全とは言い難い状態です。
fine-grained personal access tokens 「権限の範囲が広すぎる」問題を解決するのが fine-grained personal access tokens です。 レポジトリ単位でアクセス権を設定できます。
しかし、権限の広さは解決しますが、「トークンがユーザーに紐づいていることの弊害」は解消しません。
また、fine-grained personal access tokensは有効期限の設定が必須です。 管理するレポジトリの数が多いと、トークン更新行脚をする必要があります。
GitHub Apps ここで本命、 GitHub Apps の出番です。</description>
    </item>
    <item>
      <title>ぼくのかんがえたさいきょうのGo HTTPサーバー起動方法</title>
      <link>https://shogo82148.github.io/blog/2023/09/21/2023-09-21-start-http-server/</link>
      <pubDate>Thu, 21 Sep 2023 21:09:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/09/21/2023-09-21-start-http-server/</guid>
      <description>これまで何度か HTTP Server の Graceful Shutdown について記事を書きました。
Go 言語で Graceful Restart をする Go 言語で Graceful Restart をするときに取りこぼしを少なくする Go1.8 の Graceful Shutdown と go-gracedown の対応 最終的に Go 1.8 で Server.Shutdown が導入され、この件は解決を見ました。 しかし、最近「あれ？本当に正しく Server.Shutdown 使えている？」と疑問に思い、少し考えてみました。 というか ↑ の記事もまだ考慮が足りない気がする。
ぼくのかんがえたさいきょうの Go HTTP サーバー起動方法 とりあえず完成形のコード。
package main import ( &amp;#34;context&amp;#34; &amp;#34;log&amp;#34; &amp;#34;net/http&amp;#34; &amp;#34;os&amp;#34; &amp;#34;os/signal&amp;#34; &amp;#34;syscall&amp;#34; &amp;#34;time&amp;#34; ) func main() { // シグナルを待ち受ける chSignal := make(chan os.Signal, 1) signal.Notify(chSignal, syscall.SIGINT, syscall.SIGTERM) defer signal.Stop(chSignal) // 起動したいサーバーを準備 mux := http.</description>
    </item>
    <item>
      <title>Goのコメント全部消す</title>
      <link>https://shogo82148.github.io/blog/2023/09/18/2023-09-18-go-comment-eraser/</link>
      <pubDate>Mon, 18 Sep 2023 22:38:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/09/18/2023-09-18-go-comment-eraser/</guid>
      <description>深遠な理由で、ソースコードからコメントをすべて抹消したくなったことはありませんか？
そんなときに使えるツールを作りました。
shogo82148/go-comment-eraser Go製コマンドなので、 go install でインストール。
go install github.com/shogo82148/go-comment-eraser@latest ソースコードのおいてあるディレクトリを指定すると、 そのディレクトリ以下の *.go からすべてコメントを削除します。
go-comment-eraser ソースコードのあるディレクトリ 実際に shogo82148/go-comment-eraser 自身のソースコードで試した結果がこちら。
diff --git a/main.go b/main.go index 5087d08..913debc 100644 --- a/main.go +++ b/main.go @@ -65,22 +65,18 @@ func eraseComment(src string) error { return nil } -// parseFile parses the Go source code file and returns the Go source -// that is modified to erase all comments. func parseFile(src string) ([]byte, error) { -	// Parse the Go source code file + fset := token.</description>
    </item>
    <item>
      <title>ChooseALicense.com の日本語訳を公開しました</title>
      <link>https://shogo82148.github.io/blog/2023/09/16/2023-09-16-choose-a-license-in-japanese/</link>
      <pubDate>Sat, 16 Sep 2023 20:29:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/09/16/2023-09-16-choose-a-license-in-japanese/</guid>
      <description>ChooseALicense.com の日本語訳を公開しました。
choosealicense.shogo82148.com 背景 いつの間にか「オープンソースライセンスを適切に管理する係」になってしまい、 最近はライセンス文章とにらめっこする毎日のいっちーです。
そんな中お世話になったのがChooseALicense.comの付録です。 ライセンスの概要が大まかにわかります。 まあ、最終的には原文を読まないといけないわけですが、読む手がかりにはなります。
母国語が日本語の僕にとって、毎回英語読むのはきつい・・・日本語版欲しいな・・・ってことで作りました。
ツール 今回お世話になったツールたちです。
GitHub Pages BudouX GitHub Pages ChooseALicense.com は GitHub Pages でホストされています。 自然とchoosealicense.shogo82148.comのホスト先もGitHub Pagesになりました。
GitHub Pages自体はこのブログでもお世話になっている機能です。 今回個人的に初挑戦だったのは、独自ドメインの割り当てでした。 ChooseALicense.comのコードがカスタムドメインでの提供前提で組まれており、サブディレクトリでの提供では表示が崩れてしまうからです。
とは言ってもドキュメントにしたがい、GitHub側の設定を済ませたあと、自分のドメインにCNAMEレコードを挿入するだけでした。
Managing a custom domain for your GitHub Pages site お手軽なので、今後なにかに使えるかもしれないですね。
BudouX タイトルの「Choose an open source license」は「オープンソースライセンスを選ぼう」と翻訳しました。 が、これをそのまま表示すると、こうなります。
オープンソースライセンスを選ぼ う 「う」の位置がなんか気に食わない・・・。 この問題の解決のため、BudouXを利用しました。 自動でいい感じの改行位置を決めてくれます。
オープンソースライセンスを 選ぼう まとめ ChooseALicense.com の日本語訳を公開しました。
choosealicense.shogo82148.com 参考 ChooseALicense.com choosealicense.shogo82148.com オープンソースライセンスの日本語参考訳 Managing a custom domain for your GitHub Pages site GitHub Pages BudouX </description>
    </item>
    <item>
      <title>CloudFormationでECDSA形式のTLS証明書が取れた</title>
      <link>https://shogo82148.github.io/blog/2023/09/14/2023-09-14-cfn-ecdsa-acm/</link>
      <pubDate>Thu, 14 Sep 2023 18:53:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/09/14/2023-09-14-cfn-ecdsa-acm/</guid>
      <description>2022 年 11 月から ECDSA（楕円曲線デジタル署名アルゴリズム）に対応しています。
AWS Certificate Manager が楕円曲線デジタル署名アルゴリズム TLS 証明書のサポートを開始 しかし、
CloudFormation のサポートは近日中に提供が開始されます。
と書いてあるように、CloudFormation からの利用はできませんでした。
今日試してみたら、行けたっぽい（？）ので、設定方法のメモです。
設定方法 KeyAlgorithm に EC_prime256v1 もしくは EC_secp384r1 を指定します。
AWSTemplateFormatVersion: &amp;#34;2010-09-09&amp;#34; Resources: Certificate: Type: AWS::CertificateManager::Certificate Properties: DomainName: shogo82148.com ValidationMethod: DNS DomainValidationOptions: - DomainName: shogo82148.com HostedZoneId: Z1TR8BQNS8S1I7 KeyAlgorithm: EC_prime256v1 注意 ふと、AWS::CertificateManager::Certificate リソースのドキュメントを読んでいたら KeyAlgorithm という属性を見つけたので試してみました。 しかし、2023-09-14 現在説明文は
Property description not available.
の一文のみ。 リリースの案内も見つけられなかったので、心配な人は正式リリースの案内を待ちましょう。
基本的に CloudFormation のプロパティーはサービスの API と同じ名前です。 今回試してみた EC_prime256v1 という値も、ACM の API リファレンスの KeyAlgorithm を参照しました。
ACM API Reference: RequestCertificate KeyAlgorithm 参考 AWS Certificate Manager が楕円曲線デジタル署名アルゴリズム TLS 証明書のサポートを開始 ACM API Reference: RequestCertificate KeyAlgorithm AWS::CertificateManager::Certificate: KeyAlgorithm </description>
    </item>
    <item>
      <title>log/slogにログを転送する logrus hook を書いた</title>
      <link>https://shogo82148.github.io/blog/2023/09/10/2023-09-10-logrus-slog-hook/</link>
      <pubDate>Sun, 10 Sep 2023 23:39:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/09/10/2023-09-10-logrus-slog-hook/</guid>
      <description>長らく構造化ログの仕組みが標準ライブラリになかったGoですが、 Go 1.21がリリースされて晴れて log/slog が使えるようになりました。 弊社ではlogrusを使っているので、log/slogを連携するためのフックを書きました。
背景 弊社ではlogrusをメインに使っています。 特段困ったこともなく 素晴らしいライブラリだと思います！！！（大事） 強いて問題点を上げるとすれば、メンテナンスモードに入ってしまってあまり開発が活発でない、ということでしょうか。 重大なバグがあれば別ですが、新規機能の追加等は行わない方針のようです。
一方 log/slog は公式ライブラリなので、log/slogの仕様を前提としたエコシステムが、今後発展してくでしょう。
logrusを使いながらlog/slogのいいとこ取りとする方法はないか？と考えた結果作ったのが shogo82148/logrus-slog-hook です。
SYNOPSIS sloghook.New で作成したフックを差し込むだけです。 logrusに流したログがlog/slogの設定で流れてきます。
package main import ( &amp;#34;io&amp;#34; &amp;#34;log/slog&amp;#34; &amp;#34;os&amp;#34; sloghook &amp;#34;github.com/shogo82148/logrus-slog-hook&amp;#34; &amp;#34;github.com/sirupsen/logrus&amp;#34; ) func main() { h := slog.NewTextHandler(os.Stderr, nil) logrus.AddHook(sloghook.New(h)) // logrus も logrus-slog-hook もSTDERRに書き込むので、同じログが二回表示されてしまう。 // logrus側を止めて防止。 logrus.SetFormatter(sloghook.NewFormatter()) logrus.SetOutput(io.Discard) logrus.WithFields(logrus.Fields{ &amp;#34;name&amp;#34;: &amp;#34;joe&amp;#34;, &amp;#34;age&amp;#34;: 42, }).Error(&amp;#34;Hello world!&amp;#34;) // Output: // time=2023-09-10T23:32:41.229+09:00 level=ERROR msg=&amp;#34;Hello world!&amp;#34; age=42 name=joe } 注意点 logrusはエラーレベルが Trace, Debug, Info, Warn, Error, Panic, Fatal と7段階ありますが、 log/slogには Debug, Info, Warn, Error しかありません。 しかし実は整数をレベルを設定できるので、適当に割り当てました。</description>
    </item>
    <item>
      <title>actions/checkout@v4の襲撃を受けた件</title>
      <link>https://shogo82148.github.io/blog/2023/09/08/2023-09-08-actions-checkout-v4/</link>
      <pubDate>Fri, 08 Sep 2023 20:22:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/09/08/2023-09-08-actions-checkout-v4/</guid>
      <description>先日 actions/checkout@v4 がリリースされましたね。
actions/checkout@v4 まあ、何が言いたいかというと、「メジャーバージョンアップ多すぎじゃない？？？」という話。
actions/checkout@v4の襲撃 新規に作成したレポジトリには基本的にdependabotをセットアップしています。 まあそんな状況下で actions/checkout@v4 なんてリリースされたら、こうなるわけですよ。
actions/checkout のアップデートつらい pic.twitter.com/4bNeCFsE4Y
&amp;mdash; f96fd3a0-bdb9-4f10-b69f-8f765c1d341c ICHINOSEShogo (@shogo82148) September 5, 2023 よほど単純なワークフローでない限り、 actions/checkout は必須のアクションです。 GitHub Actions でCIを組んでいるレポジトリはもれなく使っています。 @shogo82148以下にあるレポジトリだけで、76個のプルリクエストが来ました。 心を無にしてマージボタンを押しまくりました。 他のorgにも参加しているので、実際に対応したプルリクエストはもっと多いです。
Node.js 16 のEOLが近い 背景には Node.js 16 が9月11日にEOLになるという話があります。 actions/checkout@v3 は Node.js 16 で動くので、当然サポート対象外になります。 そこで新しいバージョンが必要なわけです。
actions/checkout@v4 は Node.js 20 で動くようになりました。 GitHub Actions はセフルホストできるので、まだ Node.js 20 が動かない環境も残っています。 そのような環境でオプトインできるよう、メジャーバージョンアップにしたのだと思います。
Node.js 18 がスキップされた話 ちなみに Node.js 16 と Node.js 20 の間には Node.js 18 が存在するわけですが、 Node.js 18 はスキップされました。 （Node.</description>
    </item>
    <item>
      <title>ぼくのかんがえたさいきょうの[0.0, 1.0)の乱数を得るための方法</title>
      <link>https://shogo82148.github.io/blog/2023/09/04/2023-09-04-generate-random-float/</link>
      <pubDate>Mon, 04 Sep 2023 23:27:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/09/04/2023-09-04-generate-random-float/</guid>
      <description>Twitterもとい𝕏でこんなスライドが流れてきました。
$[0.0, 1.0)$ の範囲を保証しつつ、浮動小数点数が表現可能なすべての値をとるのは難しい、というお話です。 なるほど・・・確かに改めて考えてみると「浮動小数点数が表現可能なすべての値」という条件は難しいですね。 でも、スライド中で紹介されていたアルゴリズムには、もうちょっと最適化の余地があるのでは？と考えてみました。
Goの標準ライブラリでの実装 もとのスライドはC++の話っぽいけど、C++はよくわからないので、Go言語での実装を考えます。
除算法 Goの標準ライブラリはスライド中で「除算法」と呼ばれている方法で乱数を生成します。
Go 1.21.0 の実装: https://github.com/golang/go/blob/33d4a5105cf2b2d549922e909e9239a48b8cefcc/src/math/rand/rand.go#L188-L212 // Float64 returns, as a float64, a pseudo-random number in the half-open interval [0.0,1.0). func (r *Rand) Float64() float64 { // コメント略 again: f := float64(r.Int63()) / (1 &amp;lt;&amp;lt; 63) if f == 1 { goto again // resample; this branch is taken O(never) } return f } 除算法は大変シンプルですが、丸め誤差の影響で誤って 1.0 を返すことがあります。 Goは乱数を再生成することで、この問題を回避しています。
過去の実装 実際 Go 1.2 までは 1.</description>
    </item>
    <item>
      <title>ウェブ魚拓の創業者のインタビュー記事のウェブ魚拓</title>
      <link>https://shogo82148.github.io/blog/2023/09/03/2023-09-03-gyotaku/</link>
      <pubDate>Sun, 03 Sep 2023 23:01:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/09/03/2023-09-03-gyotaku/</guid>
      <description>年に一度くらいこういうことありませんか？
ウェブ魚拓の創業者のインタビュー記事読みたいな、と思って探したら、メディアが終了していてもう読めない。ウェブ魚拓を取っておけば・・・https://t.co/qpC5EdFQIJhttps://t.co/9JITbnj5ZM
&amp;mdash; f96fd3a0-bdb9-4f10-b69f-8f765c1d341c ICHINOSEShogo (@shogo82148) June 12, 2023 （はっ・・・？今年2回目・・・？）
https://t.co/xzuix067a0 魚拓にあるって教えて貰ったので引っ張り出してきた。
&amp;mdash; V (@voluntas) June 13, 2023 【魚拓】炎上の歴史とともに10周年、あの「ウェブ魚拓」創業者に会ってきた | HRナビ by リクルート https://t.co/RHWwoQwfVn
【魚拓】“握力の強さ”で日本一に 「ウェブ魚拓」創業者はいかにして肉体派プログラマーになったか | HRナビ by リクルート https://t.co/63arUxyU7Y…
&amp;mdash; V (@voluntas) June 13, 2023 Twitterもとい𝕏は最近雲行きが怪しいので、ぱっと見られるようにリンクを貼っておきます。
【魚拓】炎上の歴史とともに10周年、あの「ウェブ魚拓」創業者に会ってきた | HRナビ by リクルート 【魚拓】“握力の強さ”で日本一に 「ウェブ魚拓」創業者はいかにして肉体派プログラマーになったか | HRナビ by リクルート 新沼大樹さんも伏黒パパの役イケそう。
「呪術廻戦」伏黒パパがリアルに顕現!?　漫画みたいにTシャツへ浮き出る腹筋が「フィジカルギフテッド」と話題 魚拓 </description>
    </item>
    <item>
      <title>湘南.pm #1 で「趣味でPerlのビルドをしている話」をしてきた</title>
      <link>https://shogo82148.github.io/blog/2023/09/03/2023-09-03-shonanpm-no-1/</link>
      <pubDate>Sun, 03 Sep 2023 18:10:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/09/03/2023-09-03-shonanpm-no-1/</guid>
      <description>すでに一週間が過ぎ、今更感がありますが・・・ 「ブログに書くまでがYAPC」もといPerl Mongersという言葉もあるのでやっていきましょう。
@__papix__に声をかけていただき、8/26に開催された湘南.pm #1で発表してきました。 「趣味でPerlのビルドをしている話」と題して、AWS::Lambdaとactions-setup-perlのお話をしてきました。
趣味でPerlのビルドをしている話 資料はSpeaker Deckを見てもらうとして、簡単に補足等します。
AWS::Lambda うっかりサンプルコードの末尾に 1; を付けてしまいましたが、なんと！最新のPerlでは不要になりました！
use 5.38; use utf8; sub handle ($payload, $context) { return $payload; } # 1; # ↑ スライド資料では付けてしまったけど、なくてよい これは use 5.38 で module_true feature が有効化されるためです。 詳細は「Perlのmodule_trueフラグを先取り！」という記事を書いたのでそちらをどうぞ。 この記事を書いたときは開発版のPerlで試しましたが、 Perl 5.38 で正式リリースされています。
Perl Hackers Hub に掲載したサンプルコードを流用したことがバレてしまう・・・。
Perl Hackers Hub 第75回 AWS Lambda入門 サーバレスでもPerlを活用しよう！（1） Perl Hackers Hub 第75回 AWS Lambda入門 サーバレスでもPerlを活用しよう！（2） さて、このサンプルコード、他にもPerlの（比較的）新しい機能を使っているのですが、気がついたひとはいますか？ 実は引数の受け取り方が変わっています！
Perlには元々「サブルーチンの引数を定義する構文」がありませんでした。 @_ という記号を使うか、 shift などの配列操作関数を使います。
use utf8; # 昔からある引数の受け取り方 sub handle { my ($payload, $context) = @_; return $payload; } 1; 記号が多くて大変初心者泣かせですね。</description>
    </item>
    <item>
      <title>Eytzinger LayoutをGoで試してみた</title>
      <link>https://shogo82148.github.io/blog/2023/08/12/2023-08-12-eytzinger-layout/</link>
      <pubDate>Sat, 12 Aug 2023 18:10:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/08/12/2023-08-12-eytzinger-layout/</guid>
      <description>2021年のスライド資料だけど、たまたま𝕏に流れているを見かけました。
このスライドでEytzinger Layoutという配列をはじめて知ったのでメモ。
Eytzinger Layout 16世紀のオーストリアの貴族Michaël Eytzingerが考案したことから、この名前がついたそうです。 もともとはヨーロッパの王様の家系図に番号をつけるための方法です。 ある人物の番号が$k$のとき、父親に$2k$、母親に$2k+1$と番号をつけます。 このルールを使うと家系図に登場するすべての人物にユニークな番号をふることができます。
この番号付けのルールをバイナリツリーに応用すると、ツリー構造をポインターを使わずに表現できます。 二分ヒープを配列で表現するときの実装としてよく登場するのを目にします。 こういう名前がついているのは知らなかった。
バイナリサーチとEytzinger Layoutの関係 イマドキのCPUは非常に高速で、CPUの動作速度と比べてメモリーへの読み書きすら遅い、というレベルです。 この速度差を解消すべく、イマドキCPUはコア上にキャッシュと持っています。 読み書きの頻度の多いメモリー領域をキャッシュ上に保存することで、高速な動作を保っています。
さて、バイナリサーチはソート済みの配列から$\log n$オーダーで要素を検索する方法です。 しかし、通常のバイナリサーチはメモリーのアクセスパターンが複雑なため、CPUのキャッシュと非常に相性が悪いです。
そこでEytzinger Layoutの出番です。 Eytzinger Layoutを利用するとよくアクセスされる要素が隣接するようになります。 これによりCPUキャッシュのヒット率をあげようという作戦です。 冒頭のスライドや、以下の記事で詳しく説明されています（図があるとわかりやすいけど、面倒で力尽きた）。
Eytzinger Binary Search キャッシュフレンドリーな二分探索 ー データ構造を再考する Cache-friendly binary search 実装 Goで実装してみました。
shogo82148/go-eytzinger ソート済みの配列からEytzinger Layoutへの変換は、再帰を使うと簡単に実装できます。 （参考: Eytzinger Binary Search）
// https://github.com/shogo82148/go-eytzinger/blob/cd9c2f8a9657333f29a6b645cb2587322295ef3a/eytzinger.go#L8-L34 // Eytzinger rearranges the elements of a slice into a cache friendly binary tree // as known as [Eytzinger Layout]. // The slice must be sorted in increasing order.</description>
    </item>
    <item>
      <title>AWS::LambdaがResponse Streamingに対応しました</title>
      <link>https://shogo82148.github.io/blog/2023/08/09/2023-08-09-p5-aws-lambda-supports-response-streaming/</link>
      <pubDate>Wed, 09 Aug 2023 21:30:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/08/09/2023-08-09-p5-aws-lambda-supports-response-streaming/</guid>
      <description>AWS::LambdaがResponse Streamingに対応しました。
Response Streaming 2023年4月に発表されたAWS Lambdaの新機能です。
AWS Lambda レスポンスストリーミングの紹介 Introducing AWS Lambda response streaming 従来のLambda関数は処理がすべて完了したあとでないと結果を返すことができませんでした。 Response Streamingを利用すると、処理の途中であっても段階的に処理結果を返すことができます。
使い方 通常のLambda関数のなかで使う CODEリファレンスを返すことでResponse Streamingを使うことができます。
sub handle { my ($payload, $context) = @_; return sub { # とりあえずヘッダーだけ返す my $responder = shift; my $writer = $responder-&amp;gt;(&amp;#39;application/json&amp;#39;); # ...なんか長い処理... # 最終的な結果を返す $writer-&amp;gt;write(&amp;#39;{&amp;#34;foo&amp;#34;: &amp;#34;bar&amp;#34;}&amp;#39;); $writer-&amp;gt;close; }; } もちろん処理の途中で$writer-&amp;gt;writeを複数回呼んで、途中結果を返すことも可能です。
Function URLsと一緒に使う AWS::Lambda::PSGIを使えばFunction URLsを一緒に使うこともできます。 PSGIのDelayed Response and Streaming Body方式に対応しています。
sub app { return sub { # とりあえずヘッダーだけ返す my $responder = shift; my $writer = $responder-&amp;gt;([200, [&amp;#39;Content-Type&amp;#39; =&amp;gt; &amp;#39;application/json&amp;#39;]]); # .</description>
    </item>
    <item>
      <title>Contextに埋め込んだ値をログに出力してくれるログハンドラーを書いた</title>
      <link>https://shogo82148.github.io/blog/2023/08/04/2023-08-04-context-for-slog/</link>
      <pubDate>Fri, 04 Aug 2023 23:22:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/08/04/2023-08-04-context-for-slog/</guid>
      <description>Go言語にいよいよ構造化ログ用パッケージlog/slogが追加される、と各所で話題になってますね。
Go 1.21連載始まります＆slogをどう使うべきか しかし、どんなにドキュメントをみても、ロガーを出し入れする関数はありません。そういう使い方を議論する issue もありましたが　現状はハンドラーにそのまま渡しているだけです。 よくよく考えればトレーシングIDなどは、コンテキストに格納されているはずで、ロガーにも属性として持つと2重持ちになってしまいます。出力時だけハンドラ自身がそれを取り出して書き出せば良い、という思想に思えます。 そのためにはハンドラーを自分でつくることになります。 (強調は筆者によるもの)
たしかにトレーシングIDを2重に持つのは効率が悪いかもしれない。 そうかもしれないけど・・・でもやっぱり毎回ハンドラーを書くのは面倒・・・もうちょっと汎用的にはならないものか・・・ と結局書いちゃいました。
shogo82148/ctxslog 使い方 slogではログ関数がcontext.Contextを受け取るようになりました。 ここで渡したcontext.Contextはキャンセル処理には使用されず、値の受け渡しのみに使用されます。
このことを利用してctxslog.WithAttrsでコンテキストに値を埋め込むことができます。 ここで埋め込んだ値をctxslog.Newで作成したハンドラーが受け取って、ログに表示します。
import ( &amp;#34;context&amp;#34; &amp;#34;log/slog&amp;#34; ) func main() { // ログに出力するためにロガーをカスタマイズ handler := slog.NewTextHandler(os.Stderr, nil) slog.SetDefault(slog.New(ctxslog.New(handler))) ctx := context.Background() // このコンテキスト内のログすべてに my_context=foo-bar を埋め込む ctx = ctxslog.WithAttrs(ctx, slog.String(&amp;#34;my_context&amp;#34;, &amp;#34;foo-bar&amp;#34;)) slog.InfoContext(ctx, &amp;#34;hello&amp;#34;, &amp;#34;count&amp;#34;, 42) // ログ出力、ここで `ctx` を渡しているのがポイント slog.InfoContext(ctx, &amp;#34;world&amp;#34;) // Output: // time=2023-08-03T18:10:20.424+09:00 level=INFO msg=hello count=42 my_context=foo-bar // time=2023-08-03T18:10:20.424+09:00 level=INFO msg=world my_context=foo-bar } 実装 slog.</description>
    </item>
    <item>
      <title>AWS::Lambda 0.1.1リリースのお知らせ</title>
      <link>https://shogo82148.github.io/blog/2023/08/01/2023-08-01-p5-aws-lambda-0.1.1-are-released/</link>
      <pubDate>Tue, 01 Aug 2023 21:48:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/08/01/2023-08-01-p5-aws-lambda-0.1.1-are-released/</guid>
      <description>AWS::Lambda v0.1.1が利用可能になりました。
今回のリリースでは、以下の 5 つのリージョンを新たに追加しました。
欧州（チューリッヒ）(eu-central-2) 欧州（スペイン）(eu-south-2) アジアパシフィック（ハイデラバード）(ap-south-2) アジアパシフィック（メルボルン）(ap-southeast-4) イスラエル（テルアビブ）(il-central-1) 久しぶりにリージョン一覧を眺めていたら、いっぱい増えていてびっくりしました・・・ 欧州（チューリッヒ）、欧州（スペイン）、アジアパシフィック（ハイデラバード）リージョンは去年の 11 月、 アジアパシフィック（メルボルン）は今年の 1 月にオープンでした。長いこと気が付かず申し訳ない。
イスラエル（テルアビブ）リージョンに関しては、なんと！今日オープンです！
Now Open – AWS Israel (Tel Aviv ) Region もちろん 7 月 2 日にリリースされた Perl 5.38 にも対応済みです。
perl5380delta レイヤー ARN は以下のとおりです。 今回追加した 5 つのリージョンと、中東（アラブ首長国連邦）リージョンに関しては ARM 未対応なので注意してください。
x86_64 architecture arn:aws:lambda:af-south-1:445285296882:layer:perl-5-38-runtime-al2-x86_64:2 arn:aws:lambda:ap-east-1:445285296882:layer:perl-5-38-runtime-al2-x86_64:2 arn:aws:lambda:ap-northeast-1:445285296882:layer:perl-5-38-runtime-al2-x86_64:2 arn:aws:lambda:ap-northeast-2:445285296882:layer:perl-5-38-runtime-al2-x86_64:2 arn:aws:lambda:ap-northeast-3:445285296882:layer:perl-5-38-runtime-al2-x86_64:2 arn:aws:lambda:ap-south-1:445285296882:layer:perl-5-38-runtime-al2-x86_64:2 arn:aws:lambda:ap-south-2:445285296882:layer:perl-5-38-runtime-al2-x86_64:1 arn:aws:lambda:ap-southeast-1:445285296882:layer:perl-5-38-runtime-al2-x86_64:2 arn:aws:lambda:ap-southeast-2:445285296882:layer:perl-5-38-runtime-al2-x86_64:2 arn:aws:lambda:ap-southeast-3:445285296882:layer:perl-5-38-runtime-al2-x86_64:2 arn:aws:lambda:ap-southeast-4:445285296882:layer:perl-5-38-runtime-al2-x86_64:1 arn:aws:lambda:ca-central-1:445285296882:layer:perl-5-38-runtime-al2-x86_64:2 arn:aws:lambda:eu-central-1:445285296882:layer:perl-5-38-runtime-al2-x86_64:2 arn:aws:lambda:eu-central-2:445285296882:layer:perl-5-38-runtime-al2-x86_64:1 arn:aws:lambda:eu-north-1:445285296882:layer:perl-5-38-runtime-al2-x86_64:2 arn:aws:lambda:eu-south-1:445285296882:layer:perl-5-38-runtime-al2-x86_64:2 arn:aws:lambda:eu-south-2:445285296882:layer:perl-5-38-runtime-al2-x86_64:1 arn:aws:lambda:eu-west-1:445285296882:layer:perl-5-38-runtime-al2-x86_64:2 arn:aws:lambda:eu-west-2:445285296882:layer:perl-5-38-runtime-al2-x86_64:2 arn:aws:lambda:eu-west-3:445285296882:layer:perl-5-38-runtime-al2-x86_64:2 arn:aws:lambda:il-central-1:445285296882:layer:perl-5-38-runtime-al2-x86_64:1 arn:aws:lambda:me-central-1:445285296882:layer:perl-5-38-runtime-al2-x86_64:2 arn:aws:lambda:me-south-1:445285296882:layer:perl-5-38-runtime-al2-x86_64:2 arn:aws:lambda:sa-east-1:445285296882:layer:perl-5-38-runtime-al2-x86_64:2 arn:aws:lambda:us-east-1:445285296882:layer:perl-5-38-runtime-al2-x86_64:2 arn:aws:lambda:us-east-2:445285296882:layer:perl-5-38-runtime-al2-x86_64:2 arn:aws:lambda:us-west-1:445285296882:layer:perl-5-38-runtime-al2-x86_64:2 arn:aws:lambda:us-west-2:445285296882:layer:perl-5-38-runtime-al2-x86_64:2 arm64 architecture arn:aws:lambda:af-south-1:445285296882:layer:perl-5-38-runtime-al2-arm64:2 arn:aws:lambda:ap-east-1:445285296882:layer:perl-5-38-runtime-al2-arm64:2 arn:aws:lambda:ap-northeast-1:445285296882:layer:perl-5-38-runtime-al2-arm64:2 arn:aws:lambda:ap-northeast-2:445285296882:layer:perl-5-38-runtime-al2-arm64:2 arn:aws:lambda:ap-northeast-3:445285296882:layer:perl-5-38-runtime-al2-arm64:2 arn:aws:lambda:ap-south-1:445285296882:layer:perl-5-38-runtime-al2-arm64:2 arn:aws:lambda:ap-southeast-1:445285296882:layer:perl-5-38-runtime-al2-arm64:2 arn:aws:lambda:ap-southeast-2:445285296882:layer:perl-5-38-runtime-al2-arm64:2 arn:aws:lambda:ap-southeast-3:445285296882:layer:perl-5-38-runtime-al2-arm64:2 arn:aws:lambda:ca-central-1:445285296882:layer:perl-5-38-runtime-al2-arm64:2 arn:aws:lambda:eu-central-1:445285296882:layer:perl-5-38-runtime-al2-arm64:2 arn:aws:lambda:eu-north-1:445285296882:layer:perl-5-38-runtime-al2-arm64:2 arn:aws:lambda:eu-south-1:445285296882:layer:perl-5-38-runtime-al2-arm64:2 arn:aws:lambda:eu-west-1:445285296882:layer:perl-5-38-runtime-al2-arm64:2 arn:aws:lambda:eu-west-2:445285296882:layer:perl-5-38-runtime-al2-arm64:2 arn:aws:lambda:eu-west-3:445285296882:layer:perl-5-38-runtime-al2-arm64:2 arn:aws:lambda:me-south-1:445285296882:layer:perl-5-38-runtime-al2-arm64:2 arn:aws:lambda:sa-east-1:445285296882:layer:perl-5-38-runtime-al2-arm64:2 arn:aws:lambda:us-east-1:445285296882:layer:perl-5-38-runtime-al2-arm64:2 arn:aws:lambda:us-east-2:445285296882:layer:perl-5-38-runtime-al2-arm64:2 arn:aws:lambda:us-west-1:445285296882:layer:perl-5-38-runtime-al2-arm64:2 arn:aws:lambda:us-west-2:445285296882:layer:perl-5-38-runtime-al2-arm64:2 参考 スイスに新しい AWS リージョンがオープン A New AWS Region Opens in Switzerland スペインに新しい AWS リージョンがオープン Now Open–AWS Region in Spain インドに 30 番目の AWS リージョン — アジアパシフィック (ハイデラバード) リージョンをオープンしました Now Open the 30th AWS Region – Asia Pacific (Hyderabad) Region in India 新規開設 – オーストラリアの AWS アジアパシフィック (メルボルン) リージョン Now Open — AWS Asia Pacific (Melbourne) Region in Australia Now Open – AWS Israel (Tel Aviv ) Region perl5380delta </description>
    </item>
    <item>
      <title>「ふっかつのじゅもん」みたいなBase64亜種「base64dq」を書いた</title>
      <link>https://shogo82148.github.io/blog/2023/07/26/2023-07-26-base64dq-base64-variant-inspired-by-dragon-quest/</link>
      <pubDate>Wed, 26 Jul 2023 21:48:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/07/26/2023-07-26-base64dq-base64-variant-inspired-by-dragon-quest/</guid>
      <description>ドラゴンクエストシリーズ第一作目に登場する「ふっかつのじゅもん」っぽいBase64亜種を書いてみました。
shogo82148/base64dq 使い方 簡単に使えるようコマンドラインインターフェイスも用意しました。go installでインストール可能です。
$ go install github.com/shogo82148/base64dq/cmd/base64dq@latest base64dqコマンドが使えるようになります。 Coreutilsのbase64コマンドと同様に使えます。
$ echo &amp;#39;こんにちは&amp;#39; | base64dq づづきとづづさとづづきわづづきめづづきげうむ・・ $ echo &amp;#39;づづきとづづさとづづきわづづきめづづきげうむ・・&amp;#39; | base64dq --decode こんにちは ふっかつのじゅもん 「ふっかつのじゅもん」はドラゴンクエストシリーズ第一作目で採用されたゲームのセーブ方式です。 ゲームを中断するときには、再開したときに同じ状態からゲームを始められるよう、ゲームの状態を保存しておく必要があります。 しかしドラクエIが発売されたのは1986年5月。 当時ドラクエIはファミコン向けに発売されたのですが、ファミコンにはフラッシュROMのような贅沢なハードウェアはついていません。 電源を落とすと簡単にデーターは失われてしまいます。
そこでゲームの状態を20文字の「ふっかつのじゅもん」にエンコードし、 再開時には「ふっかつのじゅもん」をプレイヤーに入力してもらう、というセーブ方式が編み出されました。
プレイヤーはゲームを中断するたびに「ふっかつのじゅもん」を書き写す必要がありました。 当時は液晶ディスプレイなどあるはずもなく、一般の家庭にあるのはブラウン管のアナログディスプレイです。 解像度が荒く読み取るのが大変なため、「ふっかつのじゅもん」を間違え散っていったプレイヤーも多くいたと聞いています（筆者はまだ生まれていないのでよく知らない）。
ふっかつのじゅもんとBase64の関係 今では有志による解読も進みふっかつのじゅもんのジェネレーターも開発されています。
DQ1 復活の呪文解析日記によると、「ふっかつのじゅもん」は64種類のひらがなで構成されているそうです。 64。実に切りのいい数字です。 1文字で6ビットの情報を表し、合計で120ビットのセーブデータを表現しています。
このエンコード方法はBase64とまったく同じですね！ 「ふっかつのじゅもん」は、64種類のASCII文字の代わりに、64種類のひらがなを使ったBase64の亜種、と考えることができます。
ちなみにBase64がRFCに登場したのは1987年4月のRFC 989だそうです。 当時はBase64という言葉すらなく、printable encodingと呼ばれていたようです。 ドラクエIが発売されたのは1986年5月なので、Base64が一般に広まる前に「ふっかつのじゅもん」は世に公開されたわけですね。 すごい！
もちろん規格化されていないだけで「64種類の文字で情報をエンコードする」というアイディア自体はもっと昔からあったのでしょう。 でも似たようなものがゲームに使われていたのはおもしろいですね。
base64dq そういうわけで「ふっかつのじゅもん」の影響を受けて作ったのが shogo82148/base64dq です。 64種類のASCII文字の代わりに、以下の64種類のひらがなを使います。
あいうえお かきくけこ さしすせそ たちつてと なにぬねの はひふへほ まみむめも やゆよ らりるれろ わ がぎぐげご ざじずぜぞ だぢづでど ばびぶべぼ ・（パディング） 「ふっかつのじゅもん」にはパディングはないので、適当に「・」を選びました。</description>
    </item>
    <item>
      <title>GitHubのプロジェクトにUsed by counterを追加する</title>
      <link>https://shogo82148.github.io/blog/2023/07/05/2023-07-05-github-used-by-counter/</link>
      <pubDate>Wed, 05 Jul 2023 23:36:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/07/05/2023-07-05-github-used-by-counter/</guid>
      <description>GitHubのプロジェクトを見に行くと、サイドバーに「Used by（数字）」と書かれたセクションがあります。
これの設定方法を知ったのでメモ。
TL;DR レポジトリのナビゲーションバーから「Setting」をクリックし設定画面を開きます サイドバーから「Code security and analysis」を選択します 「Used by counter」という項目で、たくさん使ってもらっていそうなパッケージを選択します 背景 GitHub Actions上でFuzzingを実行するアクションを書いたでshogo82148/actions-go-fuzzというGitHub Actionを作りました。 このために作ったレポジトリの概要を眺めていると、いつの間にか「Used by 3」という表示が増えてました。 これ自体はおかしなことではありません。お試しで自分が過去に作ったレポジトリにshogo82148/actions-go-fuzzを導入したので、依存しているレポジトリは存在します。
ずっと不思議だったのは、自分の作った他のGitHub Actionにはこの表示がないこと。 たとえば「actions-setup-perl」でGitHubを検索すると、それなりに使用例が出てきます。 しかし、shogo82148/actions-setup-perlには（この文章を書く前の時点では）「Used by（数字）」のセクションはありませんでした。
原因 ただの趣味でやっているので別に利用者がいなくたって構わないんですが、 やっぱり利用者がいるとモチベーションが変わってくるじゃないですか。 そういうわけで、表示方法を探したところ公式ドキュメントにたどり着きました。
Changing the &amp;ldquo;Used by&amp;rdquo; package ドキュメントによると、ひとつのレポジトリで複数のパッケージを提供していると、 このようなことが起こるそうです。
shogo82148/actions-setup-perlの場合、GitHubの依存解析によって「JavaScriptのパッケージ」「GitHub Actionのパッケージ」の2つが検出されました。 shogo82148/actions-setup-perlはTypeScriptで実装されているので「JavaScriptのパッケージ」として認識されるのは仕方のないことです。 しかし、利用者はみんなGitHub Actionとして利用するので、実際に「JavaScriptのパッケージ」として利用する人はいません。 というかそういう使い方は想定していないので、使われていないのは正しい。 利用者がいないので、「Used by（数字）」の表示がなかったんですね。
ドキュメントに記載されている通り、「Used by counter」の設定を変更すれば無事表示されます。 shogo82148/actions-setup-perlも「GitHub Actionのパッケージ」としてカウントされるよう設定を変更したので、 この記事を書いている時点では利用者数が表示されるようになりました。
まとめ GitHubのレポジトリで利用者数が表示されるアレは「Used by counter」という名前らしい 設定の「Code security and analysis」から変更できるよ 個人的に「Code security and analysis」から変更できるというのは盲点でした。 「security」の文字だけ見て「セキュリティー関連の設定かー」と思っていたんですが、 なるほど「Code analysis（コード分析）」の設定も含まれているんですね。
レポジトリの設定多すぎて覚えきれないよ・・・。
参考 Changing the &amp;ldquo;Used by&amp;rdquo; package GitHub Actions上でFuzzingを実行するアクションを書いた shogo82148/actions-setup-perl </description>
    </item>
    <item>
      <title>GitHub Actions上でFuzzingを実行するアクションを書いた</title>
      <link>https://shogo82148.github.io/blog/2023/07/05/2023-07-05-actions-go-fuzz/</link>
      <pubDate>Wed, 05 Jul 2023 00:41:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/07/05/2023-07-05-actions-go-fuzz/</guid>
      <description>Go 1.18からGo Fuzzingの機能が追加されました。 僕もいくつかのパッケージに導入してみたのですが、予期していなかったテストパターンを見つけられて役にやっている気がします。 Fuzzテストが増えてきたので、毎回手元でFuzzテストを実行するのも大変になってきました。
簡単にFuzzテストを実行する環境を作れないかと、GitHub Actions上でFuzzテストを実行するActionを書いてみました。
shogo82148/actions-go-fuzz 使い方 Fuzzingのチュートリアルのコードで試してみましょう。
テスト対象の関数を書く main.go に文字列を反転させるコードを書きます。
// main.go package main func Reverse(s string) string { b := []byte(s) for i, j := 0, len(b)-1; i &amp;lt; len(b)/2; i, j = i+1, j-1 { b[i], b[j] = b[j], b[i] } return string(b) } チュートリアルを進めていくとわかるのですが、このコードは「マルチバイト文字を正しく処理できない」というバグがあります。 このバグをFuzzingを使って見つけてもらいましょう。
Fuzzテストを書く Reverseを2回実行すると同じ文字列に戻るはずです。 このことを確認するテストを書きます。
さらに、入力がUTF-8としてValidであるなら、出力もValidであって欲しいです。 これもテストで確認します。
package main func FuzzReverse(f *testing.F) { testcases := []string{&amp;#34;Hello, world&amp;#34;, &amp;#34; &amp;#34;, &amp;#34;!12345&amp;#34;} for _, tc := range testcases { f.</description>
    </item>
    <item>
      <title>GitHub ActionsからWorkload Identityを使ってGCPにアクセスする</title>
      <link>https://shogo82148.github.io/blog/2023/07/04/2023-07-04-access-google-cloud-from-github-actions-using-workload-identity/</link>
      <pubDate>Tue, 04 Jul 2023 11:45:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/07/04/2023-07-04-access-google-cloud-from-github-actions-using-workload-identity/</guid>
      <description>GitHub Actionsの利用量をまとめるではGitHub Actionsの使用量をGoogle Spreadsheetにまとめるスクリプトを書きました。 このときは動作確認ができればよかったので、自分のGoogleアカウントで認証して書き込みを行いました。 しかし、このスクリプトを定期的に実行するのも面倒です。
そこでGitHub Actionsのスケジュール実行機能を使い、毎日使用量を記録する設定を行いました。 イマドキAPIキーを使うのはリスクが高いので、Google CloudのWorkload Identity連携を使ってアクセスします。
Workload Identity 連携の構成 GitHub Actions からのキーなしの認証の有効化を参考にGoogle Cloud側の設定を行います。 設定内容をバージョン管理したいので、設定にはTerraformを使用します。 意外と作成するリソースが多くて大変なので、GitHub OIDC Terraform ModuleとProject API Activation Terraform Moduleを利用してみましょう。
provider &amp;#34;google&amp;#34; { batching { enable_batching = false } } # Google Cloudのプロジェクト resource &amp;#34;google_project&amp;#34; &amp;#34;my_project&amp;#34; { name = &amp;#34;my-project&amp;#34; project_id = &amp;#34;my-project&amp;#34; } # サービスアカウント resource &amp;#34;google_service_account&amp;#34; &amp;#34;github_actions&amp;#34; { project = google_project.my_project.id account_id = &amp;#34;github-actions&amp;#34; } # サービスAPIの有効化設定 module &amp;#34;project_services&amp;#34; { source = &amp;#34;terraform-google-modules/project-factory/google//modules/project_services&amp;#34; version = &amp;#34;14.</description>
    </item>
    <item>
      <title>dependabotの更新グループ化機能を使ってAWS SDK for Go v2をアップデートする</title>
      <link>https://shogo82148.github.io/blog/2023/07/02/2023-07-02-update-aws-sdk-v2-with-grouped-version-updates-for-dependabot/</link>
      <pubDate>Sun, 02 Jul 2023 11:45:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/07/02/2023-07-02-update-aws-sdk-v2-with-grouped-version-updates-for-dependabot/</guid>
      <description>dependabot の更新グループ化（Grouped version updates）機能がパブリックベータになりました。
Grouped version updates for Dependabot public beta AWS SDK for Go v2の更新設定をしてみたのでメモ。
設定内容 グループ化したい依存をgroupsに設定します。 AWS SDK for Go v2関連のバージョンアップを、aws-sdkという名前でプルリクエストを出すよう設定しました。
updates: - package-ecosystem: gomod directory: &amp;#34;/&amp;#34; schedule: interval: daily groups: # AWS SDK for Go v2 関連のバージョンアップをまとめる aws-sdk: patterns: - github.com/aws/aws-sdk-go-v2 # `*` が空文字にマッチするのかよく分からなかったので・・・ - github.com/aws/aws-sdk-go-v2/* AWS SDK for Go v2 アップデートの困りごと AWS ではたくさんのサービスが公開されているので、毎日のようにサービスのアップデートが入り、 それに合わせて AWS SDK の更新が入ります。 dependabot のような自動アップデートの仕組みを入れておくと、本当に毎日のようにプルリクエストが来るのでとても大変です。 しかし、実際使う AWS のサービスなんて、全体に比べればほんの一部です。 ほとんどが自分の使っているサービスとは無関係な更新で、dependabot が送ってくるプルリクエストのほとんどはムダなものです。
AWS SDK for Go は v2 からマルチモジュール構成になり、サービス毎に go.</description>
    </item>
    <item>
      <title>GitHub Actionsの利用量をまとめる</title>
      <link>https://shogo82148.github.io/blog/2023/06/22/2023-06-22-github-actions-usage-report/</link>
      <pubDate>Thu, 22 Jun 2023 11:45:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/06/22/2023-06-22-github-actions-usage-report/</guid>
      <description>GitHub Actionsの利用量はsettings/billingから確認できます。
それはいいんですが、問題は今月分しか確認できないこと！
「先月は〇〇分使ったから上限いくらに設定しておくか〜〜」ということができません。 APIは見つけたので、取得スクリプトを組んでみました。
Get GitHub Actions billing for an organization 集計スクリプト GitHub REST APIをたたいて、結果をGoogle Spreadsheetにまとめます。 GitHub REST APIを叩く部分はGitHub CLIを使えばすぐにできるんですが、 Google Spreadsheetへの書き込みをシェルスクリプトで組むのはちょっと大変です。
今回はGoで書いてみました。
package main import ( &amp;#34;context&amp;#34; &amp;#34;encoding/json&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;io&amp;#34; &amp;#34;log&amp;#34; &amp;#34;net/http&amp;#34; &amp;#34;os&amp;#34; &amp;#34;time&amp;#34; &amp;#34;google.golang.org/api/sheets/v4&amp;#34; ) func main() { ctx := context.Background() token := os.Getenv(&amp;#34;GITHUB_TOKEN&amp;#34;) if token == &amp;#34;&amp;#34; { log.Fatal(&amp;#34;GITHUB_TOKEN is required&amp;#34;) } sheetID := os.Getenv(&amp;#34;SHEET_ID&amp;#34;) if sheetID == &amp;#34;&amp;#34; { log.Fatal(&amp;#34;SHEET_ID is required&amp;#34;) } org := os.</description>
    </item>
    <item>
      <title>Go 1.22で導入されるforループ変数の変更</title>
      <link>https://shogo82148.github.io/blog/2023/06/22/2023-06-22-go-loopvar-experiment/</link>
      <pubDate>Thu, 22 Jun 2023 11:45:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/06/22/2023-06-22-go-loopvar-experiment/</guid>
      <description>Go 1.21 Release Candidateで、 forループ変数のセマンティクス変更の予定をしりました。 導入の背景や影響について、WikiのLoopvarExperimentで説明されています。
地味にインパクトが大きそうだったので、内容を理解するために和訳しました。 といっても訳の大半はChatGPT ChatGPT May 24 Versionのものです。便利。 多少僕の修正も入ってます。
以下LoopvarExperimentのリビジョンdce06fbの和訳です。
Go 1.22では、Goチームはforループ変数のセマンティクスを変更し、繰り返し毎のクロージャやゴルーチンにおける意図しない共有を防止することを検討しています。 Go 1.21には、この変更の予備的な実装が含まれており、プログラムをビルドする際にGOEXPERIMENT=loopvarを設定することで有効になります。 変更の影響を理解するのに協力していただける方々には、GOEXPERIMENT=loopvarを使用して試してみていただき、遭遇した問題や成功した点についてご報告いただけると幸いです。
このページでは、変更に関するよくある質問にお答えします。
この変更を試すにはどうすればいいですか？ Go 1.21を使用して、以下のようにGOEXPERIMENT=loopvarを設定してプログラムをビルドします。
GOEXPERIMENT=loopvar go install my/program GOEXPERIMENT=loopvar go build my/program GOEXPERIMENT=loopvar go test my/program GOEXPERIMENT=loopvar go test my/program -bench=. ... この問題はどのようなものですか？ 以下のようなループを考えてみましょう：
func TestAllEvenBuggy(t *testing.T) { testCases := []int{1, 2, 4, 6} for _, v := range testCases { t.Run(&amp;#34;sub&amp;#34;, func(t *testing.T) { t.Parallel() if v&amp;amp;1 != 0 { t.</description>
    </item>
    <item>
      <title>GitHub経由で脆弱性報告してみた</title>
      <link>https://shogo82148.github.io/blog/2023/06/18/2023-06-18-report-vulnerability-via-github/</link>
      <pubDate>Sun, 18 Jun 2023 17:00:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/06/18/2023-06-18-report-vulnerability-via-github/</guid>
      <description>lestrrat-go/jwxに脆弱性を発見したので報告しました。
GHSA-rm8v-mxj3-5rmq Potential Padding Oracle Attack Vulnerability 「メールでやり取りするの面倒だなー」と思っていたら、いつのまにかGitHub経由で脆弱性報告できるようになってるじゃないですか。
Privately reporting a security vulnerability というわけで試してみたお話です。
背景 脆弱性報告の難しさ 脆弱性に関する情報は悪い人に悪用される可能性があるので、GitHubのIssueで報告するのは厳禁です。 公開レポジトリのIssueは広く公開されているので、悪い人に見つかってしまいます。
そのため、基本的に脆弱性の報告者はメンテナーと直接やり取りをする必要があります。 しかし、やり取りの方法に決まったルールはありません。 GitHubではセキュリティーポリシーをSECURITY.mdに記載するルールになっているので、運が良ければSECURITY.mdに連絡先が書いてあります。
Adding a security policy to your repository 運が悪ければ連絡先を頑張って探すところからはじめなければなりません。
まあ、たいていは連絡先としてメールアドレスが見つかるので、そこにメールを送ることになります。 ただし、メールというものは脆弱性の報告に特化したものではないので、どうやって情報をやり取りするかお互いに工夫が必要です。 僕はやったことないですが、修正のパッチをメーリングリストに送るんですかね。 大変そうです。
脆弱性と聞けば、CVEのような脆弱性情報データベースや、IPAの脆弱性関連情報の届出受付を思い浮かべるひとも多いでしょう。
共通脆弱性識別子CVE概説 - IPA 魚拓 脆弱性関連情報の届出受付 - IPA 魚拓 しかしこういった制度も、メンテナーの連絡先を管理しているわけではありません。 メンテナーの連絡先を探す手間も、メンテナーとのやり取りをする手間もかわりません。 （まあやったことないけど）
実際に報告した人のレポートにもありますが、「虎の威を借る」効果は多少期待できるでしょう。 CVEやIPAの名前だけ知っているというひとは多いでので、優先度を上げてくれるメンテナーも多いと思います。
脆弱性情報をIPAへ報告して修正されました #情報処理安全確保支援士 アカネちゃん、JVNに謝辞が載る：こうしす！　こちら京姫鉄道 広報部システム課 ＠IT支線（17） - ＠IT 逆に言えば、脆弱性レポートの段階では、その程度の効果しかありません。
脆弱性の概要 lestrrat-go/jwxのJWEのデコード機能を利用する場合に、本脆弱性の影響を受ける可能性があります。
AES-CBCで暗号化されたデーターを復号するにはパディングを取り除く必要があります。 このとき不正なパディングを見つけた場合に &amp;ldquo;failed to generate plaintext from decrypted blocks: invalid padding&amp;rdquo; というエラーを返す実装になっていました。</description>
    </item>
    <item>
      <title>なぜタイムスタンプをIDとして扱ってはいけないのか</title>
      <link>https://shogo82148.github.io/blog/2023/05/29/2023-05-29-why-you-should-not-use-timestamp-as-id/</link>
      <pubDate>Mon, 29 May 2023 17:00:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/05/29/2023-05-29-why-you-should-not-use-timestamp-as-id/</guid>
      <description>背景 マイナンバーカードの導入により、今まで役所で行っていた証明書の発行手続きを、コンビニに行えるようになりました。 このコンビニ証明書交付サービスにおいて、2023年5月9日誤って他人の戸籍全部事項証明書が発行されてしまうバグが明らかになりました。
開発元である富士通Japan株式会社は、この原因について以下のように説明しています。
川崎市様における証明書誤交付ついて（お詫び） 本事象の原因は、2か所のコンビニで、2名の住民の方が同一タイミング（時間間隔1秒以内）で証明書の交付申請を行った際に、後続の処理が先行する処理を上書きしてしまうことによるものです。
「時間間隔1秒以内」という条件から、 Twitterを始めとしたSNSでは「タイムスタンプ（秒）をIDにしているのでは？」という憶測が広まりました。 （もしくはIDに類するもの）
ファイル名が秒単位の時刻なので、1秒間に複数申請があれば、後の申請の出力に上書きされてしまう、ということなのか。どうしてこれでうまくいくと思ったのか＞富士通Japan https://t.co/FOvWWMdqar
&amp;mdash; Haruhiko Okumura (@h_okumura) May 10, 2023 「そんなことやるわけないじゃん」とは思ったのですが、自分自身はともかく周りのひとは・・・？と考えたら心配になってきました。 そういうわけで、なぜタイムスタンプをIDとして扱ってはいけないのか、注意喚起することにしました。 もう話のネタとして旬は過ぎた感はあるけど、文章に残しておくことが大事なんだ。
なぜタイムスタンプをIDとして扱ってはいけないのか さて、「秒単位のタイムスタンプをIDに使う」という設計がなぜダメなのか考えていきましょう。
なお、今回の証明書誤交付の原因が「秒単位のタイムスタンプをIDに使ったため」と主張する意図はありません。 証明書発行システムの実装を例として、秒単位のタイムスタンプをIDに使った場合にどうなるか？という思考実験です。 実在のシステムとは関係ありません。
誕生日のパラドックス ダメな理由として挙げられるのは誕生日のパラドックスでしょう。
誕生日のパラドックス - Wikipedia たとえば、小中学校のクラスに同じ誕生日のペアがいたら、珍しいこともあるもんだ！と感じませんか？ 実はそんなに珍しいことではないというのが誕生日のパラドックスです。 クラスに23人いれば、その中に「同じ誕生日である二人組」が50％以上の確率で存在します。
誕生日のパラドックスを証明書発行システムに当てはめて考えてみましょう。 ユーザーがいつ証明書発行を行うかわからないので、ユーザーは一年の中のランダムな時刻に証明書発行を行うと仮定します。 年間n人のユーザーが利用した場合にIDが重複する確率は、以下のプログラム（雑）で計算できます。
# python n = 60*60*24*365 p = 1.0 for i in range(n): p = p * (n - i) / n print(i, 1-p) 実行してみると年間6612人利用でIDが重複する確率が50%を超えます。 一年が3153.6万秒あることを考えると随分と少ないことがわかります。
... 6610 0.49986985152463326 6611 0.49997469552550755 6612 0.5000795334032722 6613 0.</description>
    </item>
    <item>
      <title>RE: Akamai x UNIQLOコラボTシャツに書かれたプログラムを解読してみる</title>
      <link>https://shogo82148.github.io/blog/2023/04/23/2023-04-23-akamai-peace-for-all/</link>
      <pubDate>Sun, 23 Apr 2023 17:00:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/04/23/2023-04-23-akamai-peace-for-all/</guid>
      <description>CDNサービスで有名なAkamaiがユニクロとコラボしてTシャツを作りました。
本日、Akamaiは @UNIQLO_JP のチャリティTシャツプロジェクト「PEACE FOR ALL」に参画したことを発表4月21日(金)より グローバルで発売されます。このデザインには人々の安全、安心を守りたいというAkamaiの願いが込められています。https://t.co/HVxINmoEzd#AkamaiPeaceForAll #Uniqlo #アカマイ pic.twitter.com/dIS9YOQVZM
&amp;mdash; アカマイ･テクノロジーズ (@akamai_jp) April 14, 2023 完全に二番煎じですが、Tシャツに描かれたコードを解読してみます。
Akamai x UNIQLOコラボTシャツに書かれたプログラムを解読してみる 解読してみる Tシャツに描かれたこのコード、PEACE FOR ALLに参画するために作られたのではなく、企業ブランドの一部として作られたもののようです。 Akamaiのウェブページをよく見てみると、背景にも同じコードが使われています。
コードの文脈をまったく意識せず切り貼りしたため、Tシャツのデザインでは失われてしまった部分があります（内容を理解できる人間にとってはちょっと残念）。 しかし、営業資料っぽいPDFに同じコードが利用されており、ここからなら十分に復元可能です。
クラウド投資のリターンを最大化 - Akamai EコーマスEマガジン 行ごとに分割して、同じ文字列が出現する箇所をつなぎ合わせると、以下のようなコードが浮かび上がります。
package main; import ( &amp;#34;fmt&amp;#34;; &amp;#34;html&amp;#34;; &amp;#34;log&amp;#34;; &amp;#34;net/http&amp;#34;; &amp;#34;strconv&amp;#34;; &amp;#34;strings&amp;#34;; &amp;#34;time&amp;#34; ); type ControlMessage struct { Target string; Count int64; }; func main() { controlChannel := make(chan ControlMessage);workerCompleteChan := make(chan bool); statusPollChannel := make(chan chan bool); workerActive := false;go admin(controlChannel, statusPollChannel); for { select { case respChan := &amp;lt;- statusPollChannel: respChan &amp;lt;- workerActive; case msg := &amp;lt;-controlChannel: workerActive = true; go doStuff(msg, workerCompleteChan); case status := &amp;lt;- workerCompleteChan: workerActive = status; }}}; func admin(cc chan ControlMessage, statusPollChannel chan chan bool) {http.</description>
    </item>
    <item>
      <title>Homebrewで過去のバージョンのMySQLクライアントをインストールしたい</title>
      <link>https://shogo82148.github.io/blog/2023/03/29/2023-03-29-downgrade-homebrew/</link>
      <pubDate>Wed, 29 Mar 2023 17:45:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/03/29/2023-03-29-downgrade-homebrew/</guid>
      <description>背景 Amazon Aurora（MySQL互換）のダンプを取ろうとしたところ、以下のメッセージが表示されてうまくいきませんでした。
% mysqldump hogehoge --skip-column-statistics --single-transaction --default-character-set=utf8mb4 mysqldump: Couldn&amp;#39;t execute &amp;#39;FLUSH TABLES WITH READ LOCK&amp;#39;: Access denied for user &amp;#39;root&amp;#39;@&amp;#39;%&amp;#39; (using password: YES) (1045) AWS RDSとMySQL 8.0.32の組み合わせが悪いらしく、同じ症状の人がいました。
AWS RDSにmysqldump: Couldn&amp;rsquo;t execute &amp;lsquo;FLUSH TABLES WITH READ LOCK&amp;rsquo;: Access denied for userが出て接続できなくなった mysqldump has incompatibile change in MySQL 8.0.32 手元のmysqldumpのバージョンを確かめてみると、思いっきり影響を受けるバージョンですね。
mysqldump Ver 8.0.32 for macos13.0 on x86_64 (Homebrew) MySQL 8.0.33で修正される見込みのようですが、2023年3月29日現在未リリースです。 リリースサイクルをよく把握してないですが、MySQL 8.0 Release Notesを見る限り、 1, 4, 7, 10月のリリースのようですね。 4月まで待てば解決・・・なんですが、そこまで待っていられないので、MySQL 8.0.31へダウングレードすることにしました。</description>
    </item>
    <item>
      <title>GitHubに接続したらWARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!と怒られる件</title>
      <link>https://shogo82148.github.io/blog/2023/03/24/2023-03-24-github-identification-has-changed/</link>
      <pubDate>Fri, 24 Mar 2023 17:13:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/03/24/2023-03-24-github-identification-has-changed/</guid>
      <description>TL;DR SSH経由でGitHubに接続したら、以下のメッセージが表示されました。
% ssh -T github.com @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @ WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED! @ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY! Someone could be eavesdropping on you right now (man-in-the-middle attack)! It is also possible that a host key has just been changed. The fingerprint for the RSA key sent by the remote host is SHA256:uNiVztksCsDhcc0u9e8BujQXVUpKZIDTMczCvj3tD2s. Please contact your system administrator. Add correct host key in /Users/shogo.</description>
    </item>
    <item>
      <title>「全人類兎化計画」の特設サイトがサブドメインで展開していてエラい</title>
      <link>https://shogo82148.github.io/blog/2023/01/02/2023-01-02-rabbit-plan/</link>
      <pubDate>Mon, 02 Jan 2023 00:07:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/01/02/2023-01-02-rabbit-plan/</guid>
      <description>「全人類兎化計画」がエラいと思ったのでメモとして残しておきます。
サブドメインで公開していて偉い https://t.co/gA7pxJK5iA
&amp;mdash; f96fd3a0-bdb9-4f10-b69f-8f765c1d341c ICHINOSEShogo (@shogo82148) January 1, 2023 こういう特設サイトを公開するときは、新しいドメインをとりがちですが、「全人類兎化計画」の特設サイトのドメインは hololivepro.com のサブドメインになっています。
「全人類兎化計画」の特設サイトも公開中！
🔽特設サイトはコチラ🔽https://t.co/po5ocM1VQ6#全人類兎化計画 #兎田ぺこら #ホロライブ
&amp;mdash; ホロライブプロダクション【公式】 (@hololivetv) January 1, 2023 ドメインは企業の貴重な財産なので、きちんとした管理が必要です。 うっかり手放すとフィッシング詐欺に利用されたり、アダルトサイトに改変されたりするので、一度ドメインをとったら永遠に管理し続けなければなりません。 管理対象が増えると管理も大変です。
一方サブドメインなら、廃止しても他人に取られることはありません。クローズ時に考慮することが減るので楽ちんです。
ホロライブプロダクションのコンテンツは、LPサイトも含めてすべて hololivepro.com のサブドメインになっていますね。エラい！
全人類兎化計画｜ホロライブプロダクション　rabbit-plan.hololivepro.com hololive SUPER EXPO 2023 &amp;amp; hololive 4th fes. Our Bright Parade Supported By Bushiroad　hololivesuperexpo2023.hololivepro.com hololive（ホロライブ）公式サイト ｜ ホロライブプロダクション　hololive.hololivepro.com HOLOSTARS（ホロスターズ）公式サイト　holostars.hololivepro.com hololive production OFFICIAL SHOP [ホロライブプロダクション公式ショップ]　shop.hololivepro.com ハイスクール・ホログラフィ｜ホロスターズ　highschool-holography.hololivepro.com みんなにも真似してほしいので紹介しました。 悪い見本はよく話題になるんですが、実際にサブドメインを利用している例はあまり見ないので。
ところで「全人類兎化計画」とはいったい・・・。</description>
    </item>
    <item>
      <title>GolangでQRコード、マイクロQRコード、rMQRコードのジェネレーターを作った</title>
      <link>https://shogo82148.github.io/blog/2023/01/01/2023-01-01-rmqr-generator-written-in-golang/</link>
      <pubDate>Sun, 01 Jan 2023 23:45:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2023/01/01/2023-01-01-rmqr-generator-written-in-golang/</guid>
      <description>GolangでQRコード、マイクロQRコード、rMQRコードのジェネレーターを作りました。
shogo82148/qrcode 作った理由は、「QRコードの復元能力はどういうマジックなんだろう？」と昔から気になっていたからです。 エンコードの方法は分かったものの、なぜ復元できるのかはわからぬままですが・・・。
また、2022年5月に発表されたrMQRコードにも対応しています。
デンソーウェーブ、細長く狭いスペースにも印字できる 長方形型の新しいQRコード「rMQRコード」を開発 使い方 qrcode.Encodeにバイト列を渡すと、 QRコードの画像をimage.Imageとして返します。 あと通常の画像と同じように扱えるので、image/pngなどで書き出してください。
package main import ( &amp;#34;bytes&amp;#34; &amp;#34;image/png&amp;#34; &amp;#34;log&amp;#34; &amp;#34;os&amp;#34; &amp;#34;github.com/shogo82148/qrcode&amp;#34; ) func main() { img, err := qrcode.Encode([]byte(&amp;#34;Hello QR Code!&amp;#34;)) if err != nil { log.Fatal(err) } var buf bytes.Buffer if err := png.Encode(&amp;amp;buf, img); err != nil { log.Fatal(err) } if err := os.WriteFile(filename, buf.Bytes(), 0o644); err != nil { log.Fatal(err) } } QRコードは日本生まれの規格なので、漢字を効率的に格納するモードがあります。 JIS X 0208の範囲内にある文字は自動的に漢字モードになります。
package main import ( &amp;#34;bytes&amp;#34; &amp;#34;image/png&amp;#34; &amp;#34;log&amp;#34; &amp;#34;os&amp;#34; &amp;#34;github.</description>
    </item>
    <item>
      <title>Perlのmodule_trueフラグを先取り！</title>
      <link>https://shogo82148.github.io/blog/2022/12/25/2022-12-25-feature-module-true/</link>
      <pubDate>Sun, 25 Dec 2022 04:57:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2022/12/25/2022-12-25-feature-module-true/</guid>
      <description>Perl Advent Calendar 2022に穴が空いてしまったときの 穴埋め用に温めていた記事です。 無事完走したので公開してしまいます。
v5.38からmodule_true feature pragmaというのが入る予定らしいので試してみました。 v5.38は未リリースなので、開発版のv5.37.5で検証しています。
今まで挙動 Perlモジュールの末尾に1;という謎の記述を見たことはありませんか？
# SomeModule.pm package SomeModule; sub import { warn &amp;#34;You imported a module!\n&amp;#34;; } 1; どこかに代入しているわけでもないので、ムダな一行に見えます。 しかしこの一行がないとモジュールの読み込みに失敗する場合があります。 以下のように1;を削除して、このモジュールを読み込んでみましょう。
# SomeModule.pm package SomeModule; sub import { warn &amp;#34;You imported a module!\n&amp;#34;; } # program.pl use FindBin; use lib &amp;#34;$FindBin::Bin&amp;#34;; use SomeModule; $ perl program.pl SomeModule.pm did not return a true value at program.pl line 3. BEGIN failed--compilation aborted at program.pl line 3.</description>
    </item>
    <item>
      <title>Perl v5.38のPERL_RAND_SEED環境変数を先取り！</title>
      <link>https://shogo82148.github.io/blog/2022/12/25/2022-12-25-perl-rand-seed/</link>
      <pubDate>Sun, 25 Dec 2022 00:00:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2022/12/25/2022-12-25-perl-rand-seed/</guid>
      <description>Perl Advent Calendar 2022無事完走しました！ ＼( ‘ω’)／ウオオオオオアアアーーーッ！ 参加してくださった皆様ありがとうございました。
じつはAdvent Calendarに穴が空いたときのために、いくつかネタを用意しておきました。 もう穴埋めは必要なくなったので公開してしまいます。
開発版のPerl 5.37.3に乱数のシード値を固定する機能が入りました。 来年公開予定のPerl 5.38.0にも導入されるはずです。
今までもsrand()の引数に数値を渡せばシード値の固定はできます。 今回入った修正は、これを環境変数経由で行えるようにするものです。 PERL_RAND_SEED 環境変数を使います。
Perlのコンパイル Perl 5.37.3は開発版なのでビルド済みのバイナリは配布されていません。 plenvを使っていればビルドは簡単です。 開発版の警告を抑制するために -Dusedevelオプションの指定を忘れずに。
動作確認 以下のような乱数を10個だけ出力するスクリプトを用意します。
use v5.36; for (1..10) { say rand(); } 毎回違う結果が返ってきました。
% perl random.pl 0.3062362396895 0.674135064563842 0.0578670173801008 0.202610859737383 0.818887900456577 0.806449494310058 0.941361073774114 0.418245360994739 0.213317030100743 0.850036874006719 % perl random.pl 0.177429965538071 0.0390786576058133 0.735923747570393 0.226016785340967 0.00169495133475905 0.0499404466099662 0.842366507879287 0.0750512089990352 0.765357514136131 0.0965085242066834 % perl random.pl 0.458207000353472 0.00957464109839634 0.335823093113628 0.969883105574759 0.789114886557474 0.0210666821658236 0.</description>
    </item>
    <item>
      <title>Perlで暗号論的乱数を生成する</title>
      <link>https://shogo82148.github.io/blog/2022/12/04/2022-12-04-crypt-random-in-perl/</link>
      <pubDate>Sun, 04 Dec 2022 00:00:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2022/12/04/2022-12-04-crypt-random-in-perl/</guid>
      <description>この記事は、Perl Advent Calendar 2022 の4日目の記事です。 3日目は@hitode909で「encode_jsonとdecode_json、どっちがどっちか覚えられないので、VSCodeのsnippetにjson_stringifyとjson_parseとして登録してしまう」でした。
とつぜんPerlで暗号論的乱数を作りたくなったことはありませんか？ 僕はあります。 というわけで実現方法を調べてみました。
背景 ことの発端はGitHub Actionsのsave-stateとset-outputが非推奨になったことです。
GitHub Actions: Deprecating save-state and set-output commands actions-setup-perlでこのコマンドを使っているので、この変更に対応する必要があります。 代わりの方法として$GITHUB_STATE, $GITHUB_OUTPUT環境変数が用意されました。 ここにファイルパスが指定されるので、指定されたファイルへ所定のフォーマットで書き出せ、とのことです。 この「所定のフォーマット」の要件のひとつに暗号論的乱数があり、Perlで暗号的乱数を生成することになったのです。
単なる乱数で良ければ組み込み関数にrand関数があります。 しかしこれはperldocにも書いてあるとおり、セキュリティが重要な場面では使うべきではありません。
rand - perldoc.jp rand は暗号学的に安全ではありません。 セキュリティ的に重要な状況でこれに頼るべきではありません。
残念なことに今回はセキュリティ的に重要な状況なのです。
暗号論的乱数を作る あまり依存モジュールを増やしたくなかったので、OSの機能を直接呼び出す方針で考えました。
/dev/urandom を使う Windows APIを呼び出す syscall を使う OpenSSLを使う /dev/urandom を使う Linuxをちょっとかじった最初に思い浮かぶ方法でしょう。 Linuxには/dev/urandomという特殊ファイルが用意されており、このファイルを読むことで暗号論的乱数が手に入ります。
use v5.36; my $n = 32; my $buf; open my $fh, &amp;#39;&amp;lt;&amp;#39;, &amp;#39;/dev/urandom&amp;#39; or die &amp;#34;failed to open /dev/urandom: $!&amp;#34;; read $fh, $buf, $n or die &amp;#34;failed to read /dev/urandom: $!</description>
    </item>
    <item>
      <title>ラバーダックデバッグのすゝめ</title>
      <link>https://shogo82148.github.io/blog/2022/12/01/2022-12-01-rubber-duck-debugging/</link>
      <pubDate>Thu, 01 Dec 2022 00:00:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2022/12/01/2022-12-01-rubber-duck-debugging/</guid>
      <description>この記事は、フラー株式会社 Advent Calendar 2022 の1日目の記事です。
さてさて、今年も始まりましたアドベントカレンダー。
ところでそもそもアドベントカレンダーって何だか知ってますか？ エンジニアが日替わりでブログを書くイベント・・・ではありません。 クリスマスまでの日数をカウントダウンする「アドベントカレンダー（物理）」が元ネタです。 カレンダーの日付部分が蓋になっていて、開けるとお菓子やおもちゃなどが出てくる仕掛けになっています。 クリスマスを待ちきれない子供がクリスマスまでの期間を楽しむためのアイテムなのです。
インターネットではお菓子やおもちゃは配れないので、代わりにブログ記事を投稿するようになったのが、 今のアドベントカレンダーの始まりです。
でもやっぱり（物理）欲しくないですか？？？？ というわけで買っちゃいました！
中国からの輸入品です！梱包雑！！箱がボロボロ！！！
ラバーダックデバッグのすゝめ Amazonで開いてトップにあったものをテキトーに ラバーダックとプログラミングには深い関係があるので、ラバーダックのアドベントカレンダーを選びました。 ラバーダックデバッグと言って、 コードを一行ずつアヒルちゃんに説明するというデバッグ手法があります。 相手が無生物であっても、こうやって説明することで頭の中が整理され、バグの発見につながる・・・と言われています。
アドベントカレンダー開封 ラバーダックデバッグの素晴らしさを伝えるため、フラーアドベントカレンダーに参加してくれた人にラバーダックをプレゼントします！ 以下の写真のようにカレンダーの日付部分にアヒルちゃんが入っています。 アドベントカレンダーを担当した日のアヒルちゃんはあなたものです！
さっそく12月1日分のアヒルちゃんはいただきましました。
微妙に剥げた塗装がイカしてます。 僕も今日からプログラミングに詰まったらこの子と相談してみます。
まとめ プログラミングに詰まったらラバーダックへ相談してみよう 中国の安物には気をつけろ TODO: 来年はもうちょっと良いやつを買う 明日2日は @chooblarinで「CSS Masks活用術」です。お楽しみに！
参考 ラバーダックデバッグ アドベント カレンダー 2022、クリスマス カウントダウン カレンダー アドベント カレンダー 2022 キッズ リトル イエロー ダック、アドベント カレンダー用おもちゃ、クリスマス アドベント カレンダー </description>
    </item>
    <item>
      <title>50音順(JIS X 4061)をGoで実装してみた</title>
      <link>https://shogo82148.github.io/blog/2022/11/20/2022-11-20-implement-jis-x-4061/</link>
      <pubDate>Sun, 20 Nov 2022 17:17:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2022/11/20/2022-11-20-implement-jis-x-4061/</guid>
      <description>今後Go言語でも50音順ソートしたくなるのでは、と虫の知らせがあったので作ってみました。
shogo82148/jisx4061 50音順とは何者か 50音順は「あいうえおかきくけこ・・・」あたりまでなら簡単なので、すごく簡単に思えるじゃないですか。 しかしここに濁音・半濁音・拗音・片仮名・長音記号etc. が入ってくるとだいぶややこしくなります。
濁音を含んだソート たとえば濁点の扱いを見てみましょう。 「さどう」「さとうや」「サトー」「さと」「さど」「さとう」「さとおや」という7つの単語を並べ替えます。 普通にGo標準のソートを使うと以下のようになります。
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;sort&amp;#34; ) func main() { list := []string{ &amp;#34;さどう&amp;#34;, &amp;#34;さとうや&amp;#34;, &amp;#34;サトー&amp;#34;, &amp;#34;さと&amp;#34;, &amp;#34;さど&amp;#34;, &amp;#34;さとう&amp;#34;, &amp;#34;さとおや&amp;#34;, } sort.Strings(list) fmt.Println(list) // Output: // [さと さとう さとうや さとおや さど さどう サトー] } 一見良さそうですが・・・「さと」と「さど」が遠く離れてしまいました。 このふたつは音が似ているので近くに配置したいです。
jisx4061を使ったソート shogo82148/jisx4061を使うと解決します。
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;github.com/shogo82148/jisx4061&amp;#34; ) func main() { list := []string{ &amp;#34;さどう&amp;#34;, &amp;#34;さとうや&amp;#34;, &amp;#34;サトー&amp;#34;, &amp;#34;さと&amp;#34;, &amp;#34;さど&amp;#34;, &amp;#34;さとう&amp;#34;, &amp;#34;さとおや&amp;#34;, } jisx4061.Sort(list) fmt.</description>
    </item>
    <item>
      <title>GitHub GraphQL のノードIDフォーマットが変わるらしい (続報)</title>
      <link>https://shogo82148.github.io/blog/2022/11/16/2022-10-19-perl-webdb-vol131/</link>
      <pubDate>Wed, 16 Nov 2022 17:17:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2022/11/16/2022-10-19-perl-webdb-vol131/</guid>
      <description>以前 GitHub GraphQL のノードIDフォーマットが変わるらしい に書いたように、 将来ノードIDフォーマットが変わるらしいらしいです。 これについて、旧式のノードIDを使用した場合に警告がでるようになった、とアナウンスがありました。
GraphQL Legacy Global ID Deprecation Message というわけで、どんな警告文がでるのか試してみました。
実際の挙動 試しに僕の名前を取得するクエリを実行してみると、以下のような警告文がでました。
$ gh api graphql -f query=&amp;#39;query { node(id: &amp;#34;MDQ6VXNlcjExNTczNDQ=&amp;#34;) { ... on User { id name login } } }&amp;#39; { &amp;#34;data&amp;#34;: { &amp;#34;node&amp;#34;: { &amp;#34;id&amp;#34;: &amp;#34;MDQ6VXNlcjExNTczNDQ=&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;ICHINOSE Shogo&amp;#34;, &amp;#34;login&amp;#34;: &amp;#34;shogo82148&amp;#34; } }, &amp;#34;extensions&amp;#34;: { &amp;#34;warnings&amp;#34;: [ { &amp;#34;type&amp;#34;: &amp;#34;DEPRECATION&amp;#34;, &amp;#34;message&amp;#34;: &amp;#34;The id MDQ6VXNlcjExNTczNDQ= is deprecated. Update your cache to use the next_global_id from the data payload.</description>
    </item>
    <item>
      <title>WEB&#43;DB PRESS Vol.131にPerlとAWS Lambdaの記事を寄稿しました</title>
      <link>https://shogo82148.github.io/blog/2022/10/19/2022-10-19-perl-webdb-vol131/</link>
      <pubDate>Wed, 19 Oct 2022 20:54:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2022/10/19/2022-10-19-perl-webdb-vol131/</guid>
      <description>WEB+DB PRESS Vol.131内の連載「第75回Perl Hackers Hub」に 「AWS Lambda入門……サーバレスでもPerlを活用しよう！」というタイトルで寄稿しました。 発売日は10月22日です。
WEB+DB PRESS Vol.131、どこよりも早い表紙画像です！
Rust入門、はじめてのElixir、実装して学ぶHTTP/3を大特集！10月22日発売です！#wdpress pic.twitter.com/uEIjuPYXu6
&amp;mdash; WEB+DB PRESS編集部 (@wdpress) October 4, 2022 前回寄稿したときがVol.97第43回Perl Hackers Hubなので、約5年ぶり2回目の寄稿です。
WEB+DB PRESS Vol.97にPerlとRedisの記事を寄稿しました 内容 AWS Lambdaの上でPerlを動かしてみよう！という内容です。 AWS::Lambdaモジュールの簡単なチュートリアルになっています。 今年の4月に提供が開始されたAWS Lambda Function URLsにも対応した内容です。
作るのはもちろん！アクセスカウンター！
AWS Lambdaでできるのは計算だけで、単体では大したことはできません。 AWS Lambdaの便利なところは、他のAWSのサービスと連携できることです。 今回寄稿した記事でもその便利さが伝わるといいなと思い、Paws (Perl SDK for AWS)を使って DynamoDBと連携するところまでを書きました。 やったねたえちゃん！カウンターの値が永続化されるよ！！！
まとめ というわけで、続きは紙面でお楽しみください。
WEB+DB PRESS Vol.131の「第75回Perl Hackers Hub」です。 発売日は10月22日。
参考 WEB+DB PRESS Vol.131 AWS Lambda AWS::Lambdaモジュール AWS Lambda Function URLs の提供開始: 単一機能のマイクロサービス向けの組み込み HTTPS エンドポイント AWS LambdaでCGIを蘇らせる </description>
    </item>
    <item>
      <title>AWS::Lambda v0.0.37リリースのお知らせ</title>
      <link>https://shogo82148.github.io/blog/2022/10/08/2022-10-08-p5-aws-lambda-v0.0.37-is-released/</link>
      <pubDate>Sat, 08 Oct 2022 23:10:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2022/10/08/2022-10-08-p5-aws-lambda-v0.0.37-is-released/</guid>
      <description>AWS::Lambda v0.0.37 をリリースしました。
12のリージョンでARM64互換レイヤーを公開 新たに12のリージョンでAWS LambdaのARM64(AWS Graviton2)対応が発表されました。
AWS Lambda Functions powered by AWS Graviton2 now available in 12 additional regions 今回公開されたのは、以下の12のリージョンです。
アフリカ (ケープタウン) af-south-1 アジアパシフィック (ソウル) ap-northeast-2 アジアパシフィック (ジャカルタ) ap-southeast-3 アジアパシフィック (香港) ap-east-1 アジアパシフィック (大阪) ap-northeast-3 カナダ(中部) ca-central-1 ヨーロッパ (パリ) eu-west-3 ヨーロッパ (ストックホルム) eu-north-1 ヨーロッパ (ミラノ) eu-south-1 中東 (バーレーン) me-south-1 南米 (サンパウロ) sa-east-1 米国西部(北カリフォルニア) us-west-1 以下の10のリージョンは2021年9月から利用可能だったので、約1年遅れの登場です。 (AWS Graviton2 プロセッサを利用する AWS Lambda 関数を使用して最大 34% 優れた料金/パフォーマンスを実現)
米国東部 (オハイオ) us-east-2 米国東部(バージニア北部) us-east-1 米国西部 (オレゴン) us-west-2 アジアパシフィック (ムンバイ) ap-south-1 アジアパシフィック (シンガポール) ap-southeast-1 アジアパシフィック (シドニー) ap-southeast-2 アジアパシフィック (東京) ap-northeast-1 欧州(フランクフルト) eu-central-1 ヨーロッパ (アイルランド) eu-west-1 ヨーロッパ (ロンドン) eu-west-2 これを受け、「AWS Lambda Perl Runtime の Arm64 互換レイヤーを公開しました 」 で公開したARM64互換レイヤーも、ARM64対応のリージョンで公開しました。 利用可能なARNは以下の通りです。</description>
    </item>
    <item>
      <title>AWS SDK v2 for Goが壊れた、Googleお前もか</title>
      <link>https://shogo82148.github.io/blog/2022/09/20/2022-09-20-aws-sdk-v2-and-googleapi-break-my-code/</link>
      <pubDate>Tue, 20 Sep 2022 10:40:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2022/09/20/2022-09-20-aws-sdk-v2-and-googleapi-break-my-code/</guid>
      <description>何もしていないのに壊れました。（ライブラリのアップデートはした）
AWS SDK v2 for Goが壊れた 該当のプルリクエストはこちら:
Bump github.com/aws/aws-sdk-go-v2/service/ssm from 1.27.13 to 1.28.0 in /lambda/metadata-updater shogo82148/private-rpm-repo#87 true を *bool 型に変換できないと怒られてしまいました。
./main.go:305:19: cannot use true (untyped bool constant) as *bool value in struct literal どうやらAWS SDK v2のこのコミットの影響でビルドが通らなくなったようです: aws/aws-sdk-go-v2@a13b7a4
diff --git a/service/ssm/api_op_GetParameter.go b/service/ssm/api_op_GetParameter.go index c7617dcfd0e..f58354b6528 100644 --- a/service/ssm/api_op_GetParameter.go +++ b/service/ssm/api_op_GetParameter.go @@ -39,7 +39,7 @@ type GetParameterInput struct { // Return decrypted values for secure string parameters. This flag is ignored for // String and StringList parameter types.</description>
    </item>
    <item>
      <title>git push のときに自動的にリモートブランチを作成する設定</title>
      <link>https://shogo82148.github.io/blog/2022/08/11/2022-08-11-git-push-auto-setup-remote/</link>
      <pubDate>Thu, 11 Aug 2022 16:08:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2022/08/11/2022-08-11-git-push-auto-setup-remote/</guid>
      <description>Git 2.37.0 から git push に --set-upstream origin が要らなくなったという話。 出典はこちらのツイート:
With the newest version of Git 2.37.0, you can run just &amp;quot;git push&amp;quot; to push new branches. No more &amp;quot;--set-upstream origin&amp;quot;. Enable with:
git config --global --add --bool push.autoSetupRemote true pic.twitter.com/1SzIqzvEFR
&amp;mdash; James Ide (@JI) July 12, 2022 ツイッターだけだと忘れてしまうので、検索用のメモ。
Git のデフォルトの設定では、 git push のときに upstream が設定されていないと「--set-upstream origin をつけて再実行してくれ」と 怒られます。 v2.37.0 から、これを自動的に行うオプションが追加されたらしいです。
$ git config --global --add --bool push.autoSetupRemote true 有効化すると自動的にリモートブランチを設定してくれます。</description>
    </item>
    <item>
      <title>落とし物の iPhone を交番に届けた話</title>
      <link>https://shogo82148.github.io/blog/2022/06/11/2022-06-11-wild-iphone-appeared/</link>
      <pubDate>Sat, 11 Jun 2022 18:56:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2022/06/11/2022-06-11-wild-iphone-appeared/</guid>
      <description>タイトルのとおり。 先日落とし物の iPhone を交番に届けました。 「落とし物を拾ったら交番に届けましょうね」と小さい頃からよく言い聞かされるけど、 意外とそういう機会ないよね？？？ということでメモ。
TL;DR 落とし物を拾ったら交番に届けよう (大事) 「拾った場所と時間」を聞かれるので、しっかり覚えておこう 拾った人がもらえる「ここまで来るのにかかった費用」「拾得物の5%から20%のお礼」「落とし主が見つからなかった場合は所有権」を受け取る権利をどうする(放棄するかしないか)を聞かれるので、決めておこう 野生の iPhone が現れた！ 駅の前を通りかかったときに、たまたまスマートフォンらしき物体がが落ちているのを発見。 とりあえず、現場の状況を記録しておこうと、一緒に歩いていた @nnsnodnb 先生に現場写真をとってもらいます。 この手順は意外と重要だったりする(かもしれない)。
拾い上げて確認してみるとどうやら iPhone のようです。
飲み会の帰りで深夜午前2時とかだったので、正直見なかったことにして帰りたいところでしたが、 モノが高価なので一応交番に届けるか・・・ということになりました。
交番での手続き 外から見たら誰もいないように見えましたが、ドアを開けると中から警察官のひとが出てきてくれました。
iPhone を見せ、落とし物を拾ったことを伝えると、「どこで拾いましたか？」 「拾ったのは何時頃ですか？」 と質問を受けました。 このときに、最初に撮った現場写真が役に立ちます。今どきのスマートフォンは写真を撮った位置や時刻を記録してますからね。 (ちゃんと覚えていたので使わなかったけど、ありがとう @nnsnodnb)
その後「手続きに10分ほど時間がかかりますが、よろしいですか？」と聞かれました。 特に断る理由もないので、そのまま手続きを進めます。 手続きに必要なのは、自分(落とし物を拾った人)の 住所 ・ 名前 ・ 電話番号 です。
さらに、落とし物を拾った人の権利についての説明を受けたあと、以下のような質問を受けます。
「ここまで来るのにかかった費用」「拾得物の5%から20%のお礼」「落とし主が見つからなかった場合は所有権」を受け取る権利はどうするか 所有権を保持した場合でも、 iPhone のような個人情報が入ったものは渡せないが、それでも良いか 落とし主に連絡先を伝えることに同意するか ひとつめの質問、本当に「どうするか」としか聞かれなかったので「え、どういう選択肢があるんだ？？？」と一瞬その場で考えたんですが、 よく考えるとお礼等を受け取るのはあくまでも「権利」なので、行使 するか 放棄 するか選べるんですね。 純粋に善意で届け出た(ｴﾗｲ)ので「権利は放棄する」「連絡先を伝えることに同意する」ことを伝えました。
以上のやり取りの内容を書面にまとめてくれるので、それに署名すれば手続きは完了です。
iPhone はもらえないという話 手続きの途中で「所有権を保持した場合でも、 iPhone のような個人情報が入ったものは渡せない」と説明を受けました。 書類の控えをあとから見返すと「遺失物法第35条の規定により、法定の期間が経過しても、あなたが受け取ることができない場合があります」とあります。 「遺失物法第35条」の規定は以下の通りです。
（所有権を取得することができない物件）
第三十五条　次の各号に掲げる物のいずれかに該当する物件については、民法第二百四十条若しくは第二百四十一条の規定又は第三十二条第一項の規定にかかわらず、所有権を取得することができない。
法令の規定によりその所持が禁止されている物（法令の規定による許可その他の処分により所持することができる物であって政令で定めるものを除く。） 個人の身分若しくは地位又は個人の一身に専属する権利を証する文書、図画又は電磁的記録（電子的方式、磁気的方式その他人の知覚によっては認識することができない方式で作られた記録をいう。以下同じ。） 個人の秘密に属する事項が記録された文書、図画又は電磁的記録 遺失者又はその関係者と認められる個人の住所又は連絡先が記録された文書、図画又は電磁的記録 個人情報データベース等（個人情報の保護に関する法律（平成十五年法律第五十七号）第十六条第一項に規定する個人情報データベース等をいう。）が記録された文書、図画又は電磁的記録（広く一般に流通している文書、図画及び電磁的記録を除く。） なるほど、iPhone は第4項の「個人の住所又は連絡先が記録された文書、図画又は電磁的記録」に該当しそうです。 「いやでもロックかかっていて見れないし・・・」とも思ったけど、この規定だとロックの有無は関係なさそうですね。</description>
    </item>
    <item>
      <title>動的ライブラリの検索パスに、実行バイナリからの相対パスを入れたい</title>
      <link>https://shogo82148.github.io/blog/2022/05/27/2022-05-27-configure-rpath-via-ldflags/</link>
      <pubDate>Fri, 27 May 2022 22:30:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2022/05/27/2022-05-27-configure-rpath-via-ldflags/</guid>
      <description>C や C++ で普通にコンパイルしたバイナリを実行すると、 /lib や /usr/lib といったディレクトリから動的ライブラリを検索して来ます。 この検索パスは LD_LIBRARY_PATH 環境変数や /etc/ld.so.conf 設定ファイルで設定可能です。
しかし、これらの方法ではすべての実行コマンドの設定が上書きされてしまいます。 「自分がコンパイルしたバイナリ」のみ、検索パスをいじりたい。 できれば実行バイナリの相対パスを指定したい。
そんな場面に遭遇したので、備忘録として残しておきます。
背景 以前 Redis をインストールしてセットアップする GitHub Action actions-setup-redis を公開しました。 「Redis くらい Docker でシュッとたちあがるやろ」という話もありますが、 Workflow の中で redis-cli を使いたい場合や、 macOS で実行したい場合 Docker は使えません。 これを解決するために、actions-setup-redis では プラットフォームに合わせてビルド済みのバイナリをダウンロードする、という手法をとっています。
Redis は v6.2.0 から OpenSSL を使った SSL/TLS 通信をサポートしています。 せっかくなので SSL/TLS 通信したいですよね (というかそういう要望がきた)。 そうすると当然 Redis と OpenSSL のリンクが必要です。
別のプロジェクトですが、過去に リンクしていた OpenSSL が OS イメージから削除される という経験をしていたので、 Redis に OpenSSL をバンドルして配布することにしました。
バンドルした OpenSSL と プリインストールされている OpenSSL のバージョンがあっている保証はありません (そもそもそういう場合に備えてバンドルしてる)。 グローバルな設定を書き換えてしまっては、既存の OpenSSL に依存しているコマンドが壊れてしまいます。 でも redis-cli を使うときだけはバンドルした OpenSSL を動的ロードしたい。</description>
    </item>
    <item>
      <title>Perl の extra_paired_delimiters を先取り！</title>
      <link>https://shogo82148.github.io/blog/2022/05/16/2022-05-16-perl-extra-paired-delimiters/</link>
      <pubDate>Mon, 16 May 2022 23:30:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2022/05/16/2022-05-16-perl-extra-paired-delimiters/</guid>
      <description>そういえば Perl 5.36 もうすぐリリースだなー、なんか面白い変更あるかなー、 と perldelta を眺めていたら、あった！！！！
というわけで Perl 5.36 から導入されるらしい extra_paired_delimiters を試してみました。
Paired Delimiters 他の多くの動的言語では、シングルクォーテーション(&#39;) やダブルクォーテーション(&amp;quot;)で囲うことで文字列を表します。 これは Perl でも同じです。
use 5.35.11; use utf8; say &amp;#39;Hello World&amp;#39;; say &amp;#34;Hello World&amp;#34;; でもこれだけだとシングルクォーテーションやダブルクォーテーションを含む文字列を表現しようとしたときに、 エスケープが必要になります。 これくらいの短い文字列であれば余裕ですが、あまり長くなると大変です。
use 5.35.11; use utf8; say &amp;#39;\&amp;#39;Hello\&amp;#39; &amp;#34;World&amp;#34;&amp;#39;; say &amp;#34;&amp;#39;Hello&amp;#39; \&amp;#34;World\&amp;#34;&amp;#34;; Perl にはそれを解決するための便利な記法があります。 例えば q(文字列) と書くと &#39;文字列&#39; と書いたのと同じ意味になります。 ( ) 以外にもいくつかペアがあり、以下はすべて同じ意味になります。
use 5.35.11; use utf8; say &amp;#39;Hello World&amp;#39;; say q(Hello World); say q&amp;lt;Hello World&amp;gt;; say q[Hello World]; say q{Hello World}; この記法が便利なのは「カッコの対応をチェックしてくれる」という点です。 例えば q((Hello) World) という文字列の場合、ナイーブな実装であれば (Hello までが文字列として判定されてしまうでしょう。 しかし Perl は賢いので、 (Hello) の先頭と末尾のカッコが対応していることを認識し、 (Hello) World をひとつの文字列として扱ってくれます。</description>
    </item>
    <item>
      <title>本名の英語表記を姓名の順に統一していくぞという話</title>
      <link>https://shogo82148.github.io/blog/2022/05/06/2022-05-06-canonicalizing-my-name/</link>
      <pubDate>Fri, 06 May 2022 07:36:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2022/05/06/2022-05-06-canonicalizing-my-name/</guid>
      <description>本名の英語表記を「姓-名」の順に統一していくぞ、という決意(？) 表明です。 戸籍ネームを名乗るときは「ICHINOSE Shogo」で統一していこうと思います。
背景 日本では戸籍や住民票など、公的な文章では「姓-名」の順番で名前を扱います。日常生活でも同様です。 僕もフルネームで名乗るときは「一野瀬 翔吾」と名乗っています。 (日本語が母語でないひとのために一応補足しておくと、「一野瀬」が姓、「翔吾」が名です)
一方、英語を母国語として使っている国では、名前は「名-姓」の順番にすることが多いです。 その文化に合わせて、日本人であっても英語で自己紹介する場合 &amp;ldquo;My name is Shogo Ichinose.&amp;rdquo; のように「名-姓」の順番で名乗っている人も多いでしょう。
ただ、これにはいろんな意見があって「本人の国の文化に合わせるべき」 つまり「日本人の紹介をするときは、英語で話す場合であっても 名-姓 を使おう」という人もいます。 こういう意見は僕が中学校で英語を学び始めたことからあった気がします。
この意見を聞いて「なるほど、そのとおりだな」と感じたので、「姓-名」を使っていこうと思ったのですが、 当時は「名-姓」で表記されている書籍もたくさんありました。 英語の勉強を始めたばかりの僕は混乱していしまい、名前を書くときの気分によって「姓-名」「名-姓」が混在する、 という状況がつい最近まで続きました。 特に GitHub を使うようになってからは、 LICENSE ファイルの copyright 表記でさんざん迷いました。
そして統一へ 「まあ、名乗るときは基本 shogo82148 だからいっか」とずっとそのままだったんですが、 「公用文書に名前をローマ字表記をする場合は『姓-名』とする」というニュースを見て、改めて考え直すことにしました。 (普段ニュース興味ないから、知ったのは報道から2年半後の今・・・)
ローマ字表記「姓→名」、来年１月スタート　国の公文書 今までイマイチ決断できなかった理由のひとつに「Ichinose Shogo」だと極稀に Shogo が姓だと思う人がいる、というのがありました。 この申し合わせでは、姓と名の区別が必要なときの書き方も示されています。
各府省庁が作成する公用文等において日本人の姓名をローマ字表記する際に，姓と名を明確に区別させる必要がある場合には，姓を全て大文字とし（YAMADA Haruo）， 「姓―名」の構造を示すこととする。
長いものには巻かれろということで、姓を全て大文字として「ICHINOSE Shogo」の表記でいこう、と決めた次第です。
まとめ LICENSE ファイルの copyright 表記に「姓-名」「名-姓」が混在していたので、 「ICHINOSE Shogo」に統一することにしました。
もちろんこれは僕の個人的なポリシーです。みなさんはご自身の好きな名前を名乗ってください。
参考 外来語の取扱い、姓名のローマ字表記について 外来語の取扱い、 姓名のローマ字表記について（平成12年12月26日文化庁次長通知） 公用文等における日本人の姓名のローマ字表記について（令和元年10月25日関係府省庁申合せ） 公用文等における日本人の姓名のローマ字表記に関する関係府省庁連絡会議 公用文等における日本人の姓名のローマ字表記について（令和元年10月25日関係府省庁申合せ） ローマ字表記「姓→名」、来年１月スタート　国の公文書 </description>
    </item>
    <item>
      <title>jq の引数を省略したときの挙動が違う件</title>
      <link>https://shogo82148.github.io/blog/2022/04/25/2022-04-25-jq-program/</link>
      <pubDate>Mon, 25 Apr 2022 20:28:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2022/04/25/2022-04-25-jq-program/</guid>
      <description>JSONを加工するときに jq は必須の存在になりました。 jqハンドブック なんてものが発売されるくらいですからね。
そんな jq なんですが、@Gaku07jp が AWS CloudShell 上で 期待どおりに動かない、と困ってました。 なんでこんな挙動になるのかなーと気になったので、調査してみたメモです。
症状 問題となったのはこんな感じのシェルスクリプトです。
FOO=$(echo &amp;#39;{}&amp;#39; | jq) 普段開発で使用している macOS 上では FOO={} と展開されるのですが、 CloudShell 上では jq のヘルプメッセージが表示されます (2022-04-25現在)。
# CloudShell 上 $ FOO=$(echo &amp;#39;{}&amp;#39; | jq) jq - commandline JSON processor [version 1.5] Usage: jq [options] &amp;lt;jq filter&amp;gt; [file...] (...snip...) 原因 直接の原因は引数を省略してしまったことです。 jq の第一引数には jq の式が必要です。単に整形したい場合は jq . とすればOKです。
FOO=$(echo &amp;#39;{}&amp;#39; | jq .) macOS と CloudShell の違い スクリプトが動かない直接の原因はわかったものの、同じ jq なのに、なぜこのような違いが生まれるのか気になりますよね？ というわけでソースコードを追ってみました。</description>
    </item>
    <item>
      <title>EOL間近の AWS Lambda Runtimes を探すスクリプト</title>
      <link>https://shogo82148.github.io/blog/2022/04/19/2022-04-19-check-your-aws-lambda-runtimes/</link>
      <pubDate>Tue, 19 Apr 2022 20:28:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2022/04/19/2022-04-19-check-your-aws-lambda-runtimes/</guid>
      <description>「[要対応] AWS Lambda における Python 3.6 のサポート終了 | [Action Required] AWS Lambda end of support for Python 3.6」というメールを受け取ったので、その対応メモ。
背景 調査自体は簡単です。親切なことに送られてきたメールにやり方がバッチリ記載されています。
次のコマンドは、AWS CLI [3] を使用して、特定のリージョン内の Python 3.6 を使用しているすべての関数を一覧表示する方法を示しています。お客様のアカウント内のこうした関数すべてを確認するには、リージョンごとに次のコマンドを繰り返してください。
以下のコマンドを叩くだけ。
aws lambda list-functions \ --function-version ALL \ --region us-east-1 \ --output text \ --query &amp;#34;Functions[?Runtime==&amp;#39;python3.6&amp;#39;].FunctionArn&amp;#34; ただ、「リージョンごとに次のコマンドを繰り返してください」とあるんですよね。 えっと・・・AWSって一体いくつリージョンあるんだっけ・・・？ このメールを書いた人は自社のリージョン数を把握しているんでしょうか？ 管理しているAWSアカウントも複数あるので、全リージョン分繰り返すなんて不毛です。
調査方法 そういうわけで簡単なシェルスクリプトを書きました。
#!/bin/bash ​ for ACCOUNT in $(perl -nle &amp;#39;print $1 if /^[[](?:profile\s+)?([^]]+)/&amp;#39; ~/.aws/config); do for REGION in $(aws ec2 describe-regions --region us-east-1 --profile &amp;#34;$ACCOUNT&amp;#34; --output text --query &amp;#34;Regions[].</description>
    </item>
    <item>
      <title>RFC9226 Bioctal: Hexadecimal 2.0 の Go 実装を書いてみた</title>
      <link>https://shogo82148.github.io/blog/2022/04/15/2022-04-15-implement-bioctal/</link>
      <pubDate>Fri, 15 Apr 2022 20:44:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2022/04/15/2022-04-15-implement-bioctal/</guid>
      <description>COVID-19 のワクチン接種3回目の副反応におびえているいっちーです。 摂取から5時間経ちましたが、まだ特に症状は表れていません。 翌朝が怖い。
さて、副反応への恐怖を少しでも紛らわせようと、 RFC9226 Bioctal: Hexadecimal 2.0 を実装してみた、というお話です。
shogo82148/go-bioctal RFC9226 Bioctal: Hexadecimal 2.0 4/1 に公開されていることから分かる通り、Joke RFC です。 実用性はありません・・・が、実装することは可能です。
今年のジョークRFC「16進数2.0」。16進数を表記するには0から9の数字にABCDEFを加えた物が一般的だが、01234567cjzwfsbvにする事で、数字かどうかで最上位bitがすぐ分かり、なんとなく形が似た文字から下3bitがすぐに連想できる為humanのbrain cyclesを抑えられるという内容https://t.co/BsmKFcqv4J
&amp;mdash; Fadis (@fadis_) April 2, 2022 一般的な16進数の変換に使われる文字を、下位3bit が同じもの同士が縦に並ぶよう配置すると、以下のようになります。
0 1 2 3 4 5 6 7 8 9 A B C D E F 下の段はアルファベットが入るのに、8, 9 だけが数字で不自然ですね(？) というわけで、下段を英字だけにしたものが Bioctal です。
0 1 2 3 4 5 6 7 c j z w f s b v 一般的に人間が一度に覚えられる物事の数は 7±2 と言われています。 16個も文字とそれに対応するbit列を覚えるのは大変です。</description>
    </item>
    <item>
      <title>マイナンバーカードの住所変更したときの備忘録</title>
      <link>https://shogo82148.github.io/blog/2022/03/19/2022-03-19-change-address-of-individual-number-card/</link>
      <pubDate>Sat, 19 Mar 2022 20:44:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2022/03/19/2022-03-19-change-address-of-individual-number-card/</guid>
      <description>謎の個人ブログの「同じPCトラブルが出た人の為に備忘録を残しておきます」の頼もしさは異常
PCトラブル以外で人生とかも言及しといて欲しい
&amp;mdash; とあるコンサルタント (@consultnt_a) March 6, 2022 ちょっと明日マイナンバーカードの住所変更してくるから人生の備忘録として残しておくね・・・
&amp;mdash; f96fd3a0-bdb9-4f10-b69f-8f765c1d341c IchinoseShogo (@shogo82148) March 6, 2022 と書き込んだのをすっかり忘れていたのでやっていきます。
住所書き換えの手順 いろいろあって千葉県柏市柏の葉キャンパスから新潟県新潟市に引っ越したので、人生の備忘録として残しておきます。
「いろいろ」の詳細はそのうち書くかもしれない。書かないかもしれない。 とりあえず悪い話ではないとだけ記しておきます。
持ち物リスト 引越し前の住所の転出証明書 マイナンバーカード 利用者証明用パスワード (4桁の数字) マイナンバーカード署名用パスワード (6文字から16文字までの英数字) 僕は今回身分証明書としてマイナンバーカードを利用したましたが、もちろん運転免許証や保険証・パスポート等でもOKです。 まあ、マイナンバーカードを発行していたらどうせマイナンバーカードの住所変更も必要なので、 このリストが一番楽だと思います。
NEXT21 へ行く 新潟市中央区役所 のサービス窓口は NEXT 21 というビルに入っているので、そこに向かいます。
Google Map で調べたら自宅からバス10分、徒歩20分だったので、 「バスの平均待ち時間を考えれば大差ないな」との結論にいたり、徒歩で向かいました。 駅からだと倍くらいかかかると思うので、駅からならバスを利用したほうが良いかもしれません。
転入届を提出する NEXT 21 の二階にサービス窓口があるので、そこに転入届を出します。 エスカレーターで二階に上がったらお姉さんが待ち受けていたので、転入届を出しに来たことを伝えると、 さっと記入用紙を出してくれました。 やっぱりこれからの時期転入・転出が多いので慣れているんでしょうね。
自分名前と引越し前の住所と引越し後の住所等々を記入し窓口に提出します。 引越し前の役所でもらった転出証明書も忘れずに。 このとき身分証明書も必要になりますが、今回はマイナンバーカードを証明書として提出しました。
マイナンバーカードの住所表記を書き換える マイナンバーカードを身分証明書として提出したので、 こちらから特に何も言わずともマイナンバーカードの住所表記書き換えをやってくれました。 ただし担当が違うらしく「同じフロアにあるパスポートセンターで待っていてください」と言われたので、 指示にしたがって移動します。
10分ほど待っていたら窓口に呼び出されてマイナンバーカードの住所表記が終わっていました。
新しいマイナンバーカードの電子証明書を発行してもらう ここで注意が必要なのは「マイナンバーカードに印字された住所のみ変更される」という点です。 マイナンバーカードの電子証明書にも住所情報が書き込まれているのですが、 その変更には別途手続きが必要です。 (こう説明を受けた覚えがあるけど、一度発行した電子証明書を書き換えることは技術的に不可能なので、実際には新規証明書の発行かな？)
職員さんから「パスワード覚えていたらこのまま手続きできますよ」と案内されたので、 案内にしたがってパスワードを入力します。
利用者証明用パスワード (4桁の数字) マイナンバーカード署名用パスワード (6文字から16文字までの英数字) (QWERTYキーボードではなくABCD配列だったので打ちにくかった)</description>
    </item>
    <item>
      <title>Goの日時比較が覚えられない件</title>
      <link>https://shogo82148.github.io/blog/2022/02/23/2022-02-23-compare-time-in-golang/</link>
      <pubDate>Wed, 23 Feb 2022 22:49:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2022/02/23/2022-02-23-compare-time-in-golang/</guid>
      <description>Go言語の time.Time 型の比較は比較演算子が使えず、 Time.Before と Time.After を使う必要があります。 日本の Gopher あるあるだと思うんですが、これって覚えられないですよね・・・。 英語のネイティブスピーカーだと楽勝なんでしょうか。
よくわからなくって毎回ググっているので、対応表にまとめました。
対応表 大小関係 Go での記述 t == u ⇔ t.Equal(u) t &amp;gt; u ⇔ t.After(u) t &amp;lt; u ⇔ t.Before(u) t &amp;gt;= u ⇔ !t.Before(u) t &amp;lt;= u ⇔ !t.After(u) 以上
2023-10-24追記: Go 1.20 から Time.Compare が追加されました。 これを使うと以下のように書けます。
大小関係 Go での記述 t == u ⇔ t.Compare(u) == 0 t &amp;gt; u ⇔ t.Compare(u) &amp;gt; 0 t &amp;lt; u ⇔ t.</description>
    </item>
    <item>
      <title>AWS App Runner に Perl をデプロイして RDS につなげてみた</title>
      <link>https://shogo82148.github.io/blog/2022/02/13/2022-02-13-perl-on-aws-app-runner-connecting-vpc/</link>
      <pubDate>Sun, 13 Feb 2022 08:08:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2022/02/13/2022-02-13-perl-on-aws-app-runner-connecting-vpc/</guid>
      <description>AWS App Runner に！VPC との接続機能がやってきました！！
📣『VPC 内の RDBMS 使いたいから App Runner じゃなく ECS/Fargate 使ってますわ〜』という皆さまお待たせしました！！
本日から既存の App Runner サービスを含め、直接 VPC 内リソースにアクセスできるようになります！🎉🎉🎉https://t.co/SGDTD1kPCb 1/4 pic.twitter.com/tbVt47ORSI
&amp;mdash; Tori Hara (@toricls) February 9, 2022 Amazon RDSやAmazon ElastiCacheのような一部のサービスは VPCからの利用を前提としています。 VPCを利用することによりセキュリティーを担保しているのですが、 AWS App Runner のようなマネージドサービスと連携が難しいという欠点がありました。
しかし、今回の VPC connector サポートにより簡単に連携ができるようになりました。 というわけで、お試しで MySQL (on Amazon RDS) との連携を試してみました。
使う言語はもちろんPerl！
作るのはやっぱりアクセスカウンター！!
アクセスカウンターを用意する MySQL を使ったアクセスカウンターを知らないのでテキトーに作ります。 ファイルを直接操作するよりはずっと簡単ですね。 AWS App Runner に Perl をデプロイしてみた のときと同様、 ソースコードは shogo82148/perl-on-aws-app-runner に置いてあります。
こんな感じになりました。
# app.psgi use DBI; use 5.</description>
    </item>
    <item>
      <title>M1 Apple Silicon 移行記</title>
      <link>https://shogo82148.github.io/blog/2022/01/29/hello-apple-silicon-m1/</link>
      <pubDate>Sat, 29 Jan 2022 23:38:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2022/01/29/hello-apple-silicon-m1/</guid>
      <description>Apple M1 が登場してはや一年。 昨年末にはその強化版の M1 Pro / M1 Max が発表され、 Mac Book Pro / Air のラインナップも全て M1 に置き換わってしまいました。 使用しているツールが未対応だったこともあり、弊社ではインテル版を使い続けていたのですが、 今ではツールの M1 対応も進んできたので、徐々にM1への移行を進めています。
僕の手元にもようやく M1 Mac Book が回ってきたので、 何周か遅れている気はしますが、インテルからM1への移行やってみたよ(2022年1月版)ということで記録を残しておきます。
Homebrew 公式ドキュメントのインストール手順 に従って以下のコマンドを実行すればOKです。 インテルもM1も特に変わりはありません。
/bin/bash -c &amp;#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)&amp;#34; ただしドキュメントの冒頭に記載がある通り、インテルとM1とではインストール先が異なります。
This script installs Homebrew to its preferred prefix (/usr/local for macOS Intel, /opt/homebrew for Apple Silicon and /home/linuxbrew/.linuxbrew for Linux) so that you don’t need sudo when you brew install.
どうやら /usr/local への書き込みに root 権限が必要になったので、 /opt/homebrew へ移動したようです(要出典)。 /usr/local/bin にはデフォルトでパスが通ってますが、/opt/homebrew/bin には通っていないので、明示的に追加する必要があります。</description>
    </item>
    <item>
      <title>GitHub Actions を使って AWS SAM をデプロイしてみる</title>
      <link>https://shogo82148.github.io/blog/2022/01/02/deploy-aws-sam-with-github-actions/</link>
      <pubDate>Sun, 02 Jan 2022 17:23:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2022/01/02/deploy-aws-sam-with-github-actions/</guid>
      <description>dependabot を使って 依存ライブラリの更新に追従しているのですが、 API のようなデプロイが必要なものは当然ながらデプロイしないと意味がありません。 今までは手元でデプロイしてきましたが、いい加減面倒になったので GitHub Actions を使った自動化をしてみました。
とりあえずお試しで shogo82148/holidays-jp にワークフローを設定してみました。 AWS SAM を使った API で、 データーベースや外部サービスとの連携のないシンプルなものです。 API 自体の使い方はこちらをどうぞ。
祝日 API を公開しました 単純にデプロイした場合の問題点 GitHub Actions の環境にはすでに AWS CLI, AWS SAM CLI, Go 等々ビルドに必要なものはすでにインストールされています。 あとは 「適切な権限を設定」 すればデプロイ自体は直ぐにできます。 ただまあ、この「適切な権限を設定」が一番の難所なので今まで二の足を踏んでいたわけです。
AWS SAM で作成した API は AWS Lambda によって実行されるのですが、 Lambda 関数に適切な権限を渡すために IAM Role を作成する必要があります。 つまり SAM アプリケーションのデプロイには「IAM を操作する権限」というかなり強力な権限を GitHub Actions に渡さなければなりません。
例えば GitHub Actions からデプロイ用 IAM ユーザーのアクセスキーが漏れたとしましょう。 IAM ユーザー自体の権限を最小限に絞っていたとしても、アクセスキーを入手した人は「IAM を操作する権限」を使って「AWS アカウントのすべての操作が可能な管理者ユーザー」を作ることができてしまいます。 いわゆる 権限昇格の脆弱性 です。 「管理者ユーザー」さえ作ってしまえば、EC2 のインスタンスを大量にたてて仮想通貨のマイニングをしたり、S3 から情報を抜き取ったりと、デプロイとは無関係のことも何でもできてしまいます。</description>
    </item>
    <item>
      <title>Perl の fc で遊んでみる</title>
      <link>https://shogo82148.github.io/blog/2022/01/02/perlfunc-fc/</link>
      <pubDate>Sun, 02 Jan 2022 17:23:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2022/01/02/perlfunc-fc/</guid>
      <description>この記事は、Perl Advent Calendar 2021 の穴埋め用の予備記事です。 当日まで担当者が決まらない日が何日もあってドキドキしましたが、いやー、なんとか埋まりましたね。 記事を投稿してくださった皆様ありがとうございました。
さて、今年は万が一枠が埋まらなかった場合に備えて下準備をしておきました。
Perl 5.34.0 の try-catch を触ってみる Perl 5.35.4 の defer を先取り Perl 5.35.5 の iterating over multiple values at a time を先取り Perl の文字列用ビット操作演算子を使ってみる この辺の記事たちですね。 カレンダーが埋まる見込みが立ったので放置していたのですが、実は調査だけしていたネタがひとつ残っています。 2022年のネタにしても良いんですが、どうせその頃には忘れているので今ここで供養してしまいましょう。
というわけで、今回触ってみたのは fc 関数 です。
特に断りのない限り 2021-12-24 現在の最新安定版 Perl 5.34.0 で動作確認をしています。
Case-Folding fc 関数 は Case-Folding を行う関数です。 そもそも Case-Folding って何？って話なんですが、日本語に対応する概念が存在しないので和訳が難しい・・・。 大雑把にいうと 「大文字・小文字の正規化」 をおこなう関数です。
例えばこのブログから &amp;ldquo;Case-Folding&amp;rdquo; という文字列を検索したくなったとしましょう。 表記ゆれがあるかもしれないので、大文字と小文字の違いは無視したい、 つまり &amp;ldquo;case-folding&amp;rdquo; や &amp;ldquo;CASE-FOLDING&amp;rdquo; も対象にしたいということはよくあると思います。
こんなときこそ fc 関数の出番です。 fc 関数を使うには feature プラグマで明示的に有効化が必要です。</description>
    </item>
    <item>
      <title>Bash と PowerShell の Polyglot を作る</title>
      <link>https://shogo82148.github.io/blog/2021/12/30/polyglot-of-bash-and-powershell/</link>
      <pubDate>Thu, 30 Dec 2021 21:12:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2021/12/30/polyglot-of-bash-and-powershell/</guid>
      <description>以前 Bash と PowerShell の Polyglot を書いたことがあったんですが、 「そういえば、どこにもメモってないな〜」と思い出したので、記録として残しておきます。
背景・目的 GitHub Actions には run というステップがあります。 任意のシェルスクリプトをかける便利なステップなんですが、 マトリックスビルドでマルチプラットフォームなワークフローを書いていると罠があります。
例えば以下のワークフローは 「Hello GitHub Actions!」とログに表示するだけの簡単なものです。
on: push: pull_request: jobs: job: strategy: fail-fast: false matrix: os: [ubuntu-latest, windows-latest, macos-latest] runs-on: ${{ matrix.os }} steps: - name: Ubuntu, macOS, Windows で実行する # shell: bash # Ubuntu, macOS でのデフォルト # shell: pwsh # Windows でのデフォルト run: | echo &amp;#34;Hello GitHub Actions!&amp;#34; コメントに書いたとおり Ubuntu, macOS では bash、Windows では PowerShell Core と デフォルトのシェルが環境によって異なります。 bash にも PowerShell にも echo コマンドが存在するので、この例はなぜか動いてしまうのですが、 もっと複雑な処理ではこうも行きません。</description>
    </item>
    <item>
      <title>Perl の文字列用ビット操作演算子を使ってみる</title>
      <link>https://shogo82148.github.io/blog/2021/12/24/perl-bitwise-operator/</link>
      <pubDate>Fri, 24 Dec 2021 09:56:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2021/12/24/perl-bitwise-operator/</guid>
      <description>この記事は、Perl Advent Calendar 2021 の24日目の記事です。 23日目は @hitode909 で「リポジトリ内のソースコードを機械的にリファクタリングし続けるスクリプトを作る」でした。
今日はちょっと前から使えるようになってたけど滅多にお世話になることのない、「文字列用ビット操作演算子」を触ってみたというお話です。
特に断りのない限り 2021-12-24 現在の最新安定版 Perl 5.34.0 で動作確認をしています。
旧来のビット演算子 Perl の多くの演算子には「数値用」と「文字列用」があります。 例えば比較演算子であれば ==, != は数値用、 eq, ne は文字列用といった具合です。
しかし、ビット操作用の演算子だけには、なぜかその区別がなかったのです。 以下は perlop Bitwise String Operators から引っ張ってきた例です。 | は論理和を求める演算子ですが、両辺の型に応じて結果が変わります。
use warnings; use strict; use feature qw/say/; say 150 | 105; # = 255 (0x96 | 0x69 = 0xFF) say &amp;#39;150&amp;#39; | 105; # = 255 say 150 | &amp;#39;105&amp;#39;; # = 255 say &amp;#39;150&amp;#39; | &amp;#39;105&amp;#39;; # = 文字列の &amp;#39;155&amp;#39; (ASCII) 結果:</description>
    </item>
    <item>
      <title>AWSジャカルタリージョンでPerlランタイムが利用可能になりました</title>
      <link>https://shogo82148.github.io/blog/2021/12/16/aws-lambda-is-available-in-ap-southeast-3/</link>
      <pubDate>Thu, 16 Dec 2021 20:19:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2021/12/16/aws-lambda-is-available-in-ap-southeast-3/</guid>
      <description>Perl Advent Calendar 2021 の途中ですが、ここで臨時ニュースです。
AWSジャカルタリージョン(ap-southeast-3) が利用可能になったので、 それに併せて AWS::Lambda Perl support for AWS Lambda Custom Runtime も公開しました。
SHOGO/AWS-Lambda-0.0.34/Changes 以下のランタイムが利用可能です。
arn:aws:lambda:ap-southeast-3:445285296882:layer:perl-5-34-runtime-al2-x86_64:1 arn:aws:lambda:ap-southeast-3:445285296882:layer:perl-5-32-runtime-al2-x86_64:1 Paws はこちら。
arn:aws:lambda:ap-southeast-3:445285296882:layer:perl-5-34-paws-al2-x86_64:1 arn:aws:lambda:ap-southeast-3:445285296882:layer:perl-5-32-paws-al2-x86_64:1 Arm64 アーキテクチャについては未対応のようなので、AWS側の対応が終わり次第追って追加します。
以上、臨時ニュースでした。
引き続き Perl Advent Calendar 2021 をお楽しみください。 まだカレンダーに若干の空きがあります。ブログ記事の投稿も大歓迎です！
参考 Now Open – AWS Asia Pacific (Jakarta) Region AWS::Lambda </description>
    </item>
    <item>
      <title>Perl 5.35.5 の iterating over multiple values at a time を先取り</title>
      <link>https://shogo82148.github.io/blog/2021/12/11/perl-iterating-over-multiple-values/</link>
      <pubDate>Sat, 11 Dec 2021 13:46:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2021/12/11/perl-iterating-over-multiple-values/</guid>
      <description>この記事は、Perl Advent Calendar 2021 の11日目の記事です。 10日目は @shogo82148 で「Perl 5.35.4 の defer を先取り」でした。
Perl 5.35.5 から利用可能になった iterating over multiple values at a time を試してみたお話です。
この構文は安定版にはまだ取り込まれていません。 特に断りのない限り 2021-12-11 現在の最新開発版 Perl 5.35.6 で動作確認をしています。
まずは Perl 5.35.6 をビルドする Perl 5.35.6 は開発版なのでビルド済みのバイナリは配布されていません。 しかし plenv を使っていれば特に難しいことはありません。 注意点は開発版の警告を抑制するために -Dusedevel オプションをしていることくらいです。
plenv install 5.35.6 -Dusedevel plenv local 5.35.6 ハッシュのキーとバリューのペアの一覧を出力する Perl7関連で色々とゴタゴタがあった 影響で、 Perlの今後の機能拡張は RFC(Requests For Comments) PPC(Proposed Perl Changes) の形式を取っていく事になりました（2024-06-18修正、RFCからPPCへ名前が変更されました） この機能はそのRFCの記念すべき（？）第一号です！
Multiple-alias syntax for foreach さて、プログラムを書いているとハッシュ（連想配列）の全要素に対して何か操作をしたいということは頻繁にあると思います。 これまで Perl には専用の構文はなく、以下のように while 文と each を組み合わせて書く必要がありました。</description>
    </item>
    <item>
      <title>AWS ClockBound で遊んでみた</title>
      <link>https://shogo82148.github.io/blog/2021/12/11/aws-cloud-bound/</link>
      <pubDate>Sat, 11 Dec 2021 00:00:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2021/12/11/aws-cloud-bound/</guid>
      <description>この記事は、フラー株式会社 Advent Calendar 2021 の11日目の記事です。 10日目は @nobux42 で「再読：リファクタリング・ウェットウェア」でした。
もう一ヶ月前になりますが、AWS から ClockBound という時間を扱うとても 地味な 有益なソフトウェアがリリースされました。
Amazon Time Sync Service now makes it easier to generate and compare timestamps 地味過ぎてネタかぶりしなさそうなので 時間は現代の情報通信の基盤なので、しっかりと検証していきましょう！ 日本ではNICTの 時空標準研究室 が標準時を定めています。 名前からしてかっこいい。
ClockBound とは 一言でいうとGoogleの TrueTime のAWS版です。 TrueTime は Google が自社のサーバーセンターに設置している非常に正確な時計です。 Google が提供しているリレーショナルデータベースである Cloud Spanner は、 リージョンをまたいだ一貫性を保証するために TrueTime から生成されたタイムスタンプを利用しています。
ようするに ClockBound を使えば、 AWSのインフラ上に Google Cloud Spanner Clone を構築できる！(？)、というわけですね。 すごい！
ClockBoundD のインストール なんかすごそうなことがわかったので、とりあえず動かしてみましょう。
ClockBound はタイムスタンプを提供するデーモン「ClockBoundD」と、ClockBoundD からタイムスタンプを取得するためのライブラリ「ClockBoundC」に分かれています。 タイムスタンプの提供元がないと始まらないので、まずは ClockBoundD をインストールしていきましょう。
現時点(2021-12-11現在)ではビルド済みのバイナリは提供されていないようなので、ソースコードからビルドします。 READMEの手順にしたがってやっていきます。</description>
    </item>
    <item>
      <title>Perl 5.35.4 の defer を先取り</title>
      <link>https://shogo82148.github.io/blog/2021/12/10/perl-defer/</link>
      <pubDate>Fri, 10 Dec 2021 00:00:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2021/12/10/perl-defer/</guid>
      <description>この記事は、Perl Advent Calendar 2021 の10日目の記事です。 9日目は @shogo82148 で「Perl 5.34.0 の try-catch を触ってみる」でした。
アドベントカレンダー25日もあると疲れてくるので、今日もかる～く行きましょう。 Perl 5.35.4 から利用可能になった defer 構文を触ってみたというお話です。
defer 構文は安定版にはまだ取り込まれていません。 特に断りのない限り 2021-12-10 現在の最新開発版 Perl 5.35.6 で動作確認をしています。
まずは Perl 5.35.6 をビルドする Perl 5.35.6 は開発版なのでビルド済みのバイナリは配布されていません。 しかし plenv を使っていれば特に難しいことはありません。 注意点は開発版の警告を抑制するために -Dusedevel オプションをしていることくらいです。
plenv install 5.35.6 -Dusedevel plenv local 5.35.6 defer を使ってみる 使い方はいつものように use feature プラグマで有効化し、 defer BLOCK とするだけ。
use strict; use warnings; use feature &amp;#39;say&amp;#39;; use feature &amp;#39;defer&amp;#39;; { say &amp;#34;This happens first&amp;#34;; defer { say &amp;#34;This happens last&amp;#34;; } say &amp;#34;And this happens inbetween&amp;#34;; } 1; 出力:</description>
    </item>
    <item>
      <title>Perl 5.34.0 の try-catch を触ってみる</title>
      <link>https://shogo82148.github.io/blog/2021/12/09/perl-try-catch/</link>
      <pubDate>Thu, 09 Dec 2021 00:00:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2021/12/09/perl-try-catch/</guid>
      <description>この記事は、Perl Advent Calendar 2021 の9日目の記事です。 8日目は @doikoji で「Getopt::Longのスペルが覚えられない俺はとうとう覚える努力を放棄してラッパーを作った」でした。
アドベントカレンダー25日もあると疲れてくるので、今日はかる～く行きましょう。 Perl 5.34.0 から利用可能になった try-catch 構文を触ってみたというお話です。
特に断りのない限り 2021-12-09 現在の最新安定版 Perl 5.34.0 で動作確認をしています。
とりあえず使ってみる 使い方は簡単です。 use feature プラグマで有効化し、 try BLOCK catch (VAR) BLOCK とするだけ。 最初の try ブロックの中で die すると catch ブロックが実行されます。
use strict; use warnings; use feature qw(try); try { die &amp;#34;dead&amp;#34;; } catch($e) { print &amp;#34;catch: $e&amp;#34;; } # no more &amp;#34;;&amp;#34; here !!! 1; 出力:
try/catch is experimental at try-catch.pl line 5.</description>
    </item>
    <item>
      <title>GitHub GraphQL のノードIDフォーマットが変わるらしい</title>
      <link>https://shogo82148.github.io/blog/2021/11/29/github-graphql-global-node-id-will-change/</link>
      <pubDate>Mon, 29 Nov 2021 23:08:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2021/11/29/github-graphql-global-node-id-will-change/</guid>
      <description>弊社では Terraform GitHub Provider を使って GitHub のレポジトリ管理・権限管理などを行っているのですが、 プロバイダーが repository_id を認識してくれない問題に遭遇しました。 原因を探ってみると GitHub GraphQL API に かなり大きな変更が入ること を知ったので、メモとして残しておきます。
グローバルノードID GraphQL API から扱えるすべてのオブジェクト (レポジトリ、ユーザー、etc) にはIDが振ってあります。
Using global node IDs 例えば僕 (@shogo82148) のノードIDは MDQ6VXNlcjExNTczNDQ= です。
$ curl https://api.github.com/users/shogo82148 | jq .node_id &amp;#34;MDQ6VXNlcjExNTczNDQ=&amp;#34; このノードIDを使って GraphQL のクエリを書くことが出来ます。
$ gh api graphql -f query=&amp;#39;query { node(id: &amp;#34;MDQ6VXNlcjExNTczNDQ=&amp;#34;) { ... on User { name login } } }&amp;#39; { &amp;#34;data&amp;#34;: { &amp;#34;node&amp;#34;: { &amp;#34;name&amp;#34;: &amp;#34;Ichinose Shogo&amp;#34;, &amp;#34;login&amp;#34;: &amp;#34;shogo82148&amp;#34; } } } ノードIDにはオブジェクトの種類の情報 (MDQ6VXNlcjExNTczNDQ= の例では「ユーザー」) も含まれているので、 GitHub が管理している全オブジェクトの中から一意に目的のノードを特定することが出来ます。</description>
    </item>
    <item>
      <title>Perl の JSON::PP での数値の扱いが変わっていた件</title>
      <link>https://shogo82148.github.io/blog/2021/10/14/json-pp-on-perl/</link>
      <pubDate>Thu, 14 Oct 2021 20:58:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2021/10/14/json-pp-on-perl/</guid>
      <description>Setup Perl environment の開発中は、 いろんなバージョンのPerlをビルドして、いろんなバージョンのPerlでコードを実行します。 そんな中でPerlのコアモジュールのひとつである JSON::PP の挙動が変わっていることに気が付きました。 なんでだろう？とずっと気になったまま放置してたんですが、ちょっと調べてみました。
JSON::PP の挙動の変化 Perl 5.26 と Perl 5.28 で以下のコードを実行してみます。
use feature say; use JSON::PP qw/encode_json/; my $answer = 42; say encode_json({ answer =&amp;gt; $answer }); say &amp;#34;Answer to the Ultimate Question of Life, the Universe, and Everything: $answer&amp;#34;; say encode_json({ answer =&amp;gt; $answer }); Perl 5.26 で実行した場合: [Wandbox]三へ( へ՞ਊ ՞)へ ﾊｯﾊｯ https://wandbox.org/permlink/tEJxPrlX8oaMbj6o
{&amp;#34;answer&amp;#34;:42} Answer to the Ultimate Question of Life, the Universe, and Everything: 42 {&amp;#34;answer&amp;#34;:&amp;#34;42&amp;#34;} Perl 5.</description>
    </item>
    <item>
      <title>AWS Lambda Perl Runtime の Arm64 互換レイヤーを公開しました</title>
      <link>https://shogo82148.github.io/blog/2021/10/06/aws-lambda-perl-runtime-on-arm64/</link>
      <pubDate>Wed, 06 Oct 2021 09:06:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2021/10/06/aws-lambda-perl-runtime-on-arm64/</guid>
      <description>AWS Lambda の Arm64 対応試してみた の続き。
Achieve up to 34% better price/performance with AWS Lambda Functions powered by AWS Graviton2 processor 前回は クロスコンパイルが簡単な Go で試してみました。 でもやっぱり・・・皆さん Perl を動かしたいですよね？
というわけでご用意しました。
ARN 一覧 ランタイム本体 ランタイム本体のビルド済みレイヤーです。使い方は過去記事をどうぞ。
AWS LambdaでCGIを蘇らせる
arn:aws:lambda:ap-northeast-1:445285296882:layer:perl-5-32-runtime-al2-arm64:1
arn:aws:lambda:ap-south-1:445285296882:layer:perl-5-32-runtime-al2-arm64:1
arn:aws:lambda:ap-southeast-1:445285296882:layer:perl-5-32-runtime-al2-arm64:1
arn:aws:lambda:ap-southeast-2:445285296882:layer:perl-5-32-runtime-al2-arm64:1
arn:aws:lambda:eu-central-1:445285296882:layer:perl-5-32-runtime-al2-arm64:1
arn:aws:lambda:eu-west-1:445285296882:layer:perl-5-32-runtime-al2-arm64:1
arn:aws:lambda:eu-west-2:445285296882:layer:perl-5-32-runtime-al2-arm64:1
arn:aws:lambda:us-east-1:445285296882:layer:perl-5-32-runtime-al2-arm64:1
arn:aws:lambda:us-east-2:445285296882:layer:perl-5-32-runtime-al2-arm64:1
arn:aws:lambda:us-west-2:445285296882:layer:perl-5-32-runtime-al2-arm64:1
Paws AWS SDK for Perl のビルド済みレイヤーです。ランタイム本体と合わせてご使用ください。
AWS SDK for Perl Lambda Layerを公開しました
arn:aws:lambda:ap-northeast-1:445285296882:layer:perl-5-34-paws-al2-arm64:1
arn:aws:lambda:ap-south-1:445285296882:layer:perl-5-34-paws-al2-arm64:1
arn:aws:lambda:ap-southeast-1:445285296882:layer:perl-5-34-paws-al2-arm64:1
arn:aws:lambda:ap-southeast-2:445285296882:layer:perl-5-34-paws-al2-arm64:1
arn:aws:lambda:eu-central-1:445285296882:layer:perl-5-34-paws-al2-arm64:1
arn:aws:lambda:eu-west-1:445285296882:layer:perl-5-34-paws-al2-arm64:1
arn:aws:lambda:eu-west-2:445285296882:layer:perl-5-34-paws-al2-arm64:1
arn:aws:lambda:us-east-1:445285296882:layer:perl-5-34-paws-al2-arm64:1
arn:aws:lambda:us-east-2:445285296882:layer:perl-5-34-paws-al2-arm64:1
arn:aws:lambda:us-west-2:445285296882:layer:perl-5-34-paws-al2-arm64:1
x86_64 レイヤー レイヤーの名前にCPUアーキテクチャーが入るようになったので、 わかりやすいよう x86_64 のレイヤー名も変更しました。 もちろん今までのレイヤー名でも同じものが利用可能です。</description>
    </item>
    <item>
      <title>AWS Lambda の Arm64 対応試してみた</title>
      <link>https://shogo82148.github.io/blog/2021/10/01/arm64-in-aws-lambda/</link>
      <pubDate>Fri, 01 Oct 2021 21:36:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2021/10/01/arm64-in-aws-lambda/</guid>
      <description>AWS Lambda の ARM サポートが発表されましたね。
Achieve up to 34% better price/performance with AWS Lambda Functions powered by AWS Graviton2 processor というわけで早速触ってみました。
祝日 API で試してみる 先日公開した祝日API で試してみました。
https://github.com/shogo82148/holidays-jp/pull/22 変更は実質2行です。簡単ですね！
diff --git a/holidays-api/Makefile b/holidays-api/Makefile index a39a3fa..0908902 100644 --- a/holidays-api/Makefile +++ b/holidays-api/Makefile @@ -1,6 +1,6 @@ .PHONY: build-HolidaysFunction build-HolidaysFunction: -	GOOS=linux GOARCH=amd64 go build -o $(ARTIFACTS_DIR)/bootstrap -tags lambda.norpc ./cmd/bootstrap +	GOOS=linux GOARCH=arm64 go build -o $(ARTIFACTS_DIR)/bootstrap -tags lambda.norpc ./cmd/bootstrap .PHONY: test test: diff --git a/template.</description>
    </item>
    <item>
      <title>GitHub Actions &#43; OIDC Token の情報をAWSのセッションタグに設定してみた</title>
      <link>https://shogo82148.github.io/blog/2021/09/24/github-actions-oidc/</link>
      <pubDate>Fri, 24 Sep 2021 13:58:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2021/09/24/github-actions-oidc/</guid>
      <description>GitHub Actions で ID Token が使えるようになったと話題ですね。
うおー！サイコー！！！！！ https://t.co/2stS4miUOD
&amp;mdash; Tori Hara (@toricls) September 15, 2021 Ok I blogged about it. That&amp;#39;s how excited I am. 1. Deploy this CFN template
2. Write this GHA workflow
3. Never worry about IAM users again
https://t.co/KJrr2Jw4bE pic.twitter.com/9IcocgurxP
&amp;mdash; Aidan W Steele (@__steele) September 15, 2021 AWS IAM が OpenID Connect (OIDC) を使った認証 (sts:AssumeRoleWithWebIdentity) に対応しているので、認証プロバイダ(IdP)を用意してあげればシークレットの登録が不要になるということらしいです。 これは便利！
セッションタグを渡したい これはまさに「AWS_SECRET_ACCESS_KEY を GitHub Actions secrets へ突っ込むのに疲れた俺達は」で実現したかったことですね。 このままだとせっかく作ったアクションが不要になりそうで悔しいので このアクションにずっと追加したかった機能があるのですが、OIDCトークンを使うと簡単に実装できそうだったので、お試しで追加してみました。</description>
    </item>
    <item>
      <title>祝日APIを公開しました</title>
      <link>https://shogo82148.github.io/blog/2021/09/04/holidays-api-is-released/</link>
      <pubDate>Sat, 04 Sep 2021 18:17:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2021/09/04/holidays-api-is-released/</guid>
      <description>プログラマーなら誰しも一度は祝日について頭を悩ませたことがあるでしょう(要出典)。
日付が固定ならまだ楽なんですが、「春分の日」「秋分の日」のように天体の運行によって決まる祝日があったり、 ハッピーマンデー制度によって「成人の日(一月の第二月曜日)」のような曜日固定の祝日があったり、 振替休日という概念があったりと、ちゃんと考えるとかなり面倒です。
更に面倒なのが国の施策によってたまに変更になるという点です。 東京オリンピックの延期で祝日が移動したのは記憶に新しいですね。 前年の 12 月 4 日に法律が公布されるという、カレンダーの印刷会社泣かせなスケジュール変更です。
2021 年の祝日移動について 東京五輪開催で夏の祝日が移動 〜各言語の祝日ライブラリの 2021 年の祝日対応を追ってみる〜 プログラムなら更新可能ですが、ライブラリとして組み込まれているとうっかり更新を忘れてしまうこともありますよね。 そういうわけで API として提供されていると嬉しいな、プログラミング言語に縛られることもないし、ということで作りました。
github.com/shogo82148/holidays-jp holidays-jp.shogo82148.com 使い方 パスに日付を入力して GET リクエストを投げるだけのシンプルな API です。
ある年の祝日一覧を取得する GET /{year} で year の祝日一覧を返します。 以下は 2021 年の祝日一覧を返す例です。
curl https://holidays-jp.shogo82148.com/2021 | jq . { &amp;#34;holidays&amp;#34;: [ { &amp;#34;date&amp;#34;: &amp;#34;2021-01-01&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;元日&amp;#34; }, { &amp;#34;date&amp;#34;: &amp;#34;2021-01-11&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;成人の日&amp;#34; }, { &amp;#34;date&amp;#34;: &amp;#34;2021-02-11&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;建国記念の日&amp;#34; }, (snip) { &amp;#34;date&amp;#34;: &amp;#34;2021-11-23&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;勤労感謝の日&amp;#34; } ] } ある月の祝日一覧を取得する GET /{year}/{month} で月の祝日一覧を返します。 以下は 2021 年 1 月の祝日一覧を返す例です。</description>
    </item>
    <item>
      <title>EC2 Instance Metadata Service と Amazon Time Sync Service で IPv6 エンドポイントが利用可能になりました</title>
      <link>https://shogo82148.github.io/blog/2021/08/30/ipv6-metadata-endpoint-and-ntp-are-available/</link>
      <pubDate>Mon, 30 Aug 2021 22:39:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2021/08/30/ipv6-metadata-endpoint-and-ntp-are-available/</guid>
      <description>今日はちょっとした小ネタを
dependabot が作ったプルリクエストを整理していたら AWS Go SDK のリリースノートに面白そうなリリースを発見。
Release v1.40.0 (2021-07-14)
aws/session: Support has been added for EC2 IPv6-enabled Instance Metadata Service Endpoints (#4006)
こんなところにも IPv6 の波が！
早速試してみようと思ったんですが、なかなかうまく行かない。 今日ようやくやり方がわかったのでメモしておきます。
インスタンスメタデータ IPv6 エンドポイントを有効化する リリースのアナウンスによるとインスタンスメタデータサービス(IMDS)の IPv6 エンドポイントは明示的に有効化する必要があるそうです。
IPv6 endpoints are now available for the Amazon EC2 Instance Metadata Service, Amazon Time Sync Service, and Amazon VPC DNS Server
To get started, you need to enable the IPv6 endpoint for IMDS on your EC2 Instances.</description>
    </item>
    <item>
      <title>Mackerelにおける「混乱した代理」問題に対応しよう</title>
      <link>https://shogo82148.github.io/blog/2021/08/26/confused-deputy-problem-on-mackerelio/</link>
      <pubDate>Thu, 26 Aug 2021 21:12:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2021/08/26/confused-deputy-problem-on-mackerelio/</guid>
      <description>最近 Mackerel の AWS インテグレーション機能にいくつかセキュリティ強化のアップデートが入りました。 (「最近」と言っても最も古いアップデートは 2 年前ですが・・・)
AWS インテグレーションで IAM ロールによる認証利用時の権限チェック頻度を変更しました ほか AWS インテグレーション CloudFront 連携で取得できるメトリックを追加しました ほか 【リリース予告】AWS インテグレーションの権限チェックを強化していきます AWS Step Functions インテグレーションをリリースしました　ほか これらのアップデートは「混乱した代理問題(Confused deputy problem)」に対応するものです。 僕が AWS インテグレーションの設定をしている際にふと 「この機能、攻撃に利用できるのでは？」 と思いついてしまったので、 Mackerel サポートに問題点を伝えて修正していただきました。
リリース記事に関連する AWS のドキュメントが貼ってありますが、正直 AWS のドキュメントは難しい・・・。 そういうわけで、Mackerel の AWS インテグレーションを例に「混乱した代理問題」を噛み砕いて解説しよう、というのが本記事の趣旨です。 (いちおう Mackerel のサポートから許可は頂いています。)
TL;DR 「詳しい解説とかいらない！」という方も、最低限これだけはやっておきましょう。
Mackerel の AWS インテグレーション を利用している場合、以下の項目を確認すること。
Mackerel の AWS インテグレーション設定のページ で各設定の「編集」をクリックし、ロール ARN に緑のチェックマークが入っていること 連携用の AWS IAM Role に External ID (外部 ID)が設定されていること 設定されていても Mackerel-AWS-Integration になっている場合、それは古い設定です。今すぐ更新してください！ AWS インテグレーションのような「アクセス権の委任」を使った機能を提供する場合は以下の点に注意すること。</description>
    </item>
    <item>
      <title>AWS Lambda に EFS をマウントして Perl CGI 完全復活</title>
      <link>https://shogo82148.github.io/blog/2021/06/13/aws-lambada-efs-and-perl/</link>
      <pubDate>Sun, 13 Jun 2021 22:39:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2021/06/13/aws-lambada-efs-and-perl/</guid>
      <description>AWS Lambda で CGI を蘇らせる で蘇った CGI には致命的な問題点がありました。
カウンターの値が永続化されない
この問題を Elastic File System(EFS) をマウントすることで解決したよ、というお話です。
Amazon Elastic File System for AWS Lambda もう一年前になるんですが、 AWS Lambda の環境に Elastic File System(EFS) をマウントできるようになりました。
新機能 – Lambda 関数の共有ファイルシステム – Amazon Elastic File System for AWS Lambda 従来 AWS Lambda でデーターを永続化するには DynamoDB, RDS, S3 といったデーターストアを別途用意する必要がありました。 ファイル書き込みができる領域として /tmp がありますが、 /tmp は 512MB に制限されていたり、永続化できなかったりと、用途は限定されます。 EFS がマウントできることによって実質これらの制限がなくなります。 プログラムからは普通のファイルとして見えるので、読み書きをするのも簡単です。
よし、じゃあ、 CGI の書き込み先として試してみるか！と思ったものの、 先のリリースを見つけたときには既に別の方がやってました。
懐かしの CGI 掲示板スクリプトを AWS Lambda ＋ EFS で動かしてみた AWS::Lambda を利用してもらって非常にありがたいのですが、作者が遅れをとるとは不覚・・・ 自ら二番煎じをする必要もないかと、ずっと放置していたのでした。</description>
    </item>
    <item>
      <title>AWS App Runner に Perl をデプロイしてみた</title>
      <link>https://shogo82148.github.io/blog/2021/06/06/perl-on-aws-app-runner/</link>
      <pubDate>Sun, 06 Jun 2021 06:41:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2021/06/06/perl-on-aws-app-runner/</guid>
      <description>先月 AWS App Runner という新サービスがリリースされました。
📣 新サービス #AWSAppRunner のローンチです！🚀
＼数クリックでソースコードやコンテナイメージをデプロイ！／
AWS Fargate より高い抽象度、あるいは AWS Lambda のようなスレッドではなくプロセスそのものを実行したかった方にぜひお試しいただきたいサービスです！1/nhttps://t.co/LPFNOP7CBT
&amp;mdash; Tori Hara (@toricls) May 18, 2021 既にたくさんのデプロイしてみた系の記事が公開されていますが、流石に(残念ながら？) Perl をデプロイしている人はいないですよね？ と言うわけで、ネタがかぶらないよう Perl でやってみましょう。
ソースコードは shogo82148/perl-on-aws-app-runner においてあります。
2022-02-13追加
NEW!! VPC への接続がサポートされ RDS へもつながるようになりました！！！
AWS App Runner に Perl をデプロイして RDS につなげてみた PSGI アプリを用意する Wikipedia の PSGI のページに書いてあった例をそのまま使います。
# app.psgi my $app = sub { return [200, [&amp;#39;Content-Type&amp;#39; =&amp;gt; &amp;#39;text/plain&amp;#39;], [&amp;#34;hello, world\n&amp;#34;]]; } Dockerfile を用意する PSGI アプリを起動するのに Plack を使用するので、 cpanfile に Plack への依存を書いておきます。</description>
    </item>
    <item>
      <title>Perl 5.34 がリリースされました</title>
      <link>https://shogo82148.github.io/blog/2021/05/22/perl-5.34-is-released/</link>
      <pubDate>Sat, 22 May 2021 15:44:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2021/05/22/perl-5.34-is-released/</guid>
      <description>Perl 5.34 がリリースされましたね。 と、言うわけで、 AWS::Lambda と actions-setup-perl に Perl 5.34 を追加しました。
AWS::Lambda AWS Lambda Layers の ARN 一覧はこちら。 具体的な使い方は過去の記事を参考にどうぞ。 もちろん大阪リージョンも入ってますよ！
Amazon Linux 2 ベース Perl ランタイム arn:aws:lambda:af-south-1:445285296882:layer:perl-5-34-runtime-al2:1 arn:aws:lambda:ap-east-1:445285296882:layer:perl-5-34-runtime-al2:1 arn:aws:lambda:ap-northeast-1:445285296882:layer:perl-5-34-runtime-al2:1 arn:aws:lambda:ap-northeast-2:445285296882:layer:perl-5-34-runtime-al2:1 arn:aws:lambda:ap-northeast-3:445285296882:layer:perl-5-34-runtime-al2:1 arn:aws:lambda:ap-south-1:445285296882:layer:perl-5-34-runtime-al2:1 arn:aws:lambda:ap-southeast-1:445285296882:layer:perl-5-34-runtime-al2:1 arn:aws:lambda:ap-southeast-2:445285296882:layer:perl-5-34-runtime-al2:1 arn:aws:lambda:ca-central-1:445285296882:layer:perl-5-34-runtime-al2:1 arn:aws:lambda:eu-central-1:445285296882:layer:perl-5-34-runtime-al2:1 arn:aws:lambda:eu-south-1:445285296882:layer:perl-5-34-runtime-al2:1 arn:aws:lambda:eu-west-1:445285296882:layer:perl-5-34-runtime-al2:1 arn:aws:lambda:eu-west-2:445285296882:layer:perl-5-34-runtime-al2:1 arn:aws:lambda:eu-west-3:445285296882:layer:perl-5-34-runtime-al2:1 arn:aws:lambda:me-south-1:445285296882:layer:perl-5-34-runtime-al2:1 arn:aws:lambda:sa-east-1:445285296882:layer:perl-5-34-runtime-al2:1 arn:aws:lambda:us-east-1:445285296882:layer:perl-5-34-runtime-al2:1 arn:aws:lambda:us-east-2:445285296882:layer:perl-5-34-runtime-al2:1 arn:aws:lambda:us-west-1:445285296882:layer:perl-5-34-runtime-al2:1 arn:aws:lambda:us-west-2:445285296882:layer:perl-5-34-runtime-al2:1 Paws レイヤー arn:aws:lambda:af-south-1:445285296882:layer:perl-5-34-paws-al2:1 arn:aws:lambda:ap-east-1:445285296882:layer:perl-5-34-paws-al2:1 arn:aws:lambda:ap-northeast-1:445285296882:layer:perl-5-34-paws-al2:1 arn:aws:lambda:ap-northeast-2:445285296882:layer:perl-5-34-paws-al2:1 arn:aws:lambda:ap-northeast-3:445285296882:layer:perl-5-34-paws-al2:1 arn:aws:lambda:ap-south-1:445285296882:layer:perl-5-34-paws-al2:1 arn:aws:lambda:ap-southeast-1:445285296882:layer:perl-5-34-paws-al2:1 arn:aws:lambda:ap-southeast-2:445285296882:layer:perl-5-34-paws-al2:1 arn:aws:lambda:ca-central-1:445285296882:layer:perl-5-34-paws-al2:1 arn:aws:lambda:eu-central-1:445285296882:layer:perl-5-34-paws-al2:1 arn:aws:lambda:eu-south-1:445285296882:layer:perl-5-34-paws-al2:1 arn:aws:lambda:eu-west-1:445285296882:layer:perl-5-34-paws-al2:1 arn:aws:lambda:eu-west-2:445285296882:layer:perl-5-34-paws-al2:1 arn:aws:lambda:eu-west-3:445285296882:layer:perl-5-34-paws-al2:1 arn:aws:lambda:me-south-1:445285296882:layer:perl-5-34-paws-al2:1 arn:aws:lambda:sa-east-1:445285296882:layer:perl-5-34-paws-al2:1 arn:aws:lambda:us-east-1:445285296882:layer:perl-5-34-paws-al2:1 arn:aws:lambda:us-east-2:445285296882:layer:perl-5-34-paws-al2:1 arn:aws:lambda:us-west-1:445285296882:layer:perl-5-34-paws-al2:1 arn:aws:lambda:us-west-2:445285296882:layer:perl-5-34-paws-al2:1 合わせて Docker Image も公開済みです。</description>
    </item>
    <item>
      <title>Gradle Ribbonizer Plugin を Maven Central へ移行してみた</title>
      <link>https://shogo82148.github.io/blog/2021/05/18/hello-maven-central/</link>
      <pubDate>Tue, 18 May 2021 08:17:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2021/05/18/hello-maven-central/</guid>
      <description>全国の Android エンジニアの皆さんこんにちは。 弊社では過去に maskarade/gradle-android-ribbonizer-plugin という Gradle Plugin を使っていたのですが、 メンテナンスされている様子がないので、フォークして自前のパッチを当て shogo82148/gradle-android-ribbonizer-plugin で開発を続けていました。 (何をするプラグインなのかは本題ではないのでまた今度) コンパイルした jar ファイルは jcenter で公開していたのですが、皆さんご存知の通り 5/1 を持って閉鎖してしまいました。
Into the Sunset on May 1st: Bintray, GoCenter, and ChartCenter 猶予期間として 1 年はダウンロード可能ですが、既に新規のアップロードはできなくなっています。 そういうわけで、重い腰を上げて Maven Central へ移行することにしました。
リリース作業 Maven Central Repository への公開手順(Gradle 版) の記事を参考に以下の手順でリリースを進めます
sonatype の JIRA で issue を通してリポジトリ作成を依頼 GnuPG で jar を署名できる環境を作成 Gradle プラグインでリポジトリへ登録 Repository Manager で Maven Central Repository へリリース sonatype の JIRA で issue を通してリポジトリ作成を依頼 リポジトリ作成を依頼は JIRA で行います。 JIRA を使うにはアカウントが必要なので、以下のリンクから新規アカウントを発行します。</description>
    </item>
    <item>
      <title>AWS_SECRET_ACCESS_KEY を GitHub Actions secrets へ突っ込むのに疲れた俺達は</title>
      <link>https://shogo82148.github.io/blog/2021/03/24/actions-aws-assume-role/</link>
      <pubDate>Wed, 24 Mar 2021 21:57:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2021/03/24/actions-aws-assume-role/</guid>
      <description>「GitHub Actions から継続的デプロイをしたい！」と思ったときに、 僕の扱うデプロイ先は AWS なことが多いので AWS のキー (AWS_ACCESS_KEY, AWS_SECRET_ACCESS_KEY ) を GitHub Actions secrets へ突っ込む必要があります。 まあ一回や二回ならやるんですが、デベロップメント、ステージング、プロダクション、と複数環境あったり、 プロジェクトも複数あったりして、中々の回数設定を行わなければなりません。 設定するだけでつらいのに、AWS はキーのローテーションを勧めてきます。つらい。
と言うわけで、シークレットの管理を極力しなくて済む方法を考えて、設定用の Action を作成しました。
fuller-inc/actions-aws-assume-role Configure AWS Credentials by Assuming Roles 2021-08-19 更新 「会社でも使いたいな(ﾎﾞｿｯ」と言ったら社のアカウントで管理してもらえることになりました。 それにともないアクションの URL が shogo82148/actions-aws-assume-role から fuller-inc/actions-aws-assume-role に変更になっています。 正しくリダイレクトされるようですが、念の為 URL の変更をお願いします。
信頼関係に指定する AWS アカウント 053160724612 に変更はありません。 こんなこともあろうかと専用の AWS アカウントを作成しておいたので、まるごと権限を移しました。
使い方 まずは AWS 側に IAM Role を作成します。 IAM Role の信頼関係(trust policy) には以下の内容を記載します。 信頼する AWS アカウントには 053160724612 を指定してください。 これはフラー株式会社の管理している AWS アカウントなので、フラーを信頼できる方だけこの先に進んでください。 外部 ID(ExternalId) にはこのロールを使用する予定のレポジトリ名を入れます。</description>
    </item>
    <item>
      <title>Dependabot が起動する GitHub Actions Workflow から write 権限が無くなった件</title>
      <link>https://shogo82148.github.io/blog/2021/03/17/actions-check-permissions/</link>
      <pubDate>Wed, 17 Mar 2021 19:14:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2021/03/17/actions-check-permissions/</guid>
      <description>Dependabot から送られてくるプルリクエストのテストが最近良くコケるようになったなあと思ったら、 3 月 1 日から GitHub Actions Workflow 内の GITHUB_TOKEN のパーミッションが変更になったそうです。
GitHub Actions: Workflows triggered by Dependabot PRs will run with read-only permissions 更新されたパッケージに secrets を盗み見るような危険なコードが含まれているかもしれません。 そのようなコードでも安全に実行できるよう read-only のパーミッションで実行されるようになりました。
その結果以下のようなワークフローが失敗するようになってしまいました。
プルリクエストにラベルをつけるような、レポジトリに対して write パーミッションが必要なワークフロー 外部サービスとのインテグレーションテストをやっていて、連携のためにシークレットを読む必要があるワークフロー 2021-12-01 追記 その後のアップデートで GitHub Token のパーミッションをワークフロー中に明示できるようになり、 dependabot もこれに従うようになりました。
GitHub Actions: Workflows triggered by Dependabot PRs will respect permissions key in workflows 以下のような設定を追加すれば、GitHub Token を使ってレポジトリへの書き込みも可能です。
# Set the access for individual scopes, or use permissions: write-all permissions: pull-requests: write issues: write repository-projects: write またこの記事中で以下のように書いていますが、</description>
    </item>
    <item>
      <title>AWS Lambda Perl Runtime Layer in 大阪リージョン を公開しました</title>
      <link>https://shogo82148.github.io/blog/2021/03/02/perl-lambda-in-ap-northeast-3/</link>
      <pubDate>Tue, 02 Mar 2021 14:50:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2021/03/02/perl-lambda-in-ap-northeast-3/</guid>
      <description>AWS 大阪リージョンが一般利用可能になりました！
AWS Asia Pacific (Osaka) Region Now Open to All, with Three AZs and More Services [AWS] 日本 2 番目となる大阪リージョン ap-northeast-3 が利用可能になりました ［速報］「AWS 大阪リージョン」正式オープン。大阪ローカルリージョンを拡張し 3 つのアベイラビリティゾーンから構成、事前申し込みなど不要に というわけで、 AWS Lambda Perl Runtime AWS::Lambda in Osaka を公開しました。
ランタイム本体: arn:aws:lambda:ap-northeast-3:445285296882:layer:perl-5-32-runtime-al2:1 AWS SDK for Perl: arn:aws:lambda:ap-northeast-3:445285296882:layer:perl-5-32-paws-al2:1 Zip Archive: https://shogo82148-lambda-perl-runtime-ap-northeast-3.s3.amazonaws.com/perl-5-32-runtime-al2.zip Zip Archive: https://shogo82148-lambda-perl-runtime-ap-northeast-3.s3.amazonaws.com/perl-5-32-paws-al2.zip 大阪の Perl Monger の皆さん、ぜひご利用ください。</description>
    </item>
    <item>
      <title>ghq list が interrupted system call で死ぬ問題を直した</title>
      <link>https://shogo82148.github.io/blog/2021/02/28/fix-ghq-list-fails-with-interrupted-system-call/</link>
      <pubDate>Sun, 28 Feb 2021 23:42:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2021/02/28/fix-ghq-list-fails-with-interrupted-system-call/</guid>
      <description>常用している Mac Book Pro の OS を Big Sur に上げたんだけど、 ghq list が以下のエラーを吐くようになってしまった。
$ ghq list error failed to filter repos while walkLocalRepositories(repo): interrupted system call ghq list sometimes fails with interrupted system call #311 結論からいうと Go 1.14 から入った以下の変更が原因だったんだけど、 実際に遭遇したのは初めてだったのでメモ。
Go 1.14 でシステムコールが EINTR エラーを返すようになった Go 1.14 でランタイムに入った変更 根本的な原因は Go 1.14 リリースノート のこの辺の変更です。
A consequence of the implementation of preemption is that on Unix systems, including Linux and macOS systems, programs built with Go 1.</description>
    </item>
    <item>
      <title>改: PerlとGolangで実行できるPolyglot書いてみた</title>
      <link>https://shogo82148.github.io/blog/2021/02/23/improve-go-and-perl-polyglot/</link>
      <pubDate>Tue, 23 Feb 2021 18:00:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2021/02/23/improve-go-and-perl-polyglot/</guid>
      <description>仕事をしているときにふとひらめいた。
Perl と Golang で実行できる Polyglot 書いてみた 文字列置換の s/// に使う記号はダブルクオーテーションでも行ける！
package main; import (s&amp;#34;fmt&amp;#34;/*&amp;#34;); sub import { print &amp;#34;Hello macotasu&amp;#34;; } __END__ */) func main() { s.Println(&amp;#34;Hello macotasu&amp;#34;) } package main; import (s&amp;#34;fmt&amp;#34;/*&amp;#34;); sub import { print &amp;#34;Hello macotasu&amp;#34;; } __END__ */) func main() { s.Println(&amp;#34;Hello macotasu&amp;#34;) } Go で dot import をしなければならない、という制限がなくなるので、自由度が上がりました。
package main; import (s&amp;#34;fmt&amp;#34;/*&amp;#34;); sub import { print &amp;#34;Hello macotasu&amp;#34;; } __END__ */) import &amp;#34;math&amp;#34; func main() { s.</description>
    </item>
    <item>
      <title>AWS Lambda &#43; S3 を使ってyumレポジトリを作った</title>
      <link>https://shogo82148.github.io/blog/2021/02/21/private-yum-repo-on-s3/</link>
      <pubDate>Sun, 21 Feb 2021 08:11:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2021/02/21/private-yum-repo-on-s3/</guid>
      <description>世の中にはたくさんの OSS が公開されていて、それを Linux 上で動かす選択肢も多様になってきました。 今まで通り自前でビルドするのはもちろん, Go のようにシングルバイナリになってるならバイナリ落としてくるだけのものもあります。 DockerHub で公開されているものなら Docker でコンテナイメージをダウンロードするという手もあります。 Homebrew on Linux なんてものも登場しましたね。
選択肢が増えて動かすだけなら楽になったんですが、 事前の環境構築が最小限で済んで、バージョン管理もできて、依存もいい感じに解決してくれて、 といろいろ考えると結局は Red Hat 系なら標準のパッケージマネージャーである yum が楽なんですよね。
そういうわけで JFrog Bintray にバイナリをあげて、yum レポジトリを公開していました。 ところが今月になって 突然の Bintray 終了のお知らせ！！！
Into the Sunset on May 1st: Bintray, JCenter, GoCenter, and ChartCenter 前置きが長くなりましたね。 要するに Bintray からのお引越しを考えないといけなくなったので、 yum レポジトリを AWS S3 上に移行した、というお話です。
標準的な yum レポジトリの作り方 yum レポジトリを作るには、まず公開したい rpm パッケージが必要です。 Bintray だろうが S3 だろうが、rpm 作成の手順は一緒なので省略します。
rpm さえできてしまえば、レポジトリの作成は非常に簡単です。 createrepo コマンドをインストールして実行するだけ。
yum install createrepo createrepo /PATH/TO/REPOSITORY /PATH/TO/REPOSITORY の中を自動的に検索して、 メタデータを作成してくれます。 これをこのまま HTTP で公開すれば yum レポジトリの完成です。</description>
    </item>
    <item>
      <title>Setup Perl Environment Action のストレージを Azure Blob Storage に移行しました</title>
      <link>https://shogo82148.github.io/blog/2021/02/03/setup-perl-uses-azure-blob-storage/</link>
      <pubDate>Wed, 03 Feb 2021 21:33:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2021/02/03/setup-perl-uses-azure-blob-storage/</guid>
      <description>GitHub Actions が一般公開された際に Perl をセットアップするアクションを書きました。
Setup Perl GitHub Action を公開しました セットアップのたびに毎回コンパイルすると遅いので、コンパイル済みのバイナリを事前に Amazon S3 にアップロードしていました。 アップロード先に S3 を選んだのは単に自分が AWS に慣れているからなのですが、最近になってちょっとした問題に直面してます。 解決へ向けて S3 から Azure Blob Storage へ移行した、というお話です。
利用する分には全く影響ないはずなんですが、Azure Blob Storage を使ってみたメモも兼ねてやったことを書いておきます。
S3 の問題点 もちろん S3 自体が悪いわけじゃなくって、単に自分の見積もりが甘かっただけなんですが、 ネットワークのアウト向きのデーター転送料が高い！！！！
これまでの僕のユースケースではせいぜい数 MB のバイナリをアップロードするだけだったのが、perl のバイナリは 1 バージョン当たり 100MB 以上あります。 Perl Monger の方々は互換性に気を使うので、いろんな OS、バージョン、コンパイルオプションでテストを実行します。 各 OS(Linux, Windows, macOS)、Perl 5.6〜5.32、multi-thread オプションありなし、という条件でマトリックスのワークフローを組むと 84 ジョブ。 単純計算で 1 ワークフローを実行するだけで、約 8GB の転送が発生するわけです。 2021-02-05 現在のアウトデーター転送料は 0.09USD/GB なので、1 ワークフローあたり 0.72USD です。
去年の秋あたりから使ってくれる人が増えたようで、転送量だけで 100USD/mo を超えるようになってきました。 趣味の範囲でやってるので、ちょっと許容できる範囲を超えてきたかな・・・ということでコスト削減に乗り出しました。</description>
    </item>
    <item>
      <title>スーパー楕円をベジェ曲線で近似してみる</title>
      <link>https://shogo82148.github.io/blog/2021/01/29/super-ellipse/</link>
      <pubDate>Fri, 29 Jan 2021 22:01:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2021/01/29/super-ellipse/</guid>
      <description>最近アプリの UI で角丸アイコンを見ることが多くなりました。 この角は完全な円ではなく、スーパー楕円というものだという情報を入手しました。
スーパー楕円 UI を iOS+Swift で実装する 丸よりも丸みを感じる!? スーパー楕円の魅力とデザイン 記事の中ではベジェ曲線で近似する方法が書かれています。 なるほど、こうすれば描けるのか！と関心したので、自分でもベジェ曲線で描いてみることにしました。
スーパー楕円 スーパー楕円というのは円の方程式を以下のように拡張したものです。
$$ \left|\frac{x}{a}\right|^n + \left|\frac{y}{b}\right|^n = 1 $$
n は曲線を制御するパラメーターで n=2 は円となり、n&amp;gt;2 の場合は円と四角形のあいだのような形になります。 n が大きいほど四角形に近づいていきます。
3 次のベジェ曲線 Illustrator のようなベクターツールではおなじみのベジェ曲線です。 ベジェ曲線は任意の次数に拡張することができますが、コンピューターグラフィックスで多く用いられるのは 3 次ベジェ曲線です。
制御点を $ \boldsymbol{B}_0, \boldsymbol{B}_1, \boldsymbol{B}_2, \boldsymbol{B}_3 $ とした場合の 3 次ベジェ曲線の数式を具体的に書き下すと以下のようになります。
$$ \boldsymbol{P}(t) = \boldsymbol{B}_0(1-t)^3 + \boldsymbol{B}_1 3t(1-t)^2 + \boldsymbol{B}_2 3t^2(1-t) + \boldsymbol{B}_3 t^3 $$
近似してみる 以下の記事と同じ戦略で近似してみます。
ベジェ曲線による円の描画の制御点の位置はなぜ 0.55228…なのか? スーパー楕円は左右対称・上下対象なので、第一象限の形だけ求めれば十分です (x &amp;gt; 0, y &amp;gt; 0 )。 またアフィン変換に対して不変なので a = b = 1 の場合のみを考えます。</description>
    </item>
    <item>
      <title>Perl Runtime for AWS Lambda の Docker コンテナ対応を公開しました</title>
      <link>https://shogo82148.github.io/blog/2021/01/02/perl-runtime-supports-docker-format/</link>
      <pubDate>Sat, 02 Jan 2021 00:00:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2021/01/02/perl-runtime-supports-docker-format/</guid>
      <description>いつかやろうと思っていた AWS::Lambdaの Docker コンテナ対応、 年を越してしまったけど、ようやく手を付けました。
AWS Lambda の新機能 – コンテナイメージのサポート 使い方 以下の handler.pl を Docker コンテナとして AWS Lambda デプロイする例です。
use utf8; use warnings; use strict; sub handle { my $payload = shift; return +{&amp;#34;hello&amp;#34; =&amp;gt; &amp;#34;lambda&amp;#34;}; } 1; ビルド済みイメージを使う Amazon Linux 2 ベースの Perl Runtime 入りイメージをDocker Hub で公開しています。 これをベースにデプロイしたいファイルを追加し、CMD に実行したい関数名を指定するだけ。 簡単ですね。
FROM shogo82148/p5-aws-lambda:base-5.32-paws.al2 COPY handler.pl /var/task/ CMD [ &amp;#34;handler.handle&amp;#34; ] Docker Hub からのダウンロードに Rate Limit が適用されるようになったので、 同じイメージを Amazon ECR Public Gallery でも公開しました。 こちらを利用することも可能です。</description>
    </item>
    <item>
      <title>排他制御を行う GitHub Action を作った</title>
      <link>https://shogo82148.github.io/blog/2020/12/30/github-actions-mutex/</link>
      <pubDate>Wed, 30 Dec 2020 00:00:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2020/12/30/github-actions-mutex/</guid>
      <description>弊社では GitHub のレポジトリ管理に Terraform GitHub provider を使用しています。 いちいち手元で terraform plan や terraform apply を叩くのは面倒なので、 GitHub Actions を利用することを考えました。 tf ファイルと現実のリソースとの不整合を避けるために、 これらのコマンドは排他的に実行する必要があります。 例えば terraform apply を実行している最中に terraform plan を実行することはできません。
ここで問題になってくるのが GitHub Actions のジョブ並列数です。 2020-12-30 現在、GitHub Actions は同時に 20 並列まで実行可能ですが、逆に並列数を制限できないという贅沢な悩みがあります。 一応 Matrix Build の並列数を制限するオプションはありますが、 ワークフローをまたいだ並列数の制限はできません。
これを解決するために作ったのが actions-mutex です。
shogo82148/actions-mutex actions-mutex Marketplace 使い方 ただワークフローから uses を使って呼び出すだけ。 面倒なアクセスキーの設定等は必要ありません。簡単ですね。
on: push: branches: - main jobs: build: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - uses: shogo82148/actions-mutex@v1 - run: &amp;#34;: 排他的に実行する必要のあるタスク&amp;#34; 仕組み actions-mutex と同様のことを実現する Action として GitHub Action Locks があります。 これの使用も考えたのですが、GitHub Action Locks はバックエンドに AWS DynamoDB を使用しています。 DynamoDB のテーブルを作成した上で AWS IAM を適切に設定する必要があり、セットアップが面倒です (まあ単に DynamoDB 食わず嫌いしているだけ、というのもあります)。</description>
    </item>
    <item>
      <title>2020年に書いた GitHub Action &#43; α</title>
      <link>https://shogo82148.github.io/blog/2020/12/03/github-actions-in-2020/</link>
      <pubDate>Thu, 03 Dec 2020 00:00:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2020/12/03/github-actions-in-2020/</guid>
      <description>この記事はフラーAdvent Calendar 2020の3日目の記事です。 2日目はid:gibachan03 さんで「Androidアプリエンジニアになって気づいたiOSとの違い」でした。
さて、公開当初色々して遊んだ GitHub Actions ですが、今年も引き続き遊んでました。 いくつか新しい Action を作ったものの、このブログでは紹介していなかったので、2020年作ったものを紹介したいと思います。
actions-upload-release-asset Yet Another Upload Release Asset Action 一言で表すのならば、 Yet Another actions/upload-release-asset GitHub Action です。 GitHub の Releases にファイルをアップロードする Action です。 このアクションは GitHub 公式という安心感はあるのですが、一度のステップで1個のファイルしかアップロードできません。
ソースファイル本体と、ビルド済みバイナリと・・・と色々アップロードしたいものがあったので、新しく作りました。 actions-upload-release-asset は @actions/glob の Glob Pattern に対応しているので、一つのステップで複数のファイルをアップロードすることができます。
例えば、カレントディレクトリにあるテキストファイルを全てアップロードする例は以下のようになります。
on: release: types: - created jobs: build: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 # steps for building assets - run: echo &amp;#34;REPLACE ME!&amp;#34; &amp;gt; assets.txt - uses: shogo82148/actions-upload-release-asset@v1 with: upload_url: ${{ github.</description>
    </item>
    <item>
      <title>AWS SDK for Go v2 の今後が不安な件について</title>
      <link>https://shogo82148.github.io/blog/2020/10/24/aws-sdk-go-v2-broken/</link>
      <pubDate>Sat, 24 Oct 2020 01:06:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2020/10/24/aws-sdk-go-v2-broken/</guid>
      <description>なんだか今日はもうコードを書く気がしないので、最近思っていることをつらつらと・・・
タイトルの通り、最近 AWS SDK for Go v2 の行く末がちょっと気になっています。 あんまり話題になっているのを観測できていないので、少し現状を書いてみます。
背景 最近あったビッグイベントが v0.25.0 のリリースです。
Client Updates in the Preview Version of the AWS SDK for Go V2 パッケージの構成が見直され、APIの呼び出し方法も変わりました。 まあ、プレビュー版なのでよくあること・・・なんですが、ちょっと変更点が多すぎて追いきれない。
v0.25.0 移行で入った変更の数々 ちょっと一例を見てみましょう。
設定の読み込み Before: v0.25.0 より前は external パッケージを使って設定を読み込んでいました。
import ( &amp;#34;github.com/aws/aws-sdk-go-v2/aws/external&amp;#34; ) func loadConfig() (aws.Config, error) { return external.LoadDefaultAWSConfig() } After: これが config パッケージに変更になりました。
import ( &amp;#34;github.com/aws/aws-sdk-go-v2/config&amp;#34; ) func loadConfig() (aws.Config, error) { return config.LoadDefaultConfig() } API の呼び出し Before: Requestオブジェクトを作って、そのSendメソッドを呼ぶ形式でした。
s3svc := s3.</description>
    </item>
    <item>
      <title>GitHub Actions を使って簡単なボットを作る</title>
      <link>https://shogo82148.github.io/blog/2020/10/23/github-bot-using-actions/</link>
      <pubDate>Fri, 23 Oct 2020 22:03:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2020/10/23/github-bot-using-actions/</guid>
      <description>リリース当初は git push など GitHub 上のイベントしかトリガーにできなかった GitHub Actionsですが、 workflow_dispatch イベント の登場により手動実行ができるようになりました。
社内でもこの機能を利用してワークフローの手動実行をしていたのですが、人間とは欲深いもので「毎回ワークフローを選択してポチポチするのだるい」という声があがってきました。 そういうわけで、Pull Request のコメントをトリガーにしてワークフローを実行する簡単なボットを作ってみました。
方針 workflow_dispatch と issue_comment をトリガーにしたワークフローを作ればいいだけの気もしますが、 以下のような理由からワークフローからワークフローを呼び出す形にしました。
workflow_dispatch を使った既存のワークフローがあるので、それを流用したい トリガーが複数あると、イベントの種類に応じてペイロードの形式が異なるので、地味に処理が大変 issue_comment は全部のコメントに反応するので、本当に見たいログが埋もれてしまう コメントを投稿した Pull Request のHEADでワークフローを実行して欲しい issue_comment はイベントの発生元として、デフォルトブランチのHEADが渡ってきます イベントのペイロードには、プルリクエストへのリンクが入っているだけで、HEADの情報はわからない 実装 jfurudo1 がサードパーティのアクションを使ってゴニョゴニョやっていたものの、 あんまりうまく行ってなさそうだったので、bash script でエイヤッと書き直しました。
「build」 とコメントすると、.github/workflows/build.yml のワークフローを実行するサンプルです。
name: comment hook on: issue_comment: types: [created] jobs: distribute: runs-on: ubuntu-latest steps: - name: dispatch workflow run: | # イベントに関する詳細情報を取ってくる PAYLOAD=$(cat &amp;#34;$GITHUB_EVENT_PATH&amp;#34;) NUMBER=$(echo &amp;#34;$PAYLOAD&amp;#34; | jq -c &amp;#39;.issue.number&amp;#39;) # Issue と Pull Request のコメントが混ざってくるので、Issueは無視する if [[ &amp;#34;$(echo &amp;#34;$PAYLOAD&amp;#34; | jq -c &amp;#39;.</description>
    </item>
    <item>
      <title>AWS Lambda Perl Runtime on Amazon Linux 2 を公開しました</title>
      <link>https://shogo82148.github.io/blog/2020/08/15/perl-lambda-runtime-on-amazon-linux2/</link>
      <pubDate>Sat, 15 Aug 2020 20:44:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2020/08/15/perl-lambda-runtime-on-amazon-linux2/</guid>
      <description>Amazon Linux 2 への移行が進む AWS Lambda ですが、 ついに Custom Runtime にも Amazon Linux 2 がやってきました。
AWS Lambda now supports custom runtimes on Amazon Linux 2 同時に provided.al2 の Docker Image も公開されたので、 それを利用して Amazon Linux 2 対応の Perl Runtime Layer を作成しました。
AWS::Lambda ビルド済み公開 Perl Runtime Layer リージョン毎のArn一覧はこちら
Perl 5.32 arn:aws:lambda:af-south-1:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:ap-east-1:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:ap-northeast-1:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:ap-northeast-2:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:ap-south-1:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:ap-southeast-1:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:ap-southeast-2:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:ca-central-1:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:eu-central-1:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:eu-south-1:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:eu-west-1:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:eu-west-2:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:eu-west-3:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:me-south-1:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:sa-east-1:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:us-east-1:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:us-east-2:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:us-west-1:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:us-west-2:445285296882:layer:perl-5-32-runtime-al2:1 --runtime provided.al2 と合わせてご利用ください。</description>
    </item>
    <item>
      <title>Yet Another AWS X-Ray Go SDK でログの関連付けをサポートした</title>
      <link>https://shogo82148.github.io/blog/2020/07/06/aws-xray-yasdk-go-supports-logs-correlation/</link>
      <pubDate>Mon, 06 Jul 2020 22:49:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2020/07/06/aws-xray-yasdk-go-supports-logs-correlation/</guid>
      <description>僕が管理しているサービスでは、ALB が発行する Trace ID を調査時の手がかりとして使えるようログに出力しています。 これのおかげで、Nginx, アプリケーション, その他AWSのマネージドサービス, etc. といった異なるコンポーネントであっても、関連するログを抽出ができ、 障害発生時の役に立っています。 しかし、肝心の抽出作業がマネージドコンソールぽちぽちなため、完全に職人芸になっているというのが現状でした。
解決のための良いツールがないかな、と目をつけたのが CloudWatch ServiceLens です。 CloudWatch メトリックとログ、AWS X-Ray からのトレースを結び付けて、直感なインターフェースで分析できるというもの。
Amazon CloudWatch ServiceLens の発表 AWS X-Ray のトレース結果を送るのは、以前開発した Yet Another AWS X-Ray SDK for Go でできます。 CloudWatch Logs への出力方法は色々ありますが、僕は自作の cloudwatch-logs-agent-lite を使っています。
材料はそろった、さあ、ServiceLens で分析だ！と行きたいところですが、 ただ単にこれらの情報を送りつけるだけでは、得られる情報は X-Ray 単体、CloudWatch Logs 単体で使ったときと大差ありません。 X-Ray のトレース結果とログの関連付けが行われていないので、結局 Trace ID を使って CloudWatch Logs を検索する必要が出てきてしまいます。
ドキュメントを見る限り、2020-07-06現在 AWS X-Ray SDK for Java だけがログ関連付け機能に対応しているようです。 JavaにできてGoにできないわけがないだろう・・・ということで移植してきました。
使い方 aws-xray-yasdk-go の v1.1.1 移行で対応しているので、そのバージョンを落としてきます。
go get github.</description>
    </item>
    <item>
      <title>RE: Pull Request Title Injection とその対策</title>
      <link>https://shogo82148.github.io/blog/2020/04/02/re-pull-request-title-injection/</link>
      <pubDate>Thu, 02 Apr 2020 06:37:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2020/04/02/re-pull-request-title-injection/</guid>
      <description>@furusax が書いてくれた GitHub Action からの Slack 通知機能について以下のようにコメントしたところ、 対策案を考えてくれました。
そういえばこれって Pull Request Title Injection できないですかね？ まあ、タイトル書くの社員なのでいいんですが。
対策してみました #はてなブログ
Pull Request Title Injection とその対策 - なまえは まだ ないhttps://t.co/hIkMykFUr8
&amp;mdash; ふるさっくす (@furusax) March 31, 2020 Pull Request Title Injection とその対策 なるほど、こう来ましたか。しかし、まだまだ甘いですね・・・。
2021-08-19 追記 ドッグさん が便利なツールを作ってくれました。
rhysd/actionlint actionlint v1.4 → v1.6 で実装した新機能の紹介 GitHub Actions のワークフローファイルの静的チェッカーです。 チェック項目にこの記事で紹介したような脆弱性検知も含まれているのでおすすめです！
Pull Request Title Injection について まずはこの記事に出てくる「Pull Request Title Injection」についておさらいです。 以下のような Slack への通知を行う GitHub Actions があります。 github.event.pull_request.title はプルリクエストを送った本人が自由に設定できるので、 ここにうまいこと細工をすれば Slack への投稿内容を自由に改変できてしまうのでは？という問いかけでした。</description>
    </item>
    <item>
      <title>Yet Another AWS X-Ray Go SDK を作った</title>
      <link>https://shogo82148.github.io/blog/2020/03/30/aws-xray-yasdk-go/</link>
      <pubDate>Mon, 30 Mar 2020 06:37:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2020/03/30/aws-xray-yasdk-go/</guid>
      <description>AWS X-Ray Go SDK の地雷処理をしている話 で投げたSQLのプルリクエスト も無事マージしてもらい、 その後もちょくちょくプルリクエストを投げて地雷処理をしていたんですが、我慢できずにやってしまいました・・・。
Yet Another AWS X-Ray SDK for Go そもそも AWS X-Ray ってなんだ、という方は以下のリンクから @fujiwara さんの記事へ飛べるのでどうぞ。
AWS Lambda Perl Runtime で AWS X-Ray を使えるようになりました 使い方 だいたいオフィシャルSDKと一緒です。 ただし、パッケージ分割をしたので、呼び出す関数名等はちょっと変わってます。 他にも微妙に挙動が違う箇所があります。
環境変数の設定 AWS_XRAY_DAEMON_ADDRESS, AWS_XRAY_CONTEXT_MISSING 等の環境変数の設定項目は本家と合わせました。 ただし、以下の点が本家とは異なります。
コード内の設定が優先されます。 環境変数はコード内で明示的に設定が行われなかった場合のフォールバックです。 AWS_XRAY_CONTEXT_MISSING のデフォルト値は LOG_ERROR です。 セグメントの作り方 オフィシャルSDKは seg.Close(err) のようにセグメントを閉じるときにエラーを渡します。 Go には defer という便利な機能があるので、セグメントを閉じるときもこれを使いたいところです。 だたエラーを正しく受け取るには、以下のように戻り値に名前をつけて、defer 部分を無名関数の呼び出しにする必要があります。
// オフィシャルSDKの場合 import &amp;#34;github.com/aws/aws-xray-sdk-go/xray&amp;#34; func DoSomethingWithSubsegment(ctx context.Context) (err error) { ctx, seg := xray.BeginSubsegment(ctx, &amp;#34;service-name&amp;#34;) defer func() { seg.</description>
    </item>
    <item>
      <title>AWS X-Ray Go SDK の地雷処理をしている話</title>
      <link>https://shogo82148.github.io/blog/2020/02/11/aws-xray-golang/</link>
      <pubDate>Tue, 11 Feb 2020 06:37:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2020/02/11/aws-xray-golang/</guid>
      <description>AWS Lambda Perl Runtime で AWS X-Ray を使えるようになりました で紹介した AWSの分散アプリケーションの分析サービス AWS X-Ray。 Perl から使えるようにしたももの、自分自身は最近 Perl をあまり使っていないことに気がついた！！ので、AWSが提供しているGo実装である aws/aws-xray-sdk-goに 手を出してみることにしました。
結果、X-Rayのサービスマップやトーレスが見れるようになって便利！・・・にはなったんですが、そこまでの道のりが長かった。 「 @fujiwara さんのYAPC::Tokyo 2019での発表 から1年近く経ってるしそろそろ安定してきているでしょ！」と 軽い気持ちで始めたのが良くない。 色々と地雷(？)を踏んだので、記録として残しておきます。
依存ライブラリのcontext対応が地味に辛い X-Ray で実行をトレースするには、「今実行している関数がどこから呼ばれたのか？」という情報をうまいこと伝える必要があります。 Perlで使われているような黒魔術はGoでは使えないので、 context.Context を地道に引数に渡していくことになります。
まあ、こんなこともあろうかと、context.Context にはバッチリ対応してあるからサクッと行けるでしょ！
と思ってたんですが、現実はそうは甘くなかった。 X-Rayを入れようとしたプロジェクトではWebフレームワークとしてgoadesign/goaを使っています。 GoaのHTTPハンドラーには context.Context が渡ってくるので油断していたのですが、 contextの親をたどっていくと行き着く先は context.Background() (HTTPハンドラーなので request.Context() であってほしい)。 なんとなく context.Context 対応詐欺にあった気分です。
Goaは現在 v2, v3 の開発がメインで現在使っているのは v1 です。 v1からv3へのアップグレードには大幅な書き換えが必要なこと、アップグレードしたとしても直っている保証がないこと、 最近 Goa v1 のリリースが滞りがちなこと、などなどの理由から結局フォークしてくることにしました。
shogo82148/goa-v1 AWS X-Ray Go SDK 自体の問題ではないのですが、 Contextってタイムアウトをうまく処理するための仕組みなので、実装漏れがちですよね。 皆さん実装するときやライブラリの選定には気をつけましょう。
SQLクエリを実行する関数のシグネチャーが微妙に違う これに関しては @acidlemon 先生の kamakura.</description>
    </item>
    <item>
      <title>元Yahoo!ジオシティーズ利用者のかたへ、GitHub Pagesのすゝめ</title>
      <link>https://shogo82148.github.io/blog/2020/02/01/goodbye-geocities/</link>
      <pubDate>Sat, 01 Feb 2020 00:00:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2020/02/01/goodbye-geocities/</guid>
      <description>TL;DR 今GitHubにアップロードした内容は1000年残る！ デッドラインは 2020年2月3日(月) 午前7時(日本時間) Yahoo!ジオシティーズのデータがダウンロードできるのは2020年3月31日まで つまりYahoo!ジオシティーズから移行するなら、今！ GitHubが一番！
Yahoo!ジオシティーズは終了しました Yahoo!ジオシティーズ 公開停止からはや10ヶ月。 ちょっと古いリンクをたどると「Yahoo!ジオシティーズは終了しました」というページを目にすることが多くなりました。
Yahoo!ジオシティーズは終了しました
2019年3月31日をもちましてYahoo!ジオシティーズのサービス提供を終了いたしました。長らくご愛顧いただき誠にありがとうございました。
ホームページをお持ちのお客様につきましては、2020年3月31日までFTPによるファイルダウンロードのみご利用可能となっております。ホームページやドメインの移行方法などはサービス終了のお知らせをご確認ください。
https://info-geocities.yahoo.co.jp/
それ見てこんなツイートをしたのですが、なぜ GitHub への移行がいいのか知らない人が多いようなのでちょっと説明しますね。
みんな！FTP経由ならまだジオシティーズからホームページのダウンロードはできる！！今のうちにGitHubへ上げてその黒歴史を1000年後まで残すんだ！！！
&amp;mdash; Ichinose Shogo (@shogo82148) January 31, 2020 GitHub Arctic Code Vault なぜ今 GitHub なのかというと、 GitHub Universe 2019 で GitHub Archive Programというプログラムが発表されたからです。
今から1,000年後にソフトウェアはどのようになっているのか、また人類はどうなっているのか、推測することしかできません。しかし、今日の時点で最も重要なビルディングブロックを、確実に明日に残せるようにすることは可能です。私たちの世界は、オープンソースソフトウェアで動いています。この文明の隠れた基盤であり、全人類の共有財産です。GitHub Archive Programの使命は、次世代のためにオープンソースソフトウェアを保護することです。
GitHubは、スタンフォード大学図書館、Long Now Foundation、 Internet Archive、Software Heritage Foundation、Piql、Microsoft Research、オックスフォード大学ボドリアン図書館などの機関や団体と連携し、世界のオープンソースコードを保護していきます。この貴重な知識を保護する方法として、あらゆるデータ形式でさまざまな場所に、継続的に複数のコピーを保存していきます。保存場所には、GitHub Arctic Code Vaultと呼ばれる、少なくとも1,000年は存続する非常に長期的なアーカイブも含まれます。
https://github.blog/jp/2019-11-14-universe-day-one/
このプログラムで最長の保存場所である GitHub Arctic Code Vault は、北極圏に広がる永久凍土の深さ250mに建設されたアーカイブ施設「Arctic World Archive」。
2020年2月2日 時点でのアクティブな公開リポジトリ※のスナップショットが、QRコードとしてエンコードされフィルムに印刷されたのち、この場所に保管されます。 Arctic World Archive は地政学的に地球上でもっとも安定した場所であり、1000年の長期保存にも耐えるとのこと。</description>
    </item>
    <item>
      <title>CloudFormationのテンプレートのLinter actions-cfn-lint のご紹介</title>
      <link>https://shogo82148.github.io/blog/2019/12/06/actions-cfn-lint/</link>
      <pubDate>Fri, 06 Dec 2019 00:00:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2019/12/06/actions-cfn-lint/</guid>
      <description>この記事はフラーAdvent Calendar 2019の6日目の記事です。 5日目は@shogo82148 さんで「GitHub Goveralls Action を公開しました」でした。
さて、最近 GitHub Actions を作るのにハマっているので、今日も GitHub Actions の紹介です。
GitHub Action for CloudFormation Linter with reviewdog shogo82148/actions-cfn-lint Amazon CloudFormation Infrastructure as Code の盛り上がりも一段落し、今では当たり前のように使っている人も多いと思います。 フラー共創スタジオはAWSがメインなので、CloudFormationをメインに使っています。 色々とクセは強いですが、少なくともtfstateが行方不明になったりはしないので、まあまあ仲良くやっています。
CloudFormation Linter テンプレートを書いている上で地味にややこしいのが、プロパティーの名前や型の統一感が微妙にない、ということです。
例を挙げると、AWS::ApplicationAutoScaling::ScalableTarget の MaxCapacity は整数型です。 これはまあ、納得できますね。
ところが AWS::AutoScaling::AutoScalingGroup の MaxSize は 文字列型 なんです。説明文には「Auto Scaling グループの Amazon EC2 インスタンスの最大数」とあるのに！ オートスケールという似たような機能を持っていて、どちらもスケーリンググループの最大数を表しているの、名前も違えば型が全く違う。
この手のミスは aws cli に付属している テンプレートの validation 機能では見つけられす、実際に反映してみるしかありません。 すぐに失敗してくれればいいんですが、失敗するまでにも十数分かかったりしてかなり面倒です。
そこでおすすめなのが CloudFormation Linter。 この手の名前のミスや型のミスを指摘してくれるコマンドラインツールです。 各種エディタ用の拡張もあり、VSCodeでも使える ので、ぼくはいつもこれを使っています。
CloudFormation Linter については Classmethod さんの紹介記事もどうぞ。</description>
    </item>
    <item>
      <title>GitHub Goveralls Action を公開しました</title>
      <link>https://shogo82148.github.io/blog/2019/12/05/actions-goveralls/</link>
      <pubDate>Thu, 05 Dec 2019 00:00:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2019/12/05/actions-goveralls/</guid>
      <description>この記事はフラーAdvent Calendar 2019の5日目の記事です。 4日目はふるふる先生の「GoでJSONを良い感じに使おうと思ってハマった話」でした。
さて、首を長くして待っていた GitHub Actions がついにGAになりましたね。 (日本語版ヘルプだとまだbetaになってますが)
さっそくActionを自作してちょっと前に公開してたんですが、この機会に紹介しようと思います。
actions-goveralls - Actions GitHub Marketplace shogo82148/actions-goveralls 使い方 coveralls.io はコードカバレッジの可視化サービスです。 実は公式でGitHub Actionsを提供しており、Coveralls GitHub Action を使うと 「JavaScriptのプロジェクトであれば」簡単にカバレッジを送信することができます。
しかし、Goが出力するカバレッジはJavaScriptと形式が違うので、そのままは使えません。 他のCIではmattn/goverallsにお世話になっていたので、 これを GitHub Actions として簡単に使えるようにしました。 最小限の設定はこれだけです。
# ここらへんにテストとかの設定ば別途描く # coveralls.io に送信 - uses: shogo82148/actions-goveralls@v1 with: github-token: ${{ secrets.GITHUB_TOKEN }} path-to-profile: profile.cov 簡単ですね。
マトリックスビルド され、後発なだけあって GitHub Actions では他のCIの便利な機能を簡単に使えます。 その中でも最も便利(偏見)なのがマトリックスビルドです。 例えば以下のように設定するだけで、Linux, macOS, Windows で同じテストを実行できます。
strategy: fail-fast: false matrix: os: - ubuntu-latest - macos-latest - windows-latest runs-on: ${{ matrix.</description>
    </item>
    <item>
      <title>Setup Perl GitHub Action を公開しました</title>
      <link>https://shogo82148.github.io/blog/2019/09/18/actions-setup-perl/</link>
      <pubDate>Wed, 18 Sep 2019 23:14:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2019/09/18/actions-setup-perl/</guid>
      <description>GitHub Actions の公式レポジトリには Perl のセットアップアクションが無いぞ！ ということで三連休+αで書きました。
actions-setup-perl on GitHub Marketplace 使い方 Marketplaceの設定例は間違えているので以下を参照。(これ書いていて気がついた) 必要な Perl のバージョンを渡すだけです。簡単！
steps: - uses: actions/checkout@master - uses: shogo82148/actions-setup-perl@v1 with: perl-version: &amp;#39;5.30&amp;#39; - run: cpanm --installdeps . - run: prove -lv t Ubuntu, macOS, Windows 各種OSにも対応しています。
jobs: build: runs-on: ${{ matrix.os }} strategy: matrix: os: [&amp;#39;ubuntu-18.04&amp;#39;, &amp;#39;macOS-10.14&amp;#39;, &amp;#39;windows-2019&amp;#39;] perl: [ &amp;#39;5.30&amp;#39;, &amp;#39;5.28&amp;#39; ] name: Perl ${{ matrix.perl }} on ${{ matrix.os }} steps: - uses: actions/checkout@v1 - name: Setup perl uses: shogo82148/actions-setup-perl@v1 with: perl-version: ${{ matrix.</description>
    </item>
    <item>
      <title>AWS Lambda Perl Runtime で AWS X-Ray を使えるようになりました</title>
      <link>https://shogo82148.github.io/blog/2019/08/21/aws-xray-with-perl-lambda-runtime/</link>
      <pubDate>Wed, 21 Aug 2019 19:53:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2019/08/21/aws-xray-with-perl-lambda-runtime/</guid>
      <description>AWS Lambda 上で Perl を動かす AWS::Lambda で、 AWSの分散アプリケーションの分析サービスである AWS X-Ray をサポートしました！
AWS X-Ray って何？ Perl からどう使うの？ という人は @fujiwara さんの記事とYAPC::Tokyo 2019での発表スライドをどうぞ。
第56回　AWS X-Rayによる分散トレーシング―マイクロサービスのボトルネック，障害箇所の特定（1） 第56回　AWS X-Rayによる分散トレーシング―マイクロサービスのボトルネック，障害箇所の特定（2） 第56回　AWS X-Rayによる分散トレーシング―マイクロサービスのボトルネック，障害箇所の特定（3） 使ってみる Perl Runtime だけでなくX-Ray SDK 側でも対応が必要だったので、プルリクエストを送って取り込んでもらいました。 このプルリクエストがマージされた最新の AWS::XRay を Perl Runtime Layer にプリインストールしたので、あなたのアプリケーションですぐに使えます。
例えばこんな感じのコードを書いて、
use utf8; use warnings; use strict; use AWS::XRay qw/ capture /; sub handle { my ($payload, $context) = @_; capture &amp;#34;myApp&amp;#34; =&amp;gt; sub { capture &amp;#34;hogehoge&amp;#34; =&amp;gt; sub { sleep 1; }; capture &amp;#34;fugafura&amp;#34; =&amp;gt; sub { my $segment = shift; $segment-&amp;gt;{metadata} = $payload; }; }; return +{&amp;#34;hello&amp;#34; =&amp;gt; &amp;#34;lambda&amp;#34;}; } 1; Layer に X-Rayに対応した最新の Perl Runtime arn:aws:lambda:ap-northeast-1:445285296882:layer:perl-5-30-runtime:3 を追加、 マネージドコンソールの「Debugging and error handling」セクションにある「Enable AWS X-Ray」を有効化し、実行してみます。</description>
    </item>
    <item>
      <title>Goのバイナリに静的ファイルを埋め込むツール assets-life を書いた</title>
      <link>https://shogo82148.github.io/blog/2019/07/24/assets-life/</link>
      <pubDate>Wed, 24 Jul 2019 20:54:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2019/07/24/assets-life/</guid>
      <description>日本語の Go コミュニティだと go-bindata (なんか乗っ取り騒動とか色々あってメンテナンスされてない), go-assets (最近メンテナンス滞りがち) が有名(要出典)なやつです。 これらのライブラリに関してたくさん日本語記事が書かれて、今もたくさん検索に引っかかるのですが、残念ながら最近はメンテナンスが滞っています。
最近は statik の名前もよく見るようになりました。 その他は Resource Embedding - Awesome Go からどうぞ。
で、まあ、今回も完全に車輪の再発明なんですが、他の実装には色々と思うところがあり書いてみました。
shogo82148/assets-life USAGE なにはともあれ、まずは go get してきます。
$ go get github.com/shogo82148/assets-life assets-life というコマンドがインストールされるので、 バイナリに組み込みたいディレクトリと出力先を指定します。
$ assets-life /path/to/your/project/public public 出力先のディレクトリは Go のパッケージとしてインポートできるようになってます。 Root という変数のなかにファイルが埋め込まれており、http.FileSystem インターフェースを介してアクセスできます。
import ( &amp;#34;net/http&amp;#34; &amp;#34;example.com/your/project/public&amp;#34; ) func main() { http.Handle(&amp;#34;/&amp;#34;, http.FileServer(public.Root)) http.ListenAndServe(&amp;#34;:8080&amp;#34;, nil) } 特長 コードの再生成にコマンドのインストールが不要 これが一番の特長です。 バイナリにファイルを埋め込む都合上、静的ファイルを修正した場合にコードの再生成が必要です。 assets-life は go:generate ディレクティブを埋め込んだコードを出力するので、コードの再生成は go generate でできます。
# /path/to/your/project/public に修正を加える # コードの再生を行う $ go generate example.</description>
    </item>
    <item>
      <title>Goで指数的バックオフをやってくれるgo-retryを書いた</title>
      <link>https://shogo82148.github.io/blog/2019/07/22/go-retry/</link>
      <pubDate>Mon, 22 Jul 2019 07:33:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2019/07/22/go-retry/</guid>
      <description>完全に車輪の再発明なんですが、他の実装には色々と思うところがあり書いてみました。
shogo82148/go-retry MOTIVATION カッコいいインターフェースが欲しい インターフェースは lestrrat さんのこの資料を参考にしています。
GoらしいAPIを求める旅路 (Go Conference 2018 Spring) from lestrrat 「これ、Loop Condition だ」のあたりで、なるほど！と思ってインターフェースを真似てみました。 このインターフェースに沿って、lestrratさん自身が実装した lestrrat-go/backoff があります。 しかし、個人的にちょっと実装が複雑だなと感じたので、もうちょっとシンプルに書けないかとやってみました。
Context サポート 先行実装たちは Context がGoに取り込まれる前からあるので、 Contextに対応したインターフェースが後付だったり、 そもそもContextに対応していなかったりします。 Context未対応の Go 1.5 はすでにサポート対象外なので、もう Context が存在しない実行環境は考えなくてよいはずです。
SYNOPSIS Loop Condition Interface 使い方は lestrrat-go/backoff と大体一緒。 指数的バックオフに必要な各種パラメーターをポリシーとして与え、リトライのためのループを回します。
// 指数的バックオフの各種パラメーターをポリシーとして定義 var policy = retry.Policy{ // 初回待ち時間 MinDelay: 100 * time.Millisecond, // 最大待ち時間 MaxDelay: time.Second, // 最大試行回数 MaxCount: 10, } func DoSomethingWithRetry(ctx context.Context) (Result, error) { retrier := policy.</description>
    </item>
    <item>
      <title>AWS SDK for Perl Lambda Layerを公開しました</title>
      <link>https://shogo82148.github.io/blog/2019/07/16/aws-lambda-paws-layer/</link>
      <pubDate>Tue, 16 Jul 2019 22:43:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2019/07/16/aws-lambda-paws-layer/</guid>
      <description>ハイラルからこんにちは。
AWS LambdaでCGIを蘇らせる で作成した Perl Custom Runtime 用の AWS Lambda Layer ですが、 中でイベントのハンドリングをしているモジュールを AWS::Lambda として CPAN で公開したところ、 AWS SDKを入れて欲しい との要望が来ました。 完全にネタとして作成したモジュールですが、いるんですね使う人。 というわけで AWS SDK を含んだ AWS Lambda Layer を公開しました。
使い方 公開レイヤーを使う AWS公式ではPerl用のSDKは提供していないので、Pawsという非公式SDKを使いました。 何も考えずにテキトウにインストールしてみたらSDKだけで121MBありました。 Perl本体が85MBなのでSDKのほうがでかい。 AWS Lambdaで作成できる関数は250MBが上限なので、流石に半分SDKに持っていかれるのはつらかろうと、Perl本体とは別のレイヤーに分けてあります。
レイヤーは最大5つまで登録できるので、Perl本体(例: arn:aws:lambda:ap-northeast-1:445285296882:layer:perl-5-30-runtime:2 )に加えて 以下のレイヤーを追加することで、Paws を呼び出すことができるようになります。
arn:aws:lambda:ap-east-1:445285296882:layer:perl-5-30-paws:1 arn:aws:lambda:ap-northeast-1:445285296882:layer:perl-5-30-paws:1 arn:aws:lambda:ap-northeast-2:445285296882:layer:perl-5-30-paws:1 arn:aws:lambda:ap-south-1:445285296882:layer:perl-5-30-paws:1 arn:aws:lambda:ap-southeast-1:445285296882:layer:perl-5-30-paws:1 arn:aws:lambda:ap-southeast-2:445285296882:layer:perl-5-30-paws:1 arn:aws:lambda:ca-central-1:445285296882:layer:perl-5-30-paws:1 arn:aws:lambda:eu-central-1:445285296882:layer:perl-5-30-paws:1 arn:aws:lambda:eu-west-1:445285296882:layer:perl-5-30-paws:1 arn:aws:lambda:eu-west-2:445285296882:layer:perl-5-30-paws:1 arn:aws:lambda:eu-west-3:445285296882:layer:perl-5-30-paws:1 arn:aws:lambda:sa-east-1:445285296882:layer:perl-5-30-paws:1 arn:aws:lambda:us-east-1:445285296882:layer:perl-5-30-paws:1 arn:aws:lambda:us-east-2:445285296882:layer:perl-5-30-paws:1 arn:aws:lambda:us-west-1:445285296882:layer:perl-5-30-paws:1 arn:aws:lambda:us-west-2:445285296882:layer:perl-5-30-paws:1 いつの間にかマネージドコンソールから編集ができるようになっていたので、開発がはかどりますね。
カスタムランタイムでもAWS Lambdaのマネージドコンソールから内容の編集ができる・・・？ Perl も編集できるぞ・・・ pic.twitter.com/4228rG0hca
&amp;mdash; Ichinose Shogo (@shogo82148) July 16, 2019 ZIP アーカイブを使う ビルド済みのZIPアーカイブも公開しています。 以下のURLを指定して新規レイヤーを作成することで利用できます。</description>
    </item>
    <item>
      <title>GoのバイナリをRubyスクリプトとしても扱う</title>
      <link>https://shogo82148.github.io/blog/2019/07/02/go-build-polyglot/</link>
      <pubDate>Tue, 02 Jul 2019 21:55:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2019/07/02/go-build-polyglot/</guid>
      <description>$ ruby --help Usage: ruby [switches] [--] [programfile] [arguments] (中略) -x[directory] strip off text before #!ruby line and perhaps cd to directory (後略) なんか Ruby にも -x あるらしいので。
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;runtime&amp;#34; ) const script = ` #!ruby puts &amp;#34;Hello Ruby World!!\n&amp;#34; __END__ ` func init() { runtime.KeepAlive([]byte(script)) } func main() { fmt.Println(&amp;#34;This is Go world!!&amp;#34;) } はい。
$ go build -o main main.go $ ./main This is Go world!</description>
    </item>
    <item>
      <title>サーバーの時刻を伝える time wellknown uri を実装してみた</title>
      <link>https://shogo82148.github.io/blog/2019/05/27/time-over-https/</link>
      <pubDate>Mon, 27 May 2019 12:10:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2019/05/27/time-over-https/</guid>
      <description>インターネットをさまよっていたら、 /.well-known/time の存在を知ったので、雑に実装してみました。
使い方 うまいこと共存できそうだったので、HTTP/WebSocketで時刻同期するWebNTPを書いた で作成した WebNTP の一部として実装してあります。
shogo82148/go-webntp $ go get github.com/shogo82148/go-webntp/cmd/webntp $ webntp -serve :8080 $ curl -I localhost:8080/.well-known/time HTTP/1.1 204 No Content X-Httpstime: 1558915632.285965 Date: Mon, 27 May 2019 00:07:12 GMT 仕様 HTTPには「予約済みのURI」というものが定義されています。(RFC5785)。
Well-Known URIs Let&amp;rsquo;s Encrypt でドメインの所有権確認に使用される ACMEプロトコル(RFC8555) や、 Mastodon のユーザーディスカバリーに使用する WebFinger(RFC7033)等々、 近年話題になったサービスの裏方で使われています。
/.well-known/acme-challenge ACMEプロトコル(RFC8555) /.well-known/webfinger WebFinger(RFC7033) Time over HTTPS も Well-Known URIs を利用するプロトコルのひとつです。
/.well-known/time Time over HTTPS specification 仕様としては非常に単純で、サーバー側は HTTP の HEAD に対して、 Date ヘッダーをつけたリクエストを返すだけ。 より高精度な時刻を得るために X-HTTPSTIME ヘッダーに秒未満の情報を入れた Unix タイムスタンプ を返すこともできます。</description>
    </item>
    <item>
      <title>CloudFormationのMackerel用インテグレーションを作ってる話</title>
      <link>https://shogo82148.github.io/blog/2019/04/17/cfn-mackerel-macro/</link>
      <pubDate>Wed, 17 Apr 2019 18:26:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2019/04/17/cfn-mackerel-macro/</guid>
      <description>Mackerel は mkr コマンドを用いて cli から操作ができます。 mkr コマンドを用いると 監視ルールを GitHub で管理 したり、 カスタムダッシュボードを管理したり、といったことができます。 しかし、個人的に以下のような不満があります。
サービス、ロール、ホスト、新ダッシュボード等々、監視設定以外のリソースに対応していない 旧ダッシュボードは対応しているんだけど、新ダッシュボード対応がまだ 新ダッシュボードのUIは使いやすくてすごくいいんだけど、コピペや一斉置換ができないので、テキストで管理したい 出力がJSONなのつらい JSON手で書くの難しくないですか？ メトリックスの送信設定と監視設定の管理が別になってしまう カスタムメトリックス送っているのに監視設定を忘れた、みたいなことが起こる メトリックスの送信設定については、以前 サーバーレスでCloudWatchメトリクスをMackerelに転送する で CloudFormation上での管理を実現しました。 ここにさらに Mackerel の監視設定を追加できれば、最強なのでは？とやってみました。
例 あれこれ説明する前に例を見てもらったほうがわかりやすいと思うので、こんなことができますよ、という設定例から。
例1: レスポンスタイムの99%パーセンタイルを監視する Mackerel の AWSインテグレーション は ALB に対応していますが、 レスポンスタイムのメトリックスは平均レスポンスタイムだけです。 「平均」は代表的な統計値ですが、全体としては速いんだけど一部のリクエストだけ遅い、という状況を見逃してしまいます。 レスポンスタイムの大まかな分布をパーセンタイルで把握したい、ということはよくありますよね？ (K社でZabbixを使って監視していたときによくお世話になった)
今回作ったインテグレーションを使えば、以下のように「Mackerelのサービス定義」「メトリックスの転送設定」「監視設定」が CloudFormation のテンプレートとして表現できます。
AWSTemplateFormatVersion: 2010-09-09 # Type: Mackerel::* を使うためのおまじない Transform: - AWS::Serverless-2016-10-31 - Mackerel - JSONString Resources: MackerelService: Type: Mackerel::Service Properties: Name: &amp;#34;awesome-service&amp;#34; # メトリックスを転送する Lambda 関数 MetricsForwarder: Type: AWS::Serverless::Application Properties: Location: ApplicationId: arn:aws:serverlessrepo:us-east-1:445285296882:applications/mackerel-cloudwatch-forwarder SemanticVersion: 0.</description>
    </item>
    <item>
      <title>新元号の候補約4510万件が漏洩！！</title>
      <link>https://shogo82148.github.io/blog/2019/02/28/leak-gengo/</link>
      <pubDate>Thu, 28 Feb 2019 18:26:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2019/02/28/leak-gengo/</guid>
      <description>平成の次の元号候補、4510万4656件の漏洩が確認された。
テキスト形式 (301MB) gz圧縮版 (108MB) 政府は「新元号、情報管理を徹底へ　漏洩なら差し替え」との方針を示しており、 早急な差し替え対応を行うと思われる。
2019-04-01 追記:
$ curl -s https://t.co/OCaFAriJIt | cat -n | grep 令和
726041令和
無事漏洩してました！！！
&amp;mdash; Ichinose Shogo (@shogo82148) 2019年4月1日 追記ここまで
と、まあ、二番煎じなわけですが。
新元号は漏洩すると変更されるということなので常用漢字2文字の全組み合わせ約228万通りをすべて記載したテキストファイルを作成しました。漏洩させていきましょう。https://t.co/G06utDbgka pic.twitter.com/8UcPDqNdXo
&amp;mdash; いんぐらむ (@kazuokiriyama) 2019年2月26日 ただ、このツイートのリプライのもあるとおり漏洩漏れがあるようですし、 新元号に使われる可能性のある漢字は常用漢字ではない可能性だってあると僕は考えいます。 だって、お国のやることですからね。下手したら改元に合わせて「常用漢字の見直しもやる」ということだって考えられます。
というわけで、僕は ShiftJIS, EUC-JP で表現可能な文字列まで範囲を広げることにしました。 Unicodeへの統一が進んでいるとはいえ、 ShiftJIS, ECU-JP で動いているレガシーなシステムもあるでしょうし、この範囲に収めるだろうなという予想です。
ShiftJISからUnicodeへの変換には規則性がないので、変換テーブルを使う必要があります。 Goのコードを漁った ら以下の変換表を参照していたので、これを利用しました。
https://encoding.spec.whatwg.org/index-jis0208.txt 非漢字も含まれているので、雑に漢字を絞ったあと、
curl https://encoding.spec.whatwg.org/index-jis0208.txt | grep CJK | cut -f3 | cut -d&amp;#39; &amp;#39; -f1 | sort | uniq &amp;gt; kanji.txt 直積列挙スクリプトに突っ込めば出来上がり。</description>
    </item>
    <item>
      <title>外部サービスでもIAM Roleで認証がしたい！</title>
      <link>https://shogo82148.github.io/blog/2019/02/12/ssm-sign-proxy/</link>
      <pubDate>Tue, 12 Feb 2019 12:46:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2019/02/12/ssm-sign-proxy/</guid>
      <description>背景 外部サービスのAPIやWebHookを叩くときには、多くの場合 API トークンが必要になります。 もちろん API トークン無しでも叩けるサービスはありますが、GitHub APIのようにトークン無しではリクエスト数が大きく制限されたり、 一部機能が制限されてしまう場合があります。
外部連携サービスが増えてくると、このAPIトークンをどうやって管理するかが問題になってきます。 プロダクションに投入されているサービスは普通複数のサーバーから構成されており、各サーバーにAPIトークンを配布するのはちょっと面倒です。 この問題に対して、以下のようなことが行われて来ました。
プライベートネットワークからのアクセスに限定した Proxy を立てる APIトークンの管理は Proxy に任せる DevOpsが注目され、Slackの利用が広まったころに、このような目的で書かれたProxyサーバーがよく登場しました。
社内IRCをSlackに移行した時にやったこと この記事で紹介されている kayac/nopaste Slackboard〜Slackプロキシサーバ in Go〜 Slackプロキシサーバ〜slackboard〜を利用したメルカリのSlack活用法 App::Ikachan - 様々なサーバのバッチ処理の結果等を IRC のチャンネルに通知するサーバ (IRCはHTTPで動いているわけではないし、大本の目的もコネクション維持だけど、認証も代理でやってくれる) しかし、これらのサーバーはSlack専用だったりIRC専用だったりします。 Slackだけじゃなくって、GitHubにコメント登録したり、Mackerelのグラフアノテーションを投稿したり、 他のサービスとも連携したい！
最近はどんなAPIもHTTPで提供されるようになったので(IRCは・・・ウッ・・・そんなのなかった)、もっと汎用的に書けるのではとやってみました。
実装 APIトークンの保管場所として AWS Systems Manager Parameter Store を採用しました。 Parameter Store からAPIトークンを取り出す部分と、実際にAPIを叩く部分は AWS Lambda を使用します。 各サーバーに Forward Proxy デーモンを立てておき、APIを使いたいアプリケーションはこのProxyを経由するようにします。
この図ではEC2インスタンスを例にしていますが、IAM Roleを付与できるAWSのサービスであれば何でも (ECS, Lambda, CodeBuild, etc.) APIにアクセスすることができます。
外部サービスのAPIを叩くのが Lambda 関数というのもポイントです。 APIトークンをヘッダーに設定するのか、URLの一部に含めるのか、クエリストリングに含めるのか・・・といった設定方法はサービスによってまちまちです。 Lambda 関数がこの辺の設定を肩代わりしてくれるので、APIトークンの扱いを気にする必要はありません。 また、API利用時にうっかりAPIトークンを漏らしてしまう心配もなくなります。
APIトークンの管理をしたいんじゃない！！ただ、APIを叩きたいだけなんだ！！！！ という思いから、Proxy デーモンはシークレットに関しては何も関与しません。</description>
    </item>
    <item>
      <title>Let&#39;s Encrypt の証明書取得を AWS Lambda でやってみた</title>
      <link>https://shogo82148.github.io/blog/2019/02/07/acme-cert-updater/</link>
      <pubDate>Thu, 07 Feb 2019 19:22:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2019/02/07/acme-cert-updater/</guid>
      <description>背景 ここ数年で暗号化されていないHTTPは減り、常時TLSが当たり前になってきました。 公開用のページはもちろん、開発段階のページでもTLSは必須です。 普段はAWS上で開発をしているので、AWS Certificate Managerを利用することが多いのですが、 ちょっとしたお遊びにELBやCloudFormationを使うのはオーバーキルです。 そこで EC2 にもインストールできて、無料で使える Let&amp;rsquo;s Encrypt を使って証明書を発行することを考えました。
Let&amp;rsquo;s Encrypt で発行できる証明書は期間が90日と短く、60日ごとの自動更新が推奨されています。 証明局とAPIとAPIクライアントの実装例は提供するから、あとの自動化部分は自前で頑張ってねという感じなので、自動化部分を頑張らないといけません。 今回は実行環境として AWS Labda、ACME(Automatic Certificate Management Environment)クライアントとして certbot、 認証方法に dns-01、認証に必要なDNSレコードの書き換えに AWS Route 53 を使用する、という構成にしました。
ソースコードをGitHubに挙げたのと、前回と同様に AWS Serverless Application Repository へ上げたので、ぜひご利用ください。
shogo82148/acme-cert-updater shogo82148/acme-cert-updater on AWS Serverless Application Repository 関連手法 Amazon Linux 2 に certbot をインストールして使う Amazon Linux 2 のドキュメントに TLS 対応のウェブサーバーを立てる例が載っています。 Let&amp;rsquo;s Encrypt で証明書を取る方法も紹介されているので、まずはこれを利用することを考えました。
付録: Amazon Linux 2 での Let&amp;rsquo;s Encrypt と Certbot の使用 - チュートリアル: Amazon Linux 2 で SSL/TLS を使用できるように Apache ウェブサーバーを設定する この方法は以下の理由から見送りました。</description>
    </item>
    <item>
      <title>サーバーレスでCloudWatchメトリクスをMackerelに転送する</title>
      <link>https://shogo82148.github.io/blog/2019/01/31/mackerel-cloudwatch-transfer/</link>
      <pubDate>Thu, 31 Jan 2019 17:44:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2019/01/31/mackerel-cloudwatch-transfer/</guid>
      <description>背景 サーバーの監視にMackerelを使っているのですが、 用意されているメトリクスでは足りずカスタムメトリクスを追加することが多々あります。 Mackerel Agent Pluginsを利用すればメトリクスを増やすこと自体は簡単なのですが、 Agentを設置するインスタンスが増えるので、サーバー保守の手間が増えてしまいます。
僕のユースケースでは監視対象はたいていAWSのマネージド・サービスなので、 AWS CloudWatch に投稿されたメトリクスが Mackerel で見れれば十分なことが多いです。
そこで、以下の記事を参考に AWS Lambda と CloudWatch Events を組み合わせて、Mackerelへメトリクスを転送するスクリプトを書いてみました。
Amazon LambdaでCloudWatchのメトリクスをMackerelに監視させる デプロイしてみる 今回はなんと！皆さんの AWSマネジメントコンソールから、クリックひとつでデプロイできるようにしてみました！
mackerel-cloudwatch-forwarder ・・・と、その前に下準備が必要です。 MackerelのダッシュボードからAPIキーをコピーしてきて、 AWS Systems Manager パラメータストアに Secure String として登録しておきます。 スクショでは Mackerel のものだと分かりやすいよう /development/api.mackerelio.com/headers/X-Api-Key という名前をつけました。 この名前を後で使うので覚えておきましょう。
次に AWS Lambda の画面を開き、「関数の作成」をクリックします。
「一から作る」「設計図」「AWS Serverless Application Repository」の3つの選択肢が表れるので、 「AWS Serverless Application Repository」 を選択します。 検索BOXに「Mackerel」と入れると、mackerel-cloudwatch-forwarderが 出てくるので、それを選択します。 なお、この選択肢はデフォルトでは表示ないので、「Show apps that create custom IAM roles or resource policies」にチェックを入れましょう。
アプリケーションの内容とパラメーターの設定画面に移ります。 「ParameterName」にパラメーターストアに登録したパラメーター名を入れましょう。 スクショの例では「/development/api.mackerelio.com/headers/X-Api-Key」を入力します。
「カスタムIAMロールを作成することに同意」のチェックボックスを選択したあと、デプロイ！</description>
    </item>
    <item>
      <title>CloudFormationでECSタスクのドレインをやる</title>
      <link>https://shogo82148.github.io/blog/2019/01/30/drain-ecs-task-with-cloudformation/</link>
      <pubDate>Wed, 30 Jan 2019 17:44:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2019/01/30/drain-ecs-task-with-cloudformation/</guid>
      <description>やってみたはいいものの、1年後には仕組みを忘れていそうなのでメモ。
背景 昔はサービス毎にポコポコEC2インスタンスを立てていたのですが、 幸か不幸かインスタンスのリソースが余り気味でした。 そこで、最近流行りのコンテナ技術に乗っかって Amazon ECS (Amazon Elastic Container Service) を使って、 ひとつのインスタンスに複数のサービスを載せようと目論みました。
ちょうどその頃、Spot Fleetというものを使うと、 スポットインスタンスをお手軽に借りられるという話を聞いたので、 Spot Fleet + ECS で格安クラスターを作ってみよう！と手を出してみました。
(・・・もちろん、Fargateが東京リージョンで使えるようになったことは知っているけれど、スポットインスタンスの価格に負けてしまった・・・)
AWS Fargate 東京リージョン サービス開始のお知らせ AWS Fargate で最大 50% の値下げを発表 ECS最適化インスタンスの更新問題 クラスターを作るだけなら、そう難しくはなく、インスタンス起動時にAmazon ECS-Optimized Amazon Linux AMIを使うだけです。 問題はこのイメージは定期的に更新される、ということです。 更新情報を流しているSNSトピックがあるので、これをサブスクライブしておくと、時たま更新通知が来ます。
Amazon ECS-Optimized Amazon Linux AMI の更新の通知のサブスクライブ この更新には機能追加はもちろん、セキュリティーフィックスも含まれているので、 なるべく早く新しいイメージに移行する必要があります。 移行は大まかに以下の手順で進めます。
新しいAMIイメージに更新した Spot Fleet を作成する 古いインスタンスに残っているタスクをいい感じに終了する(ドレイン) 突然殺すとユーザーにエラーが見えてしまうので、受付中のリクエストを捌き切ってから終了しないといけない ドレインが始まるとECSがタスク数を調整するために、新しいインスタンスにタスクをお引越ししてくれる ドレインが終了したら、古いインスタンスをシャットダウンする ここで問題になってくるのが「古いインスタンスに残っているタスクをいい感じに終了する(ドレイン)」の部分。 コンソールからポチポチするのも面倒なので、自動化したいところ。 しかし、いろいろとドキュメントをあさってみたのですが、「APIかawscliを叩く」「SNSとAWS Lambda をうまいこと組み合わせて頑張る」みたいな方法しか見当たらない・・・ しかもAWSの公式ブログ
コンテナインスタンスのドレイン How to Automate Container Instance Draining in Amazon ECS Amazon ECS におけるコンテナ インスタンス ドレイニングの自動化方法 ・・・みんなどうやってるの・・・？</description>
    </item>
    <item>
      <title>IAM認証でAWS RDSへ接続するMySQLドライバを作った</title>
      <link>https://shogo82148.github.io/blog/2019/01/13/rdsmysql/</link>
      <pubDate>Sun, 13 Jan 2019 17:44:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2019/01/13/rdsmysql/</guid>
      <description>AWS RDS には IAM 認証を使って接続する機能があります。
MySQL および PostgreSQL に対する IAM データベース認証 IAM 認証情報を使用して Amazon RDS への接続をユーザーに許可する方法を教えてください。 これを使って接続するGo言語のSQLドライバを書いてみました。
https://github.com/shogo82148/rdsmysql 使い方 IAMデータベース認証はデフォルトで無効になっているので、まずはこれを有効化します。 次に AWSAuthenticationPlugin を認証方式に指定して、新しいユーザーを作りましょう。
IAM データベース認証の有効化と無効化 データベースアカウントの作成 CREATE USER jane_doe IDENTIFIED WITH AWSAuthenticationPlugin AS &amp;#39;RDS&amp;#39;; 他のSQLドライバはimportするだけで使えるのですが、 rdsmysqlではAWSへの権限情報を設定しなければならない都合上、 sql.Register を自前で呼び出す必要があります。 とは言っても、AWS SDKがいい感じに設定ファイルとか環境変数とか読んでくれるので、 rdsmysql.Driver にAWSセッションを渡すだけです。
c := aws.NewConfig().WithRegion(&amp;#34;ap-northeast-1&amp;#34;) s := session.Must(session.NewSession(c)) d := &amp;amp;Driver{ Session: s, } sql.Register(&amp;#34;rdsmysql&amp;#34;, d) db, err := sql.Open(&amp;#34;rdsmysql&amp;#34;, &amp;#34;jane_doe:@tcp(db-foobar.ap-northeast-1.rds.amazonaws.com:3306)/&amp;#34;) if err != nil { log.Fatal(err) } defer db.Close() あとは通常のMySQLドライバとして呼び出すだけです。 go-sql-driver/mysql のラッパーになっているので、 DNS等の書き方はこれに準じます。 認証部分は rdsmysql がやってくれるので、パスワードは空でOKです。 パスワードの管理から開放されて楽ですね！</description>
    </item>
    <item>
      <title>AWS LambdaでCGIを蘇らせる</title>
      <link>https://shogo82148.github.io/blog/2018/12/16/run-cgi-in-aws-lambda/</link>
      <pubDate>Sun, 16 Dec 2018 17:44:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2018/12/16/run-cgi-in-aws-lambda/</guid>
      <description>この記事は Perl Advent Calendar 2018の15日目の記事です。 (キリの良いところまでできたのと、記事が書かれていなかったので代打投稿)
Custom Runtime のリリースにより、AWS Lambda 上でPerlが動くようになりました。
PerlをAWS Lambdaで動かす 次は AWS Lambda + CGI でサーバーレスだな...
&amp;mdash; Ichinose Shogo (@shogo82148) 2018年12月8日 ということで、やっていきましょう。
できたもの 動かすのはもちろん、 CGIアクセスカウンター 。 なんと嬉しいことに、最近になって WwwCounter の新バージョン(Ver3.16)がリリースされ、 Perl 5.26 に対応しました！
2018-11-11 perl 5.26に対応。(Ver3.16)
更新履歴によれば一つ前の Ver 3.15 のリリースは2003-03-23なので、なんと15年ぶりのアップデートです。 杜甫々さんの AWS Lambda で動かしてくれ！！ という声が聞こえてきそうですね・・・！！！
動いたーーーー！！！！
実装はこちら
AWS::Lambda ちなみにWwwCounterのアップデートはPerl 5.26で「@INCからカレントディレクトリが削除」された件への対応だと思います(コミットログがないので予想)。
第46回　Perl 5.26で変わること（1） - Perl Hackers Hub 実装説明 「そもそもCGIってなんだ？」っていう人も多くなってきたと思うので、そこらへんの歴史の話にも軽く触れます。 この辺の歴史をリアルに体験したわけではないので、誤り等あればご指摘ください。
CGIとは Common Gateway Interface の略で、 WebサーバーとCLI(Command Line Interface)アプリケーションのやり取りの方法を決めた規格です。</description>
    </item>
    <item>
      <title>PerlをAWS Lambdaで動かす</title>
      <link>https://shogo82148.github.io/blog/2018/11/30/perl-in-lambda/</link>
      <pubDate>Fri, 30 Nov 2018 17:44:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2018/11/30/perl-in-lambda/</guid>
      <description>AWS Lambda で Custom Runtime が発表されました！
新機能 – AWS Lambda :あらゆるプログラム言語への対応と一般的なコンポーネントの共有 New for AWS Lambda – Use Any Programming Language and Share Common Components AWS Lambda Now Supports Custom Runtimes, and Enables Sharing Common Code Between Functions Custom Runtime により好きなプログラミング言語でLambda関数を書くことができ、 いくつかの言語についてはAWSおよびパートナーから bootstrap が提供されます。
提供される言語にCOBOLが入って話題になっていますが、 当然ながら(？)Perlはありません。
Custom Runtimeは shell script でも書ける簡単なものなので、Perlでも書いてみました。
Perl in AWS Lambda 以下のスクリプトを bootstrap という名前で保存します。
#!/usr/bin/env perl use utf8; use warnings; use strict; use lib &amp;#34;$ENV{LAMBDA_TASK_ROOT}/local/lib/perl5&amp;#34;; use Furl; use JSON; my $furl = Furl-&amp;gt;new; my ($handler, $function) = split /\.</description>
    </item>
    <item>
      <title>Goのnil,true,falseは変数名に使えるという話</title>
      <link>https://shogo82148.github.io/blog/2018/11/22/go-nil/</link>
      <pubDate>Thu, 22 Nov 2018 17:44:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2018/11/22/go-nil/</guid>
      <description>@Linda_pp さんのツイートをみて
Go 言語の nil って NilLit じゃなくて Ident &amp;quot;nil&amp;quot; としてパースされるのか．それで気付いたけど nil := 42 みたいに普通に変数宣言できる（unused でエラーになるけど）
&amp;mdash; ドッグ (@Linda_pp) 2018年11月22日 なるほど、これは面白い。 と少し遊んでみたメモ。
言語仕様にある通り、Goのキーワードは以下の25個です(Go1.11.2)。
break default func interface select case defer go map struct chan else goto package switch const fallthrough if range type continue for import return var この一覧に nil や true, false は入っていません。 これらは builtinという扱いになっており、識別子として利用可能です。
そのため、変数名等に利用可能というわけですね。面白い。
package main import ( &amp;#34;fmt&amp;#34; ) func main() { nil := 42 fmt.Println(nil) // Output: // 42 } 以下、色々遊んでみた例。</description>
    </item>
    <item>
      <title>PHPer向けGoのJSONデコーダーを作った</title>
      <link>https://shogo82148.github.io/blog/2018/09/24/go-phper-json/</link>
      <pubDate>Mon, 24 Sep 2018 17:44:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2018/09/24/go-phper-json/</guid>
      <description>必要に迫られて作りました。 PHPでエンコードしたJSONをいい感じにデコードしてくれるGoのパッケージです。
shogo82148/go-phper-json 背景 さて、PHPerの方々には当たり前のことかもしれませんが、PHPの言語仕様について少しおさらいです。 それがどうしてGoで問題になるか見ていきます。
PHPのarray問題 PHPはとても便利なプログラミング言語なので、配列を扱うことができます。 ここでPHPの配列のマニュアルを読んでみましょう。
http://php.net/manual/ja/language.types.array.php
PHP の配列は、実際には順番付けられたマップです。マップは型の一種で、 値をキーに関連付けます。 この型は、さまざまな使い道にあわせて最適化されます。 配列としてだけでなく、リスト (ベクター)、 ハッシュテーブル (マップの実装の一つ)、辞書、コレクション、スタック、 キュー等として使用することが可能です。 PHP の配列には他の PHP 配列を値として保持することができるため、 非常に簡単にツリー構造を表現することが可能です。 (強調部分は筆者によるもの)
重要なことなのでもう一度。
配列としてだけでなく、リスト (ベクター)、 ハッシュテーブル (マップの実装の一つ)、辞書、コレクション、スタック、 キュー等として使用することが可能です。
他の言語でリスト、ハッシュテーブル、辞書等と呼ばれているものは、PHPにおいてはいずれも配列です。 PHPにとっては、整数を添字にしているか、文字列を添字にしているかの違いでしかありません。 (PHP7.xから整数が添字の場合に最適化が入るようになったらしいけど、大きな挙動の変更はないはず)
そのため、以下のスクリプトは true を返します。
&amp;lt;?php $a = array(&amp;#34;apple&amp;#34;, &amp;#34;banana&amp;#34;); $b = array(0 =&amp;gt; &amp;#34;apple&amp;#34;, 1 =&amp;gt; &amp;#34;banana&amp;#34;); var_dump($a == $b); // bool(true) この仕様のため、JSONにエンコードすると最初は配列だったのに、 処理を進めていくうちにうっかり文字列のキーを作ってしまって、 JSONのオブジェクトに変わってました、ということが起こりえます。 Goにおいて両者は全く違う型なので、デコードの際に非常に困ります。
&amp;lt;?php $a = array(1, 2, 3); print json_encode($a); // [1,2,3] $a[&amp;#34;foo&amp;#34;] = &amp;#34;bar&amp;#34;; print json_encode($a); // {&amp;#34;0&amp;#34;:1,&amp;#34;1&amp;#34;:2,&amp;#34;2&amp;#34;:3,&amp;#34;foo&amp;#34;:&amp;#34;bar&amp;#34;} このような悲劇を防ぐために、 JSON_FORCE_OBJECT というオプションがあるのですが、 オプションの名前通りに全部JSONのオブジェクトになってしまいます。 この要素だけJSONの配列にして欲しい！といった細かな操作はできません。</description>
    </item>
    <item>
      <title>〜夏休みの自由研究〜 電波時計のサマータイム対応状況を調べてみた</title>
      <link>https://shogo82148.github.io/blog/2018/08/20/summer-time-homework/</link>
      <pubDate>Mon, 20 Aug 2018 09:29:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2018/08/20/summer-time-homework/</guid>
      <description>僕は知っています。
ぜひ、みなさんもお手元の電波時計で試してみてください！
と書いても、試してくれる人なんていないことを。
僕は知っています。
説明書や仕様書に書いてあったとしても、書いてあるとおりに動作する機械なんて、ほんの一握りだということを。
というわけで、楽しい夏休みの自由研究です。 秋葉原で適当に買った1000円から3000円くらいの電波時計に、サマータイムのフラグを有効にした電波を受信させてみて、どういう挙動になるか調査してみました。
TL;DR 10機種(SEIKO, CITIZEN, CASIO, MAG, ELECOM, その他)に対して、サマータイムフラグを有効にした状態で Web JJY の電波を送信しました。
今回の調査範囲では、夏時間の時刻(1時間 or 2時間ズレた時刻)を表示する時計は見つからなかった 夏時間実施中(DST)と表示 する時計は実在する 室内で使うならCASIOの電波時計はクオーツ時計だと思ったほうがいい 電波受信の様子をYouTubeにあげておいたので興味のある方はどうぞ。
背景 2018年、日本は記録的な猛暑に見舞われ、 観測史上最高の気温41.1度を記録し、 熱中症とみられる症状で90人以上が亡くなるという甚大な被害を被った。
今週の天気　記録的な猛暑　底知れぬ暑い夏 日本で猛暑　気温41.1度で観測史上最高 気象庁「災害と認識」熱中症死の疑い６日で９０人超 この記録的猛暑を受け、政府・与党によって2020年の東京五輪・パラリンピックの酷暑対策として、夏の期間だけ時間を2時間繰り上げる「サマータイム(夏時間)」の導入が検討されている。
酷暑対策でサマータイム導入へ　秋の臨時国会で議員立法　３１、３２年限定 これに対して、「電波時計が狂うのではないか」「日本中の電波時計がゴミになる」等、電波時計が正しい時刻を示さなくなるとの指摘が相次いでいる。
サマータイム導入で「電波時計が狂う」？　メーカーに聞いた サマータイムで日本中の電波時計がゴミになる(かも)という話 電波時計は、NICT(情報通信研究機構)が提供している標準電波(JJY)を受信し、時刻の同期を行っている。 この標準電波には、時、分、通算日、年、曜日といったタイムコード情報に加え、 将来の拡張性のための「予備ビット」が設けられている。 この予備ビットに関して、「標準電波の出し方について」には、夏時間情報として意味を持たせる場合の例が記載されているが、これはあくまでも例であり、告示などで正式に決まっているものではない。 しかし、現実に市販されている電波時計のなかにも、仕様上予備ビットの状態を認識する機種がする。
標準電波の送信周波数40kHzを提供する「おおたかどや山標準電波送信所」は1999年6月運用開始、送信周波数60kHzを提供する「はがね山標準電波送信所」は2001年10月運用開始である。 日本でサマータイムが導入されたのは1948年から1951年の期間だけなので、 今後サマータイムが導入されることとなれば、標準電波の運用が始まってから初のサマータイム導入となる。
夏時刻法 - Wikipedia 長波帯標準電波施設 パンフレット(PDF) そのため、仕様上はサマータイムへ対応している電波時計であっても、初のサマータイム実施によって未知の挙動を示すことが十分に想定される。 そこで、本記事では、実際にサマータイム実施中の電波を電波時計に受信させ、 どのような挙動を示すのかを明らかにする。
目的 2018年8月現在日本で市販されている電波時計が、サマータイムの情報を含んだ標準電波(JJY)を受信した場合の挙動を調査し、 仮に、2019年、2020年にサマータイムが導入された場合の影響を明らかにする。
実験方法 秋葉原で購入した以下の電波時計に対して、標準電波と同様の電波を送信し、時刻の同期を行う。
CITIZEN 8RZ152 CITIZEN 4RL432-019 SEIKO SQ698S SEIKO KR331W MAG T-694 SM-Z ELECOM CLK-DD001RD 京都大和 171038 (製造元不明) 31756 CASIO DQD-710J-8JF CASIO TTM-160NJ-8JF 電波の送信には、Samsung Galaxy Note8 SC-01K を用いて、JJYシミュレータWeb版を実行する。</description>
    </item>
    <item>
      <title>GoAst ViewerをWebAssemblyへビルドしてみた</title>
      <link>https://shogo82148.github.io/blog/2018/08/19/goast-viewer-using-wasm/</link>
      <pubDate>Sun, 19 Aug 2018 07:29:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2018/08/19/goast-viewer-using-wasm/</guid>
      <description>もうすぐリリースのGo1.11ではWebAssemblyのサポートが予定されています。 (2018/08/19現在の最新版はGo1.11rc1)
Go言語がWebAssemblyをサポートへ。GOARCHは「wasm」、GOOSは「js」に 正式リリース前に少し遊んでみようということで、@yuroyoroさんのGoAst ViewerをWebAssemblyへビルドしてみました。
GoAst Viewer WebAssembly Version shogo82148/goast-viewer JavaScriptの連携方法 コードをASTに変換し、JSONとしてエンコードする部分(ast.go)に関しては、一切変更しなくても動きました。素晴らしい。
ただし、さすがにブラウザ上でHTTPサーバーは動かない(そういえば試してないけど、動かないよね？？)ので、JavaScriptとの連携部分を実装してあげる必要があります。 syscall/jsパッケージはまだ実験段階というステータスで機能が限られているので、 連携には少し工夫が必要です。
JavaScriptからGoの関数を呼ぶ JavaScriptからGoの関数を呼ぶには window にコールバック関数として必要な関数を登録します。
// GoASTParse 関数を定義(Go言語) js.Global().Set(&amp;#34;GoASTParse&amp;#34;, js.NewCallback(func(args []js.Value) { source := args[0].String() // ...ASTへの変換処理... })) 戻り値をGoからJavaScriptへ返す js.NewCallback なのですが、もともとは addEventListener にわたすコールバック関数なので、 関数の戻り値を受けわたす方法がありません。 回避方法はいろいろあるでしょうが、今回はコールバック関数の引数にコールバック関数指定してもらうことにしました。
// GoASTParse 関数を定義(Go言語) js.Global().Set(&amp;#34;GoASTParse&amp;#34;, js.NewCallback(func(args []js.Value) { source := args[0].String() // ...ASTへの変換処理... args[1].Invoke(string(body)) })) // GoASTParseを呼び出す(JavaScript) GoASTParse(&amp;#34;package main; func main() {}&amp;#34;, function(body) { // ASTの表示処理 }) まとめ Goのバイナリ全般に言えることですが、WASMになってもやっぱりサイズが大きい(3.5M)。 今後のパフォーマンス向上に期待です。
GoよりAngulerJSの方が難しかったʕ　ﾟ皿ﾟ ʔ</description>
    </item>
    <item>
      <title>Web JJY が夏時間に対応しました</title>
      <link>https://shogo82148.github.io/blog/2018/08/11/web-jjy-summer-time-support/</link>
      <pubDate>Sat, 11 Aug 2018 07:29:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2018/08/11/web-jjy-summer-time-support/</guid>
      <description>サマータイムなんて日本人には関係ないと思っていた時期が僕にもありました。 ところが何やら日本にもサマータイムがやってくる動きがあるようです。
酷暑対策でサマータイム導入へ　秋の臨時国会で議員立法　３１、３２年限定 さて、長波JJY(市販の電波時計のための電波)には夏時間の情報が含まれています。 「将来の拡張性のための予備ビット」という扱いなので、対応している時計なんてないだろう、と思っていたら、 なんと対応している時計が存在しているらしいということを知りました。
その事実を確かめるため、Webブラウザを使って電波を出してみたで紹介した JJYシミュレータWeb版に夏時間を有効にするチェックボックスを追加しました。
CITIZEN 8RZ152 の動作例 夏時間への同期、完了しました 😂😂😂 pic.twitter.com/3tMcCYdXpP
&amp;mdash; Ichinose Shogo (@shogo82148) 2018年8月9日 念の為書いておきますが、今は午前8時です
&amp;mdash; Ichinose Shogo (@shogo82148) 2018年8月9日 DST(Daylight Saving Time)の表示が出て、夏時間に切り替わったことがわかりますが、なぜか6時間もズレています・・・。
もう、こんな時間だ……そろそろ寝よう……
？？？お前24時間表記だっただろ？どうしたんだ？？？
(今は20時です) pic.twitter.com/8PViLOaj85
&amp;mdash; Ichinose Shogo (@shogo82148) 2018年8月10日 悲報 11日を迎えることができず pic.twitter.com/pw0k0Qo8RY
&amp;mdash; Ichinose Shogo (@shogo82148) 2018年8月10日 もはや数字ではないものが出てきた。
まとめ 夏時間に対応した電波時計の存在は事実でした。 しかし、機種によっては挙動がおかしくなるようです(N=1)。
ぜひ、みなさんもお手元の電波時計で試してみてください！
JJYシミュレータWeb版 ※ 利用の結果生じた損害について、一切責任を負いません。
参考 標準電波の出し方について 酷暑対策でサマータイム導入へ　秋の臨時国会で議員立法　３１、３２年限定 Webブラウザを使って電波を出してみた サマータイムで日本中の電波時計がゴミになる(かも)という話 サマータイム導入で「電波時計が狂う」？　メーカーに聞いた 「サマータイム導入はコンピュータシステム的に難あり」は本当か サマータイム実施は不可能である from UEHARA, Tetsutaro 僕もサマータイム実施は不可能だと思います・・・。</description>
    </item>
    <item>
      <title>S3からファイルを落とすだけのツールを作った</title>
      <link>https://shogo82148.github.io/blog/2018/06/20/s3cli-mini/</link>
      <pubDate>Wed, 20 Jun 2018 07:29:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2018/06/20/s3cli-mini/</guid>
      <description>S3からファイルを落とすだけのツールを作りました。
s3cli-mini 目的 流行りのCD(継続的デリバリー)を実践するために、専用のデプロイツールをダウンロードする目的で作りました。
主なデプロイ先はAWSなので、デプロイ操作には awscli が必要です。 しかしCDに使用しているCircleCIが公式に提供しているコンテナイメージにはawscliがインストールされていません。 もちろん apt-get install awscli であとからインストールすることは可能ですが、そのぶんジョブの実行時間が長くなってしまいます。 また、インストールされる awscli のバージョンが古く、ローカル環境ではうまく動くけど、 CircleCI上では最新の機能が使えず失敗するということがありました。
そこでもう awscli を使うことは諦めて、Goで AWS API を叩いてデプロイするバイナリを作ってしまうことを考えました。 Goであればシングルバイナリでインストール可能で、CI/CD環境とローカルでバージョンが一致せず悩まされることはありません。 また並行処理が得意なので、デプロイの時間短縮も図れます。
しかし、このデプロイ用のバイナリをどこに置くか・・・プロジェクト固有の処理が入っているので外部には公開したくない。 かといってプライベートなS3バケットに置くと、ダウンロードに awscli が必要になってしまう・・・。 awscli を使うのは諦めたはずでは・・・という、いわゆる「鶏が先か、卵が先か」問題に陥ってしまいました。
そこでS3からのダウンロードの処理に特化したミニawscliが欲しくなって作成したのが s3cli-mini です。
使い方 現状v0.0.1でサポートしているのは cp コマンドのみです。 S3バケットからファイルをダウンロードしたり、S3バケットへファイルをアップロードしたり、 別のS3バケットへファイルを転送することができます。
# download from a S3 bucket s3cli-mini cp s3://your-bucket/foobar.zip . # upload to a S3 bucket s3cli-mini cp foobar.zip s3://your-bucket/ # copy the file from a S3 bucket to another S3 bucket.</description>
    </item>
    <item>
      <title>GoでHTTPとS3を透過的に扱う</title>
      <link>https://shogo82148.github.io/blog/2018/06/09/go-s3-protocol/</link>
      <pubDate>Sat, 09 Jun 2018 07:29:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2018/06/09/go-s3-protocol/</guid>
      <description>Goの http.Transport には RegisterProtocol というメソッドが生えていて これを使うと、 HTTP以外のプロトコルを透過的に扱うことができます。 代表的なのは http.NewFileTransport で、これを使うと、file://path/to/file.txt みたいなURLでファイルにアクセスすることができます。 (Goオフィシャルの例) この仕組を使って、S3へのアクセスも透過的にできるようにしてみたので、メモ。
新しいプロトコルを作成するのは非常に簡単です。 http.RoundTripperインターフェースを実装し、リクエストに応答するレスポンスを作ってあげればいいだけです。 S3の場合以下のようになります。(エラー時の扱いが雑だけど・・・)
package main import ( &amp;#34;net/http&amp;#34; &amp;#34;github.com/aws/aws-sdk-go/aws&amp;#34; &amp;#34;github.com/aws/aws-sdk-go/aws/session&amp;#34; &amp;#34;github.com/aws/aws-sdk-go/service/s3&amp;#34; ) type s3RoundTripper struct { s3 *s3.S3 } func newS3RoundTripper(session *session.Session) http.RoundTripper { return &amp;amp;s3RoundTripper{ s3: s3.New(session), } } func (rt *s3RoundTripper) RoundTrip(req *http.Request) (*http.Response, error) { host := req.Host if host == &amp;#34;&amp;#34; { host = req.URL.Host } path := req.URL.Path ctx := req.Context() out, err := rt.</description>
    </item>
    <item>
      <title>Goの構造体のコピーを防止する方法</title>
      <link>https://shogo82148.github.io/blog/2018/05/16/macopy-is-struct/</link>
      <pubDate>Wed, 16 May 2018 07:29:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2018/05/16/macopy-is-struct/</guid>
      <description>去年仕込んだネタが見つかってしまったので、macopy 構造体について一応解説。
https://t.co/mHq6oWY3rj
macopyさん構造体だったのか・・・
&amp;mdash; serinuntius (@_serinuntius) 2018年5月14日 2021-05-25 追記
今はこの方法では動かないというツイートを見かけました。
これで出てくる &amp;quot;Goの文法を使った構造体のコピーを防ぐ方法&amp;quot; が動かなかった話ですが https://t.co/FpEnspIfmN このへんに書いてありました.重要なことはその型がstructであること,Lock だけでなく Unlockも実装されていることでした.https://t.co/zQc6T058Ip このように変更すると検知されました
&amp;mdash; おりさの (@orisano) May 25, 2021 どうやら Go 1.11 から判定基準が 「sync.Locker を実装しているか」に変わっていたようです。 (修正コミット: c2eba53, Issue: #26165)
というわけで、 macopy 構造体を以下のように変更する必要があります。
type macopy struct{} func (*macopy) Lock() {} func (*macopy) Unlock() {} 追記ここまで
目的 深淵な理由で Go の構造体のコピーを禁止したい場合があると思います。 kuiperbelt のケースでは、sync/atomic パッケージを使ってフィールドを更新しているので、 フィールドへの読み書きは必ず sync/atomic パッケージを使わなければなりません。 sync/atomic パッケージを使わずに構造体をコピーするとレースコンディションが発生してしまうので、コピーを禁止する必要がありました。
// https://github.com/kuiperbelt/kuiperbelt/blob/e3c1432ed798716c8e88183518f9126951c227f3/stats.go#L20-L28 type Stats struct { connections int64 totalConnections int64 totalMessages int64 connectErrors int64 messageErrors int64 closingConnections int64 noCopy macopy } // atomic.</description>
    </item>
    <item>
      <title>OctopressからHugoに乗り換えた</title>
      <link>https://shogo82148.github.io/blog/2018/04/10/migrate-to-hugo/</link>
      <pubDate>Tue, 10 Apr 2018 07:49:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2018/04/10/migrate-to-hugo/</guid>
      <description>OctopressからHugoに乗り換えました。 以下のような理由からです。
Rubyの環境をメンテナンスし続けるのが面倒 最近Octopress自体の更新が滞っている ビルド時間が長い 一番最初の理由が大きくて、いつもビルドしていた環境を壊してしまって修復が面倒になってしまいました。 そこでようやく重い腰を上げて移行したというわけです。
移行手順 OctopressからHugoへの移行は先人たちがたくさんいるので、それを参考にします。
# 記事のコピー cp octopress-site/source/_posts/* hugo-site/content/post/ # 画像のコピー cp -r octopress-site/source/images/* hugo-site/static/images/ # 記事のタイムスタンプの形式を変える # Hugoでは、&amp;#34;2016-09-25T15:09:57&amp;#34;のような形式のタイムスタンプでないとパースに失敗します find . -type f -exec sed -i &amp;#34;&amp;#34; -e &amp;#39;s/date: \([0-9]\{4\}-[0-9]\{2\}-[0-9]\{2\}\) \([0-9]\{2\}:[0-9]\{2\}\)$/date: \1T\2:00+09:00/g&amp;#39; {} \; パーマネントリンクを維持するために OctopressからHugoへ移行する方法 のRubyスクリプトを利用させていただきました。
dir = &amp;#39;content/post/&amp;#39; Dir::foreach(dir) do |filename| if filename =~ /\.markdown$/ slug = filename.gsub(/\d{4}-\d{2}-\d{2}-/, &amp;#39;&amp;#39;).sub(&amp;#39;.markdown&amp;#39;, &amp;#39;&amp;#39;) puts &amp;#34;#{filename} : #{slug}&amp;#34; lines = [] File::open(dir + filename) do |f| f.each do |line| lines &amp;lt;&amp;lt; line end end File::open(dir + filename, &amp;#39;w&amp;#39;) do |f| lines.</description>
    </item>
    <item>
      <title>Mackerel AWS Integration 用の CloudFormation テンプレートを書いた</title>
      <link>https://shogo82148.github.io/blog/2018/01/02/cloudformation-template-for-mackerel-integration/</link>
      <pubDate>Tue, 02 Jan 2018 12:36:51 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2018/01/02/cloudformation-template-for-mackerel-integration/</guid>
      <description>昨年の年末から Mackerel の本格導入を始めました。 それに当たって AWS Integration 用の CloudFormation テンプレートを書いたので、 他のプロジェクトでも導入が簡単になるよう公開しました。
shogo82148/cf_mackerel 使い方 GitHub Pages でテンプレートを公開しているので、 template-body にテンプレートのURLを指定して、 新しいスタックを作成するだけです。
aws cloudformation create-stack --stack-name &amp;#34;MackerelIntegrationIamUser&amp;#34; \ --template-body https://shogo82148.github.io/cf_mackerel/mackerel.yaml \ --capabilities CAPABILITY_NAMED_IAM 新しい名前付きIAMロールを作成するので CAPABILITY_NAMED_IAM が必要です。
作成がうまくいくとOutputに以下のようなARNが出力されるので、 MackerelのAWS Integrationの設定画面へ入力しましょう。
arn:aws:iam::xxxxxxxxxxxx:role/MackerelAWSIntegrationRole-ap-northeast-1 ロール名について ロール名が意図せずに変わってしまって連携が切れてしまうのを防ぐため、 ロール名は決め打ちです。
MackerelAWSIntegrationRole-ap-northeast-1
ロール名にリージョン名(この場合は ap-northeast-1)が含まれていますが、 作成されたロールはグローバルなリソースなので、他のリージョンでも使用可能です。 わざわざリージョン名含めているのは CloudFormation の警告にしたがったためです。
警告
IAM リソースに名前を付けると、複数のリージョンで同じテンプレートを再利用した場合に、回復不能なエラーが発生する場合があります。 これを防止するために、Fn::Join と AWS::Region を使用して、次の例のように地域固有の名前を作成することをお勧めします RoleName
回復不能なエラー！！
コワイので実際に何が起こるかは試してませんが、警告には素直に従っておくことにします。
参考 AWS::IAM::Role - AWS CloudFormation - mackerelのAWSインテグレーション用IAM Userをcloudformationで作る Tomohiro/tf_mackerel 同じことをするTerraformのモジュール </description>
    </item>
    <item>
      <title>MeCabをAWS Lambdaで動かす(2017年版)</title>
      <link>https://shogo82148.github.io/blog/2017/12/06/mecab-in-lambda/</link>
      <pubDate>Wed, 06 Dec 2017 05:39:57 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2017/12/06/mecab-in-lambda/</guid>
      <description>AWS Lambda上で鯖(Mackerel)の曖昧性問題を機械学習で解決しようの記事の中で、 Lambda上でMeCabを動かすことについて以下のように触れられています。
日本語を扱う自然言語処理ではMeCabを扱うことが多いですが、Lambda上でMeCabを動かすのは一手間必要なようです。
確かにLambda上でMeCabを動かすのは一手間必要です。 しかし、参照している記事は少し古くて、今はもう少し手軽にできるようになっています。
ブコメでも言及しましたが、改めて記事として残しておこうと思います。
ビルド方法(2017年版) 結論から言うと Norio Kimura さんのコメント 通りにビルドするのが、2017年12月現在一番楽な方法です。 (お返事すっかり忘れていてスイマセン・・・情報提供ありがとうございます)
調べてみると、AWS Lambda では環境変数 LD_LIBRARY_PATH が既に設定されていて /var/task/lib を含んでいました。元記事で ./configure &amp;ndash;prefix=$PROJECT_HOME/local ではなく ./configure &amp;ndash;prefix=$PROJECT_HOME とすればライブラリとの動的リンクは何もしなくても実現できます。さらにコードが展開されるディレクトリ /var/task を固定値だと決め打ちして PROJECT_HOME を /var/task にして開発すれば MeCab に渡すパラメーターの設定（-d, -r）も不要になります。undocumented な仕様に２つも依存していて気持ち悪いですが、MeCab を呼ぶ側のコードを Lambda 用に変更する必要がなくなります。
コメント中の元記事というのは、こちらの記事のことです。
AWS Lambda で MeCab を動かす export PROJECT_HOME=/var/task # LAMBDA_TASK_ROOT # 1. プロジェクト用にディレクトリを作成 mkdir -p &amp;#34;$PROJECT_HOME&amp;#34; # 2. MeCabのダウンロードとインストール # googlecodeサービス終了に伴い、ダウンロードURLが元記事と変わっていることに注意 cd &amp;#34;$HOME&amp;#34; curl -fsSL &amp;#34;https://drive.google.com/uc?export=download&amp;amp;id=0B4y35FiV1wh7cENtOXlicTFaRUE&amp;#34; -o mecab.tar.gz cd mecab-0.996 .</description>
    </item>
    <item>
      <title>Go言語の浮動小数点数のお話</title>
      <link>https://shogo82148.github.io/blog/2017/10/28/golang-floating-point-number/</link>
      <pubDate>Sat, 28 Oct 2017 20:12:48 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2017/10/28/golang-floating-point-number/</guid>
      <description>元ネタ:
[JavaScriptの問題]
var a = 0.3 - 0.2;
var b = 0.2 - 0.1;
var c = a==b;
cの中身はどれ？
&amp;mdash; RAO(らお)@けもケP-31 (@RIORAO) 2017年10月24日 正確な実数計算をやらされるJavaScriptくん #擬竜戯画 pic.twitter.com/ipE56C2YbV
&amp;mdash; RAO(らお)@けもケP-31 (@RIORAO) 2017年10月26日 コンピューターで浮動小数点数を扱ったことのある人なら一度は経験する、 数学上の計算とコンピューター上の計算が合わない計算の一例ですね。
この件に関して、Go言語では正しく(=数学的な結果と同じように)計算できるとの情報が。
おそらくGoはコンパイラがa=0.1とb=0.1に変換していると思われます。
添付した画像のコードだとtrueになりますが、constをvarに変更するとfalseになります。constはコンパイル時に計算されますが、varは実行時に計算されるためです。 pic.twitter.com/LpKZF2kOjH
&amp;mdash; morikuni (@inukirom) 2017年10月27日 しかしながら、inukiromさんのこの推察、半分はあってますが、半分は間違っていると思います。 なぜGo言語でこのような結果になったのか、検証してみました。
Goの数値定数の型について 以前Go言語でコンパイル時フィボナッチ数列計算で紹介した Better C - Go言語と整数 #golangにもあるように、 Goの定数には「型がない(場合がある)」「任意の精度で計算してくれる」という特徴があります。
このため、普通はどう考えてもオーバーフローしそうなこんな演算も・・・
package main import ( &amp;#34;fmt&amp;#34; ) func main() { var i uint64 = 31415926535897932384626433832795028841971693993751058209749445923078164062862089986280348253421170679 % 1000000007 fmt.Println(i) } play.golang.org/p/FkMVpY2Fa3 型がない定数同士の演算は 162132938 と正しい答えを出してくれます。</description>
    </item>
    <item>
      <title>ACMのドメイン検証をシミュレートするやつ書いた</title>
      <link>https://shogo82148.github.io/blog/2017/10/22/aws-certification-manager-validation/</link>
      <pubDate>Sun, 22 Oct 2017 15:45:02 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2017/10/22/aws-certification-manager-validation/</guid>
      <description>始まりは一件のメールから。
Title: Action Required - Your certificate renewal
Greetings from Amazon Web Services,
You have an AWS Certificate Manager (ACM) provided SSL/TLS certificate in your AWS account that expires on Nov 04, 2017 at 12:00:00 UTC. That certificate has the following domains: example.com, *.example.com
AWS account ID: xxxxxx AWS Region name: us-east-1 Certificate identifier: arn:aws:acm:us-east-1:xxxxxx:certificate/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
Therefore, ACM has initiated the process to renew this certificate. You must take the action below before Nov 04, 2017 at 12:00:00 UTC to avoid certificate expiration, which might cause your website to become unreachable.</description>
    </item>
    <item>
      <title>Perl 5.26 &amp; Unicode 9.0 で変わる書記素クラスタ(grapheme cluster)のお話</title>
      <link>https://shogo82148.github.io/blog/2017/08/25/unicode9-grapheme-cluster/</link>
      <pubDate>Fri, 25 Aug 2017 07:08:44 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2017/08/25/unicode9-grapheme-cluster/</guid>
      <description>WEB+DB PRESS Vol.100が発売されましたね。 記念すべき Vol.100 おめでとうございます！
WEB+DB PRESS の連載「Perl Hackers Hub」今回のテーマは「【第46回】Perl 5.26で変わること」です。 Perl 5.26 で追加になった機能、アップグレードの際に気をつけなければならないところ( 特に @INC 問題とか )などに触れられているので、 Perl Monger の方はぜひ読むとよいと思います。
追加された機能のひとつとして Unicode 9.0 サポートが挙げられているのですが、以下のような簡単な紹介に留まっています。
Unicode 9.0にはオリンピックで活躍するであろう金銀 銅メダルの絵文字などが追加されました。
Unicode 9.0 で変わるのはそれだけではありません！ Unicode 9.0 での 書記素クラスタ(grapheme cluster) の扱いを少し前に調査したので紹介します。
書記素クラスタ(grapheme cluster)とは 書記素クラスタ(grapheme cluster)とは、人間にとって自然な1文字を表すものです。
たとえば &amp;ldquo;é&amp;rdquo; という文字は一見1文字に見えますが、 length で文字数をカウントすると2文字としてカウントされます。
$ perl -Mutf8 -E &amp;#39;say length &amp;#34;é&amp;#34;&amp;#39; 2 これは length がUnicodeのコードポイント数を数えており、 &amp;ldquo;é&amp;quot;が&amp;quot;e&amp;rdquo;(U+0065) + アクセント記号(U+0301) の2つのコードポイントで構成されているためです。
他にも異字体セレクタというのがあったり、 絵文字シーケンスというのがあったりして、 コードポイントの数＝文字数とは限りません。
これらの文字たちを1文字として数えるための概念が書記素クラスタ(grapheme cluster)です。
Unicode 9.0での変更点 Unicode 8.</description>
    </item>
    <item>
      <title>Go1.9から使える Monotonic Clocks を試してみた</title>
      <link>https://shogo82148.github.io/blog/2017/06/26/go19-monotonic-clock/</link>
      <pubDate>Mon, 26 Jun 2017 09:21:42 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2017/06/26/go19-monotonic-clock/</guid>
      <description>先日Go1.9beta1がリリースされました。
Go 1.9 Beta 1 is released!
Announcement:https://t.co/lV5nvXwOoR
Get it!https://t.co/2LhlOo2EtX#golang pic.twitter.com/zm09DwX93q
&amp;mdash; Go (@golang) 2017年6月14日 Go 1.9 Release Notes 型エイリアスのサポート、math/bitsパッケージ、 sync.Map型など、 今回のアップデートでも便利そうな機能が追加されます。 詳しくはtenntennさんのGopher Fest 2017参加レポートをどうぞ。
今回のリリースノートを見て、個人的に注目しているのはMonotonic Clocksのサポートです。 他の機能追加はTwitterとかで見かけるけど、 Monotonic Clocksはなぜかあまり見ない・・・。 beta1がでて手軽に試せるようになったので、試してみました。
Monotonic Clocks Go1.8以前で取得していた時刻は「wall clock」といい、現在の正しい時刻を知るために使います。 一方「monotonic clock」は、時間を計るために使うものです。 Go1.9からはtime.Nowで取得できる時刻に「wall clock」と「monotonic clock」が含まれるようになります。
timeパッケージのドキュメントから コード片を引用します。
t := time.Now() ... operation that takes 20 milliseconds ... u := time.Now() elapsed := t.Sub(u) 上のコードで elapsed は 20ms となるはずですが、 実際はそうはならないケースがあります。 具体的には以下のようなケースです。
ntpdなどによってOSの時刻が変更された場合 うるう秒が挿入・削除された場合 Go1.9からはこのようなケースでも正しく時間を計ることができます。
うるう秒を入れてみた うるう秒が入ったときの挙動が気になったので実際にやってみました。 セットアップが簡単になるようNICTのPerl版SNTPのGolangポートを作ったので、 それを使って偽物のうるう秒を挿入してみます。</description>
    </item>
    <item>
      <title>ぼくのかんがえたさいきょうのcontext対応版go-mysql-driverをマージしてもらった</title>
      <link>https://shogo82148.github.io/blog/2017/06/16/mysql-driver-and-context/</link>
      <pubDate>Fri, 16 Jun 2017 07:11:15 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2017/06/16/mysql-driver-and-context/</guid>
      <description>go-sql-driverにcontext.Context対応するプルリクエスト go-sql-driver/mysql#608 を送って取り込んでもらいました！！ 現時点ではまだ正式リリースされていませんが、次のリリース(version 1.4)から使えるようにはずです。 masterブランチではすでに使えるようになっているので、引き続き人柱募集中です。
コネクションプーリングを実装していて、自分も「context.Contextサポートしたい！」というかたのために、 実装の概要をメモとして残しておきます。
おおまかな仕組み 「contextの監視のみを行うgoroutine(以下、watcher goroutine)」をあらかじめ起動しておく 「やりたい処理を実際に実行するgoroutine(以下、executor goritune)」とchannelを経由してcontext.Contextをやり取りする watcher goroutineがこの実装で一番重要な部分です。
watcher goroutine の実装 一番重要な watcher goroutine の実装例から見てみましょう (実際には細かい最適化などが入るため、マージされたコードとは異なります)。
func (mc *mysqlConn) startWatcher() { // executor goritune と `context.Context` のやり取りをするための channel watcher := make(chan context.Context, 1) mc.watcher = watcher // executor goritune で処理が完了したことを知るための channel finished := make(chan struct{}) mc.finished = finished // コネクションがCloseされたことを知らせるための channel mc.closech = make(chan struct{}) // ここから watcher goroutine 本体 go func() { for { // executor goritune から `context.</description>
    </item>
    <item>
      <title>Re: GoとPythonとGrumpyの速度ベンチマーク</title>
      <link>https://shogo82148.github.io/blog/2017/05/30/grumpy/</link>
      <pubDate>Tue, 30 May 2017 17:53:32 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2017/05/30/grumpy/</guid>
      <description>GoとPythonとGrumpyの速度ベンチマーク ～Googleのトランスパイラはどれくらい速い？～という記事を拝読したのですが、 もう一歩踏み込んで検証して欲しい・・・。
並列処理性能が優れているほか、PythonコードからGoのパッケージをPythonモジュールのように呼び出して利用することもできるという特徴がある。
とGoogle、すごくスケールするPython実行環境をGoで開発から引用しているのに、 この件に全く触れていないんですよね。 Twitterに呟いたってどうせ誰もやってくれない気がするので、自分で試してみました。
環境 この記事を書いている2017年5月30日現在の最新バージョンで検証しました。
go version go1.8.3 darwin/amd64 CPython 2.7.13 Grumpy d8d01899f5 Grumpyのインストール方法はREADMEにある通り。
make export GOPATH=$PWD/build export PYTHONPATH=$PWD/build/lib/python2.7/site-packages ただ個人的な環境問題としてPythonのバージョン管理に利用しているpyenvとの相性が悪いらしく、 pyenvが管理しているPythonへのパスを直接通す必要がありました。 (これがないとPythonスクリプトがなぜかbashに処理される。なんかこの問題最近Twitterで見たような・・・)
export PATH=$HOME/.pyenv/versions/2.7.13/bin:$PATH モンテカルロ法を並列実行してみる まず、並列処理性能について検証してみましょう。 モンテカルロ法の各試行は独立しているので、並列実行にするのは容易です。 Python2のthreadingモジュールを使って並列実行してみましょう。
コード #coding:utf-8 # モンテカルロ法 Pure Python 並列版 import threading import random import sys class MyThread(threading.Thread): def __init__(self): super(MyThread, self).__init__() self.c = 0 def run(self): r = random.Random() c = 0 for _ in xrange(num): x = r.random() y = r.</description>
    </item>
    <item>
      <title>String::RandomのGo移植を書いてみた</title>
      <link>https://shogo82148.github.io/blog/2017/05/04/go-rerand/</link>
      <pubDate>Thu, 04 May 2017 10:57:37 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2017/05/04/go-rerand/</guid>
      <description>golangkyotoでString::RandomのGo移植についての発表があったと聞き、 これに対抗して以前途中まで書いていたString::RandomのGo移植をちょっといじって公開しました。
shogo82148/go-rerand 背景 ナイーブな実装の問題点 実はgolangkyoto以前にもGoの正規表現エンジンを使ってランダムな文字列を生成する試みはあって、 たしかにこれは面白そうだと記事を読んでいました。
「Goの正規表現エンジンを使ってファジング用ツールを書いてみる」 しかし、gocha同様、この実装では文字列の長さが幾何分布に従うため、短い文字が多めにでてしまいます。
% gocha -n 100000 &amp;#39;a*&amp;#39; | sort | uniq -c 50054 24894 a 12633 aa 6278 aaa 2994 aaaa 1517 aaaaa 809 aaaaaa 400 aaaaaaa 206 aaaaaaaa 109 aaaaaaaaa 54 aaaaaaaaaa 22 aaaaaaaaaaa 15 aaaaaaaaaaaa 7 aaaaaaaaaaaaa 4 aaaaaaaaaaaaaa 3 aaaaaaaaaaaaaaa 1 aaaaaaaaaaaaaaaa 正規表現のパターンを数え上げとその問題点 この問題を解決するために 「この先何パターンあるかを調べておけば、正規表現が表す文字列の集合からランダムに文字列を取り出せるのでは？」 と考え、golangkyoto以前からちょこちょこ実装を進め、不完全ながらも一応動作するところまでは書いていたのです。 有向グラフの経路数えあげ問題なので、メモ化再帰を使って頑張れば解けます。 少々面倒ですが、おねえさんの問題と比べれば簡単です。
パターンを数え上げる都合上、組み合わせが無限にある a* ような正規表現は扱えません。 a{1,10} のように明示的に範囲を指定する必要があります。 たとえば a{1,10} は10パターン組み合わせがあるので、20万個ランダムに生成すると、それぞれのパターンがおおよそ2万個ずつ生成されます。 (-d オプションについては後述)
$ rerand -d -n 200000 &amp;#39;a{1,10}&amp;#39; | sort | uniq -c 20153 a 19863 aa 19899 aaa 19908 aaaa 19975 aaaaa 20000 aaaaaa 20081 aaaaaaa 20021 aaaaaaaa 20072 aaaaaaaaa 20028 aaaaaaaaaa [ab]{1,3}のような正規表現でも、それぞれのパターンがおおよそ同じ数だけ生成されます。</description>
    </item>
    <item>
      <title>Re: PostgreSQLで排他制約がめっちゃ便利！！</title>
      <link>https://shogo82148.github.io/blog/2017/04/22/postgresql-exclusion-constraint/</link>
      <pubDate>Sat, 22 Apr 2017 19:10:21 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2017/04/22/postgresql-exclusion-constraint/</guid>
      <description>PostgreSQLで排他制約がめっちゃ便利！！を拝見したのですが、 とても些細なミスがあるのに気がついてしまいました。 本題とは関係ない重箱の隅をつつくような話なので、わざわざコメントするほどのことでもないかと考えていたのですが、 どうしても試してみたいクエリを思いつき、 偶然にもRedis、PostgreSQL、MySQLで近傍検索したときに セットアップしたPostgreSQL環境が残っていたのでやってみました。
試したかったこと そーだいさんの記事からSQLの実行結果を一部引用します。
demo=# SELECT * FROM schedule; schedule_id | room_name | reservation_time -------------+-------------+----------------------------------------------- 1 | soudai_room | [&amp;#34;2017-04-16 11:30:00&amp;#34;,&amp;#34;2017-04-16 12:00:00&amp;#34;) 4 | soudai_room | [&amp;#34;2017-04-16 12:00:00&amp;#34;,&amp;#34;2017-04-16 12:30:00&amp;#34;) 5 | soudai_room | (&amp;#34;2017-04-16 12:30:00&amp;#34;,&amp;#34;2017-04-16 12:40:00&amp;#34;) 8 | soudai_room | [&amp;#34;2017-04-16 14:30:00&amp;#34;,&amp;#34;2017-04-16 16:00:00&amp;#34;) (4 行) schedule_idの5をよく見て下さい。 他のスケジュールは半開区間[)(開始時刻は期間に含むが、終了時刻は期間に含まない)になっているのですが、 schedule_idの5だけ開区間()(開始時刻も終了時刻も期間に含まない)になっています。 つまり 2017-04-16 12:30:00 ジャストに空き時間があるのです。
ここに予約を入れてみたい！！！
試してみた 環境再現 以下のSQLを実行して、そーだいさんの記事と同じ内容を含んだテーブルを作成します。
CREATE TABLE schedule ( schedule_id SERIAL PRIMARY KEY NOT NULL, room_name TEXT NOT NULL, reservation_time tsrange NOT NULL ); INSERT INTO schedule (schedule_id, room_name, reservation_time) VALUES (1, &amp;#39;soudai_room&amp;#39;, &amp;#39;[&amp;#34;2017-04-16 11:30:00&amp;#34;,&amp;#34;2017-04-16 12:00:00&amp;#34;)&amp;#39;), (4, &amp;#39;soudai_room&amp;#39;, &amp;#39;[&amp;#34;2017-04-16 12:00:00&amp;#34;,&amp;#34;2017-04-16 12:30:00&amp;#34;)&amp;#39;), (5, &amp;#39;soudai_room&amp;#39;, &amp;#39;(&amp;#34;2017-04-16 12:30:00&amp;#34;,&amp;#34;2017-04-16 12:40:00&amp;#34;)&amp;#39;), (8, &amp;#39;soudai_room&amp;#39;, &amp;#39;[&amp;#34;2017-04-16 14:30:00&amp;#34;,&amp;#34;2017-04-16 16:00:00&amp;#34;)&amp;#39;); -- schedule_idが1から始まってしまい、INSERTした内容と重複してしまうので調整 SELECT setval (&amp;#39;schedule_schedule_id_seq&amp;#39;, 8); SELECTを実行すると同じ内容になっていることを確認できます。</description>
    </item>
    <item>
      <title>Perl&#43;List::Utilの64bit整数の罠にはまった話</title>
      <link>https://shogo82148.github.io/blog/2017/04/13/perl-int64/</link>
      <pubDate>Thu, 13 Apr 2017 19:52:13 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2017/04/13/perl-int64/</guid>
      <description>先日 Google Code Jam Qualification Round 2017 が開催されました (って何？というひとはAboutのページを確認。本題では無いので説明略)。
僕もこれに参加して、D以外の問題A,B,Cを解いて、無事Round1へ進むことができました。 しかしPerlで解いたC-largeだけ何故か間違いの判定。 原因を探ってみたところ、PerlおよびList::Utilの64bit整数の罠にはまっていたことに気が付いたので、その備忘録として残しておきます。
問題が発生したコード 問題が発生するのは以下の計算をするコードです。
max: 250000000000000000と249999999999999999で大きい方を返す div: 249999999999999999を2で割った商を求める この計算をそれぞれ二通りの計算方法で実装してみます。
use 5.24.0; use List::Util qw(max); say &amp;#34;max:&amp;#34;; say max(250000000000000000, 249999999999999999); say max(249999999999999999, 250000000000000000); say &amp;#34;div:&amp;#34;; say int(249999999999999999/2); say 249999999999999999 &amp;gt;&amp;gt; 1; max: 順番を変えただけなので、同じ結果をになるはず div: 割り算と等価なビットシフトに置き換えたので、同じ結果になるはず 僕は「同じ結果になるはず」と期待していました。 しかし、これを実行してみると以下のようになります。
[Wandbox]三へ( へ՞ਊ ՞)へ ﾊｯﾊｯ https://wandbox.org/permlink/5fUBzLmBCRKUo4xZ max: 249999999999999999 250000000000000000 div: 125000000000000000 124999999999999999 原因 250000000000000000は大体2^57.8なので、64bitの整数で十分表現できます。 しかし倍精度浮動小数点数として扱われると、精度が53bit分しかないので正確に表現できないのです。
例えば以下のコードは&amp;quot;true&amp;quot;を出力します(ここだけ何故かGo)。
package main import ( &amp;#34;fmt&amp;#34; ) func main() { fmt.</description>
    </item>
    <item>
      <title>Go言語のヒープに確保するデータの初期化コストについて調べてみた(Go1.8.1版)</title>
      <link>https://shogo82148.github.io/blog/2017/04/13/go1-8-allocation/</link>
      <pubDate>Thu, 13 Apr 2017 08:23:08 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2017/04/13/go1-8-allocation/</guid>
      <description>golangで
p := new(Type)
と
p := &amp;amp;Type{}
の使い分けってどうするべきだろう?
&amp;mdash; MURAOKA Taro (@kaoriya) 2017年4月12日 こちらのツイートに対して、以下のベンチ結果が紹介されていました。
Go言語のヒープに確保するデータの初期化コストについて調べてみた しかしhnakamur2さんも言及しているように、 これはGo1.2.2時の結果。 その後、GoのコンパイラがGo実装になったり、SSAが導入されたりと、 今のコンパイラの実装は当時とは全く違うものになっています。
というわけで、現時点での最新のバージョン(Go1.8.1)で、同様の検証をおこなってみました。
検証コード 検証に使用したコードはGo1.2.2のときと全く同じものです。
// alloc_overhead.go package main type container struct { v [64]byte } func MakeContainer() *container { c := container{} return &amp;amp;c } func MakeContainerOneLine() *container { return &amp;amp;container{} } func MakeContainerNew() *container { return new(container) } func main() { _ = MakeContainer() _ = MakeContainerOneLine() _ = MakeContainerNew() } // alloc_overhead_test.</description>
    </item>
    <item>
      <title>Redis、PostgreSQL、MySQLで近傍検索</title>
      <link>https://shogo82148.github.io/blog/2017/03/28/database-gis/</link>
      <pubDate>Tue, 28 Mar 2017 19:59:49 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2017/03/28/database-gis/</guid>
      <description>「サーバーで付近の情報を通知するサービスのつくり方」 という、Geohashを使って近傍検索を実現する記事をみつけました。 最近Redisに関する記事を書いた関係で、 この記事をみて「GeohashはRedisと一緒に使うともっと便利だよ！」と思わず宣伝したくなったのですが、 MySQL5.7でInnoDBに空間インデックス(Spatial Index)のサポートが入ったので 「MySQLでももっと簡単にできるのでは？」と思い、 RedisやMySQLを含めたいろんなDBで近傍検索を実現する方法を調べてみました。
以前、スマートフォンのセンサを活用して花火の打ち上げ場所を推定するアプリを作った関係で、 地球上での距離計算の実装も気になったので、それについても調査してみました。
関連知識 GeoHash Geohash（ジオハッシュ） は緯度・経度を短い文字列に変換する方法です。 距離が近い2地点のGeohashは似たような文字列になるという特徴があります(一部例外あり)。 この特徴を利用すると、文字列検索だけで近傍検索が実現できます。
地球上の二点間の距離 地球は完全な球体ではなく、回転楕円体であることが知られています。 地球の形がわからないと緯度・経度などを決められないので、 地球楕円体が定義されています。 近似方法によっていくつか種類があるのですが、GPSなどで使われているWGS84がよく使われているようです。
国土地理院が提供している測量計算サイトでは 距離と方位角の計算を使って緯度・経度から距離を計算できます。 回転楕円体上の距離の厳密解は求められない(要出典)ので、 数値計算によって求めることになります。 計算式を見て分かる通り非常に複雑なので、なんらかの近似をしている実装がほとんどです。
各種DBでの実現方法 Redis Redisでは3.2からGEO関連の機能をサポートしています。 ソート済みセットにGeohashを組み合わせて実現しています。
簡単に試してみました。データは以下の記事から拝借したものを使用します。
MySQLで指定した緯度経度から半径nメートル内検索っぽいのを実現するSQL PostgreSQLとOracleで緯度経度から半径nメートル内検索を実行してみる。 GEOADDでデータ挿入です。 ちなみにデータを削除するGEODELは用意されていないとのこと。 中身はソート済みセットなので、ZREMでいいんですね。
$ cat command.txt GEOADD geotable 139.777254 35.713768 上野駅 139.774029 35.711846 西郷隆盛像 GEOADD geotable 139.774744 35.712737 上野の森美術館 139.770872 35.712351 不忍池弁財天 GEOADD geotable 139.775696 35.716293 野口英世博士像 139.775803 35.715420 国立西洋美術館 GEOADD geotable 139.776544 35.716319 国立科学博物館 139.772776 35.717186 東京都美術館 GEOADD geotable 139.</description>
    </item>
    <item>
      <title>Go言語のchanはいったいいくつ付けられるのか試してみた</title>
      <link>https://shogo82148.github.io/blog/2017/03/17/how-many-chan-can-i-write-in-golang/</link>
      <pubDate>Fri, 17 Mar 2017 21:10:25 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2017/03/17/how-many-chan-can-i-write-in-golang/</guid>
      <description>pecoに入った修正をみて、果たしてchanはいくつまで付けられるのか気になったので、 雑に試してみました。 先に断っておきますが、全く有用ではないですよ。
背景 pecoに入った修正はこちら(一部抜粋)。
Make Resume a blocking operation #411 diff --git a/interface.go b/interface.go index 3d4472f..fff446c 100644 --- a/interface.go +++ b/interface.go @@ -162,8 +162,8 @@ type Screen interface { // Termbox just hands out the processing to the termbox library type Termbox struct { mutex sync.Mutex -	resumeCh chan (struct{}) -	suspendCh chan (struct{}) +	resumeCh chan chan struct{} +	suspendCh chan struct{} } // View handles the drawing/updating the screen diff --git a/screen.</description>
    </item>
    <item>
      <title>HTTP/WebSocketで時刻同期するWebNTPを書いた</title>
      <link>https://shogo82148.github.io/blog/2017/03/11/go-webntp/</link>
      <pubDate>Sat, 11 Mar 2017 18:48:09 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2017/03/11/go-webntp/</guid>
      <description>Go1.8からhttp/httpgtraceが追加され、 HTTP通信にフックを差し込めるようになりました。 以前触った時はパフォーマンス測定に利用しましたが、 他に面白い活用法はないかとWebNTPというのを作ってみました。
webntp HTTP/HTTPS/Websocket上でNTP(Network Time Protocol)っぽいことをするプログラムです。
HTTP/HTTPSで時刻同期 日本標準時はNICTの管理する原子時計が基準になっており、 NICTでは原子時計に直結したNTPサーバー(ntp.nict.jp)の提供を行っています。 それに加えて、https/httpサービスも提供しており、 ブラウザを使って現在時刻を取得できます。
APIは簡単でミリ秒単位のtimestampを返してくれるだけです。 その情報からサーバーとクライアント間の時間のズレを算出するわけですが、 HTTP通信では、DNSの名前解決、TCPハンドシェイク、TLSハンドシェイク等々の時間が入ってしまうため、 正確なズレを求めることは困難です。
そこでhttp/httpgtraceを使って、ハンドシェイクを除いたリクエストの送信時刻、レスポンスを最初に受信した時刻から、 より正確なズレを知ることができるのではと作ったのがWebNTPです。 NICTのJSON形式のAPIに対応しており、 以下のように時刻を取得できます。
$ go get github.com/shogo82148/go-webntp/cmd/webntp $ webntp https://ntp-a1.nict.go.jp/cgi-bin/json server https://ntp-a1.nict.go.jp/cgi-bin/json, offset -0.006376, delay 0.024411 2017-03-11 16:08:06.150393313 +0900 JST, server https://ntp-a1.nict.go.jp/cgi-bin/json, offset -0.006376 WebNTPはNICTのAPIと同様の内容を返すサーバーにもなれます。 本家のフォーマットにしたがい、しっかりとうるう秒の情報も返すようになっているので、 ntpdのSLEWモードを切った状態でお試しください。
$ webntp -serve :8080 $ curl -s http://localhost:8080/ | jq . { &amp;#34;id&amp;#34;: &amp;#34;localhost:8080&amp;#34;, &amp;#34;it&amp;#34;: 0, &amp;#34;st&amp;#34;: 1489217288.328757, &amp;#34;time&amp;#34;: 1489217288.328757, &amp;#34;leap&amp;#34;: 36, &amp;#34;next&amp;#34;: 1483228800, // 今年の1/1にあったうるう秒の情報 &amp;#34;step&amp;#34;: 1 } ところで、URLにcgi-binが入っているのは、過去との互換性を保つためにそうなっているのか、 今もCGIで動いているのか、気になる・・・ (少なくとも初期実装はPerlのCGIだったみたいですね)。</description>
    </item>
    <item>
      <title>go-JSONStoreの高速化と機能追加</title>
      <link>https://shogo82148.github.io/blog/2017/03/05/tune-up-go-jsonstore/</link>
      <pubDate>Sun, 05 Mar 2017 16:19:25 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2017/03/05/tune-up-go-jsonstore/</guid>
      <description>以前mattnさんが紹介していたschollz/jsonstore。 時間が経ってしまいましたが「ここは高速化できそうだなー」といじってみたので、 やってみたことをメモ。
本来は上流にフィードバックしたほうがよいのですが、 本家のほうも修正が入ってコンフリクトして面倒になったので、 フォーク版をそのまま置いておきます。
shogo82148/jsonstore 高速化 まだまだ高速化できそうなところがあったので、いじってみた部分です。
ロックの範囲を最小にする ロックの範囲を小さくすることで、並列処理時の性能が上がります。 例えば、jsonstoreに値を入れるSetメソッドは、 以下のようにSet全体がロックの対象になっていました。
func (s *JSONStore) Set(key string, value interface{}) error { // Set の中全体がロックの対象になっている s.Lock() defer s.Unlock() b, err := json.Marshal(value) if err != nil { return err } if s.data == nil { s.data = make(map[string]*json.RawMessage) } s.data[key] = (*json.RawMessage)(&amp;amp;b) return nil } jsonのエンコード処理はjsonstoreの中身を触らないので並列実行可能です。 次のように s.data だけをロックの対象にすれば十分です。
func (s *JSONStore) Set(key string, value interface{}) error { // json.Marshal は並列実行可能 b, err := json.</description>
    </item>
    <item>
      <title>Redisを使ってユニークなIDを配布する</title>
      <link>https://shogo82148.github.io/blog/2017/02/26/unique-id-supplier-using-redis/</link>
      <pubDate>Sun, 26 Feb 2017 19:37:45 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2017/02/26/unique-id-supplier-using-redis/</guid>
      <description>スケーラブルにIDを生成する方法として Twitterのsnowflakeが有名です。 1024台までスケールすることが出来ますが、各snowflakeのサーバにユニークなWoker IDを割り振る必要があります。 IDを振るためのサーバにIDを振るのが問題になるとは難しいですね。
各snowflakeサーバにIDを振る親玉Worker ID配布サーバを作るというアイデアはあったのですが、 Worker IDサーバの可用性を考えるのが大変で手を付けていませんでした。 最近になってWorker IDサーバとしてRedisを使い、ソート済みセット型で管理すれば楽できるのでは？ と思いついたので、やってみたというお話です。
概要 レポジトリはこちらです。
shogo82148/yaraus 他のsnowflake-likeなID発番サーバの実装として katsubushiや sonyflakeなんていうのもあります。 これらのID発番サーバにRedisを使ってWorker IDを割り振るコマンドです。 Redis3.2以上推奨です。
使い方 Go製なのでgo getでインストールできます。
go get github.com/shogo82148/yaraus/cmd/yaraus # 1から1023までのIDが使えるようにRedisを初期化 $ yaraus init -min 1 -max 1023 # ユニークなIDが必要な処理を実行する $ yaraus run -- echo {} 2017/02/25 17:19:16 getting new id... 2017/02/25 17:19:16 client id: YourHostName-1488010756.738-1, id: 1 2017/02/25 17:19:16 sleep 2s for making sure that other generates which has same id expire.</description>
    </item>
    <item>
      <title>Rust vs Go の終戦へ向けてPolyglotを作ってみた</title>
      <link>https://shogo82148.github.io/blog/2017/02/25/rust-and-go-ploygolot/</link>
      <pubDate>Sat, 25 Feb 2017 16:58:27 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2017/02/25/rust-and-go-ploygolot/</guid>
      <description>「Golang Rust」とググると、関連項目は「Rust vs Go」のように GolangとRustが対立しているような項目ばかりです。 まあまあ、もっと仲良くやろうじゃないですか、ということで、 どうしたら仲良くなれるかを考えました。 Polyglotにして同じソースコードの中に閉じ込めてやれば、 そのうち仲良くなるのではないかと考え、 RustとGoのPloyglotを作ってみました。
結果 /*/*/ package main import &amp;#34;fmt&amp;#34; func main() { fmt.Print(&amp;#34;Hello Go!!&amp;#34;) _ = `*/*/ fn main() { println!(&amp;#34;Hello Rust!!&amp;#34;); //` } /*/*/ package main import &amp;#34;fmt&amp;#34; func main() { fmt.Print(&amp;#34;Hello Go!!&amp;#34;) _ = `*/*/ fn main() { println!(&amp;#34;Hello Rust!!&amp;#34;); //` } 仕組み 一番のポイントは最初の行の /*/*/ です。 RustもGoも/* */形式の複数行コメントに対応していますが、 Rustはネストに対応しており、Goはネストはできないという違いがあります。 この違いにより、Rustは/*/*/を/* /* /のように「二重にネストしたコメントの開始部分」として扱いますが、 Goは/* / */のように「/をコメントアウトしたもの」と見なします。 これにより2行目package main以降はGoには普通のコードに見えますが、 Rustからは単なるコメントとして認識されます。
次はGoからRustへの切り替えです。 Goではバッククオートで複数行文字列を定義できるので、その中にRustのコードを書きます。 この中ではバッククオートさえ使わなければ自由にRustのコードを書くことが出来るので、 あとはGoのコードだけ上手くコメントアウトされるよう調整すれば完成です。</description>
    </item>
    <item>
      <title>WEB&#43;DB PRESS Vol.97にPerlとRedisの記事を寄稿しました</title>
      <link>https://shogo82148.github.io/blog/2017/02/23/perl-webdb-vol97/</link>
      <pubDate>Thu, 23 Feb 2017 18:27:53 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2017/02/23/perl-webdb-vol97/</guid>
      <description>昨年末にSongmuさんからお話を頂き、 WEB+DB PRESS Vol.97内の連載「第43回Perl Hackers Hub」に 「PerlでのRedis活用法」というタイトルで寄稿しました。 発売日は2月24日です。
内容 簡単に内容を紹介しておきます。 Perl使いではじめてRedisを使う人向けに書いたつもりです。
Redisの簡単な説明 Redisのインストール方と、Perlからの接続方法、そしてRedisの型の説明です。 記事の中でも紹介していますが、Redisはその豊富な型が特長です。 読者はきっとPerl使いだろうということで、Perlの型(Perlにも型はあるんだよ！！)と 比較しながら簡単に紹介しています。
Redisの応用例とCPANモジュールの紹介 Redisを使うとこんなことができるよ、という紹介です。 CPANで公開されているRedis関連のモジュールも合わせて紹介しています。
Redis自体の注意点 以前Redisを使ったサービスの運用に携わっていたのですが、 そのなかで実際に起きたことを元に、Redisの注意点について書きました。 さいわいサービスが停止するような事故にはありませんでしたが、 メトリックスを眺めながらエンジニア勢でヤバイヤバイ騒いでましたね・・・。 みなさんも気をつけて下さい。
執筆してみての感想 昔から文章を書くのにはだいぶ苦手意識があり、 今回の執筆も非常に苦労しました。 一文の前半を書いた時点で 「今から書こうとしている情報は本当に必要なのか」 「自分の記憶違いで間違った情報なのでは」と不安になり、 色々考えているうちに、何書こうとしてたのかわからなくなるんですよね。 まずは適当に書き上げて、後からちゃんと推敲しよう、 とは思いつつもなかなか進められず・・・。 スループットを上げたい。
細かい表現とかも気になってなかなか進まないので、 こういうの入れて頑張ろうと思います！
VS Codeでtextlintを使って文章をチェックする gitbookで技術書を書く環境の構築手順 (執筆が進まないと、こういう環境構築に時間をかけてしまうのもよくないと思うんだ・・・)
余談 ところで、Vol.97と第43回ってどっちも素数ですね！ 雑なプログラムを書いて調べてみたところ、 両方素数になるのはVol.83, 第29回以来、7回目(これも素数だ！)。 次はVol.101, 第47回です。 そのときのPerl Hackerは誰になるのでしょうか。楽しみですね！
use warnings; use strict; sub is_prime { my $n = shift; return 0 if $n &amp;lt; 2; my $i = 2; while($i*$i&amp;lt;=$n) { return 0 if $n % $i == 0; $i++; } return 1; } my $i = 1; for my $n(1.</description>
    </item>
    <item>
      <title>Go言語でコンパイル時フィボナッチ数列計算</title>
      <link>https://shogo82148.github.io/blog/2017/02/19/golang-compile-time-fib/</link>
      <pubDate>Sun, 19 Feb 2017 09:06:05 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2017/02/19/golang-compile-time-fib/</guid>
      <description>整数の公式でフィボナッチ数列を求めるという記事を読んで、 「これコンパイル時ならGoでも簡単に計算できるのでは？」と思いやってみたメモ。
背景 みんな大好きフィボナッチ数列(要出典)。 漸化式で定義されているため、再帰やループを使って書くことが多いと思いますが、 閉じた式で書くことが知られています。 ただし、この一般式には無理数の演算が入るので、コンピュータで厳密に扱うことはできません。 ところが、さきほど紹介した記事で紹介された方法を使うと、整数の演算のみで実現できるそうです。
原理などはネタ元の記事を参照してもらうとして、 Python3では以下のように書けるらしいです。
def fib(n): return (4 &amp;lt;&amp;lt; n*(3+n)) // ((4 &amp;lt;&amp;lt; 2*n) - (2 &amp;lt;&amp;lt; n) - 1) &amp;amp; ((2 &amp;lt;&amp;lt; n) - 1) ある程度大きなフィボナッチ数を求める場合、 計算途中の値が非常に大きくなるため、多倍長整数が必要となります。 Python3は多倍長整数に組み込みで対応していますが、 Goではmath/bigパッケージを利用する必要があります。
なんか面倒だなGolangと思っていたのですが、 Better C - Go言語と整数 #golangを読んで、 「Goの定数には型がない(場合がある)」「任意の精度で計算してくれる」ということを知り、 「つまりコンパイル時に定数として計算すれば楽にいけるのでは！！」と考えたわけです。
結果 ちょっと複雑な式ですが、個々の演算自体はPython3もGoも変わらないので、 翻訳は簡単ですね。
package main import &amp;#34;fmt&amp;#34; const Fib0 = 1 // 0だけはうまくいかない const ( _ = (4 &amp;lt;&amp;lt; (iota * (3 + iota))) / ((4 &amp;lt;&amp;lt; (2 * iota)) - (2 &amp;lt;&amp;lt; iota) - 1) &amp;amp; ((2 &amp;lt;&amp;lt; iota) - 1) Fib1 Fib2 Fib3 Fib4 Fib5 Fib6 Fib7 Fib8 Fib9 Fib10 Fib11 Fib12 Fib13 Fib14 Fib15 Fib16 Fib17 Fib18 Fib19 Fib20 Fib21 ) func main() { fibs := []int{ Fib0, Fib1, Fib2, Fib3, Fib4, Fib5, Fib6, Fib7, Fib8, Fib9, Fib10, Fib11, Fib12, Fib13, Fib14, Fib15, Fib16, Fib17, Fib18, Fib19, Fib20, Fib21, } for i, fib := range fibs { fmt.</description>
    </item>
    <item>
      <title>go-sql-proxyがcontextに対応しました</title>
      <link>https://shogo82148.github.io/blog/2017/02/16/go-sql-proxy-in-go18/</link>
      <pubDate>Thu, 16 Feb 2017 07:16:44 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2017/02/16/go-sql-proxy-in-go18/</guid>
      <description>Go1.8ではdatabase/sqlのcontextサポートが入ります。 (きっと今日のGo 1.8 Release Partyで詳しく説明があるはず、たぶん) それにともないGo言語でSQLのトレースをするで紹介した shogo82148/go-sql-proxyでもcontextを扱えるようにしました。
Go1.8新機能のサポート Golang 1.8 でやってくる database/sql の変更点で mattnさんが紹介しているように、Go1.8ではdatabase/sqlにいくつか新機能が追加されます。 (mattnさんの対応が早すぎて、メソッド名とか微妙に変更が入っているので注意)
特に大きなのがcontextのサポートでしょう。以下のようなコードでクエリのキャンセルが可能になります。
ctx, cancel := context.WithCancel(context.Background()) go func() { // 1秒待ってからキャンセル time.Sleep(1 * time.Second) cancel() }() rows, err := db.QueryContext(ctx, &amp;#34;SELECT name FROM test where id = ?&amp;#34;, id) if err != nil { log.Fatal(err) } go-sql-proxyでもcontext対応を行ったので、 proxyを経由した場合でも、キャンセルが可能になります。 (もちろん、originとなるドライバの対応も必要です)
Go1.8ではcontextサポート以外にもいくつか新機能が追加される予定です。 これらについても、originとなるドライバが対応していれば、go-sql-proxy経由でも全く同じように扱えます。
contextとHookの関連付け contextにHookを関連付けて、一部のクエリにだけHookを付けることができるようになりました。 例えば以下のようなコードでctxに関連したクエリだけログを出力できます。
package main import ( &amp;#34;context&amp;#34; &amp;#34;database/sql&amp;#34; &amp;#34;github.com/shogo82148/go-sql-proxy&amp;#34; ) var tracer = proxy.NewTraceHooks(proxy.TracerOptions{}) func main() { // 何もしないproxyをインストール proxy.</description>
    </item>
    <item>
      <title>Go1.8のGraceful Shutdownとgo-gracedownの対応</title>
      <link>https://shogo82148.github.io/blog/2017/01/21/golang-1-dot-8-graceful-shutdown/</link>
      <pubDate>Sat, 21 Jan 2017 12:44:32 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2017/01/21/golang-1-dot-8-graceful-shutdown/</guid>
      <description>Go1.8beta1が出た時に、Go1.8で追加される予定のGraceful Shutdownについて書く！ とTwitterに書き込んで早1ヶ月。 この前の金曜日にGo1.8rc2がリリースされ、正式リリースも間近になってきて、 さすがに書かねばという気持ちになって来たので、がんばって検証してみます。
公式サポートで増える予定の機能 以前Go言語でGraceful Restartをするときに取りこぼしを少なくするで 紹介したようにshogo82148/go-gracedownというものを書きました。 あれから時は経ち、ついにGo1.8からはGraceful Shudownがbuild-inの機能として提供される予定です。 公式サポートが入ることによって、以下のような機能を使えるようになります。
HTTP/2のGraceful Shutdownができる HTTP/2ではGOAWAYフレームという接続を切ることを通知する機能があります。 Go1.8からはシャットダウン時にこのGOAWAYフレームを送ってくれるようになります。 GOAWAYフレームはサーバ側から任意のタイミングで送ることができ、 どこまで正常に処理できたかをクライアントに伝えられるという利点があります。
余談ですが、この機能はx/net/http2を利用している場合は動かないらしいです。 importしたときには動かないけどbundleしたときにだけ動く黒魔術が使われているためです。 覚えておいても今後絶対使うことはなさそう。というか使いたくない・・・。
contextが使える go-gracedownを作った頃は、contextはまだ標準パッケージに取り込まれていなかったので対応していませんでした。 (1.7のリリース時に対応を怠っていただけとも言える) net/httpのシャットダウンはもちろんcontextに対応しています。 これにより、Graceful Shutdownを中断して強制終了する、 ということが簡単にできるようになります。
公式サポートで変更になる予定の挙動 Keep-Aliveでのリクエストの挙動が少し変わります。 1.7以前のgo-gracedownでは、クライアントにKeep-Aliveが無効になったのを伝え、 クライアント側から接続を切るのを待つように実装してしました。 多少接続時間が延びたとしてもクライアント側でよくわからないエラーになるよりはマシだろ、との考えからです。
1.8からはシャットダウン時にIdle状態(TCP接続は有効だけど、リクエストは処理していない状態)な接続は切断されます。 内部で使っているServer.SetKeepAlivesEnabledの 挙動が変更になったためです。
Goの中の人的には「この挙動が原因で万が一トラブルになっても、クライアントがリトライしてくれるから大丈夫でしょ」とのことのようです。 サーバシャットダウン以外にもネットワークトラブル等でも接続は切れるので、 クライアント側で頑張ってというのは正論ですが、 どの程度エラーが増えるのかは気になるところです。
go-gracedownの対応 go-gracedownはGo1.8でコンパイルされたときはbuild-inの機能を直接使うようになります。 中身はほとんどがインターフェースの互換性を保つためのコードなので、 機能的なメリットは完全になくなってしまいました・・・。 HTTP/2サポートも問題なく動くはずです。 逆にパッケージの依存が増えること以外はデメリットはないともいえます。
Go1.7以下では今までの方法にフォールバックしてくれます。 というわけで、以下のような人には有用です。
深淵な理由でGo1.7以下しか使えない人 Go1.8とGo1.7以下のサポートがどうしても必要な人 Go1.8にアップグレードしたけど、graceful shutdownの処理を書き換えるのがめんどくさい人 ところで、環境が悪いときに性能を落としたり機能を制限することをフォールバック(fall back)というわけですが、 逆に環境が良いときに性能を上げたり機能を拡張することはなんていうんですかね？ モデムでは通信環境が良いときに高速な通信方式に切り変えることを「フォールフォワード(fall forward)」というらしいです。 「Go1.8ではbild-inのGraceful Shutdownにフォールフォワードする」で使い方あってます？
使い方 Server.Shutdownを使う Go(その3) Advent Calendarの 最終日の記事でも扱ってますが改めて。
package main import ( &amp;#34;context&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;log&amp;#34; &amp;#34;net&amp;#34; &amp;#34;net/http&amp;#34; &amp;#34;os&amp;#34; &amp;#34;os/signal&amp;#34; &amp;#34;syscall&amp;#34; &amp;#34;github.</description>
    </item>
    <item>
      <title>Re:golang の http.Client を速くする</title>
      <link>https://shogo82148.github.io/blog/2017/01/14/re-golang-dns-cache/</link>
      <pubDate>Sat, 14 Jan 2017 17:02:12 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2017/01/14/re-golang-dns-cache/</guid>
      <description>先日mattnさんの記事を読みました。
golang の http.Client を速くする nettというパッケージを使って 名前解決の結果をキャッシュすることで、http.Clientを早くするというものです。 この記事に関して、ちょっと疑問に思ったことがあったので、検証してみました。
疑問 疑問に思ったのは以下の点です。
名前解決遅すぎでは？ ベンチマークの結果を見ると5億ns(=500ms)ほど速度が改善しています。 3つのURLに対してリクエストを投げているので、初回を除く2回DNSのキャッシュがヒットし、 名前解決2回分の速度改善になるはずです。 と、いうことは、名前解決1回あたり250msかかっている計算になります。 googleのsearchは302でリダイレクトがかかるので、Client.Getの呼び出し1回あたり2回リクエストが飛ぶ、 ということを計算に入れても100msほどかかる計算です。
Google先生の謎テクノロジーによってかなりの最適化がされているはずですし、 ネットワークプロバイダのDNSキャッシュにヒットする可能性も高いでしょう。 名前解決程度にこんなに時間がかかっていたらスプラトゥーンが出来ない！ (mattnさんがスプラトゥーンをプレイしているかは知らない)
2017/01/16追記: mattnさんはスプラトゥーンをプレイしていないそうです。残念。
あとスプラトゥーンしてません。。。
&amp;mdash; mattn (@mattn_jp) 2017年1月14日 もちろん、ネットワークが混雑していたり、 モバイルネットワークを利用していたり、という可能性もありますが、 ちょっと不自然な印象を受けました。
Keep-Aliveされてるのでは？ スキーマがhttpsになっているので、Google先生相手ならHTTP2で通信していてもおかしくありません。 HTTP2は基本的にドメイン毎にコネクションを1つだけ張って、それを使いまわします。 もし仮にHTTP1.1で通信していたとしても、http.ClientはデフォルトでKeep-Aliveが有効になっているので、 普通に使うとコネクションを再利用してくれます。
そういうわけで、名前解決以前にそもそもTCPのコネクション確立もスキップされている可能性が高いのでは？ と思ったわけです。 この予想が正しければ、名前解決は初回リクエストでしか行われないので、ベンチマークに差はでないはずです。
HTTPリクエストの様子をトレースしてみる これらの疑問を解消するために、HTTPリクエストの様子をさらに詳細に解析してみることにしました。
DNSキャッシュなし版をトレースする Go1.7からnet/http/httptraceというパッケージが追加され、 名前解決やコネクション確立etcのタイミングにフックを仕込めるようになりました。 これを利用すれば各段階でどの程度時間がかかっているかが具体的に分かるはずです。
頑張って自前でフックを差し込んでもよいのですが、 deeeetさんのgo-httpstatという便利パッケージがあるので、 これをありがたく利用させていただきます。 go-httpstatを使うと時間計測を行うコードを簡単に差し込むことができます。
package main import ( &amp;#34;io&amp;#34; &amp;#34;io/ioutil&amp;#34; &amp;#34;log&amp;#34; &amp;#34;net/http&amp;#34; &amp;#34;time&amp;#34; &amp;#34;github.com/tcnksm/go-httpstat&amp;#34; ) var ( urls = []string{ &amp;#34;https://shogo82148.github.io/blog/2016/12/20/redis-fast-0-dot-19-released/&amp;#34;, &amp;#34;https://shogo82148.github.io/blog/2016/12/15/leap-second-in-datetime-dot-pm/&amp;#34;, &amp;#34;https://shogo82148.github.io/blog/2016/11/23/qr-code/&amp;#34;, } ) func main() { client := &amp;amp;http.</description>
    </item>
    <item>
      <title>Redis::Fast 0.19リリースのお知らせ</title>
      <link>https://shogo82148.github.io/blog/2016/12/20/redis-fast-0-dot-19-released/</link>
      <pubDate>Tue, 20 Dec 2016 22:38:27 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2016/12/20/redis-fast-0-dot-19-released/</guid>
      <description>Redis::Fast 0.19 をリリースしました。 主な変更点は以下の通りです。
reconnect_on_error オプションの追加 Sentinelのノード一覧が更新されない不具合の修正 IPv6の実験的サポート reconnect_on_error オプションの追加 @yoheimutaさんからのプルリクエストです。 今まではネットワークエラーが発生した時のみ再接続処理が走っていましたが、 Redisがエラーを返した場合にも再接続を行うようになります。 マスタースレーブ構成をしているときに、 何らかの原因によりRedis::Fastからのコネクションを維持したまま、 マスターがスレーブに降格してしまった場合に対処するための機能です。 以下のように設定することで、新しいマスターに再接続を行うことが可能になります。
my $r = Redis::Fast-&amp;gt;new( reconnect =&amp;gt; 1, # 0以上で再接続有効 reconnect_on_error =&amp;gt; sub { my ($error, $ret, $command) = @_; if ($error =~ /READONLY You can&amp;#39;t write against a read only slave/) { return 1; # 再接続を行う。次の再接続まで最低1秒空ける } return -1; # 再接続は行わない }, ); Sentinelのノード一覧が更新されない不具合の修正 Redis::FastにはどれかひとつのSentinelノードに接続すると、 他のノードの情報を自動的に収集する機能があります。 この機能が最新のRedisでは動いていなかったので修正しました。 具体的にいつからなのかまでは追ってないのですが、 Redisのバージョン3.0.6から3.2.6の間のどこかで ノード一覧の形式が変わってしまったようです。
(最近Sentinelの話題を聞かないけど、みんな使ってるのかな・・・)
IPv6の実験的サポート サーバの指定にIPv6のアドレスが使えるようになりました。 Redis::Fast-&amp;gt;new(server =&amp;gt; &amp;quot;[::1]:6379&amp;quot;) のような指定ができます。</description>
    </item>
    <item>
      <title>DateTime.pmにうるう秒の修正が入った話</title>
      <link>https://shogo82148.github.io/blog/2016/12/15/leap-second-in-datetime-dot-pm/</link>
      <pubDate>Thu, 15 Dec 2016 22:17:47 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2016/12/15/leap-second-in-datetime-dot-pm/</guid>
      <description>こんにちは、DateTime.pm Watcherのいっちーです。 本日面白いパッチがDateTime.pmに取り込まれたので、ご紹介したいと思います。
そのpullreqがこちらです。Closedになっていますが、該当コミットはmasterに取り込まれています。
The leap second in 2012 was on 2012-07-01 not 2012-06-01. #48 per https://confluence.qps.nl/display/KBE/UTC+to+GPS+Time+Correction the leap second in 2012 was on 2012-07-01 not 2012-06-01. It&amp;rsquo;s is well known that leap seconds only occur directly before Jan 1st or July 1st.
適当な和訳「2012年に挿入されたうるう秒は2012年6月1日ではなく2012年7月1日です。よく知られているように、今までに挿入されたうるう秒は1月1日と7月1日の直前だけです。」
diff --git a/lib/DateTime/LeapSecond.pm b/lib/DateTime/LeapSecond.pm index 66e1b2b..4a38be2 100644 --- a/lib/DateTime/LeapSecond.pm +++ b/lib/DateTime/LeapSecond.pm @@ -108,7 +108,7 @@ sub _initialize { 1999 Jan. 1 +1 2006 Jan. 1 +1 2009 Jan.</description>
    </item>
    <item>
      <title>Twitterの二次元コード問題と、QRコード・フレームQRの見分け方</title>
      <link>https://shogo82148.github.io/blog/2016/11/23/qr-code/</link>
      <pubDate>Wed, 23 Nov 2016 10:32:43 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2016/11/23/qr-code/</guid>
      <description>先日Twitterの公式アプリがQRコード® (お店やお友達を簡単にフォローするために) の作成と読み取りに対応しました。 しかし、生成されるQRコードが標準規格に準拠していないため、 「他のリーダーで読めない」「法的に問題があるのでは？」等々の指摘が出ていました。 人事ながらTwitterさんのことが心配になったので少し調べてみました。
なお、僕は法律の専門家ではないため、本記事の正確性は保証できません。 あくまで個人的な見解なので、 実際にQRコード®を使用するさいは各自の判断でお願いします。
指摘ツイート Twitterが生成するQRコード、規格(JIS X 0510・ISO/IEC 18004)を大幅に逸脱しているので「QRコード®」を名乗ること自体に法的なリスクがある。
&amp;mdash; 祥太(4/15レイフレ18 C19+20) (@shota_) 2016年11月17日 「デンソーウェーブは、JIS、ISOの規格に沿ったQRコードに限っては特許権を行使しませんが、規格を逸脱したQRコードについてはこの限りではございませんので、特許権を行使させていただくこともございます。」
(出典: https://t.co/SKXgBGSb8E )
&amp;mdash; 祥太(4/15レイフレ18 C19+20) (@shota_) 2016年11月17日 明暗暗転で読み取らないという話を多数見かけますけど、そちらについては「ISO/IEC 18004からは逸脱」「JIS X 0510には準拠」(規格票7.3.8参照)という微妙な状況なのです。多分ISOには準拠しているのでアプリは悪くないと思います。
&amp;mdash; 祥太(4/15レイフレ18 C19+20) (@shota_) 2016年11月17日 たしかに qrcode.comのFAQには 特許について以下の記述があります。
色を付けたりイラストを入れるような使い方をしても問題ありませんか？ (中略) また、QRコードにイラストを重ねたりデザインを乗せるということは、QRコードの規格から外れ「QRコードではないもの」となってしまう可能性がございます。 デンソーウェーブは、JIS、ISOの規格に沿ったQRコードに限っては特許権を行使しませんが、規格を逸脱したQRコードについてはこの限りではございませんので、特許権を行使させていただくこともございます。
2022-06-05追記: 改めてqrcode.comのFAQを確認したところ、以下のように文言が変更されていました。
色を付けたりイラストを入れるような使い方をしても問題ありませんか？ QRコードにイラストを重ねたり、デザインをのせて変形してしまうと、ちょっとした汚れや欠けでも読み取りが出来なくなったり、読み取りの反応が悪くなってしまうことがありますので推奨しておりません。 安定した読み取りという面から、JIS、ISOの規格で制定されている内容に従ってご利用いただくことを推奨しております。
なおイラストやデザインを施すような使い方をご希望の場合は、デンソーウェーブのフレームQR®をご利用ください。
特許権の行使についての文言が削除されています。 2017年1月28日で特許権が有効期限切れになり、デンソーウェーブが特許権を行使することができなくなったからだと思います。 このことから特許についてはクリアになったと言えるでしょう。
とはいえFAQにあるとおり、読み取り性能の観点からイラストを入れるのは非推奨、という点は変わりありません。
追記ここまで
問題点 公式アプリの生成する二次元コードは以下のような問題があります。
データパターンの20%近くがアイコンで上書きされている 「アライメントパターン」がTwitterのロゴで欠けている 明暗暗転している(一応JISには沿っているらしい) 法的リスク以前に、 読み取り性能/互換性が劣化するので使わない方が無難でしょう。
自分のプロフィールのURL (僕の場合は https://twitter.com/shogo82148 )を QRコードに変換すれば公式アプリのリーダーでも読めるので、 こちらの方がオススメです。
QRコード関連の権利 特許 QRコード®のJIS規格JIS X 0510には、 関連する特許として特許第2938338号「二次元コード」があげられています。 ただし、特許の保護期間は20年なので、1994年に出願されたこの特許は2014年で消滅しています。 したがってこの特許を理由に訴えられることはなさそうです。</description>
    </item>
    <item>
      <title>GitHub Pagesがhttpsをサポートしたので切り替えてみた</title>
      <link>https://shogo82148.github.io/blog/2016/06/10/github-page-supports-https/</link>
      <pubDate>Fri, 10 Jun 2016 00:53:51 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2016/06/10/github-page-supports-https/</guid>
      <description>このブログを設置しているGithub PagesがHTTPSに正式対応したらしいので、HTTPSを強制するように設定してみました。
HTTPS for GitHub Pages やったこと ページ内にHTTP経由で取得したリソースが含まれていると、 警告が出たり取得自体がブロックされたりしてしまうので、 全てHTTPS経由で取得するように書きなおす必要があります。 画像・CSS・Javascript等のURLを、以下のようにnetwork-path referenceへの置き換えましょう。 HTTPでページを開いた場合はHTTPで、HTTPSでページを開いた場合はHTTPSで、リソースを取得してくれます。
&amp;lt;a href=&amp;#34;http://google.co.jp&amp;#34;&amp;gt; &amp;lt;a href=&amp;#34;//google.co.jp&amp;#34;&amp;gt; このサイトはHTTPのレンダリングにOctopressを使っています。 最新版のOctopressではnetwork-path referenceを使ってくれるので特に対応は不要です。 このサイトの場合は古すぎてHTTP参照だったので、 「Octopressをアップデートした」を参考にしてアップデートしました。 はてなブックマーク連携など、自分でカスタマイズした部分に関しては手作業で対応したました。
HTTPS強制の設定 Securing your GitHub Pages site with HTTPS どおりに設定を有効化すればOKです。 ユーザ毎ではなくプロジェクト毎の設定のようなので、 プロジェクト用のページを作っている場合は個別に設定が必要です。
はてなブックマークについて HTTPとHTTPSは別URLとして扱われるようなので、過去の記事に対するはてブ数はリセットされてしまいます。 解決方法は無いかと調べてみたものの、現象無理っぽいです。
自分のブログは http から https に移行したけど、記事についたはてブを移行することは出来なかった（はてなのサポートに聞いた）。分からないでもないけど、https 移行の躊躇材料になるという点においてはイケてない。
&amp;mdash; Takashi Masuda (@masutaka) 2016年6月6日 はてなさんの方で対応してくれないかな・・・
2016/06/30追記: DISQUSのマイグレーション 記事にコメントをつけるのに使っているDISQUSをマイグレーションするのを忘れてて、 過去のコメントが見れなくなっていたので追記。
DISQUSのホームから「Admin」「Edit Settings」で設定画面を開き、 Website URLの近くの「Changing domains? Learn how.」をクリックします。 すると「Migration Tools」が開くので、「Start URL mapper」「you can download a CSV here」をクリック。 5分くらいするとDISQUSがコメントを管理しているURL一覧がメールで届くので、 それを元に新旧URLの対応表を作ります。</description>
    </item>
    <item>
      <title>net/httpで安全に静的ファイルを返す</title>
      <link>https://shogo82148.github.io/blog/2016/04/13/serving-static-files-in-golang/</link>
      <pubDate>Wed, 13 Apr 2016 02:29:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2016/04/13/serving-static-files-in-golang/</guid>
      <description>net/httpで静的ファイルを返すで、 http.ServeFileを使っていてアレ？と思ったのでちょっと詳しく調べてみました。 (http.FileServerを使うものだと思ってたため)
結論だけ先に書いておくと
やはり、特に理由がなければhttp.FileServerを使ったほうが良さそう どうしてもhttp.ServeFileを使う場合は定数でパス指定をする 「自作パスルータを使っている」かつ「Go 1.6.1 未満を使っている」場合はとくに要注意 ディレクトリトラバーサル脆弱性 紹介されているのは以下のコードです。
http.HandleFunc(&amp;#34;/static/&amp;#34;, func(w http.ResponseWriter, r *http.Request) { http.ServeFile(w, r, r.URL.Path[1:]) }) しかし、参照先の「Go Golang to serve a specific html file」には Actually, do not do that. (やっちゃいけない)とコメントされています。 ディレクトリトラバーサルにより 脆弱性の原因となってしまう可能性があるためです。
脆弱性再現のために、以下の様なコードを書いてGo1.5でコンパイルして実行してみました。
package main import ( &amp;#34;net/http&amp;#34; &amp;#34;strings&amp;#34; ) func main() { http.ListenAndServe(&amp;#34;:3000&amp;#34;, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { if strings.HasPrefix(r.URL.Path, &amp;#34;/static/&amp;#34;) { http.ServeFile(w, r, r.URL.Path[1:]) } else { http.NotFound(w, r) } })) } ..を含んだパスをリクエストしてみます。(実行した場所によって..の数は変わるので適宜調整してみてください)</description>
    </item>
    <item>
      <title>PerlでもGoでも実行できるQuine書いた</title>
      <link>https://shogo82148.github.io/blog/2016/04/06/ployglot-quine-of-golang-and-perl/</link>
      <pubDate>Wed, 06 Apr 2016 10:07:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2016/04/06/ployglot-quine-of-golang-and-perl/</guid>
      <description>昨日のPolyglotを元にPerlでもGoでも実行できるQuine書いた。
package main;import(&amp;#34;fmt&amp;#34;);var(q=`printf&amp;#39;package main;import(&amp;#34;fmt&amp;#34;);var(q%c%c%s%c/*%c);sub import{}sub var{$_%cshift%c~s!%c(.*)%c/\*!$1!gr;eval}%c__END__%c&amp;#39;,61,96,$_,96,61,61,61,96,96,10,10;print&amp;lt;DATA&amp;gt;`/*=);sub import{}sub var{$_=shift=~s!`(.*)`/\*!$1!gr;eval} __END__ */);func main(){s:=`package main;import(&amp;#34;fmt&amp;#34;);var(q=%c%s%c/*=);sub import{}sub var{$_=shift=~s!%c(.*)%c/\*!$1!gr;eval} __END__ */);func main(){s:=%c%s%c;fmt.Printf(s,96,q,96,96,96,96,s,96)} `;fmt.Printf(s,96,q,96,96,96,96,s,96)} Perlで実行してもGoで実行しても自分自身を出力します。</description>
    </item>
    <item>
      <title>PerlとGolangで実行できるPolyglot書いてみた</title>
      <link>https://shogo82148.github.io/blog/2016/04/05/polyglot-of-perl-and-golang/</link>
      <pubDate>Tue, 05 Apr 2016 12:27:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2016/04/05/polyglot-of-perl-and-golang/</guid>
      <description>Rubyの会社をPerlの会社に変えてしまおう計画。 Golangのフリをして忍び込ませれば行けるのではという話になったので、 GoでもPerlでも実行できるコードを書いてみた。
出来上がったのがこちら。
package main; import (&amp;#34;fmt&amp;#34;); var (s=0/*==); sub import {} sub var { print &amp;#34;Hello macotasu&amp;#34;; } __END__ */) func main() { fmt.Println(&amp;#34;Hello macotasu&amp;#34;) } 一番のポイントはvar (s=0/*==);の行ですね。 Perlで解釈すると正規表現置換s///として解釈され、/*が無視されます。 Goで解釈すると変数sへの代入として解釈され、/*がコメントとして扱われます。
あとはGoのキーワードをPerlが解釈できないので、ちょっと書き方を工夫します。
package main はGoでもPerlでも似たような意味で解釈されるのでそのまま Goの import, var はPerlで解釈できないので、()を省略せずに書いてPerlの関数呼び出しっぽくする 省略可能なセミコロンをちゃんと書く GoとPerlのコードは分かれているのでどんな処理でも自由に書くことができますが、 import だけGoでもPerlでも解釈されてしまうというという制限があります。 import するパッケージが一個だけなら問題ないんですが、 複数書く場合は以下のように２個め以降をすべてドットインポートする必要があって男気あふれる感じです。 (Perlでは文字列結合として解釈される。Goではvarのあとにimportかけないっぽいので、ここに押し込むしかない。)
package main; import ( &amp;#34;fmt&amp;#34; . &amp;#34;math&amp;#34; ); var (s=0/*==); sub import {} sub var { print &amp;#34;Hello macotasu&amp;#34;; } __END__ */) func main() { fmt.</description>
    </item>
    <item>
      <title>Webブラウザを使って電波を出してみた</title>
      <link>https://shogo82148.github.io/blog/2016/03/29/web-jjy/</link>
      <pubDate>Tue, 29 Mar 2016 12:19:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2016/03/29/web-jjy/</guid>
      <description>読者の持っている至って普通のコンピューターは、実は電波時計の時刻合わせを行うために必要な標準電波の発信装置が備わっている。
コードは以下から入手できる。
shogo82148/web-jjy JJYシミュレータWeb版 動かし方 パソコンのイヤホンジャックにアンテナ(普通のイヤホンで十分です)を接続し、電波時計の近くに置きます。 音量を最大にし、「Start」ボタンを押すと信号が送信されます。 電波時計を強制受信モードにし、時刻が設定されるのを待ちましょう。
パソコンの時間を基準にするので、あらかじめntpとかで時刻設定をしておくといいと思います。
原理 標準電波JJYは日本標準時のタイムコードを送信する電波で、 東日本では40kHz、西日本では60kHzの周波数で発信されています。 電波時計はこの信号を使って時刻合わせをしています。
この信号をオーディオデバイスから出力する電波時計用JJYシミュレータというものがあるのを知り、 「今のWebブラウザならjavascriptだけで実装できるのでは？」と思いやってみました。 一般的なオーディオデバイスは、20kHz以上の周波数の再生には適していないため、そのままでは40kHz/60kHzの信号は出せません。 そこで、電波時計用JJYシミュレータは、歪んだ波形に含まれる高調波を利用しています。 ボリュームを大きくして音が割れた状態になると、音声信号は矩形波に近いかたちになります。 矩形波には3倍、5倍、7倍&amp;hellip;の奇数倍の周波数成分が含まれているため、 (世はまさに大フーリエ時代とか見ると楽しい) 13.333kHzの矩形波を出力することで、39.999kHzの信号を出せるというわけです。
元のソフトウェアはWindowsのバイナリ形式でしたが、 WebAudioの登場によりWebブラウザからも同様のことが行えるようになりました。
最後に 少し前にCPUから出るノイズを使ってAMラジオの電波を発信するという記事が話題になりましたね。
普通のコンピューターからAMラジオを鳴らそう CPUやオーディオデバイスも電気で動いている以上、電波が出ているのは当たり前のことなのですが、 こうやって改めて確認できると面白いですね。
パソコンから出る程度の電波強度では、電波法に抵触することはないと思いますが、 うっかり強力な電波を発信しないよう気をつけてください。</description>
    </item>
    <item>
      <title>数値と文字列がごちゃ混ぜになっているJSONをよしなにParseするやつ作った</title>
      <link>https://shogo82148.github.io/blog/2016/03/23/go-weaktyping/</link>
      <pubDate>Wed, 23 Mar 2016 20:44:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2016/03/23/go-weaktyping/</guid>
      <description>Goは数値と文字列を厳格に区別しますが、他の言語もそうとは限りません。 例えばPerlは数値と文字列を自動変換してくれるので、気をつけていないといつの間にか数値が文字列になっていたりします。 その言語の中に閉じていいれば問題ないのですが、Goとやり取りしようとすると困ります。 そんなときに使えるライブラリを書いてみました。
shogo82148/go-weaktyping 背景 map[string][]*stringを返してくるライブラリがあって、 そのままだと扱いにくいのでなんとか構造体にできないかと頭を悩ませていました。 JSONに一旦変換すれば楽かなーとも思ったのですが、一部フィールドを数値に変換する必要がありました。 JSONの数値と文字列を区別するため、JSONの文字列をGoの数値型に変換するのは厄介です。 タグにjson:&amp;quot;,string&amp;quot;と指定すると変換可能になりますが、逆にJSONの数値を受け付けなくなりますし、 JSONに変換すると文字列になってしまいます。 変換先の構造体は普通のJSONの操作にも使いたかったので、これでは困ります。 「数値も文字列もUnmarshalできて、Marshalするときには数値になる」ようなJSONライブラリが必要でした。
&amp;quot;encoding/json&amp;quot;に代わる新しいJSONライブラリを・・・とも考えたのですが、 よく考えるとUnmarshal時の挙動は&amp;quot;encoding/json&amp;quot;.Unmarshalerインターフェースを実装することでカスタマイズ可能です。 こうして作ったのが go-weaktyping です。
使い方 builtinの型の先頭を大文字にしたものを用意しているので、 適当にUnmarshalして欲しいところでbuiltinの型の代わりに指定するだけです。 以下は整数型をUnmarshalする例です。
package main import ( &amp;#34;encoding/json&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;log&amp;#34; &amp;#34;github.com/shogo82148/go-weaktyping&amp;#34; ) func main() { ptr := &amp;amp;struct { Foo weaktyping.Int `json:&amp;#34;foo&amp;#34;` }{} if err := json.Unmarshal([]byte(`{&amp;#34;foo&amp;#34;:123}`), ptr); err != nil { log.Fatal(err) } fmt.Println(&amp;#34;Foo:&amp;#34;, ptr.Foo) if err := json.Unmarshal([]byte(`{&amp;#34;foo&amp;#34;:&amp;#34;456&amp;#34;}`), ptr); err != nil { log.Fatal(err) } fmt.Println(&amp;#34;Foo:&amp;#34;, ptr.Foo) } {&amp;quot;foo&amp;quot;:123}が正常にUnmarshalできるのはもちろん、 通常はエラーになってしまう{&amp;quot;foo&amp;quot;:&amp;quot;456&amp;quot;}のUnmarshalも問題なく行えます。 Marshal時は通常のint型と同様に振る舞います。</description>
    </item>
    <item>
      <title>Redisのトランザクション・スクリプト・ランキングを扱うPerlモジュールを公開しました</title>
      <link>https://shogo82148.github.io/blog/2016/03/18/releaes-redis-modules/</link>
      <pubDate>Fri, 18 Mar 2016 22:16:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2016/03/18/releaes-redis-modules/</guid>
      <description>以前Redisでスコアを複数設定できるランキングを作ってみたけど、 Githubの肥やしになっていてもあれなので、CPANizeしました。 あわせて、この実装のために作ったユーティリティモジュールも別モジュールとして公開しました。
Redis::LeaderBoardMulti Redis::Script Redis::Transaction Redis::LeaderBoardMulti 最初の基準で順位を決められなかった場合の第二基準が欲しいというときに使うモジュールです。 インターフェースがRedis::LeaderBoard互換になるように調整したので、 前回とインターフェースがちょっと変わっています。
se Redis; use Redis::LeaderBoard; my $redis = Redis-&amp;gt;new; my $lb = Redis::LeaderBoardMulti-&amp;gt;new( redis =&amp;gt; $redis, key =&amp;gt; &amp;#39;leader_board:1&amp;#39;, order =&amp;gt; [&amp;#39;asc&amp;#39;, &amp;#39;desc&amp;#39;], # asc/desc, desc as default ); # Redis::LeaderBoardに合わせて複数指定できるようになりました $lb-&amp;gt;set_score( &amp;#39;one&amp;#39; =&amp;gt; [100, time], &amp;#39;two&amp;#39; =&amp;gt; [ 50, time], ); my ($rank, $score, $time) = $lb-&amp;gt;get_rank_with_score(&amp;#39;one&amp;#39;); Redis::LeaderBoard互換なのでそのまま入れ替えられるはずですが、以下のような実装上の制限があります。
スコアはすべて64bit符号付き整数 Redis::LeaderBoardのスコアは倍精度浮動小数点型なので小数も扱えるが、Redis::LeaderBoardMultiは整数だけ Redis 2.8.9以降のみで動きます 同順の場合の出現順 Redis::LeaderBoard は ZRANK, ZREVRANK を使い分けているので、orderパラメータによって昇順/降順が変わります Redis::LaederBoardMulti は ZRANK しか使わないので、必ず昇順になります 一応 Lua Script を使わないオプションもそのまま残してありますが、特に理由がない限りデフォルト(Lua Script を使う)で使うといいと思います。 どうしてもロックの範囲が広くなってしまう場合があり、楽観的ロックでは効率が悪いケースがあるためです。</description>
    </item>
    <item>
      <title>ngrokみたいなHTTPプロキシを書いてみた</title>
      <link>https://shogo82148.github.io/blog/2016/03/14/http2-over-websocket/</link>
      <pubDate>Mon, 14 Mar 2016 22:59:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2016/03/14/http2-over-websocket/</guid>
      <description>開発中のWebアプリをみんなに試してほしいけど、 サーバなんてなくて開発環境がローカルにしか無くて公開できないということは、 開発初期段階だとよくあることだと思います。 もちろん本格的にやるならテスト用にサーバを建てるべきですが、 小さなものならngrokを使うと簡単です。 ngrokの公開サーバへのHTTPリクエストをローカルにリレーして、 ローカルのサーバをお手がるに公開できるサービスです。
びっくりするほど簡単に公開できて便利ですが、 一応oAuthで制限とかかけたいなーとかカスタマイズしてみたくなってきたので、 似たようなものを自作できないかといろいろ遊んでみました。
その結果、HTTP2 over Websocketみたいな謎なものが出来上がってしまったというお話です。
HTTP2 over Websocketというアイデア ngrokっぽいものを実現するためには、 サーバが受け取ったHTTPリクエストをローカルの環境に転送する必要があります。 ご存知のとおり通常のHTTPではサーバ側からのプッシュ配信が難しいので、Websocketを使うのが良さそうです。 しかし、複数のコネクションで並列にやってくるHTTPリクエストを、一本のWebsocketに束ねる必要があり、 上手く制御するのは大変そうです。
さて、HTTP2は一つのTCPコネクションで複数のリクエストを並行処理する仕様があります。 「複数のリクエストを一本に束ねる」という点ではなんか似ているので、なんだか流用できそうな気がしてきました。 Golangならきっと上手いことinterfaceを実装すれば、なんとかできるのではとやってみました。
実装 HTTP2は暗号化や複雑なフロー制御を行っていますが、 外から見ればnet.Connインターフェースに読み書きしている何かに過ぎません。 そして、websocket.Connもnet.Connを実装しているので、そのままHTTP2のライブラリに渡せるはずです。
そうしてできたのが以下のサーバです。
package main import ( &amp;#34;errors&amp;#34; &amp;#34;log&amp;#34; &amp;#34;net/http&amp;#34; &amp;#34;net/http/httputil&amp;#34; &amp;#34;sync&amp;#34; &amp;#34;golang.org/x/net/http2&amp;#34; &amp;#34;golang.org/x/net/websocket&amp;#34; ) type transport struct { m sync.Mutex t http.RoundTripper closed chan struct{} } var t *transport func main() { t = &amp;amp;transport{} s := websocket.Server{Handler: websocket.Handler(Handler)} http.Handle(&amp;#34;/&amp;#34;, s) go http.ListenAndServe(&amp;#34;:3000&amp;#34;, nil) http.</description>
    </item>
    <item>
      <title>nginx-omniauth-adapterのGolangポート作った</title>
      <link>https://shogo82148.github.io/blog/2016/03/10/go-nginx-oauth2-adapter/</link>
      <pubDate>Thu, 10 Mar 2016 12:51:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2016/03/10/go-nginx-oauth2-adapter/</guid>
      <description>「nginx で omniauth を利用してアクセス制御を行う」という記事で、 ngx_http_auth_request_moduleの存在を知ったので、 Golangでnginx_omniauth_adapterと似たようなものを作ってみました。
shogo82148/go-nginx-oauth2-adapter 背景 typester/gateは単体でも動くようになっていますが、 例えばIP制限などちょっと高度なことをしたい場合には結局nginxを前段に置く必要があります。 nginxとgateの設定を同時にいじる必要があって煩雑だと感じていました。
そんな中「nginx で omniauth を利用してアクセス制御を行う」という記事で、 ngx_http_auth_request_moduleの存在を知りました。 gateが認証＋Proxyをやってしまうのに対して、認証だけRubyのomniauthモジュールで行いProxyはnginxに任せるという方法です。
以前から記事の存在は知っていたのですが、Rubyの実行環境をそろえるのが億劫で手を出せずにいました。 小さなアプリなので自分の慣れた言語で実装しても大したことないのではと思い、Goで実装してみることにしました。
使い方 go getで落として来れます。 最低限client_idとclient_secretの指定が必要です。 nginx_omniauth_adapterと同じ環境変数名で設定できるほか、YAML形式の設定ファイルを読みこませることができます。 YAMLの形式はREADMEを参照してください。
$ go get github.com/shogo82148/go-nginx-oauth2-adapter/cli/go-nginx-oauth2-adapter $ export NGX_OMNIAUTH_GOOGLE_KEY=YOUR_CLIENT_ID $ export NGX_OMNIAUTH_GOOGLE_SECRET=YOUR_CLIENT_SECRET $ go-nginx-oauth2-adapter $ go-nginx-oauth2-adapter -c conf.yaml # 設定ファイルでの指定も可能 PerlでHTTPサーバ書いているひとにはおなじみのServer::Starterにも対応しているので、 それ経由で立ち上げておくと設定の更新・プログラム自身の更新等が楽になると思います。
start_server --port 18081 -- go-nginx-oauth2-adapter -c conf.yaml nginx側の設定はexamplesディレクトリを参照してください。 ヘッダ名・パス名等を合わせてあるので、nginx_omniauth_adapterと同じ設定で動くはずです。
また、h2oの設定はプログラマブルだからh2oでもちゃんと設定ファイルを書けば動くのではと考え、 h2oの設定も書いてみました。 mrubyからproxyに渡るリクエストを書き換える方法がない(？)っぽいので、アプリ側で認証情報をとることはできないですが、一応制限はできます。 basic認証の実装を見る限りremote-userヘッダだけは渡せるようなので、これを使えばなんとかなるかもしれないですが、未確認です。 (Ruby慣れてないからってGoで実装したけど、結局Rubyを書いていて面白い)
nginx_omniauth_adapterとの違い 厳密に同じ挙動を実装するのが面倒だったため、挙動に若干の違いがあります。 一番大きなものは認証後のリダイレクト先です。
nginx_omniauth_adapterは認証後、一度adapterのURLにリダイレクトしてから、アプリサーバの/_auth/callbackにリダイレクトします。 それに対してgo-nginx-oauth2-adapterは認証後、アプリサーバの/_auth/callbackに直接リダイレクトします。 この違いのため、Google Developers Consoleの「承認済みのリダイレクト URI」に設定するべきURIが異なることに注意してください。 nginx_omniauth_adapterはadapter自身のURI、go-nginx-oauth2-adapterはアプリサーバの/_auth/callbakを指定します。
この挙動のため、go-nginx-oauth2-adapterはアプリの追加のたびにnginxの設定に加え「承認済みのリダイレクト URI」に正しいURIを追加する必要があります。 もちろん設定箇所がGoogle Developers Consoleではないだけで、nginx_omniauth_adapterもリダイレクト先の設定は必要です。 GoogleでもFacebookでも認証できるようにしたいという場合、nginx_omniauth_adapterは設定を一箇所変えればOKですが、go-nginx-oauth2-adapterは各サービスに登録し直す必要があります。 現状、認証に使うサービスをユーザが選ぶ仕組みがないので、そのまま放置してあります。</description>
    </item>
    <item>
      <title>転職して一週間がたちました</title>
      <link>https://shogo82148.github.io/blog/2016/03/08/join-fuller/</link>
      <pubDate>Tue, 08 Mar 2016 15:55:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2016/03/08/join-fuller/</guid>
      <description>転職して1週間がたち，新しい生活サイクルにも慣れてきましたので近況報告をします． 面白法人を卒業し、3月1日から Fuller 株式会社で働き始めました！ アプリの視聴率調査のApp Ape Analyticsの提供を中心に、スマフォアプリの開発・分析をやってる会社です。
Pythonの会社なのか？ 私も入るまでみんなPythonを使っている会社だと思っていたのですが、 実際はPythonとjavascript半々くらいで使われています。（若干javascript勢の方が多いかも？） 最近は一部Goが導入されつつあるようでが、残念ながらPerlは影も形もありません。 折角Perlな会社にいたので、Perlの布教活動に勤しみたいと思っています。
業務の感じ チームみんなで改善点を話し合って、みんなで解決していくような感じです。 慣れないツールばっかりで苦労してますが、頑張ります。
会社の雰囲気 ひとことで言うと大学の研究室みたいな感じです。（こう言えば多くの人に伝わるんじゃないかなと） 社員の高専卒の割合が非常に高く僕自身も高専の出身なので、懐かしい感じです。
最後に一言 TLを追ってなかったので全然気が付かなかったけど、退職と転職のタイミングがamacbee氏と完全に一致していてびっくりした。 僕も26日退社、1日入社だったのです。
転職して一週間がたちました 退職します 折角なので、記事の中身もamacbee氏に合わせてみました。</description>
    </item>
    <item>
      <title>グロンギ語翻訳辞書をアップデートしました</title>
      <link>https://shogo82148.github.io/blog/2016/02/27/update-grongish-dictionary/</link>
      <pubDate>Sat, 27 Feb 2016 10:27:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2016/02/27/update-grongish-dictionary/</guid>
      <description>やることがたくさんあるときに限ってどうでもいいことが捗ってこまっているいっちーです。 先日、挑戦状を受け取ったので、グロンギ語翻訳の品質改善に挑戦しました。
《緊急告知》2月26日(金)、何かが起こる!!「仮面ライダークウガ」にまつわる新商品のようですが・・・。ページに書かれているのは、グロンギ語？お客様の中で、リントの言葉に翻訳できる方はいらっしゃいますか～？ https://t.co/hMDQCST6Tz
&amp;mdash; プレミアムバンダイ (@p_bandai) 2016年2月17日 仮面ライダークウガより衝撃の新アイテム登場 ボンジ・ジュグギゾ・ガギバギ・グスと判明!(投げやり) お手軽に試せるページも作ったので、こちらでお試し下さい。
グロンギ語翻訳 変換の仕組み 変換の仕組みの詳細は以前書いた記事をどうぞ。 概略だけ書いておくと、 日本語からグロンギ語への変換はMeCabを使った読み・品詞推定の結果もとに、 変換ルールを適用して翻訳しています。 グロンギ語から日本語への翻訳は、この翻訳問題が実は仮名漢字変換と同じ問題だということを利用して、 IMEの辞書をグロンギ語対応したものを使っています。
変換ロジックの修正 旧版の問題点 ボンジジュグギゾガギバギグス: 紺地重視を再開する ゲゲルンギバブゾロヅボパザセザ: ゲームのしなくっ持つのはだれだ ゲゲルゾザジレスゾ: ゲームを始めるぞ 「この日」は「ボンジ」が正しいのですが、「ボボジ」と変換していたため正しく認識できていませんでした。 「の」は通常「ガ」になるのですが、助詞として現れたときは「ン」になります。 さらに連体詞の一部として出てきたときも「ン」になるのですが、こちらのルールが抜けていました。
さらなる改良 旧版はmecab-skkdicを元にした辞書を使っていましたが、 mozcベースに変更しました。 mozcの辞書はクラスタリングや語彙化のような粒度調整が行われており、変換精度の向上が期待できます。 どのようが調整が行われたかはMozcソースコード徹底解説 や 言語処理学会でのMozcの資料を見るとよいと思います。
mozcの変換エンジンをそのまま使えると良かったのですが、すごく面倒なことがわかったのでギブアップしました。 (依存モジュールの関係で32bit版しかビルドできず64bitのプログラムからは直接呼び出せないとか、C++とかC++とかC++とか) mozcとMeCabの辞書構造は非常に似ているので、MeCabの辞書形式に変換して利用しています。 mozcには共起辞書を使った補正機能(例えば同じ「かいたい」という読みでも、「猫を飼いたい」「マグロを解体」を出し分ける機能)など、 MeCabにはない機能も入っているので、そのうち挑戦してみたいですね。 ただし、mozcには機能だけ組み込まれていて辞書が入っていないので、mozcを使っただけだと大差ないかもしれません。
改良の結果 ボンジジュグギゾガギバギグス: この日重視を再開する ゲゲルンギバブゾロヅボパザセザ: ゲームの資格を持つ子は誰だ ゲゲルゾザジレスゾ: ゲームを始めるぞ だいぶ近くなりました。 「重視」と「遊戯」はグロンギ語で同じ音なので、難しいですね。
変換サーバの実装 ライブラリはPythonで書いてあるので、 PythonのWebフレームワークであるPyramidを使ってAPI化してみました。
デプロイ時のファイル置き換えをアトミックにする sakuraのVPS上でdrootを使って起動しています。 kazuhoさんの「server-starter が SIGHUP 受け取ると pull 型のデプロイツールが起動して、そいつが新しいディレクトリにイメージを展開して、そこに chroot してアプリケーションが動き出すスタイル」を実践してみたくなったので、以下のようなスクリプトを書いてみました。
CONTAINER_DIR=/var/containers/hogehoge-$$ tar zfx hogehoge.tar.gz -C $CONTAINER_DIR droot run --root $CONTAINER_DIR exec gunicorn server:application &amp;amp; CHILD=$!</description>
    </item>
    <item>
      <title>MeCabのGolangバインディングを書いてみた</title>
      <link>https://shogo82148.github.io/blog/2016/02/11/golang-mecab-binding/</link>
      <pubDate>Thu, 11 Feb 2016 19:32:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2016/02/11/golang-mecab-binding/</guid>
      <description>GolangからMeCabを呼び出すライブラリ探せばあるにはあるのですが、 なんだかどれもメモリ管理がちょっと怪しいんですよね・・・。
GolangでMeCabを使う。 yukihir0/mecab-go Go言語から mecab を使う - Qiita rerofumi/mecab Go で Mecab を使ってみた メモリ管理はbluele/mecab-golangが一番しっかりしているっぽいですが、 libmecabの一番高機能だけど面倒な使い方しか対応していなくて、ちょっとカジュアルに遊ぶにはつらい。
というわけで、カジュアルな用途から高度な使い方まで対応したWrapperを書いてみました。
shogo82148/go-mecab 使い方 READMEとgodocのexamplesからのコピペになってしまいますが、 簡単に使い方の紹介です。
インストール go getで取ってくることはできますが、事前にlibmecabとリンクするための設定が必要です。
$ export CGO_LDFLAGS=&amp;#34;-L/path/to/lib -lmecab -lstdc++&amp;#34; $ export CGO_CFLAGS=&amp;#34;-I/path/to/include&amp;#34; $ go get github.com/shogo82148/go-mecab mecabコマンドと一緒にmecab-configがインストールされているはずなので、 それを使うのが楽でしょう。
$ export CGO_LDFLAGS=&amp;#34;`mecab-config --libs`&amp;#34; $ export CGO_FLAGS=&amp;#34;`mecab-config --inc-dir`&amp;#34; $ go get github.com/shogo82148/go-mecab MeCabはデフォルトで/usr/local/以下に入るので、他の実装では決め打ちしている例が多いですが、 100%とは言い切れないので面倒ですが都度指定にしてあります。 cgoはpkg-configに対応しているで、MeCab側が対応してくれると環境変数の設定が不要になってもっと楽なんですけどね。
カジュアルに使う Parseを使うとmecabコマンドと同等の結果を文字列として受け取れます。
tagger, err := mecab.New(map[string]string{}) if err != nil { panic(err) } defer tagger.Destroy() result, err := tagger.</description>
    </item>
    <item>
      <title>AWS Lambda で MeCab を動かす(改)</title>
      <link>https://shogo82148.github.io/blog/2016/02/10/mecab-in-lambda/</link>
      <pubDate>Wed, 10 Feb 2016 14:52:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2016/02/10/mecab-in-lambda/</guid>
      <description>MeCabのPythonバインディングをいじってた関係で、MeCabについてインターネットをさまよっていたら、 AWS Lambda で MeCab を動かすという記事を見つけました。 Lambdaの計算リソースで形態素解析できるのは楽しいですねー。 ただ実装にまだまだ改善できそうな部分があったので修正してみました。
2017/12/06追記 Norio Kimuraさんのコメントを受けて、MeCabをAWS Lambdaで動かす(2017年版)を書きました。 以下の手順でも動きますが、少し簡単に出来るようになっています。
問題点 第一に**「外部プロセスを起動しているので遅い」**という点です。 外部プロセスの起動は非常に重くて数百msかかります。 MeCabは非常に高速で数msもあれば解析が終わるのに、もったいないですよね。
第二に**「OSコマンドインジェクションの危険性がある」**という点です。 解析対象の文字列をコマンドライン引数として渡しており、この際シェルを経由しています。 そのため、{&amp;quot;sentence&amp;quot;: &amp;quot;$(ls)&amp;quot;}のような文字列を渡すと、シェルがコマンドとして実行してしまいます。 API Gatewayなどで外部に公開した場合、第三者が何でもし放題な状態になってしまいます。
頑張ってMeCabをライブラリとして呼ぶ 全ての元凶は外部プロセス起動にあるので、頑張ってMeCabをライブラリとして呼んでみましょう。 そもそもなんで外部プロセス起動をしていたかというと、 LD_LIBRARY_PATHが正しく設定されていないためimport MeCab時にlibmecab.soを発見できないからです。 なんとかならないものかと探したところ、Stack Overflowにそれっぽい記事がありました。
Setting LD_LIBRARY_PATH from inside Python 「環境変数を設定してから自分自身をexecし直す方法」と「ctypesを使って絶対パス指定で読み込む方法」が紹介されています。 前者の方がvoteは多いですがLambdaでこれをやるのは大変そうなので、後者で試してみます。
# preload libmecab import os import ctypes libdir = os.path.join(os.getcwd(), &amp;#39;local&amp;#39;, &amp;#39;lib&amp;#39;) libmecab = ctypes.cdll.LoadLibrary(os.path.join(libdir, &amp;#39;libmecab.so&amp;#39;)) 一度読み込んでしまったライブラリは再利用されるため、 import MeCabはここで読み込んだライブラリにリンクされます(importの順番が重要なの闇な感じがする)。 LD_LIBRARY_PATHが正しく設定されている必要はありません。
さて、これでlambda_function.pyとtokenizer.pyが分かれている必要がなくなったので、二つを合体してみましょう。
# coding=utf-8 import os import settings import logging logger = logging.getLogger(__name__) logger.setLevel(settings.LOG_LEVEL) # preload libmecab import ctypes libdir = os.</description>
    </item>
    <item>
      <title>Redisでスコアを複数設定できるランキングを作ってみた</title>
      <link>https://shogo82148.github.io/blog/2016/02/06/redis-leader-board-multi/</link>
      <pubDate>Sat, 06 Feb 2016 02:30:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2016/02/06/redis-leader-board-multi/</guid>
      <description>ランキングを作っているとスコアを複数設定したいことがよくあると思います。 例えば「得点が同じだったら早くその得点を出した人優先」とか「勝ち点が同じだったら得失点差が大きい方優先」とかのように、 最初の基準で順位を決められなかった場合の第二基準が欲しいみたいな場合です。
ランキングを作るのにはRedisのSorted Setを使うのが便利ですが、残念ながらSorted Setはひとつしかスコアを設定できません。 少し前にどうやったら実装できるかと社内チャットで話題に上ったので、試しにRedis::LeaderBoardMulti(仮名)という名前で書いてみました。
shogo82148/p5-Redis-LeaderBoardMulti 使い方 メソッドの名前はRedis::LeaderBoardにあわせてありますが、 スコアが複数指定できるようになった関係でちょっと変わってます。
use Redis; use Redis::LeaderBoard; my $redis = Redis-&amp;gt;new; my $lb = Redis::LeaderBoardMulti-&amp;gt;new( redis =&amp;gt; $redis, key =&amp;gt; &amp;#39;leader_board:1&amp;#39;, order =&amp;gt; [&amp;#39;asc&amp;#39;, &amp;#39;desc&amp;#39;], # asc/desc, desc as default ); $lb-&amp;gt;set_score(&amp;#39;one&amp;#39; =&amp;gt; 100, time); # 第二基準は時間=得点が同じだったら早くその得点を出した人優先 $lb-&amp;gt;set_score(&amp;#39;two&amp;#39; =&amp;gt; 50, time); my ($rank, $score, $time) = $lb-&amp;gt;get_rank_with_score(&amp;#39;one&amp;#39;); set_scoreの第二引数以降はすべてスコアとして扱われます。(そのためRedis::LeaderBoardと互換性はない) 上の例では「得点が同じだったら早くその得点を出した人優先」になってます。
制限事項 実装の都合により、以下のような制限があります。
スコアはすべて64bit符号付き整数です Redis::LeaderBoardのスコアは倍精度浮動小数点型なので小数も扱えるが、Redis::LeaderBoardMultiは整数だけ Redis 2.8.9以降のみで動きます 実装の仕組み Sorted Setの同じスコアを持つメンバーは辞書順にソートされます(zaddの同じスコアを持つ要素の項を参照)。 例えば以下の様にメンバー「a」「b」「c」を追加すると、必ず「abc」の順番になることが保証されています。
127.0.0.1:6379&amp;gt; ZADD ranking 0 &amp;#34;a&amp;#34; 0 &amp;#34;b&amp;#34; 0 &amp;#34;c&amp;#34; (integer) 3 127.</description>
    </item>
    <item>
      <title>Redis::Fast 0.17 をリリースしました</title>
      <link>https://shogo82148.github.io/blog/2016/01/23/redis-fast-0-dot-17-released/</link>
      <pubDate>Sat, 23 Jan 2016 16:20:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2016/01/23/redis-fast-0-dot-17-released/</guid>
      <description>Redis::Fast 0.17 をリリースしました。 主な変更点は以下のとおりです。
I/Oの待ち合わせに使うシステムコールをselect(2)からpoll(2)に変更 hiredisをv0.13.3にアップデート macでテストが終わらない問題がありましたが、この変更によって修正されています。
hiredisはconnect(2)をnonblokingモードで呼び出しています。 nonblockingなので接続が未完了であってもすぐに制御を返し、errnoにEINPROGRESSが設定されます。 この場合、manにあるようにselect(2)で書き込み可能になるのを待つことで、接続完了を検知できます。
select(2) で書き込み可能になった後に、 getsockopt(2) を使って SOL_SOCKET レベルで SO_ERROR オプションを読み出すこ とにより、 connect() が成功したか、失敗したかを判断できる。
linuxの場合はこれで上手く動くのですが、macだと何故かselect(2)が永遠に制御を返さない場合があるようです。 接続先が存在しない場合に起こるのですが、制御を返す場合もあるので謎です。
いろいろ調べてはみたのですがselect(2)だとどうやっても上手く動かなかったので、poll(2)に変更しました。 poll(2)変更版でテストしてみると、接続先が存在しない場合にPOLLOUTを返すケースとPOLLHUPを返すケースがあるようです。 どうやらPOLLHUPにあたるイベントが来た時の挙動がlinuxとmacとで違うらしい？ 謎です。</description>
    </item>
    <item>
      <title>UnityのBitmapフォントの収録文字のdiffを取る</title>
      <link>https://shogo82148.github.io/blog/2015/12/22/diff-of-unity-bitmap-font/</link>
      <pubDate>Tue, 22 Dec 2015 19:04:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2015/12/22/diff-of-unity-bitmap-font/</guid>
      <description>Unityで文字を描画するには 「BMFont(Bitmap Font Generator)でビットマップフォントを作る方法」等にあるように ビットマップフォントを自分で作ってあげないといけないらしいです。 (ダイナミックフォントというものもあるらしいけど、まだ安定性が検証ができていないので使ってない。)
フォントに入っている全部の文字を収録するとでかくなりすぎるので、一部の文字だけ収録するのが一般的だと思います。 入れる文字は自分で選ぶわけですが、フォントファイルを更新する際に、以前は使えた文字が入っていなくてつらい思いをしたので、 gitで差分をみれるようにしてみました。
gitのいろんなファイル形式の差分を見やすくする方法は Git Diffでcsvの差分を見やすく表示するを参照。
csvのときと同じ要領で、まずはfntファイルをdiffを取りやすい形式に変換するスクリプト(fnt2txt)を用意し
#!/bin/bash grep &amp;#39;char id=&amp;#39; $1 | cut -d&amp;#39; &amp;#39; -f2 | cut -d= -f2 | perl -MEncode -ne &amp;#39;printf &amp;#34;%04x: %s\n&amp;#34;, $_, encode_utf8 chr($_) if $_ &amp;gt;= 32&amp;#39; fnt2txtを使う設定を.git/configに設定します。
[diff &amp;#34;fnt&amp;#34;] textconv = fnt2txt 最後に拡張子.fntに対してだけこの設定が反映されるようにすればOKです。
*.fnt diff=fnt こんな感じでdiffが見れます。
diff --git a/foo.fnt b/foo.fnt index 79391c0..e262b2d 100755 --- a/foo.fnt +++ b/foo.fnt @@ -93,6 +93,7 @@ 007c: | 007d: } 007e: ~ +00a0: 00a1: ¡ 00a2: ¢ 00a3: £ 事故防止に是非ご利用ください。</description>
    </item>
    <item>
      <title>MeCabをPython3から使う(続報)</title>
      <link>https://shogo82148.github.io/blog/2015/12/20/mecab-in-python3-final/</link>
      <pubDate>Sun, 20 Dec 2015 01:03:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2015/12/20/mecab-in-python3-final/</guid>
      <description>Python3からMeCabを扱おうとして挫折していたのですが (MeCabをPython3から使う(中間報告))、 改めて調査して、上手くいかなかった原因が分かったのでご報告します。
おさらい Python3で以下のようにMeCabを使おうとすると
import MeCab tagger = MeCab.Tagger(&amp;#39;&amp;#39;) text = u&amp;#39;MeCabで遊んでみよう!&amp;#39; node = tagger.parseToNode(text) while node: print(node.surface + &amp;#39;\t&amp;#39; + node.feature) node = node.next surfaceが全く読み取れないという現象に遭遇していました。
BOS/EOS,*,*,*,*,*,*,*,* 名詞,一般,*,*,*,*,* 助詞,格助詞,一般,*,*,*,で,デ,デ 動詞,自立,*,*,五段・バ行,連用タ接続,遊ぶ,アソン,アソン 助詞,接続助詞,*,*,*,*,で,デ,デ Traceback (most recent call last): File &amp;#34;m.py&amp;#34;, line 10, in &amp;lt;module&amp;gt; print( node.surface + &amp;#39;\t&amp;#39; + node.feature ) UnicodeDecodeError: &amp;#39;utf-8&amp;#39; codec can&amp;#39;t decode byte 0xa3 in position 1: invalid start byte 解決策 詳しい原因なんてどうでもいいからMeCabを使いたい人向けに、最初に解決方法を書いておきます。 以下のように本当に解析したい対象を解析する前に、一度parseをしておけばOKです。
import MeCab tagger = MeCab.</description>
    </item>
    <item>
      <title>PerlのDBIx::Class利用上の注意点</title>
      <link>https://shogo82148.github.io/blog/2015/12/17/dbix-class/</link>
      <pubDate>Thu, 17 Dec 2015 18:35:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2015/12/17/dbix-class/</guid>
      <description>この記事は、Perl 5 Advent Calendarの17日目の記事です。
Redis::Fast の reconnect についての中で DBIx::Classのreconnectについても触れています。 DBIx::Classの安全にreconnectionが行えるように考慮されていますが、色々と注意点があります。 reconnection周りで調べてみたので、Advent Calendarの枠を借りてまとめたいと思います。
DBIx::Classとは DBIx::ClassはPerlのO/Rマッピングモジュールです。 テーブル間のリレーションを定義でき、JOIN句の入ったクエリもサポートする等、かなり高機能なモジュールです。 もう僕はJOIN句をDBIx::Class以外で書ける気がしません。 詳しくはtypester先生の解説記事をどうぞ。
Perl Hackers Hub 第3回　DBIx::Classでデータベース操作（1） 第3回　DBIx::Classでデータベース操作（2） 第3回　DBIx::Classでデータベース操作（3） サンプル サンプルとしてユーザの所持金を管理する簡単なアプリを作ってみます。 Webアプリとか作るの面倒だったので、コンソールアプリです。
package My::Schema::User { use base &amp;#39;DBIx::Class::Core&amp;#39;; __PACKAGE__-&amp;gt;table(&amp;#39;user&amp;#39;); __PACKAGE__-&amp;gt;add_columns( id =&amp;gt; { data_type =&amp;gt; &amp;#39;INTEGER&amp;#39;, is_nullable =&amp;gt; 0, is_auto_increment =&amp;gt; 1, }, username =&amp;gt; { data_type =&amp;gt; &amp;#39;VARCHAR&amp;#39;, size =&amp;gt; 255, is_nullable =&amp;gt; 0, }, ); __PACKAGE__-&amp;gt;set_primary_key(&amp;#39;id&amp;#39;); # userとmoneyは1対1の関係で、userに対応するmoneyが必ず存在しなければならない __PACKAGE__-&amp;gt;has_one( &amp;#39;money&amp;#39; =&amp;gt; &amp;#39;My::Schema::Money&amp;#39;, { &amp;#39;foreign.</description>
    </item>
    <item>
      <title>git-mergeの挙動をカスタマイズする</title>
      <link>https://shogo82148.github.io/blog/2015/12/16/customize-git-merge/</link>
      <pubDate>Wed, 16 Dec 2015 22:24:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2015/12/16/customize-git-merge/</guid>
      <description>最近gitのコンフリクト解消職人みたいになっていてすごくつらいです。 普通のプログラムであれば順番が重要なので手動でのコンフリクト解消は避けられないのですが、 僕が相手にしているのは最終的にMySQLに食わせるデータなのでそこまで順番は重要ではありません。 順番に挿入したところで、MySQLが順番にかえしてくれるとは限りませんからね。 このようなケースではある程度機械的にマージできるのでは？と調べてみました。
merge driver いろいろググってみるとgitattributesでファイル毎にマージの細かい挙動を制御できるようです。 通常マージの方法はgitがよしなに選択してくれますが、merge属性に以下の項目を指定することでマージの方法を強制することができます。
text テキストファイルとしてマージする。 コンフリクトすると &amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;, =======, &amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;でコンフリクトした場所を教えてくれる。 binary バイナリファイルとしてマージする。 コンフリクトするとマージしようとしたファイルを残しておいてくれる。 union テキストファイルとしてマージする。 textと違ってコンフリクトしてもマーカを付けない。どちらの変更も残すように適当にマージしてくれる。 適当なので コンフリクト時の行の順番は保証されない text, binaryはコンフリクトしたときによく見る挙動ですね。 unionは初めて知ったので、簡単なレポジトリを作って挙動を確かめてみました。
$ # masterブランチ上でmembers.txtにAliceを追加する $ git init $ echo Alice &amp;gt; members.txt $ git add members.txt $ git commit -m &amp;#39;add Alice&amp;#39; [master (root-commit) 8c39714] add Alice 1 file changed, 1 insertion(+) create mode 100644 members.txt $ $ # add-bobブランチ上でmembers.txtにBobを追加する $ git checkout -b add-bob Switched to a new branch &amp;#39;add-bob&amp;#39; $ echo &amp;#39;Bob&amp;#39; &amp;gt;&amp;gt; members.</description>
    </item>
    <item>
      <title>Goでデプロイ神社書いてみた</title>
      <link>https://shogo82148.github.io/blog/2015/12/13/go-deploy-shrine/</link>
      <pubDate>Sun, 13 Dec 2015 10:51:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2015/12/13/go-deploy-shrine/</guid>
      <description>Go その2 Advent Calendar 2015の13日目の記事です。
その1 その2 その3 六曜を知ることができる便利コマンドを作ってみたお話です。
Deploy神社とは Maco_Tasuが作ったいつdeployしたら安全かを教えてくれる便利APIです。 詳しくは作者ブログ記事をどうぞ。(Deploy神社APIを作った- 眠すぎて明日が見えない)
便利APIなのですが、依存している外部APIが利用できなくなってしまったため、Deploy神社自体が利用できなくなっています。
作ってみた デプロイする時間が分からないと不便なので、Go実装を作ってみました。
shogo82148/go-deploy-shrine go getしてきてお祈りを捧げればデプロイするべき時間を教えてくれます。
$ go get github.com/shogo82148/go-deploy-shrine/cli/pray $ pray 今日は旧暦の11月3日(先勝)です。deployは午前中に済ませましょう。 先勝 - Weblio
六曜の一。急用や訴訟などによいとされ，早く事を行うのがよく，午前は吉，午後は凶という日。先勝日。せんかち。さきがち。
今日12月13日は先勝で午前中にデプロイするのが良いようです。便利ですね。
六曜とは むかしのカレンダーには暦注と呼ばれる「今日の運勢」みたいなものが記載されていたらしいです。 六曜はその暦注のひとつで、現在のカレンダーにも記載されることの多い影響力の大きなものです。
詳しくはWikipediaで。
六曜 - Wikipedia 旧暦の(月＋日)を6で割った余りから簡単に求めることができます。
0: 大安 1: 赤口 2: 先勝 3: 友引 4: 先負 5: 仏滅 旧暦とは 旧暦の月日を求めることができれば六曜は簡単に出せるのですが、 日本における旧暦である天保暦は月の満ち欠けと太陽の動きを元にした暦法であり、 月と太陽の動きを正確に予測する必要があります。
Go版デプロイ神社では「日の出・日の入りの計算―天体の出没時刻の求め方」で紹介されていた計算式を用いています
2033年旧暦閏月問題 天保暦をそのまま当てはめると2033年に月を決定できない問題が知られています。 日本カレンダー暦文化振興協会というところが「閏11月を推奨する」との見解を2015年8月に出しています。
2033年旧暦閏月問題の見解 Go版デプロイ神社では時憲暦方式を採用したつもりです。
せめてGoっぽい話題を 引数に日付を渡すとその日の六曜をかえしてくれます。 いろんな形式に対応していて、以下はすべて2006年1月2日の六曜を返します。
$ pray 20060102 $ pray 1/2/2006 $ pray 2-Jan-06 $ pray 2-Jan-2006 $ pray 2/Jan/2006 $ pray &amp;#39;Jan 2 2006&amp;#39; 2006-01-02は旧暦の12月3日(友引)です。昼のdeployはさけましょう。するなら朝晩が吉です。 引数の解析には tkuchiki/parsetimeを使っています。 たいていの日時フォーマットなら解析してくれる便利ライブラリです。</description>
    </item>
    <item>
      <title>Perl の DateTime 利用上の注意点</title>
      <link>https://shogo82148.github.io/blog/2015/12/09/perl-datetime/</link>
      <pubDate>Wed, 09 Dec 2015 00:00:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2015/12/09/perl-datetime/</guid>
      <description>この投稿は Perl 5 Advent Calendar 2015 の 9日目の記事です。
Perl の Time::Piece 利用上の注意点 という記事の最後にDateTimeへの言及があったのですが、 DateTimeはDateTimeでいろいろとハマりどころがあるんですよね・・・。 僕も今年いくつか罠にハマりました。ちょうどアドベントカレンダーの季節ですし、この機会にハマりどころをまとめてみることにします。
遅い いろんなところで言われていることですが 遅い です。 試しに代表的な日付を扱うモジュールでベンチをとってみました。 (比較のために時間をとるためのPerlの組み込み関数も入れてあります)
# いろんな形式で今の時間を取得する use Benchmark qw/ cmpthese /; use Time::HiRes (); use Time::Moment; use Time::Piece (); use DateTime; cmpthese 0, { &amp;#39;time&amp;#39; =&amp;gt; sub { time }, &amp;#39;Time::HiRes&amp;#39; =&amp;gt; sub { Time::HiRes::time }, &amp;#39;localtime&amp;#39; =&amp;gt; sub { () = localtime }, &amp;#39;Time::Moment&amp;#39; =&amp;gt; sub { Time::Moment-&amp;gt;now }, &amp;#39;Time::Piece&amp;#39; =&amp;gt; sub { Time::Piece-&amp;gt;localtime }, &amp;#39;DateTime&amp;#39; =&amp;gt; sub { DateTime-&amp;gt;now( time_zone=&amp;gt;&amp;#39;Asia/Tokyo&amp;#39; ) }, }; Rate DateTime Time::Piece Time::Moment localtime Time::HiRes time DateTime 5303/s -- -95% -98% -99% -100% -100% Time::Piece 103765/s 1857% -- -67% -71% -98% -99% Time::Moment 313599/s 5814% 202% -- -11% -93% -98% localtime 354215/s 6580% 241% 13% -- -92% -98% Time::HiRes 4706723/s 88658% 4436% 1401% 1229% -- -72% time 16536995/s 311751% 15837% 5173% 4569% 251% -- それにしてもTime::Moment速いですね。組み込みのlocaltimeと互角とは。</description>
    </item>
    <item>
      <title>Go言語でGraceful Restartをするときに取りこぼしを少なくする</title>
      <link>https://shogo82148.github.io/blog/2015/11/23/golang-graceful-restart-2nd/</link>
      <pubDate>Mon, 23 Nov 2015 20:51:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2015/11/23/golang-graceful-restart-2nd/</guid>
      <description>少し前にStarletにGraceful Restartが時たま上手く動かない問題を修正するpullreqを投げました。 原因は割り込みハンドラ内でexitを呼んでいたからでした。 「割り込みハンドラ内ではフラグを建てるだけ」 「メインのプログラム内でそのフラグを見て分岐する」という原則があるのですが、それを守るのは難しいということですね。 (しかし新たな問題を産んでしまいrevertされてしまいましたが・・・ まあ修正後のコードも考え方は一緒です。割り込みホント難しい・・・)
このpullreqを取り込んでもらうときに再現実験をやってみたのですが、 Goでもちゃんと動くのかな？と気になったので Go言語でGraceful Restartをするで紹介した プログラムに同じテストをやってみました。
2017-01-22追記: Go1.8以降でGraceful Shutdownがbuild-inになるので、この記事で紹介したライブラリは不要となりました。 詳しくはGo1.8のGraceful Shutdownとgo-gracedownの対応を参照。
mannersでテストしてみる 前回の記事ではmannersとgo-server-starterの 組み合わせが良さそうとの結論になったので、この組み合わせでテストしてみます。 以下テストに使用したコードです。 (今回の内容とは直接関係は無いですが、go-server-starterに変更が入ってFallbackのやり方が前回から少し変わってます)
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;log&amp;#34; &amp;#34;net&amp;#34; &amp;#34;net/http&amp;#34; &amp;#34;os&amp;#34; &amp;#34;os/signal&amp;#34; &amp;#34;syscall&amp;#34; &amp;#34;time&amp;#34; &amp;#34;github.com/braintree/manners&amp;#34; &amp;#34;github.com/lestrrat/go-server-starter/listener&amp;#34; ) var now = time.Now() func main() { log.Printf(&amp;#34;start pid %d\n&amp;#34;, os.Getpid()) signal_chan := make(chan os.Signal) signal.Notify(signal_chan, syscall.SIGTERM) go func() { for { s := &amp;lt;-signal_chan if s == syscall.SIGTERM { log.Printf(&amp;#34;SIGTERM!!!!\n&amp;#34;) manners.Close() } } }() listeners, err := listener.</description>
    </item>
    <item>
      <title>Goオールスターズで登壇してきました</title>
      <link>https://shogo82148.github.io/blog/2015/10/14/go-all-stars/</link>
      <pubDate>Wed, 14 Oct 2015 08:11:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2015/10/14/go-all-stars/</guid>
      <description>先週の日曜日に登壇してきました。
過去に自作したGoプロダクトの紹介 - Goオールスターズ from Shogo Ichinose 過去に自作したGoプロダクトの紹介 - Goオールスタース 発表の10日くらい前にsongmuさんがKAYACのIRCに現われオールスターを募集に来てくださったものの、 弊社スターの都合がつかないため僕が代わりに発表してきました。
KAYACではGoプロダクトたくさん動いていますが説明は作者にお任せしたほうがいいかなと思い、 自作のGoプロダクトをメインに発表してきました。
go-rgba4444 androidbinary - Androidのバイナリファイルを解析するgoのライブラリ go-sql-proxy - Go言語でSQLのトレースをする go-dithering - Go言語で画像の減色を行う go-prove/go-tap - Go言語でPerlのテストを早くする go-webtail/go-webtail - Go-webtailってのを書いた go-prove、CPANに上げればいいんじゃない？w #eventdots
&amp;mdash; songmu (@songmu) 2015年10月11日 Perl Archive Network とはいったい・・・
KAYACではいろんなGoプロダクトが動いているのでこちらもどうぞ。
go-katsubushi snowﬂake-likeなIDジェネレータ stretcher Consul/Surfと連携したデプロイツール rin AWS-S3に出力されたログをRedshiftへインポートするツール mirage Dockerを使ったテスト用環境構築 alphawing Android/iOSアプリの社内配信ツール スライドにちょこちょこ修正いれててGopherくん人形もらうの忘れてたけどもらっておけばよかった。
他の人の発表はこちら。
Goオールスターズ GoオールスターズToggetterまとめ Goオールスターズで登壇してきました - おそらくはそれさえも平凡な日々 Goオールスターズでpackage managementについて話してきました - YAMAGUCHI::weblog Goだけでモバイルアプリを作ろう Goオールスターズ - 考える人、コードを書く人 </description>
    </item>
    <item>
      <title>AnySan::Provider::Slackとape-slackを書いた</title>
      <link>https://shogo82148.github.io/blog/2015/09/28/anysan-provider-slack-and-ape-slack/</link>
      <pubDate>Mon, 28 Sep 2015 22:11:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2015/09/28/anysan-provider-slack-and-ape-slack/</guid>
      <description>先週、今のプロジェクトでのメインのコミュニケーションツールをIRCからSlack切り替えました。 それにともないIRCに済んでいたボットたちもお引越しする必要があったので、 ボットとSlackをつなぐためのライブラリを書きました。
AnySan::Provider::Slack ape-slack Perlとgoのボットが住んでいるのでそれぞれの言語で実装してあります。
AnySan::Provider::Slack PerlのAnySan用のモジュールです。
use AnySan; use AnySan::Provider::Slack; my $slack = slack token =&amp;gt; &amp;#39;YOUR SLACK API TOKEN&amp;#39;, channels =&amp;gt; { &amp;#39;general&amp;#39; =&amp;gt; {}, }; $slack-&amp;gt;send_message(&amp;#39;slack message&amp;#39;, channel =&amp;gt; &amp;#39;C024BE91L&amp;#39;); AnySan-&amp;gt;run; AnySanを使うだけでも便利なんですが、 今のプロジェクトではAnySanを対話形式で使いやすくするようにUnazuSanを使っています。 UnazuSanはIRC前提で書かれていて、AnySan::Provider::Slackをインストールしてもそのままは使えません。
UnazuSanを置き換えるもの面倒なので、イベントの名前を書き換えて投げ直すことで、 SlackのメッセージをIRCに見せかける方法をとっています。 またSlackのOutgoing Webhookで@つきのmentionを捕まえるにもあるように、 Slackのメンションは &amp;lt;@U08DGJVJ7&amp;gt;のような形式になってしまい、UnazuSanは自分へのメッセージとして扱ってくれません。 これをUnazuSanが解釈できる形式に置き換えるのがポイントです。
use 5.010; use warnings; use utf8; use Encode qw/encode_utf8/; use UnazuSan; use AnySan; use AnySan::Provider::Slack; my $unazu_san = UnazuSan-&amp;gt;new( host =&amp;gt; &amp;#39;example.com&amp;#39;, password =&amp;gt; &amp;#39;xxxxxxxxxxx&amp;#39;, enable_ssl =&amp;gt; 1, join_channels =&amp;gt; [qw/arcade/], respond_all =&amp;gt; 1, ); my $slack = slack( token =&amp;gt; &amp;#39;YOUR SLACK TOKEN&amp;#39;, channels =&amp;gt; {}, as_user =&amp;gt; 1, ); AnySan-&amp;gt;register_listener( slack =&amp;gt; { event =&amp;gt; &amp;#39;message&amp;#39;, cb =&amp;gt; sub { my $receive = shift; # fake irc privmsg $receive-&amp;gt;{event} = &amp;#39;privmsg&amp;#39;; $receive-&amp;gt;{message} =~ s/&amp;lt;\@xxxxx&amp;gt;:/unazusan:/; AnySan-&amp;gt;broadcast_message($receive); }, } ); $unazu_san-&amp;gt;on_command( help =&amp;gt; sub { my ($receive, @args) = @_; $receive-&amp;gt;reply(&amp;#39;help &amp;#39;.</description>
    </item>
    <item>
      <title>ISUCON5の予選に参加して惨敗してきた</title>
      <link>https://shogo82148.github.io/blog/2015/09/28/isucon5-qualifying/</link>
      <pubDate>Mon, 28 Sep 2015 06:16:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2015/09/28/isucon5-qualifying/</guid>
      <description>こんにちは、チームぽわわ4 feat. ネコトーストラボです。 ISUCON5の予選に参加してきて見事に惨敗してきました。
お題 「ISUxi」という名前の「高負荷に耐えられるSNSコミュニティサイト」。 日記やコメントの投稿ができて、ホーム画面には「あしあと」「あなたへのコメント」「あなたの友だちの日記エントリ」「あなたの友だちのコメント」が表示されています。 日記にはprivateとpublicの公開範囲があって、これの出し分けも必要です。 やることおおい・・・。
やったこと 〜開始 時間余裕でしょと思ったら全くそんなことなかった
&amp;mdash; ひさいち (@hisaichi5518) 2015年9月25日 時間余裕でしょと思ったら全くそんなことなかった
&amp;mdash; Ichinose Shogo (@shogo82148) 2015年9月25日 5時間で決着をつける https://t.co/AbnnSyHuZ8
&amp;mdash; Ichinose Shogo (@shogo82148) 2015年9月26日 バッテリ残量との戦いがすでに始まっている #ISUCON #アダプタ忘れた
&amp;mdash; Ichinose Shogo (@shogo82148) 2015年9月26日 〜午前中 ソースコードをgit管理下に置くとか準備したあと、ソースコードを眺めてスキーマやクエリの改善ができないかを見てました。 主にインデックスに不足は無いか、ループクエリは無いかを見てみました。 インデックスに関しては必要そうなところにはすでに貼ってあって、これ以上することなさそうな感じ。 ループクエリに関しては、ホーム画面の「あなたの友だちのコメント」の部分で、エントリ情報や、関連するユーザの情報を取ってくるところで見つけたので、JOINに書き換えられないか着手。 しかし、実行計画が大きく変わって極端に遅くなってしまい、なんだこれーってなってました。
〜14時 SQLじゃ無理だってことで、Redisに切り替え。 エントリやコメントをRedisのリストで管理して、 エントリやコメントを投稿したときに友だち全員に配信する形式に変更しました。
ある程度書けてこれで動くのでは！ってとこまで書けたんだけど、 「投稿した時に友だちに配信」形式だと、友だち関係があとから変化するケースに対応できないという気がつく。 いろいろ考えてみたものの、友だち関係が変化した場合は元の実装を使うしか思いつきませんでした。
そしてここでバッテリー切れ・・・
あと3%…(ヽ´ω`)
&amp;mdash; Ichinose Shogo (@shogo82148) 2015年9月26日 〜16時 アダプタを借りることができて延命しました。ありがとうございます！
アダプター貸していただけました。ありがとうございます！m(__)m #isucon
&amp;mdash; Ichinose Shogo (@shogo82148) 2015年9月26日 コメント部分のキャッシュが一応は動いたので、エントリ部分についてもRedisを使ったキャッシュ化を進めてました。 200位スコアはあがるものの劇的な改善にはならず・・・(ヽ´ω`)
〜19時 コメントや日記部分これ以上の改善案を思いつけなかったので、諦めてあしあとの改善に着手。 DATE()関数をGROUP BY句に使っていてインデックスが使えない感じだったので、 カラムにしてインデックスが効くように書き換え。 しかし、ベンチが最後まで通らず、この修正は断念・・・。</description>
    </item>
    <item>
      <title>テストでも:ok_maopy:したい人へ</title>
      <link>https://shogo82148.github.io/blog/2015/09/19/ok-macopy/</link>
      <pubDate>Sat, 19 Sep 2015 23:44:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2015/09/19/ok-macopy/</guid>
      <description>shogo82148/p5-Acme-OkMacopy use strict; use Test::More; use Acme::OkMacopy; ok_macopy &amp;#34;macopy is cool&amp;#34;, &amp;#34;ok_macopy&amp;#34;; done_testing; 様子です pic.twitter.com/sA96GmqKmQ
&amp;mdash; トーカナイザの守護霊 (@mackee_w) 2015年9月17日 :ok_macopy:</description>
    </item>
    <item>
      <title>Go言語でPerlのテストを早くする</title>
      <link>https://shogo82148.github.io/blog/2015/09/19/faster-perl-test-with-go-lang/</link>
      <pubDate>Sat, 19 Sep 2015 21:49:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2015/09/19/faster-perl-test-with-go-lang/</guid>
      <description>Test::mysqld::Multiというモジュールを書いてみたみたいな涙ぐましい努力により5分で終わるようになったテストですが、 プロジェクトのコードも増えて人も増えた影響で、 テスト時間が約7分まで伸び、テストのキューに10個近く並んで順番待ちさせられるという状況になってしまいした。
この状況を解決すべく go-prove というものを書いてみたので、そのご紹介です。
proveが遅い理由 proveがテストの結果を読むところがブロッキングI/Oになっているらしく、そのせいで遅くなっているらしいです。
Perl-Toolchain-Gang/Test-Harness#30 実際に結果読んでいるところはこの辺ですかね。 selectとか使っていてなるべくブロッキングしないような作りにはなっていそうですが、どこかでブロッキングしてしまっているようです。 今のプロジェクトだと32コアのCPUで32並列で動かしてもCPUを100%使い切ることができませんでした。
Shunme ググるとShunmeというプロジェクトでproveの問題を解決しようという試みが行われているようです。
Shunmeというperl用のテストハーネスモジュールを書き始めました magnolia-k/p5-Shunme しかし残念ながらproveのプラグイン機構はサポートしておらず、Formatterの指定オプションもないようです。 今のプロジェクトではプラグインでMySQLを立てたり、JUnitでテスト結果をフォーマットしたりということをしているので、そのままは使えなさそう。 ちょっと改造するにはソースコードの理解が大変そうなので断念。 「(逆に遅くなるときも有ります)」というところも気になりますね・・・。
go-prove いろいろテストの実行方法を調べてはみましたが、どの方法も並行処理に苦労している模様。 テストファイル自体はただのPerlのスクリプトなので、実行して集計する部分は別にPerlにこだわる必要ないのでは？ 並行処理といえば今ならGolangでしょ！ってことでproveのGo実装を書いてみました。
go-prove 例えば以下のようなテストをかいて、
use Test::More; ok &amp;#34;macopy&amp;#34;; done_testing; go-proveコマンドと実行すると、JUnit形式でテスト結果が出力されます。
$ go-prove 2015/09/19 21:45:44 start t/macopy.t 2015/09/19 21:45:44 finish t/macopy.t &amp;lt;testsuites&amp;gt; &amp;lt;testsuite tests=&amp;#34;1&amp;#34; failures=&amp;#34;0&amp;#34; time=&amp;#34;0.225&amp;#34; name=&amp;#34;t_macopy_t&amp;#34;&amp;gt; &amp;lt;properties&amp;gt;&amp;lt;/properties&amp;gt; &amp;lt;testcase classname=&amp;#34;t_macopy_t&amp;#34; name=&amp;#34;&amp;#34; time=&amp;#34;0.225&amp;#34;&amp;gt;&amp;lt;/testcase&amp;gt; &amp;lt;/testsuite&amp;gt; &amp;lt;/testsuites&amp;gt; go-prove -j 32とするとgoroutineを32個生成して、32並列でテストを実行してくれます。 I/Oの処理をGolangのランタイムがよしなにやってくれるので、楽ちんです。
また、今のプロジェクトではApp::Prove::Plugin::MySQLPoolを使っているので、それ相当の機能をgo-prove -plugin mysqldで使えるようにしました。 プラグインを有効にするとMySQLサーバを立ち上げて、その接続先情報をGO_PROVE_MYSQLD環境変数に設定してくれます。
実際にプロジェクトのコードで試してみたところ7分かかっていたテストが4分を切るようになりました。 CPUの使用率も100%近くになって、有効活用できているようです。
まとめ Perl製のproveは並列実行に弱い Goで書きなおしてCPUをフル活用できるようになった 早くはなるものの、既存のテストコードに手を加える必要があってちょっと怖いかなと思ったので、プロジェクトへの組み込みはやってません。 まあ本番環境で走るものではないので、ある程度動くことが確認できたら置き換えてみたいですね。</description>
    </item>
    <item>
      <title>PerlからGolangを呼び出す</title>
      <link>https://shogo82148.github.io/blog/2015/08/30/golang-to-perl-xs-converter/</link>
      <pubDate>Sun, 30 Aug 2015 22:52:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2015/08/30/golang-to-perl-xs-converter/</guid>
      <description>GoのコードをPerlから呼び出せるようにするgo2xsを書いてみました。
使い方 Perlから使いたい関数に以下のようにgo2xsで始まるコメントを付けておきます。
package main //go2xs hello func hello(str string) string { return &amp;#34;Hello &amp;#34; + str } go2xsをgo getして、xsのグルーコードを作成。 その後通常のPerlモジュールと同じ手順でコンパイルします。 Go 1.5から入ったShared Libraryの機能を使っているのでGo 1.5が必要です。
go get https://github.com/shogo82148/go2xs/cli/go2xs go2xs -name hoge hoge.go perl Makefile.PL make あとは普通に呼び出すだけ。
perl -Mblib -Mhoge -e &amp;#39;print hoge::hello(&amp;#34;World&amp;#34;)&amp;#39; Hello World 制限事項 今はまだ、整数・浮動小数点型・文字列しか扱えません。
あとGoのShared Libraryを複数回読み込むことができないっぽい？ (ref. https://github.com/golang/go/issues/11100 ) ので、go2xsを使ったコードを二つ以上useすると死にます。
FFI::Rawを使う方法 go2xsはGoをShared Libraryとしてコンパイルしているだけなので、go2xsを使わなくても頑張れば呼び出すことができます。 Golang で Shared Library を出力する。で紹介されているこちらのコードで試してみます。
package main import ( &amp;#34;C&amp;#34; &amp;#34;log&amp;#34; ) //export fib func fib(n int) int { if (n &amp;lt; 2) { return n } return fib(n - 2) + fib(n - 1) } func init() { log.</description>
    </item>
    <item>
      <title>YAPC::Asia2015へ行ってきた</title>
      <link>https://shogo82148.github.io/blog/2015/08/23/yapc-asia-2015/</link>
      <pubDate>Sun, 23 Aug 2015 00:48:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2015/08/23/yapc-asia-2015/</guid>
      <description>YAPC::Asia2015へ行ってきましました。 Blogを書くまでがYAPCらしいので、簡単に
今年の会場は東京ビッグサイトです。 ▼▼みたいになってるところの中にはじめて潜入してきました。 あの中って会議室なんですね。
去年は毎回立ち見ですごく大変だったけど、今年はかなり会場が広くなったおかけで、 大体席を確保できて楽にトークを聴けました。 しかし会場が東京ビッグサイトであっても、人気トークは立ち見になってしまうのがYAPCのすごいところ・・・。 それでも、前の人の頭でスライドが全く見えないみたいなことはなかったので、広い会場は便利です。
以下、今年見たトークです。
言語開発の現場 はてなブックマークのトピックページの裏側 技術ブログを書くことについて語るときに僕の語ること タイトルが9割 世界展開する大規模ウェブサービスのデプロイを支える技術 全サーバで一斉にgit pullするつらい話だった と、思ったら途中からstretcherの話になった HTTP/2時代のウェブサイト設計 CSSスプライトみたいなファイルを一つにまとめてリクエストを減らす技術はHTTP/2ではオワコンになる 何よりもデータ量を減らすことが大事 【sponsored contents】若手エンジニア達の生存戦略 Google Cloud Platformの謎テクノロジーを掘り下げる 朝寝坊して途中からの参加でした(=_=) Googleのコンテナ技術BorgやGoogleのネットワークについての話 我々はどのように冗長化を失敗したのか MySQLで2億件のシリアルデータと格闘したチューニングの話 データ分析基盤を支える技術 いろいろなツールの比較についてのお話でした なんか色々なオープンソースのソフトウェアを紹介していたけど、「自分で構築しようとするな」とのこと D言語みんな使ってね Parallelism, Concurrency, and Asynchrony in Perl 6 Perl6では並列・並行・非同期処理が簡単に書けるらしいので、その紹介 Promiseやawaitみたいな他の言語で取り入れられている概念がPerlでも使えるらしい 来年Perl6でドローンが飛んでいるのを期待してます Profiling &amp;amp; Optimizing in Go Goのプロファイリングと最適化のデモでした sync.Pool 存在は知っていたけど実際に使っているコード始めて見た気がする。bytes.Bufferの作成に使っていたんだけど、メモリアロケート程度なら同期コストの方が高いのでは〜って思っていた。 改めて見返してみるとPerlについての話がPerl6の並列・並行・非同期処理くらいしかないきがする。 (YAPCのPとは一体)
最後に、呪いを掛けられたのでMySQL5.7の罠についてリンクを貼っておきますね。 http://yoku0825.blogspot.jp/2015/08/yapcasia-mysql-57lt.html Passwordの有効期限のデフォルトがいつの間にか360日になるのは話題になってたのを知っていたけど、他にも罠満載でした。</description>
    </item>
    <item>
      <title>go-webtailってのを書いた</title>
      <link>https://shogo82148.github.io/blog/2015/06/21/go-webtail/</link>
      <pubDate>Sun, 21 Jun 2015 23:28:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2015/06/21/go-webtail/</guid>
      <description>Rubyで書かれたwebtailのGo移植を書いてみました。
go-webtail オリジナルのwebtailはRubyなので、Rubyistではない僕が使おうとするとまずRubyの実行環境からそろえないといけなくてつらい。 ワンバイナリでダウンロードするだけで使えるやつが欲しいなあと常々思っていたのでGolangです。 htmlやjavasctiptの部分もバイナリに含まれているので、インストールも簡単です。
引数無しで実行すると8080ポートで待ち受けて、標準入力から読み込んだ結果をWebsocketで読めるようにしてくれます。
go get github.com/shogo82148/go-webtail/cmd/webtail # インストール echo hogehoge | webtail ファイルもtailできます。
webtail hoge.log fuga.log それぞれ、http://localhost:8080/hoge.logとhttp://localhost:8080/fuga.logで見れるようになります。
mirageと一緒につかう mirageは待ち受けポートを複数設定できます。 (SEE ALSO Dockerで非エンジニアでも開発環境を上げ下げできる、mirageというツールを作りました) その一つをwebtailに割り当てて以下のようにDockerfileに書いておけば、非(サーバサイド)エンジニアでも開発環境のログが見れるようになります。 (見れても理解できるのか？って疑問もあるけど、まあ、全く見れないよりは・・・)
ADD webtail / CMD ./docker_run.sh 2&amp;gt;&amp;amp;1 | /webtail --prefix webtail # ブラウザで見れる代わりにdocker logsで見れなくなるのでこっちのほうがいいかも CMD ./docker_run.sh 2&amp;gt;&amp;amp;1 | tee hoge.log | /webtail --prefix webtail 残念ながらwebsocket対応はしていないので、websoket対応にしたmirageが必要です。 httputil.NewSingleHostReverseProxy互換のrproxyってのを使ったら簡単にwebsocket対応ができて素晴らしいですね。 (mirage自身に手を加える必要があるなら、mirageにこういう機能をつけるべきだったのでは説はある)</description>
    </item>
    <item>
      <title>Test::mysqld::Multiというモジュールを書いてみた</title>
      <link>https://shogo82148.github.io/blog/2015/06/20/test-mysqld-multi/</link>
      <pubDate>Sat, 20 Jun 2015 10:41:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2015/06/20/test-mysqld-multi/</guid>
      <description>Test::mysqldのインスタンスを一度に大量に作りたい人向けに Test::mysqld::Multiというモジュールを書いてみました。
2016/12/22追記: Test::mysqld::MultiはTest::mysqld 0.20 の一部として取り込まれました (p5-Test::mysqld#13)。 APIは少し変わっているので、詳しくはPODを参照してください。 合わせてApp::Prove::Plugin::MySQLPool 0.06 より、 本記事で紹介した高速化が利用できます。
背景 先日Jenkins EC2 Plugin で Spot Instance を使ってテストを回すというのを、 tkuchikiさんにお願いして僕の関わっているプロジェクトでやっていただきました。 CPUのたくさん載ったインスタンスを安く使えるようになったので、 8並列で動いてたテストを24並列で動かせるようになりました。やった3倍速だ！！！ 9分程かかってたテストが7分で終わるようになりました！！！ あれ・・・思ったほど早くなってない・・・。
ログを眺めているとproveコマンドが立ち上がってから、実際にテストが走り始めるまで数分の時間がありました。 App::Prove::Plugin::MySQLPoolを使っているのですが、 ここで時間がかかっているようです。
App::Prove::Plugin::MySQLPoolはテストの並列度分だけMySQLのインスタンスを立ち上げますが、 一個インスタンスを立ち上げたら、それにアクセスできるようになるまでずっと待っているようです。 MySQLの起動に5秒かかるとして24並列で動かしたら2分かかるわけで無視できない長さになります。
作ったもの n個一度に立ち上げて全部にアクセスできるまで待つ実装にすれば速くなるのでは！ってことでTest::mysqld::Multiというのを書いて、 App::Prove::Plugin::MySQLPoolからそれを使うようにしました。 とりあえずtest-mysql-multiブランチにコミットしてあります。 App::Prove::Plugin::MySQLPoolに取り込んでもらうか別のモジュールとして分離するか、後々のことは未定。 今のプロジェクトで使ってみてちょっとの間様子見してみます。 7分かかってたテストが5分程度で終わるようになったので、効果はあるようです。
ちなみに、並列度が24と半端なのはそれ以上並列度を上げても速くならなかったため。 32コアあるマシンなんだけど使い切れてません。 どこにボトルネックがあるんだろうな・・・。
まとめ プロセス一覧にmysqldが24個並ぶの楽しい</description>
    </item>
    <item>
      <title>MeCabをPython3から使う(中間報告)</title>
      <link>https://shogo82148.github.io/blog/2015/06/02/mecab-in-python3/</link>
      <pubDate>Tue, 02 Jun 2015 23:12:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2015/06/02/mecab-in-python3/</guid>
      <description>先日このようなツイートを見かけて、 「Python3になってGCの挙動変わったのかな？」と疑問に思ったので調査してみました。
MeCabをPythonから使う注意点とか - Shogo&amp;#39;s Blog http://t.co/vJnOqZfUd7 @shogo82148さんから python3だと変数に代入しなくても動くのだけど2.xでは留意しないといけない
&amp;mdash; NOKUBI Takatsugu野首貴嗣 (@knok) 2015年6月1日 Python3へのMeCabインストール 手元のPython3.4.3にMeCab Bindingをインストールします。 MeCabの公式(Google Codeサービス停止にともないgithub pageへ移行している模様)から落とせる Python BindingはPython2.x向けのため、setup.pyがそのままでは動きません。 Python3.xでは非互換な文法の変更が入ったので以下のように書き換える必要があります。
diff --git a/setup.py.org b/setup.py index 4486cbb..657945a 100644 --- a/setup.py.org +++ b/setup.py @@ -7,7 +7,7 @@ def cmd1(str): return os.popen(str).readlines()[0][:-1] def cmd2(str): - return string.split (cmd1(str)) + return cmd1(str).split() setup(name = &amp;#34;mecab-python&amp;#34;, version = cmd1(&amp;#34;mecab-config --version&amp;#34;), あとは python setup.py install で入ります。
動かしてみる 以前書いた「MeCabをPythonから使う注意点とか」を見返しながら、 GCされて上手く動かない例 をPython3.4.3で動かしてみます。 文字列の扱いが変わったり、print文の扱いが変わったりしているので、その部分だけ書き換えが必要です。
import MeCab tagger = MeCab.</description>
    </item>
    <item>
      <title>各ブランチの最後にコミットした人を知る</title>
      <link>https://shogo82148.github.io/blog/2015/05/21/branch-committer/</link>
      <pubDate>Thu, 21 May 2015 00:50:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2015/05/21/branch-committer/</guid>
      <description>ブランチが大量にあるので整理したい、けど大人数で開発しているから誰がどのブランチいじってるか分からない、 ということがあったので、出し方のメモ。
githubのbranch一覧も見ればいいじゃん！っていう意見もあると思うんだけど、 「自分のbranch一覧」は見れるんですが「特定のだれかのbranch一覧」が見れない・・・。
git-for-each-refを使うと各ブランチに対していろいろ操作できるようです。 各ブランチの最後にコミットした人一覧を出すには以下のコマンド。
git for-each-ref --format=&amp;#39;%(authordate:short) %(authorname) %(refname)&amp;#39; --sort=-committerdate refs/remotes/origin/ formatは自由にいじれるのでいろいろ遊べます。 例えば、ブランチをたくさん抱え込んでいる人の一覧を表示する例。
git for-each-ref --format=&amp;#34;%(authorname)&amp;#34; refs/remotes/origin/ | sort | uniq -c | sort -nr 参考 git-for-each-ref - Output information on each ref リモートブランチも含め更新日時が新しい順番にソートする ブランチ一覧を更新時刻つきで表示したい場合、gitのfor-each-refが使える。 </description>
    </item>
    <item>
      <title>Go言語でSQLのトレースをする</title>
      <link>https://shogo82148.github.io/blog/2015/05/13/golang-sql-proxy/</link>
      <pubDate>Wed, 13 May 2015 01:22:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2015/05/13/golang-sql-proxy/</guid>
      <description>ぴっぴ先輩が「Go言語で発行したクエリを確認したい」って言ってて、 「MySQL使っているならGeneral Logを吐けばよいのでは？」と返したんだけども、 もっと汎用的な方法はないものかと考えてみました。
Golangの database/sql はどんなDBでも対応できるよう、ドライバを自由に入れ替えることができます。 ドライバは単にdatabase/sql/driverにあるインターフェースを満たしている何かなので、 ユーザが自由に作ることができるし、interfaceを経由して直接呼び出すことも可能です。 この仕組を使って、別のドライバにそのまま渡すプロキシを作れば、ログを吐けるのでは？ということでやってみました。
go-sql-proxy 使い方 まず最初にgo-sql-proxyをドライバとして登録します。
hooks := &amp;amp;proxy.Hooks{ // Hook functions here(Open, Exec, Query, etc.) } sql.Register(&amp;#34;new-proxy-name&amp;#34;, proxy.NewProxy(&amp;amp;another.Driver{}, hooks)) あとは登録したドライバと使って新しいDBハンドラを開くだけです。
db, err := sql.Open(&amp;#34;new-proxy-name&amp;#34;, dataSourceName) このハンドラを使ってクエリ実行を行うと、Hooksで登録した関数が呼び出されます。 元のドライバを直接使った場合と同じように振る舞うので、既存のコードを一切変えること無くHookを差し込めて便利！
トレーサの例 簡単なトレーサを書いてみるとこんな感じ。 発行したSQLのクエリをログに吐き出します。
package proxy import ( &amp;#34;database/sql&amp;#34; &amp;#34;database/sql/driver&amp;#34; &amp;#34;log&amp;#34; &amp;#34;github.com/mattn/go-sqlite3&amp;#34; &amp;#34;github.com/shogo82148/txmanager&amp;#34; ) func main() { sql.Register(&amp;#34;sqlite3-proxy&amp;#34;, NewProxy(&amp;amp;sqlite3.SQLiteDriver{}, &amp;amp;Hooks{ Open: func(conn *Conn) error { log.Println(&amp;#34;Open&amp;#34;) return nil }, Exec: func(stmt *Stmt, args []driver.Value, result driver.Result) error { log.</description>
    </item>
    <item>
      <title>Goのトランザクションマネージャ作った</title>
      <link>https://shogo82148.github.io/blog/2015/05/09/go-txmanager/</link>
      <pubDate>Sat, 09 May 2015 15:17:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2015/05/09/go-txmanager/</guid>
      <description>Golangのdatabase/sqlはBeginとCommitでトランザクションの制御を行うことができます。 クエリの実行が確実に成功するのであれば難しくは無いのですが、 トランザクション内でエラーが発生場合、確実にトランザクションを終了させるのは少し面倒です。 また、ネストができないので、「トランザクションの中から呼び出しても外から呼び出しても、関数の中はトランザクション内」みたいなことができません。 PerlにはDBIx-TransactionManagerというものがあるのですが、 このGolang版が欲しくなったので作ってみました。
txmanager 簡単な使い方 sql.DB をラップした txmanager.DB を使います。 Begin, Commit する代わりに TxBegin, TxCommit を使ってトランザクションを開始・終了すると txmanagerの管理下になります。 確実にトランザクションが終了させるために、トランザクションを開始したらdefer tx.TxFinish()を忘れないように。
import ( &amp;#34;database/sql&amp;#34; &amp;#34;github.com/shogo82148/txmanager&amp;#34; ) func Example(db *sql.DB) { dbm := txmanager.NewDB(db) // トランザクション開始 tx, _ := dbm.TxBegin() defer tx.TxFinish() // INSERTはトランザクションの中で実行される _, err := tx.Exec(&amp;#34;INSERT INTO t1 (id) VALUES(1)&amp;#34;) if err != nil { tx.TxRollback() } tx.TxCommit() } 実際にはこれに加えてエラー処理も必要です。 txmanager.Do を使うと、トランザクションの開始処理・終了をtxmangerがやってくれるので少し楽になります。
import ( &amp;#34;database/sql&amp;#34; &amp;#34;github.com/shogo82148/txmanager&amp;#34; ) func Example(db *sql.</description>
    </item>
    <item>
      <title>Go言語でGraceful Restartをする</title>
      <link>https://shogo82148.github.io/blog/2015/05/03/golang-graceful-restart/</link>
      <pubDate>Sun, 03 May 2015 12:10:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2015/05/03/golang-graceful-restart/</guid>
      <description>とあるHTTPサーバをGolangで立てようって話になったんだけど、 止まると困るので無停止でサーバ再起動をしたい。 PerlにはServer::Starterという有名モジュールがあるんだけど、 Golangはどうなってるの？ってことで調べてみました。
2017-01-22追記: Go1.8以降でGraceful Shutdownがbuild-inになるので、この記事で紹介したライブラリは不要となりました。 詳しくはGo1.8のGraceful Shutdownとgo-gracedownの対応を参照。
gracefulじゃないバージョン Golangの標準ライブラリを使ってHTTPサーバを立ててみる例。 レスポンスが一瞬で終わってしまうとよくわからないので、sleepするhandlerを追加しておきます。
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;log&amp;#34; &amp;#34;net/http&amp;#34; &amp;#34;os&amp;#34; &amp;#34;time&amp;#34; ) var now = time.Now() func main() { log.Printf(&amp;#34;start pid %d\n&amp;#34;, os.Getpid()) s := &amp;amp;http.Server{Addr: &amp;#34;:8080&amp;#34;, Handler: newHandler()} s.ListenAndServe() } // https://github.com/facebookgo/grace/blob/master/gracedemo/demo.go から一部拝借 func newHandler() http.Handler { mux := http.NewServeMux() mux.HandleFunc(&amp;#34;/sleep/&amp;#34;, func(w http.ResponseWriter, r *http.Request) { duration, err := time.ParseDuration(r.FormValue(&amp;#34;duration&amp;#34;)) if err != nil { http.Error(w, err.Error(), 400) return } time.</description>
    </item>
    <item>
      <title>Go言語で画像の減色を行う</title>
      <link>https://shogo82148.github.io/blog/2015/04/25/quantize-image-in-golang/</link>
      <pubDate>Sat, 25 Apr 2015 21:49:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2015/04/25/quantize-image-in-golang/</guid>
      <description>ちょっとGIFアニメを作りたくなって、最近Go触ってるしGoでやってみよう！とやってみたメモ。 ImageMagikでいいじゃん説もあるけど、最終的にツールとして配布したいなってことでGoです。
主に減色まわりについて。
2021-12-07修正
昨今のアレコレ(LOSING LENA)の関係で記事中の Lenna さんの画像をマンドリルに置き換えました。
何はともあれ実装してみる 以前、「ターミナル操作の記録(ttyrec)からGIFアニメを生成するツールを作った」という記事を見たので、 これを参考に実装してみる。
package main import ( &amp;#34;image&amp;#34; &amp;#34;image/color/palette&amp;#34; &amp;#34;image/gif&amp;#34; _ &amp;#34;image/png&amp;#34; &amp;#34;os&amp;#34; ) func main() { reader, err := os.Open(&amp;#34;Mandrill.png&amp;#34;) if err != nil { return } defer reader.Close() img, _, err := image.Decode(reader) if err != nil { return } paletted := image.NewPaletted(img.Bounds(), palette.WebSafe) for y := img.Bounds().Min.Y; y &amp;lt; img.Bounds().Max.Y; y++ { for x := img.Bounds().Min.X; x &amp;lt; img.Bounds().Max.X; x++ { paletted.</description>
    </item>
    <item>
      <title>Go言語でshuffleする話</title>
      <link>https://shogo82148.github.io/blog/2015/04/25/shuffle-in-golang/</link>
      <pubDate>Sat, 25 Apr 2015 18:07:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2015/04/25/shuffle-in-golang/</guid>
      <description>Fisher-Yates shuffleを使ってシャッフルライブラリ作ってみました。
https://github.com/shogo82148/go-shuffle 標準ライブラリのsortと似たような感じで使えます。 デフォルトでintとfloat64とstringのシャッフルに対応していて、 他の型をシャッフルしたい場合はインターフェースを実装してね、って感じです。 実装が簡単なので、インターフェース定義する手間とシャッフルのアルゴリズム自前で書く手間ほとんど一緒ではという気もするけど、 まあライブラリ作成の練習ってことで。
で、ここからが本題。 Fisher-Yates shuffleの名前は以前から知ってたけど、 この前某プロジェクトで以下のようなshuffleの実装を発見。
package main import &amp;#34;math/rand&amp;#34; func shuffle(a []int) { for i := range a { j := rand.Intn(i + 1) a[i], a[j] = a[j], a[i] } } Fisher-Yates shuffleと似ているけど、なにかが違う。 ちゃんとシャッフルされているのか気になったので検証してみました。
検証 n個の数列をシャッフルすることを考えます。 シャッフルの後i番目の要素がj番目に移動する確率を $P_n(i, j)$ と定義します(golangのコードにあわせて0-originで考えます)。
完全にランダムにシャッフルされていれば、 元の数列のどの要素も0からn-1の範囲に一様分布するはずです。 つまり、以下の式がなりたてば「シャッフルされている」と言えそうです。
$$ P_n(i, j) = \frac{1}{n}　(i, j = 0, \dots, n - 1) $$
n=1の場合 n=1の場合は、必ず0番目と0番目の入れ替え(つまり順番変わらない)になります。 上で定義した確率を計算すると$P_1(0, 0) = 1/1$となるので、シャッフルされていると言えます。</description>
    </item>
    <item>
      <title>社内ISUCONにチームぽわわ3.5で参加しました</title>
      <link>https://shogo82148.github.io/blog/2015/04/19/kayac-isucon/</link>
      <pubDate>Sun, 19 Apr 2015 19:12:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2015/04/19/kayac-isucon/</guid>
      <description>木曜日の社内ISUCONにチームぽわわ3.5として参加してきました。 (今年のISUCON本番に4にアップデート予定) さきに結果だけ書いておくと、 1位はfujiwaraさんとacidlemonさんのチーム、 2位はチームぽわわ3.5、 3位はぴっぴ先輩率いるチーム例の青い紐でした。
オムライスと紐を倒したので僕は満足です。 簡単にやったことを書いておきます。
課題内容 Twitterみたいな短文投稿サイトです。 トップページにアクセスすると全ユーザの発言最新100件がみれて、 ログインすると発言したり自分の投稿履歴を確認したりできます。 僕が新卒で入ってきたときはPerlでしたが、今年の参考実装はGolang製です。 (Rubyもあったらしいけど使った人いたのかな)
やったこと 僕自身は、相方になったたいがさんに「こんなことしてみては〜」と言ってみる係をやってました。 具体的な対応としては以下の通りです。
nginxにレスポンス吐かせる Nginxのレスポンスタイムをパーセンタイル値で計測するMunin plugin とかを参考にしてもらって、レスポンスタイムを吐くようにしてもらいました。
ログをテキトウスクリプトで集計したとろこ、トップページの全ユーザの発言最新100件みれるページが重いみたい。 高速化の第一ターゲットをトップページにしぼりました。
MySQLにSlowQuery吐かせる トップページが重いっぽいというのはわかったものの、 どのクエリが重いかまでは分からない(もちろんコード読んでたので検討はついてたけど)ので、 処理に0.1秒以上かかっているクエリを吐くようにしました。
インデックスの追加 既存のコードに触れずにお手軽ってことで、まずはDBにインデックスを張るところから。 workload10で、99583から101033にスコアアップ！ まあ、他のボトルネックを潰していない段階だとこんなもんでしょうね・・・。
ループクエリ・無駄クエリの削除 明らかに無駄クエリっぽいところがあったのでそこを修正しました。
投稿100件取得したあとに、100回ユーザ名の取得処理をしている JOINを使って書き換えました 実行計画が狂って逆に遅くなるという事態に陥ったので、IGNORE INDEXとかして頑張った ユーザの投稿を全取得してるのに、最新1件の情報しか使ってないところ LIMITをつけて制限 全投稿をCOUNTしているところ せっかくGolang使ってるんだから楽しようと、グローバル変数に突っ込んでcount++してみた 「グローバル変数に突っ込んでみた」対策みたいに、下手にアプリサーバで情報を保持すると DBとアプリサーバに差ができてしまうので、実運用では避けるべきテクニックですね。 あとになって考えると、ベンチ回す前にアプリサーバの再起動忘れてたのにベンチ通ってたので、 投稿数数えなくてもよかったのでは・・・。
nginxによる静的ファイルの配信 cssとかjsをGolangでかえしていたので、nginxで返すようにしました。 これで724338から802905(workload:100)にScoreアップ！
画像の縮小 Twitterらしく投稿には100x100程度のサイズのアイコンが表示されるんですが、 元画像が1000x1000程度だったので縮小しました。 ただ、ベンチが画像にアクセスしにこないので、まったくの効果なし。 最終計測では結局元画像に戻しました。 実運用では確かに効果があると思うんですが、まずはログを見て判断しろという教訓ですね。
まとめ あとはworkloadの調整とかやって最終スコアは935519でした。 2位にはなったものの、インデックス追加とかループクエリの削除とか最低限のことが何とか出来たって感じです。 もっと精進します。
tech kayac へのポストまだかな〜</description>
    </item>
    <item>
      <title>Perlで文字列の出現回数を調べる</title>
      <link>https://shogo82148.github.io/blog/2015/04/09/count-substrings-in-perl/</link>
      <pubDate>Thu, 09 Apr 2015 23:28:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2015/04/09/count-substrings-in-perl/</guid>
      <description>Perlで特定の文字列の出現回数を調べたくなって、調べてみたメモ。
ググるとすぐに見つかった。 perlで指定文字列の出現回数を取得する(正規表現)
指定文字列の出現回数は正規表現を使って
$count++ while($str =~ m/$pattern/g);
もしくは
$count = (() = $str =~ m/$pattern/g);
が、一瞬何をやっているのか把握できない・・・。 こういう意味なのかなーって予想はしてみたけど、あってるか一応調査。
whileを使った方法 //g をスカラーコンテキストの中でマッチさせると、 前回マッチした場所を覚えておいてくれて、次のマッチでその場所から検索を再開してくれるらしい。 (Using regular expressions in Perl - perlretut) マッチした場所は pos で取得可能。
my $str = &amp;#34;hoge fuga foo bar&amp;#34;; while ($str =~ m/[a-z]+/g) { say pos $str; } whileを後置にして、ループの回数を数えるようにすれば、最初の方法になる。
ループを使わない方法 これが一番謎だった。
//g をリストコンテキストで評価すると、マッチした文字列がリストになって帰ってくるらしい。 (Quote-Like Operators - perlop)
複数の変数に一括して代入するときに ($foo, $bar) = (1, 2) みたいな書き方をするけど、 () = ... の部分はこれの代入先の変数が一個もないケース。 要するに「リストコンテキストで評価してね」という意味のイディオムみたい。
まとめると、以下のような処理を簡略化して一行にしたのがループを使わない方法みたいです。</description>
    </item>
    <item>
      <title>名前付き引数とオプション引数とオーバーロードを同時に使うとUnityが死ぬ</title>
      <link>https://shogo82148.github.io/blog/2015/03/29/unity-internal-compiler-error/</link>
      <pubDate>Sun, 29 Mar 2015 12:13:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2015/03/29/unity-internal-compiler-error/</guid>
      <description>オーバーロードの優先順位付けが少しおかしくて、 名前付き引数とオプション引数と一緒に使うと死ぬ場合があるというお話。 ぴーちんが昨日言ってたやつ。 いんたーねっつにも乗っけておく。
問題となるのは以下のようなコード。
class MainClass { void Foo (int fuga) { } void Foo (string hoge, int fuga = 10) { } void Bar() { Foo (fuga: 20); } } このコードは以下のような例外を吐いて死ぬ。
Internal compiler error. See the console log for more information. output was: Unhandled Exception: Mono.CSharp.InternalErrorException: Internal error at Mono.CSharp.MethodGroupExpr.IsApplicable (Mono.CSharp.ResolveContext ec, Mono.CSharp.Arguments&amp;amp; arguments, Int32 arg_count, System.Reflection.MethodBase&amp;amp; method, System.Boolean&amp;amp; params_expanded_form) [0x00000] in &amp;lt;filename unknown&amp;gt;:0 at Mono.CSharp.MethodGroupExpr.OverloadResolve (Mono.CSharp.ResolveContext ec, Mono.</description>
    </item>
    <item>
      <title>travisがいつのまにやらcsharpをサポートしていた件</title>
      <link>https://shogo82148.github.io/blog/2015/03/29/travis-supports-csharp/</link>
      <pubDate>Sun, 29 Mar 2015 11:54:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2015/03/29/travis-supports-csharp/</guid>
      <description>いつもテスト実行でお世話になっているtravisさんがC#をサポートしていました。
以前から C#をサポートして欲しいという要望はあったのですが、 2014年12月あたりからついに使えるようになってたみたいです。
以前はC言語のフリをして、設定ファルで頑張ってmonoをインストールする必要があったのですが、
## Travis CI Integration language: c install: - sudo apt-get install mono-devel mono-gmcs script: - xbuild hogehoge.sln 今はlanguageにcsharpを設定して、solutionを指定するだけです。
## Travis CI Integration language: csharp solution: hogehoge.sln MiniMeggagePack もこちらの設定を使うようにしてみました。
nunitを使ってテストする場合は結局sudo apt-get install nunit-consoleする必要があるみたいですが、 複数バージョンのmonoでテストできたりしていい感じです。 ただ、ドキュメントにはmono2.10.8もサポートしているとあるのにmonoのインストールが404で失敗したり、 他のバージョンでも時たまmonoのインストールにコケたり、 3.8.0でnunitのテストが上手く動かなかったり、不安定な感じがしてます。 徐々に改善していくといいなー。
参考 Building a C#, F#, or Visual Basic Project </description>
    </item>
    <item>
      <title>git diffでcsvの差分を見やすく表示する</title>
      <link>https://shogo82148.github.io/blog/2015/03/24/git-diff-csv/</link>
      <pubDate>Tue, 24 Mar 2015 23:08:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2015/03/24/git-diff-csv/</guid>
      <description>ExcelやGoogle Spreadsheetを使って作ったデータをプログラムに取り込むのにcsv形式が便利でよく使っているんですが、 gitで履歴管理をしてもdiffが見づらい・・・。 gitのdiffがかなり自由にカスタマイズできることを知ったので、いろいろいじってみたメモ。
例として、以下のようなcsvファイルを編集することを考えます。
id,name,param_a,param_b,param_c,param_d,param_e 101,hoge,314,159,265,358,979 102,fuga,271,828,182,845,904 一行目は列の見出しになっていて、プログラムからは列番号ではなくparam_dの様に指定する、 という作りになってます。 id: 101の行のparam_dの数値に変更が入った場合、普通のgitだと以下のようになります。
diff --git a/hogehoge.csv b/hogehoge.csv index c8dbd17..37f4ff5 100644 --- a/hogehoge.csv +++ b/hogehoge.csv @@ -1,3 +1,3 @@ id,name,param_a,param_b,param_c,param_d,param_e -101,hoge,314,159,265,358,979 +101,hoge,314,159,265,359,979 102,fuga,271,828,182,845,904 二行目に何か変更があったことはわかりますが、 param_d だとはすぐにはわかりませんね・・・
YAMLに変換して比較する バイナリファイルであっても差分が確認できるよう、 git-diffを実行する前に変換ツールを実行する機能があります。 拡張子がcsvのファイルに対してこの機能が働くように.gitattributesに以下の行を足します。
*.csv diff=csv .git/config に変換ツールの設定を追加します。 key: valueの形式になっていると見やすそうなので、変換先の形式にはyamlを選びました。
[diff &amp;#34;csv&amp;#34;] textconv = csv2yaml ここで指定しているcsv2yamlは自前で用意する必要があります。 インターネット上をさまよえば同名のツールはいくらでもありそうですが、今回は自分でgoを使って書きました。 csv2yaml.goをコンパイルしてパスの通る場所においておきましょう。 csv2yamlは自分のよく使うcsvのフォーマットにあわせて以下のようなカスタマイズをしてあります。
idという名前のキーを必ず最初にする それ以外のキーはアルファベット順にソートする この状態でgit diffを実行すると以下のようになります。
diff --git a/hogehoge.csv b/hogehoge.csv index c8dbd17..37f4ff5 100644 --- a/hogehoge.csv +++ b/hogehoge.csv @@ -3,7 +3,7 @@ param_a: &amp;#34;314&amp;#34; param_b: &amp;#34;159&amp;#34; param_c: &amp;#34;265&amp;#34; - param_d: &amp;#34;358&amp;#34; + param_d: &amp;#34;359&amp;#34; param_e: &amp;#34;979&amp;#34; - id: &amp;#34;102&amp;#34; name: fuga これなら param_d が変更されたとすぐに分かりますね。</description>
    </item>
    <item>
      <title>git で管理しているリポジトリの各ブランチの中身をそれぞれ個別のディレクトリにエクスポートする(git-archive版)</title>
      <link>https://shogo82148.github.io/blog/2015/03/20/git-pack-branch/</link>
      <pubDate>Fri, 20 Mar 2015 18:38:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2015/03/20/git-pack-branch/</guid>
      <description>git で管理しているリポジトリの各ブランチの中身をそれぞれ個別のディレクトリにエクスポートする を読んで、 git-archive を使うともう少しシンプルに書けるんじゃないかと思ってやってみた。
git branch | sed -e &amp;#39;s/^[\* ]*//g&amp;#39; | xargs -n1 -I% sh -c &amp;#39;git archive --prefix=%/ % | tar x&amp;#39; .gitconfig とかでエイリアスを設定しておくといいんじゃないでしょうか
以上</description>
    </item>
    <item>
      <title>map[string]Hoge or map[string]*Hoge ?</title>
      <link>https://shogo82148.github.io/blog/2015/02/22/should-i-use-a-pointer-in-go/</link>
      <pubDate>Sun, 22 Feb 2015 02:14:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2015/02/22/should-i-use-a-pointer-in-go/</guid>
      <description>Go言語でポインタを使うべきか使わないべきか問題。 「ケース・バイ・ケースなので、状況に応じて使い分けましょう！」という結論が出るのは目に見えているので、 具体例について検証してみた結果を書いておきます。
背景 他の人のコードレビューを見ていたら、 レビュアーが「コピーをしないで済むのでstructの受け渡しにはポインタ使ったほうがいいと思います！」とコメントしていて、 そうなのか？と思ったのですがあんまり自信がなかったので検証してみました。 コメントがついていたのは以下のようなコード。
package hoge import ( &amp;#34;strconv&amp;#34; ) type Hoge struct { A int B int C int } func NewHogeMapStruct() map[string]Hoge { m := make(map[string]Hoge) for i := 0; i &amp;lt; 10000; i++ { m[strconv.Itoa(i)] = Hoge{i, i, i} } return m } ポイントは以下の点です。
受け渡すstructはintが3つ程度の小さなもの mapに入れて返す benchmarkを使って検証する ポインタを使わない版と使う版を両方作ってベンチマークをとってみます。
package hoge import ( &amp;#34;strconv&amp;#34; ) type Hoge struct { A int B int C int } // ポインタ使わない版 func NewHogeMapStruct() map[string]Hoge { m := make(map[string]Hoge) for i := 0; i &amp;lt; 10000; i++ { m[strconv.</description>
    </item>
    <item>
      <title>GithubのIRCフックがgollumをサポートしました</title>
      <link>https://shogo82148.github.io/blog/2014/11/15/github-irc-hook-supports-gollum/</link>
      <pubDate>Sat, 15 Nov 2014 22:24:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2014/11/15/github-irc-hook-supports-gollum/</guid>
      <description>GithubのIRCフックがgollum(Wikiページの変更通知)をサポートしました。
最近ぴーちんさんがWikiの編集業に精を出していて、編集の度にIRCに「変更しました！」とポストしてました。 「自動で通知してくれるとうれしいよねー」と話していたら、ある秘密を教えてもらいました。
acidlemon: githubのwiki編集のIRC通知、ここに秘密が隠されています https://github.com/github/github-services/blob/master/lib/services/irc.rb acidlemon: Blameおして黄色い変なアイコンを調べれば何をすれば良いかわかるはず おや・・・何処かで見た黄色いアイコンが・・・
真似してgithub-servicesにプルリクエストをだしてマージしてもらった。 で、さっき対応イベント一覧見てたらgollum増えてる！ マージのときのコメントで「a few days」と言われたので2,3日かかるのかな？と思ってたけど、24時間経たないうちに反映されたよ！ 早い！！
さっそくGithub::Hooks::Managerを使って設定しておきました。 「[project-name] shogo82148 edited wiki page hogehoge」みたいに編集されたページが通知されます。
便利！！！
SEE ALSO github-services github の irc hook に幾つかの event type が追加されました - @soh335 memo GithubのHookについてのまとめとソリューション - おそらくはそれさえも平凡な日々 </description>
    </item>
    <item>
      <title>Gitで作業ディレクトリの変更を破棄したのに差分が出続けて困った話その2</title>
      <link>https://shogo82148.github.io/blog/2014/10/21/git-case-sensitivity/</link>
      <pubDate>Tue, 21 Oct 2014 00:56:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2014/10/21/git-case-sensitivity/</guid>
      <description>先日「Gitで作業ディレクトリの変更を破棄したのに差分が出続けて困った話」と いうのを書きましたが、より強力な敵が現われました。 このときは文字コードが原因で git checkout -- &amp;lt;file&amp;gt; しても差分が残り続けるというもので、git add してコミットし直すことで回避出来ました。 しかし、今度の敵は git checkout -- &amp;lt;file&amp;gt; しても git add &amp;lt;file&amp;gt;しても差分が残り続けます。
なんだ・・・このボスを倒したら新たなラスボスが現れた感・・・
acidlemon先生の手助けにより事無きを得たのですが、 ちょっと不明な点もあったので、その点もあわせてメモを残しておきます。
症状 git checkout -- &amp;lt;file&amp;gt; しても、git add &amp;lt;file&amp;gt; しても、git reset --hard HEAD しても、 何をしても差分が出続ける・・・なんだこいつ・・・
$ git checkout -- AwesomeFeature $ git add . $ git status On branch master Changes not staged for commit: (use &amp;#34;git add &amp;lt;file&amp;gt;...&amp;#34; to update what will be committed) (use &amp;#34;git checkout -- &amp;lt;file&amp;gt;.</description>
    </item>
    <item>
      <title>Redis::Fast 0.13をリリースしました</title>
      <link>https://shogo82148.github.io/blog/2014/10/16/redis-fast-0-dot-13-released/</link>
      <pubDate>Thu, 16 Oct 2014 23:51:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2014/10/16/redis-fast-0-dot-13-released/</guid>
      <description>Redis::Fast 0.13をリリースしました。 主な変更点は以下のとおりです。
passwordオプションの対応 maxclientsに達した場合に、deep recursion することがある問題の修正 トランザクション内で再接続処理が行われる問題の修正 passwordオプションの対応 今更感のある機能ですね。昔は対応してたんです。 対応してたんですが、Sentinel対応のために接続開始周りをごそっと入れ替えて、そのときに間違ってパスワード認証機能を削除しちゃってたっぽいです(・ω&amp;lt;) なんというかごめんなさい。
実際実装してテストしてみると、認証失敗したときにdouble freeで落ちてちょっとハマりました。 hiredisを使う場合はredisAsyncSetConnectCallbackに指定する関数内で、コネクションを切断するような処理(password認証とか)はしないようにしましょう。
maxclientsに達した場合に、deep recursion することがある問題の修正 Redis::Fastでは、接続処理の中で、コネクションに名前をつけたり、パスワード認証したり、その他独自の処理を実行しています。 この処理の途中でも再接続処理が走ってしまい、 再接続処理の中で再接続処理が実行されて、その再接続処理の中で再接続が&amp;hellip; というような無限ループに突入する場合があります。 maxclientsに達した場合、一度コネクションの確立に成功したあとに接続が切られるので、この無限ループに入ってしまうようです。
接続処理中は再接続処理を行わないようにすることで対応しました。
トランザクション内で再接続処理が行われる問題の修正 Redis::Fast 0.07以降、MULTI-EXECコマンドを遣ったトランザクションの中にいるときは再接続処理が行わないようになっています。 その仕組みを作るにあたって、トランザクションの中にいるか外にいるかを表すフラグをコマンド送信前に更新していました。
再接続を禁止する MULTI コマンドを送る 結果を受け取る 必要なコマンド発行を行う 再接続を許可する EXECコマンドを実行する 結果を受け取る しかしこれだと 5 と 6 の間で再接続が起こってしまいます。 EXECコマンドがまだ実行されていないので、ここはまだトランザクションの中ですね。
Redis::Fast 0.13ではフラグの更新はコマンドが成功したときに変更してあります。
MULTIコマンドを送る 結果を受け取る 再接続を禁止する 必要なコマンド発行を行う EXECコマンドを実行する 結果を受け取る 再接続を許可する これでトランザクション中に再接続処理が走ることは無いはずです。</description>
    </item>
    <item>
      <title>gitで作業ディレクトリの変更を破棄したのに差分が出続けて困った話</title>
      <link>https://shogo82148.github.io/blog/2014/10/04/gitattribute-eol-equals-crlf/</link>
      <pubDate>Sat, 04 Oct 2014 15:05:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2014/10/04/gitattribute-eol-equals-crlf/</guid>
      <description>gitで変更した覚えの無いファイルに差分が出ていたので、 作業ディレクトリの変更を破棄したのに、 git statusで差分が出続けて困ったのでメモ。
症状 gitではgit checkout -- &amp;lt;file&amp;gt; ってコマンドを叩くと、 作業ディレクトリの変更を破棄できます。
$ git checkout -- hoge.txt $ git status On branch master Changes not staged for commit: (use &amp;#34;git add &amp;lt;file&amp;gt;...&amp;#34; to update what will be committed) (use &amp;#34;git checkout -- &amp;lt;file&amp;gt;...&amp;#34; to discard changes in working directory) modified: hoge.txt しかし、差分が出続ける&amp;hellip; git checkout -- &amp;lt;file&amp;gt; ならさっきやったよ！
git reset --hard HEAD して全変更を破棄してもダメでした。
原因 .gitattributesに改行コードの指定があったからでした。
*.txt text=auto eol=crlf これが指定されていると、CRLFなファイルをコミットしようとしても、 レポジトリには改行コードがLFで保存されるようになる。
$ cat .</description>
    </item>
    <item>
      <title>ISUCON4にチームぽわわで参加しました</title>
      <link>https://shogo82148.github.io/blog/2014/10/03/isucon-powawa-4/</link>
      <pubDate>Fri, 03 Oct 2014 19:55:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2014/10/03/isucon-powawa-4/</guid>
      <description>遅くなりましたが、ISUCON4のレポートです。 まこぴーとchroneさんとともにチームぽわわで参加し、惨敗してきました。
2014-10-06 追記: 競技中に使ったレポジトリを公開しました。
事前準備 メンバー三人で集まって、去年のnopasteアプリで練習 chroneさんは初参戦なので雰囲気を掴んでもらう Ansibleを使っていこうっていう話になったので、プレイブックを書いて遊んでみる githubにprivate repositoryを予め建てる PayPalに対応してるっぽいので、ログインを試みるも何故か失敗 諦めてクレカ情報を直接入力 どうなってるんですかgithubさん！！！ 競技 10時くらいまで お題確認 サーバのセットアップはchroneさんにお願いしスムーズにできた サーバは人数分準備 僕がコミット＆実行確認をこまめに繰り返すタイプなので、書いたコードはすぐにデプロイしてテストに回したい！！ サーバ一台だとインフラの調整とアプリの確認がかぶって面倒 かといってローカルで同じ環境用意するのも面倒 AMIがあるならそれを使っちゃえ！(って記事を去年見た気がしたので) 密かにUkigumoで自動デプロイする仕組みを作っておいた 書いたコードはすぐにデプロイしてテストに回したい！！ あらかじめukigumo-agentを起動 github-hookを設定してコミットしたら実行 Github::Hooks::Receiverいじってたのはこれやるためだったんだけど、Ukigumoさんで十分でした。便利ですね！！ 去年はサーバに入って作業する人(まこぴー)がかなり忙しそうだったので、なんとか解消したかった お昼くらいまで nginxで静的ファイル配信とかMySQLのクエリ分析とか いっちーさんは早速Redis::Fastに手を付ける みんなもRedis::Fast使ってね！！ あとUkigumoさんのおもり UkigumoとAnsibleのお陰で僕が何もしなくても、まこぴー氏が「nginxで静的ファイル配信したよ！」って言って数分後には確認できる状態になっていて便利 これのおかげでページが真っ白になっているのに気がつく 普通に設定を書き換えるとMIMEの設定がなくなるらしい Ukigumo++ 14時くらいまで chroneさんにMySQLのクエリ改善 COUNT() している部分を一行SELECTだけにする修正とか 一部Redis::Fastに書き換えた版も一応スコアでる アプリが単純すぎてMySQLでもRedisでも大差ないスコア 自分の環境でmy.cnfの調整をしたら、MySQL gone awayしてしまってつらいことに Redisに書き換えたものの、reportのロジックには手をつけてなかったので、効果あるのではと MySQLだけ再起動したらそうなるらしいけど、ansibleのplaybookにアプリの再起動手順も含まれていたので全部再起動かかってたと思うんだけど・・・ 結局サーバごと再起動しました(・ω&amp;lt;) 17時くらいまで workloadを上げるとfailが大量にでて/reportのチェックでコケる問題 トランザクションとかFOR UPDATEの問題かと思ってSQLをいじくりまわす 初期データの考慮を忘れてたことに気が付き、初期化スクリプトを組む 18時まで workload変えてベンチ走らせたり最後のあがき まとめ 初期化大事！！ 社内ISUCONに参加したときも初期化で散々な目にあった Ansibleがあまり効果的に使えてなかった configいじるのが速いので、どうしても直接いじっちゃう 各個人にサーバ用意したけど、微妙に環境が違ってつらい </description>
    </item>
    <item>
      <title>Github::Hooks::ReceiverがX-Hub-Signatureをサポートしました</title>
      <link>https://shogo82148.github.io/blog/2014/09/23/github-hooks-receiver-supports-x-hub-signature/</link>
      <pubDate>Tue, 23 Sep 2014 00:25:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2014/09/23/github-hooks-receiver-supports-x-hub-signature/</guid>
      <description>Github::Hooks::ReceiverにX-Hub-SignatureをサポートするPull Requestを送ったら、 速攻取り込まれ、さらにGithubのコミット権とPAUSEのco-maintパーミッションをもらったというお話。
X-Hub-Signature GithubのWebhookは大変便利なんですが、特に対策をしないままだと 他の人にcurlとかで叩かれてしまう可能性があります。 本来であればIPアドレスで制限をかけるべきなんですが、 iptablesの設定とかよくわからないし・・・と思ってGithubのドキュメントを読んでいたら、 もっとお手軽な方法発見。
Securing your webhooks GithubからのリクエストにはX-Hub-Signatureというのがついていて、 これを使うとPayloadの検証ができるらしい。 Github::Hooks::Receiverは このヘッダを全くみていないようだったのでPull Requestを送ってみた。
Github::Hooks::Receiver 0.02以降で、以下のようにsecretの指定ができるようになります。
use Github::Hooks::Receiver::Declare; my $receiver = receiver { secret &amp;#39;secret1234&amp;#39;; # Webhookの設定画面のsecretの項目と同じものを入力 on push =&amp;gt; sub { # レポジトリにPushされた時の処理とかをゴニョゴニョ書く }; }; my $psgi = $receiver-&amp;gt;to_app; $receiver-&amp;gt;run; これでsecretを知らない人がリクエストを偽装できなくなるので安心です。 secretはエントロピーが高いほうがいいので ruby -rsecurerandom -e &#39;puts SecureRandom.hex(20)&#39; みたいなコマンド使うといいらしいですよ。
String::Compare::ConstantTime Signatureの比較にはRubyのsecure_compareのような関数を 使ったほうがいいらしい。 Github::Hooks::Receiverでは、そのPerl版のString::Compare::ConstantTimeを使ってみた。 ちょっと引数のチェックに甘いところがあって、segmentation fault場合があったので、こちらにもPull Requestを送っておきました。 Github::Hooks::Receiverは使う前にチェックを入れてあるので、現行バージョンでも問題なく動くはず。
String::Compare::ConstantTimeはXSで書かれたモジュールなんですが、 この手のバグが入り込みやすいのでXS難しいですね。
まとめ XS怖い Github::Hooks::Receiverにsecretを指定できるようになったので、IP制限がかけられない場合でも安心 でも、可能であればIP制限もしましょうね XS怖い 追記 IP制限について Songmu先生よりコメントをいただきました。</description>
    </item>
    <item>
      <title>Githubさんにpack exceeds maximum allowed sizeって言われた</title>
      <link>https://shogo82148.github.io/blog/2014/09/13/github-remote-push-pack-size-exceeded/</link>
      <pubDate>Sat, 13 Sep 2014 10:51:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2014/09/13/github-remote-push-pack-size-exceeded/</guid>
      <description>Githubに手元のレポジトリをpushしようとしたら、 「Pushできないよ！！」って言われたときのメモ。
コミット数が17kほどあって、画像とかサイズが比較的大きいファイルがたくさんあるレポジトリを、 一度に全部pushしようとしたら「制限を超えてます」って言われてダメだった。
$ git push origin master Counting objects: 280874, done. Delta compression using up to 4 threads. Compressing objects: 100% (60497/60497), done. remote: fatal: pack exceeds maximum allowed size error: pack-objects died of signal 13 error: failed to push some refs to &amp;#39;git@github.com:***/****.git&amp;#39; ググってみると、おんなじような症状が見つかった。
Github remote push pack size exceeded リモートへのPushはオブジェクトを全部一つにPackしてしまうので、 一度に大量のコミットをPushしようとすると制限に引っかかるらしい。 (そして、サイズを制限する方法はないみたい)
解決策は「2回以上に分けてPushしてね」とのこと
git push remoteB &amp;lt;some previous commit on master&amp;gt;:master ... git push remoteB &amp;lt;some previous commit after the last one&amp;gt;:master git push remoteB master 頑張ってコミットログを遡ってコミットハッシュを調べるのはつらかったので、 打ってあったタグからコミットハッシュを調べてPushした。</description>
    </item>
    <item>
      <title>秘密鍵から公開鍵をつくる</title>
      <link>https://shogo82148.github.io/blog/2014/09/03/get-public-key/</link>
      <pubDate>Wed, 03 Sep 2014 13:40:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2014/09/03/get-public-key/</guid>
      <description>githubに公開鍵を登録しようと思ったけど、 手元に秘密鍵しかなくて困った時のメモ。
ssh-keygenを使うとできます。
# 秘密鍵を読み込んで公開鍵を出力する ssh-keygen -y -f ~/.ssh/id_rsa この公開鍵って登録したっけ？ ってときには以下のコマンドでフィンガープリントを確認できます。
# 公開鍵のフィンガープリントを取得する ssh-keygen -l -f ~/.ssh/id_rsa.pub </description>
    </item>
    <item>
      <title>YAPC::Asia 2014 に行ってきた #yapcasia</title>
      <link>https://shogo82148.github.io/blog/2014/08/31/yapcasia/</link>
      <pubDate>Sun, 31 Aug 2014 16:02:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2014/08/31/yapcasia/</guid>
      <description>YAPC::Asia 2014 に参加してきました。 「ブログに書くまでがYAPC」らしいので、メモ書き。
見たトーク Perl meets Real World 〜ハードウェアと恋に落ちるPerlの使い方〜
デモ中のURLが「localhost」になってたんであれ？って思ったんですが、WebサーバはPC上にあったんですね。RaspberryPi上でPerl動くんじゃなかったんですか！ ネギ振りミククラウド化するって言ってたんで期待してます Go For Perl Mongers
お待たせしました。Perl で BDD を簡単に実践する最高にクールなフレームワークができました
DBIx::Class - what is it and what is it good for?
HashRefInflatorの存在を初めて知りました 今関わってるプロジェクトでDBICのRowObject生成コストが問題になってるんで、後で試してみたいです Scala In Perl Company : Hatena
WHERE狙いのキー、ORDER BY狙いのキー
Get a kick out of CPAN
初心者が Web エンジニアのコミュニティに触れてみて感じたこと - ゆとりエンジニアの成長戦略
突然ITインフラを任された人のための…監視設計入門
半端なPHPDisでPHPerに陰で笑われないためのPerl Monger向け最新PHP事情(5.6対応)
MacにはPHPが最初から入ってるらしいですよ モバイルアプリとAPIのありかたを考える2014
Mobile Application Development for Perl Mongers [ninjinkun x gfx]
シングルトンは嫌だシングルトンは嫌だ そんなにビッグでもないデータ処理手法の話
一日分の解析ならなんとか一台で、でも一ヶ月分となると・・・ってことが多いんでもうちょっと調査して、どれかに手を出してみようかな・・・ typester先生のキーノート</description>
    </item>
    <item>
      <title>PerlのXS中に起きたシグナルの扱い</title>
      <link>https://shogo82148.github.io/blog/2014/07/05/signal-in-xs/</link>
      <pubDate>Sat, 05 Jul 2014 11:56:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2014/07/05/signal-in-xs/</guid>
      <description>Redis::Fast にIssueが来ていたので、 それに関して調査したお話です。
接続タイムアウトすると double free check に引っかかる brpop みたいな長時間ブロックするコマンド中にシグナルが入ると、最初の1回が無視される 前者はC言語つらいって話で頑張って double free になる条件を探せばいいんですが、 後者はシグナル時のPerlやPOSIX APIの挙動を知らなくと解決できなそう。 そういうわけで、主に後者について調べた結果をまとめておきます。
PERL_ASYNC_CHECKってXS中から呼んでもいいの？ 言いたいことは最初に書いとけって偉い人に言われたので、最初にこの記事の結論を。 「よしななタイミングでPERL_ASYNC_CHECKを呼べばいいっぽい」みたいです。 でも、 ** 「PERL_ASYNC_CHECKってXS中から呼んでもいいの？」 ** という点に確証が持ててないので、 識者のご意見を募集してます！
selectの挙動を調べる Redis::FastはRedisからのレスポンスを待つのにLinuxのselect apiを叩いてます。 ファイルとかが読み書き可能になるまで処理をブロックしてくれるいいやつです。 しかし、select が処理をブロックしている間にシグナルを受信すると、うまく処理ができてないらしい。 そこで割り込み発生時の挙動を確認してみます。
困った時のmanページ(select) をちゃんと読めば書いてありますね。
エラーならば -1 を返し、 errno にエラーを示す値が設定される;
EINTR シグナルを受信した。
Redis::Fastはerrnoを特に確認せず、とにかくエラーが発生したらリトライになってたのでダメだったみたいです。 通信にエラーが起きたわけではないので、再接続処理とかみたいな複雑なリトライ処理は必要なく、 単にもう一度selectしなおせば良さそうです。
Perlさんのシグナル処理のタイミング 「割り込みかかったら再度select」っていうふうに修正してみたんですが、 今度はPerlのシグナルハンドラがなかなか呼び出されない！！
use Redis::Fast; $SIG{TERM}= sub { warn &amp;#34;TERM handler called&amp;#34;; }; my $c =-&amp;gt;new(reconnect=&amp;gt;2, every =&amp;gt; 100, server =&amp;gt; &amp;#34;localhost:6379&amp;#34;); $c-&amp;gt;brpop(&amp;#34;a&amp;#34;, 100); # 100秒経ったら諦めて戻ってくる このコードを実行中にSIGTERMを送ると、送った瞬間に&amp;quot;TERM handler called&amp;quot;と表示されて欲しいのですが、 brpopコマンドが終わるまで実行されない……</description>
    </item>
    <item>
      <title>IRCに癒やしボットを入れてみた</title>
      <link>https://shogo82148.github.io/blog/2014/06/04/irc-healing-bot/</link>
      <pubDate>Wed, 04 Jun 2014 07:37:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2014/06/04/irc-healing-bot/</guid>
      <description>別チームがIRCに癒やしボットを入れてたので、自分のチームのチャンネルにも入れてみた。
Instagramに登録する InstagramのDeveloperサイトに開発者として登録します。 Authentication のページを見ながら、Server-side (Explicit) Flow を参考にアクセストークンを取得します。
Instagram APIを叩く https://api.instagram.com/v1/tags/$TAGNAME/media/recent?access_token=YOUR_ACCESS_TOKENを叩くと TAGNAMEに関連する画像の情報がJSONで帰ってくるので、 Perlからこのエンドポイントを叩きます。 IRCとのやりとりにはUnazuSanを使いました。
!/usr/bin/env perl use 5.014; use warnings; use strict; use utf8; use Encode qw/encode_utf8/; use Furl; use JSON; use UnazuSan; sub neko { state $data = undef; state $time = 0; if( !$data || time - $time &amp;gt; 60 * 60) { $time = time; my $furl = Furl-&amp;gt;new; my $res = $furl-&amp;gt;get(&amp;#39;https://api.instagram.com/v1/tags/%E7%8C%AB/media/recent?access_token=YOUR_ACCESS_TOKEN&amp;#39;); my $hash = JSON::decode_json($res-&amp;gt;content); $data = $hash-&amp;gt;{data}; } my $media = $data-&amp;gt;[rand(scalar @$data)]; return $media-&amp;gt;{images}{standard_resolution}{url}; } my $unazu_san; my $NICKNAME = &amp;#39;iyashi&amp;#39;; $unazu_san = UnazuSan-&amp;gt;new( host =&amp;gt; &amp;#39;127.</description>
    </item>
    <item>
      <title>キレイになったコトバとハートを元に戻すツール作った</title>
      <link>https://shogo82148.github.io/blog/2014/06/01/anti-sizukatter/</link>
      <pubDate>Sun, 01 Jun 2014 00:24:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2014/06/01/anti-sizukatter/</guid>
      <description>現実世界にご満足の方消えてなくなってほしいの！！！
しずかったーを使うと個性あふれるコトバを使ってもキレイにしてくれるので とっても便利ですね！ でも、本当は何を言っているのか真意を知りたい・・・。
そんな人のために、キレイになったコトバとハートを元に戻す アンチしずかったー を作りました。
仕組み しずかったーは単純な文字列置換で動いているみたいなので、 対応表を頑張って作りました。 それをMeCab用の辞書に変換し、 Igoを使ってバイナリ辞書に変換、 igo-javascriptでブラ失礼しちゃう上で解析できるようにしました。
既知の問題点 しずかったー前後の文脈関係なく変換しちゃうので、 同音異義語は元に戻らないことがあります。 特にひらがな・カタカナは失敗することが多いです。(「（お昼寝したい）ふわふわ」だとか「ブラ失礼しちゃう」だとか)
あと、マシュマロ的な内緒の言葉はさすがのしずかちゃんでも代替表現が思いつかなかったらしく、 全部ハートになってしまいます。 元に戻せと言う方が頑張ればなんとかできそうなので期待しないでく時代が変わればかっこいい。
まとめ またおもしろいものを作ってしまいましたが、 igo-javascriptのバグを発見できたりしたので、いいのです。
自宅警備員でお時間ある方の皆様、天才だと思ったらぜひおしゃべり広場や「いいね！」広場で共有をお願いします。</description>
    </item>
    <item>
      <title>C#のconditional Attributeのコンパイル結果を見てみる</title>
      <link>https://shogo82148.github.io/blog/2014/05/29/conditional-attribute/</link>
      <pubDate>Thu, 29 May 2014 19:20:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2014/05/29/conditional-attribute/</guid>
      <description>C#で「ある環境では関数の定義ごと消したい」みたいな要件があって、 そういう用途にconditinal attributeが使えるのかなーと話題のあがったので、実際に確認してみました。
結論から言えばできないのですが、せっかく調べたのでメモとして残しておきます。
conditional attribute 「デバッグ時のみにしか実行して欲しくない関数」みたいなものを定義するための機能です。
using System; using System.IO; using System.Diagnostics; namespace ConditionalAttributeTest { class MainClass { public static void Main (string[] args) { Log(&amp;#34;fugu&amp;#34;); } [ConditionalAttribute(&amp;#34;DEBUG&amp;#34;)] public static void Log(string message) { Console.WriteLine(message); } } } こんなふうに書いておくと DEBUG シンボルが定義されている時にだけLogの呼び出しが行われます。
&amp;gt; mcs -d:DEBUG ConditionalAttributeTest.cs &amp;gt; mono ConditionalAttributeTest fugu &amp;gt; mcs ConditionalAttributeTest.cs &amp;gt; mono ConditionalAttributeTest 逆アセンブルしてみる DEBUG付きでコンパイルした結果を逆アセンブルしてみます。
// ...前略 // method line 2 .method public static hidebysig default void Main (string[] args) cil managed { // Method begins at RVA 0x2058 .</description>
    </item>
    <item>
      <title>初期化なしのusing文ってOK？</title>
      <link>https://shogo82148.github.io/blog/2014/05/27/using-statement-without-instantiating/</link>
      <pubDate>Tue, 27 May 2014 13:48:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2014/05/27/using-statement-without-instantiating/</guid>
      <description>C# の using ステートメント、普通は変数の初期化とか new とかをまとめてやるものだと思ってたんですが、 某プロジェクトでusing文をこんな感じで使っているのを見かけました。
var hoge = new Hoge(); using(hoge) { // using( var hoge = new Hoge() ) { ならよく見る ... } 見慣れない書き方だったので、本当にリソース解放が行われているのか不安・・・。 リソース解放が行われているのか調べてみました。
まずは結論 リソース解放自体は行われているので、ちゃんと書いてあれば問題なし しかしエラーをコンパイル時に見つけられない場合があるので非推奨 逆アセンブルして調べてみた コンパイル結果見ればちゃんとリソース解放されているかわかるよね！ ってことでバイナリを逆アセンブルして調べてみました。
サンプルコード 検証に使ったのはこんなコード。
using System; using System.IO; namespace UsingTest { class MainClass { public static void Main (string[] args) { var sr = new StreamReader (&amp;#34;hoge.txt&amp;#34;); Console.WriteLine (&amp;#34;Hoge: {0}&amp;#34;, sr.ReadLine ()); } } } 僕はMac使いに転向したので、Monoを使います。 mcsを使ってコンパイル、monodis ってのを使うとILを見れるらしいです。 Windowsだったら .</description>
    </item>
    <item>
      <title>C# でお手軽にMessagePack解析！</title>
      <link>https://shogo82148.github.io/blog/2014/05/25/mini-message-pack/</link>
      <pubDate>Sun, 25 May 2014 01:38:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2014/05/25/mini-message-pack/</guid>
      <description>MiniMessagePack.csってのを作った。 C#のプロジェクトにファイルひとつ導入するだけで、お手軽にMessagePackの解析ができます。
なんで作ったの？ MiniJSON の置き換えが目的です。 とあるUnityプロジェクトでMB単位のJSONをパースする箇所があってですね・・・ パースにはMiniJSONを使っているのですが、さすがに対象がでかすぎて重たい。 そこでMessagePackへの置き換えを検討してみたわけです。
もちろん C# で動く MessagePack のパーサはすでにあって、 messagepack-cliとかmessagepack-unityとか見つけました。 しかし、Unityのちょっと古いMonoで動かすためにちょっとゴニョゴニョしないといけなかったり、 MiniJSON との互換性を取るためにもゴニョゴニョしないといけなかったり(実際やってみたらキャストが大量に失敗して辛かった・・・)、 今回の用途にはちょっと高機能かなーと思ったので作っちゃいました！
つかいかた デコードする byteの配列を渡すとパースして返してくれます。 配列はList&amp;lt;object&amp;gt;で、マップはDictionary&amp;lt;string, object&amp;gt;になります。
using MiniMessagePack; // it means {&amp;#34;compact&amp;#34;:true,&amp;#34;schema&amp;#34;:0} in JSON var msgpack = new byte[] { 0x82, 0xa7, 0x63, 0x6f, 0x6d, 0x70, 0x61, 0x63, 0x74, 0xc3, 0xa6, 0x73, 0x63, 0x68, 0x65, 0x6d, 0x61, 0x00 }; var packer = new MiniMessagePacker (); object unpacked_data = packer.Unpack (msgpack); /* unpacked_data = new Dictionary&amp;lt;string, object&amp;gt; { { &amp;#34;compact&amp;#34;, true }, { &amp;#34;schema&amp;#34;, 0}, }; */ エンコードする オブジェクトを渡すと MessagePack にエンコードして返してくれます。</description>
    </item>
    <item>
      <title>travis-ciでC&#43;&#43;11のテストをする</title>
      <link>https://shogo82148.github.io/blog/2014/05/22/use-cpp11-in-travis/</link>
      <pubDate>Thu, 22 May 2014 23:34:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2014/05/22/use-cpp11-in-travis/</guid>
      <description>今 C++ を書くなら C++11 だよね！と言うわけでC++11の新機能を使ってコードを書いたので、 travis-cliでテストしたらFAIL。
$ g++ -std=gnu++0x hogehoge.cpp sorry, unimplemented: non-static data member initializers unimplemented・・・だと・・・。
頑張って動かしてみたのでメモ。
autoconf の設定をする autotoolsを使っていたので、 C++11 に対応しているかのチェックを追加しておきます。
ax_cxx_compile_stdcxx_11.m4をダウンロードし、 configure.ac でm4ファイルをダウンロードするようにしておきます。
m4_include([m4/ax_cxx_compile_stdcxx_11.m4]) AX_CXX_COMPILE_STDCXX_11 AC_LANG([C++]) travis.yaml を設定する ぐぐったらstackoverflowでやり方を見つけました。 標準でテストに使われるコンパイラは古いようなので、新しいバージョンのものをインストールするように設定します。
language: cpp compiler: - clang - gcc before_install: # g++4.8.1 - if [ &amp;#34;$CXX&amp;#34; == &amp;#34;g++&amp;#34; ]; then sudo add-apt-repository -y ppa:ubuntu-toolchain-r/test; fi # clang 3.4 - if [ &amp;#34;$CXX&amp;#34; == &amp;#34;clang++&amp;#34; ]; then sudo add-apt-repository -y ppa:h-rayflood/llvm; fi - sudo apt-get update -qq install: # g++4.</description>
    </item>
    <item>
      <title>Google Test を使ってC&#43;&#43;のテストしてみた</title>
      <link>https://shogo82148.github.io/blog/2014/05/18/test-with-google-test/</link>
      <pubDate>Sun, 18 May 2014 21:24:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2014/05/18/test-with-google-test/</guid>
      <description>C++ なライブラリを書こうと思い、C++のテストってどうやるんだろうと調べたメモ。 テストフレームワークとして Google C++ Testing Framework を使用、 コンパイルにはautotoolを使ってtravis-ciでテストするところまでやってみました。
やってみた結果→ cpp-test
Testを書く Google Test の入門ガイドに書いてあったテストをコピペしてきました。
#include &amp;#34;gtest/gtest.h&amp;#34; int Factorial(int n); TEST(FractionTest, hoge) { EXPECT_EQ(1, Factorial(1)); EXPECT_EQ(2, Factorial(2)); EXPECT_EQ(6, Factorial(3)); EXPECT_EQ(40320, Factorial(8)); } テストの対象となる関数はこちら。
// calculate 1 * 2 * 3 * ... * n int Factorial(int n) { if(n == 0) return 1; return n * Factorial(n - 1); } テスト用実行ファイルのビルドをする せっかくならしっかりしたものをつくろうと、Autotoolsを使ってビルドしてみました。 新しめの Autotools (Autoconf&amp;amp;Automake) を使ってみよう を参考に Makefileのひな形を書いていきます。
Google Test と Travice CI で、C言語で書いたライブラリの継続的インテグレーションをしてみた結果 ではGoogle Testをシステムにインストールしていますが、 システムへのインストールは推奨されていないのと、手元で動かすのが面倒だったので Fused Source File を作ってGoogle Testを自分のプロジェクトに同梱しちゃいました。</description>
    </item>
    <item>
      <title>Redis::Fast 0.07 をリリースしました！</title>
      <link>https://shogo82148.github.io/blog/2014/05/17/redis-fast-0-dot-07-released/</link>
      <pubDate>Sat, 17 May 2014 16:27:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2014/05/17/redis-fast-0-dot-07-released/</guid>
      <description>Redis::Fast 0.07 をリリースしました。 現時点での最新バージョンである Redis.pm 1.974 とコンパチブルになります。
主な修正点は以下の通りです
Redis Sentinel 対応 トランザクション内での再接続禁止 再接続にDB選択し直し Redis Sentinel 対応 Redis Sentinel というのは自動フェールオーバーの仕組みらしいです。 (ソースはコピペしたきただけで仕組みはあまり理解していない) どんなものかは本家ドキュメントや実際に検証してみた人の記事をご参照ください。
Redis Sentinel Documentation Redis 2.8 の Sentinel の動きを検証してみた Redis Sentinelを動かしてみた 前から移植作業は進めてたのですが、本家 Redis.pm でもテストがコケたりしてちょっと不安だったのでリリースを見送ってました。 今日 Redis.pm の安定版がリリースされたのでこっちも追従しますよ！！
コネクションを作るときに sentinels を渡すと Redis Sentinel から接続情報を取ってきてくれます。 一緒に reconnect を設定しておいてあげると、Masterに何かあった時に接続情報を再取得→ 自動的に Slave へフェールオーバーしてくれます。
use Redis::Fast; my $redis = Redis::Fast-&amp;gt;new( sentinels =&amp;gt; [ &amp;#39;127.0.0.1:26379&amp;#39; ], service =&amp;gt; &amp;#39;mymaster&amp;#39;, reconnect =&amp;gt; 1, ); トランザクション内での再接続禁止 Redisにも簡単なトランザクション機能があって、 複数の命令を同時に実行することができます。 トランザクション中に再接続が発生するとトランザクションがリセットされてしまうので、 接続前の命令を再投入する必要があるのですが、Redis.</description>
    </item>
    <item>
      <title>Androidのバイナリファイルを解析するgoのライブラリ</title>
      <link>https://shogo82148.github.io/blog/2014/05/07/androidbinary/</link>
      <pubDate>Wed, 07 May 2014 13:29:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2014/05/07/androidbinary/</guid>
      <description>Androidのアプリの実態はzipファイルなのでunzipすれば簡単に中身を見ることができるわけですが、 開いてもバイナリファイルが入っているだけでよくわかりません。 AndroidSDKに付属しているaaptというツールを使えば読めるんだけどインストールが大変で苦しんでいる人がいたので、 お手軽に解析できるgolangのライブラリを書いてみました。
使い方 go getしてくる githubのレポジトリ からダウンロードしてきます。
go get github.com/shogo82148/androidbinary AndroidManifest.xmlを解析する io.ReaderAtインターフェースを満たすオブジェクトをandroidbinary.NewXMLFileに渡すと解析してくれます。
f, _ := os.Open(&amp;#34;AndroidManifest.xml&amp;#34;) xmlFile, _ := androidbinary.NewXMLFile(f) reader := xmlFile.Reader() // reader を読むと普通のXMLファイルとして読める resources.arscを解析する アプリ名などの設定はAndroidManifest.xmlには直接書かれておらず、 リソースファイルに書いてあることがほとんどです(開発者がよほどものぐさでなければ)。 リソースの情報はapk内のresources.arscに書かれているので、 このファイルを読む機能もついてます。
f, _ := os.Open(&amp;#34;resources.arsc&amp;#34;) tableFile, _ := androidbinary.NewTableFile(f) // ID 0x7F040000 に対応するリソースを読む config := &amp;amp;androidbinary.ResTableConfig{} val, _ := tableFile.GetResource(androidbinary.ResId(0x7f040000), config) アプリ名はロケールによって変わったりするので、 configで設定できます。 例えば日本語の名前を取得したい場合はこんな感じ。
// ID 0x7F040000 に対応するリソース(日本語)を読む config := &amp;amp;androidbinary.ResTableConfig{} config.Language[0] = &amp;#39;j&amp;#39; config.Language[1] = &amp;#39;a&amp;#39; val, _ := tableFile.</description>
    </item>
    <item>
      <title>Tweepyの2.3.0が出ました</title>
      <link>https://shogo82148.github.io/blog/2014/04/27/tweepy-2-dot-3-0-released/</link>
      <pubDate>Sun, 27 Apr 2014 21:51:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2014/04/27/tweepy-2-dot-3-0-released/</guid>
      <description>Tweepyの2.3.0が出ました。 「Tweepy が Application-only Authentication に対応します」僕のprも取り込まれていて、 Application-only Authentication が標準で使えるようになりました。 というわけで、早速遊んでみます。
Application-only Authenticationで遊ぶ 使い方は「tweepyでApplication-only Authenticationしてみた」のときとほぼ同じ。 Tweepy本体に取り込んでもらったので、名前空間がちょこっと変わったくらいです。 Consumer Key と Consumer Secretだけ設定すればいいので、簡単に使えます。
#!/usr/bin/env python # -*- coding: utf-8 -*- import tweepy import codecs import sys sys.stdin = codecs.getreader(&amp;#39;utf-8&amp;#39;)(sys.stdin) sys.stdout = codecs.getwriter(&amp;#39;utf-8&amp;#39;)(sys.stdout) CONSUMER_KEY = &amp;#39;YOUR CONSUMER KEY&amp;#39; CONSUMER_SECRET = &amp;#39;YOUR CONSUMER SECRET&amp;#39; def main(): user_id = &amp;#34;JO_RI&amp;#34; auth = tweepy.AppAuthHandler(CONSUMER_KEY, CONSUMER_SECRET) api = tweepy.API(auth) arg = {&amp;#39;id&amp;#39;: user_id, &amp;#39;include_rts&amp;#39;: 1} user_statuses = tweepy.Cursor(api.user_timeline, **arg).</description>
    </item>
    <item>
      <title>Tweepy が Application-only authentication に対応します</title>
      <link>https://shogo82148.github.io/blog/2014/04/18/tweepy-will-application-only-auth/</link>
      <pubDate>Fri, 18 Apr 2014 06:37:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2014/04/18/tweepy-will-application-only-auth/</guid>
      <description>以前 「tweepyでApplication-only Authenticationしてみた」で 書いたTweepyのAuthHandlerを本体に取り込んでもらいました。 リリースタイミングとかよくわかってないですが、次のリリースとかでApplication-only Authenticationを簡単に使えるようになります、たぶん。
(2014-04-27追記) このprを取り込んだTweepy 2.3.0がリリースされました。早速遊んでみたのでこちらもどうぞ&amp;gt;Tweepyの2.3.0が出ました
取り込まれるまでの経緯 「Application-only Authentication 対応しないの？」って質問は去年からあった(tweepy#318) 先日「ここに動くコード載ってるよ」と僕の記事が紹介される 昨日の夕方「コントリビュートしてみない？」とブログやgithub経由で頼まれる やるしか無い！と思って昨日のうちにpr作成 朝起きたら取り込まれてた 日本語なんてマイナーな言語で記事が書いてあっても、読んでくれる人は読んでくれるんですね。 Tweepy は僕も何度か使ったことがあるので Issue とかみて開発状況をチェックしていたんですが、 見覚えのある名前が見えたときはびっくりしました。
ちょっとしたコードでも公開しておくといいことがあるよ、というお話でした。 最近ここも全然更新してないので、もっとアウトプットしていかないと・・・。</description>
    </item>
    <item>
      <title>スパコンで約2時間36分かかったという、5×5の魔方陣の全解列挙を、おねえさんのコンピュータで試す</title>
      <link>https://shogo82148.github.io/blog/2014/03/19/letscount-magic-square/</link>
      <pubDate>Wed, 19 Mar 2014 18:26:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2014/03/19/letscount-magic-square/</guid>
      <description>高校生がスパコンを使って5x5の魔方陣の全解を求めたというニュースをきっかけに、 魔方陣の全解列挙が流行っているようです。
高校生がスーパーコンピュータを使って5×5魔方陣の全解を求めることに成功(筑波大プレスリリース) スパコンで約2時間36分かかったという、5×5の魔方陣の全解列挙を、パソコンで試す（C++） 「全解列挙」「数え上げ」「組み合わせ爆発」・・・そして整然とならんだこのマス目・・・ あのおねえさんを思い出しますね。
と、いうわけで、「おねえさんのコンピュータ」の魔方陣版を作ってみました。
おねえさんのコンピュータ(魔方陣編) 「全解列挙をパソコンで試す」の記事と同じような感じで、頭の悪いコードをずらずらと書いてあります。 以下の様な特徴があります。
マスを埋める順番はスパコンで求めたものをベース ただし、対称な位置にあるマスを優先(反転・回転の検索を早い段階で打ち切るため) asm.js による最適化！ firefoxで特に高速に動作します わかってはいたけど、asm.jsは人間の書くものではない WebWorkerを使った並列計算 実はまだ5x5の計算結果を見てないのですが、 途中までの計算スピードから推測すると十数時間程度で計算が終わるかと・・・。 (Mac Book Air Mid 2012, 4並列)
コンパイルの手間が無いのでお手軽に試せます。 もっと速いマシンでやればすぐに結果がでてくると思うので、みなさんのレポートお待ちしています。</description>
    </item>
    <item>
      <title>githubのタブサイズを変えるChrome拡張を作った</title>
      <link>https://shogo82148.github.io/blog/2014/02/10/github-tab-change/</link>
      <pubDate>Mon, 10 Feb 2014 08:01:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2014/02/10/github-tab-change/</guid>
      <description>にゃんぱすー。 最近 C# のコードを見ることが多くなってきました。 開発はVSやMonoDevelop等のIDEを使っているのですが、 diffの確認程度ならgithub上で行っています。 しかし、github上の表示は崩れて非常に読みづらい・・・。
githubのコードプレビューはタブストップが8文字幅で表示されます。 しかし、有名ドコロのIDEはデフォルトがタブインデント、4文字幅で設定されているので、 どうしても表示が狂ってしまいます。 タブインデントではなくスペースインデントを使えば解決☆ なのですが、スペースインデントの中にタブインデントを混入する場合が多々あるので、僕は疲れました・・・。 混在したときのコードなんて、読めたものじゃないですよ。
そこで、githubのタブサイズを変更する Chrome拡張を作ってみました。 ユーザスタイルシートでもできるんですが、まあ、勉強を兼ねて。
GithubTabChange インストール後、github上のレポジトリを開くと≡みたいなマークがURLの横に表示されます。 それをクリックでタブサイズの設定変更が可能です。 githubのプレビューの一斉設定だけでなく、 レポジトリ単位でタブサイズを切り替えることができます。
アイコンとか設定画面のデザインとかちゃんとしたものを作る気力はなかったので、 皆さんのprをお待ちしております。
GithubTabChange on github (これ作ってるときに、githubのHTMLソースの中にtab-size-8というクラスを見つけたのですが、実はどこかに隠し機能としてあるんですかね？)</description>
    </item>
    <item>
      <title>Redis::Fast 0.06 released</title>
      <link>https://shogo82148.github.io/blog/2014/02/01/redis-fast-0-dot-06-released/</link>
      <pubDate>Sat, 01 Feb 2014 21:36:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2014/02/01/redis-fast-0-dot-06-released/</guid>
      <description>こんにちは、もうすぐ17才と100ヶ月を迎えるいっちーです。 今朝、Redis::Fast 0.06をリリースしました。 主な変更点はメモリーリークの修正と、エラー発生時にSegmentation Faltで落ちる問題の修正です。
メモリーリーク Redis::Fastをサブスクライバーモードで動作させると、メモリを無限に食い続ける問題をついに！ついに！修正しました。 原因は、一言で言ってしまえば、Perlのリファレンスカウントの扱いの勉強不足です・・・。
XSの中でPerlのオブジェクトを作るとき、プログラマが手動でリファレンスカウントを制御する必要があります。 とはいうものの、全てのオブジェクトのリファレンスカウントを制御するのは大変なので、 XSには「揮発性」という考え方があります。 sv_2motralを使って変数を揮発性に設定しておけば、よしななタイミングでオブジェクトを解放してくれます。 gfx先生のブログにもあるように、 オブジェクト作成したら原則sv_2motralをつけるようにすれば、 メモリーリークはほとんどなくなるはずです。
SV * s = newSVpv(&amp;#34;Hello World&amp;#34;,0); // Perl の文字列オブジェクト sv_2motral(s) // 揮発性にすることで、使われなくなったら自動的に解放してくれる この「よしななタイミング」をよく理解していなかったのでリークしてました・・・。 XSからオブジェクトへアクセスできなくなったときでないとオブジェクトを解放できないので、 揮発性のオブジェクトが実際に解放されるのは「XSで書かれた関数が終了してPerlに戻るとき」です。 メッセージを待ち続けるwait_for_messages関数は (タイムアウトをしない限り)ずっと終了しないので、 揮発性のオブジェクトを解放するタイミングが一切なかったのです。
不要になったら解放されるよう、揮発性オブジェクトの有効範囲を明示的に指定しました。
sv_2motral(s); ENTER; SAVETMPS; sv_2motral(v); FREETMPS; LEAVE; // v はココで解放される // s は生き残ってる perlcallとかちゃんとドキュメントを読みましょう &amp;gt; 自分
Segmentation Falt 同期的にコマンドを実行してる最中にSIGNAL等で実行が中断されると、 Segmentation Faltが起こる問題を修正しました。 Redis::Fastは同期モードでコマンドを発行したときでも、 hiredisの非同期モードの機能を使って通信しています。 コマンド実行中にエラーが発生すると、 コールバック関数の呼び出しタイミングが変わってしまい、 メモリの確保・解放のタイミングが狂ってしまっていました。
このバグ、試した環境の中ではUbuntu+Perl5.14でしか再現しませんでした。 他の環境ではたまたま解放後もアクセスできてしまって、 正常に動作してしまっていたようです。 嫌なバグだ・・・。
まとめ C言語でメモリ管理するコードは書くべきでない。</description>
    </item>
    <item>
      <title>Unity Test Tools を使ってみる</title>
      <link>https://shogo82148.github.io/blog/2013/12/21/unity-test-tools/</link>
      <pubDate>Sat, 21 Dec 2013 21:02:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2013/12/21/unity-test-tools/</guid>
      <description>みなさんこんにちは、 最近つらいことばかりで元気のないいっちーです。 少しでもつらいことを解消できないかと Unity Test Tools ってので遊んでみました。
背景 最近あったつらいことのひとつに「Unityで作ってるプロジェクトで、機能拡張したときに間違えて一行消しちゃった！！！」 ってのがあります。
もちろん僕が消したわけじゃないですよ！！！ 僕サーバサイドエンジニアですから、Unityはいじりません。 でも、一応修正コミットは見ていたはずなので、気がつけなかったのは残念です・・・。
どんなにコード書く人が頑張っても、レビューする人が頑張っても、 人間誰だってミスします。 じゃあ、機械にやらせよう！テストコードだ！って話なんですが、 コードカバレッジが低く、今回のつらい事例でもテストがありませんでした。 一部書いてあるテストも、担当者が代わってからなんか怪しい・・・。
あと、自分も手元でテスト動かしてみたのですが、今のテスト面倒・・・。
Unityのコンソールにドバッと流れる テストが全部通ったのか、失敗したのかよくわからない ユニットテストを1項目だけやりたいとかどうやるんだろう 「テストの実行」が「シーンの再生」なので1項目とかどうすんの？ Unity Test Tools つらいので解決方法を探るべくインターネットの海をさまよっていたら Unity Test Tools なるものを発見。
Unity Test Tools Released これを書いてる時点で、3日前のリリースです！ タイムリーだ！！
英語でよくわかんないけど、スクリーンショットはわかりやすくてかっこいいぞ！ 遊んでみよう！
事前準備 まず、Unity Testing Tools をダウンロードしてこよう！ Aseet Store に並んでるので、ダウンロードボタンを押してしばらく待ってれば Unity が勝手に使える状態にしてくれます。
簡単なユニットテストを書いてみる 以前れもんさんが書いた「#24 「Unityでコルーチンも単体テストしよう」 tech.kayac.com Advent Calendar 2012」を Unity Testing Tools でやってみました。
テストの対象はこんな感じのクラスです(短く書けそうな部分があったのでちょっと変えた)。
namespace MyProject { public class Plan { public string Title { get; private set; } public string Text { get; private set; } public Plan(string title, string text) { Title = title; Text = text; } } } れもんさんの記事ではSharpUnitを使っていましたが、 Unity Test Tools は NUnit というテストフレームワークを使うようです。 Plan のテストをNUnitを使って書きなおしてみます。</description>
    </item>
    <item>
      <title>Ark-View-DataTable グラフや表やCSVを簡単に表示したい</title>
      <link>https://shogo82148.github.io/blog/2013/12/07/ark-view-datatable/</link>
      <pubDate>Sat, 07 Dec 2013 20:11:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2013/12/07/ark-view-datatable/</guid>
      <description>こんにちは、最近ログの解析をして遊んでいるいっちーです。 解析の結果は最終的にグラフに出すわけなのですが、 先輩方がよく使っているのもあって Google Charts を使ってます。
で、このグラフを他の人に見せると「その元データCSVでちょうだい！」と言われるんです&amp;hellip;。
もちろんcsvを作るなんてこと簡単にできるんですが、 今のプログラムにはグラフ用のテンプレートとHTMLで表出力するためのテンプレートとCSV用のテンプレートがあって、 グラフが追加されるたびにコピペして微妙に書き直し、 という不毛な作業が発生してしまうのです。つらい。
Ark::View::DataTable 使い回しの効かないテンプレートとかなんのためのテンプレートなのか。 データだけ用意してあとはそれぞれのテンプレートに入れるだけとなるのが理想的だよねー、と思い続けて早数ヶ月。 ようやく重い腰を上げて Ark::View::DataTableってのを書きました。
使い方 Data::Google::Visualization::DataTable をレンダリングするための ArkのViewです。
use Ark::View::DataTable; use Data::Google::Visualization::DataTable; sub gvis :Local { my ($self, $c) = @_; my $datatable = Data::Google::Visualization::DataTable-&amp;gt;new(); $datatable-&amp;gt;add_columns( { id =&amp;gt; &amp;#39;x&amp;#39;, label =&amp;gt; &amp;#34;X&amp;#34;, type =&amp;gt; &amp;#39;number&amp;#39; }, { id =&amp;gt; &amp;#39;y&amp;#39;, label =&amp;gt; &amp;#34;Y&amp;#34;, type =&amp;gt; &amp;#39;number&amp;#39; }, ); # 〜〜〜〜正弦波を描きましょう〜〜〜〜 $datatable-&amp;gt;add_rows( map { [$_, sin(2*3.1415926535*$_/500)] } 1..1000, ); $c-&amp;gt;stash-&amp;gt;{table} = $datatable; $c-&amp;gt;forward( $c-&amp;gt;view( &amp;#39;DataTable&amp;#39; ) ); } Controllerに感じでかくと使えます。 「/gvis?</description>
    </item>
    <item>
      <title>ISUCON3の本戦に参加してきた</title>
      <link>https://shogo82148.github.io/blog/2013/11/09/isucon3/</link>
      <pubDate>Sat, 09 Nov 2013 23:58:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2013/11/09/isucon3/</guid>
      <description>ISUCON3の予選を何とか通過し、 本戦へと参戦してきました。
大会中の方針とか考えたこととかメモ。
お題 Tw○tter&amp;ndash;likeな画像投稿サービス ユーザをフォローできる フォローしたユーザが画像を投稿すると、タイムラインに画像が流れる 公開範囲を全員に公開・フォロワーのみに公開・自分だけに公開から選べる タイムラインはロングポーリングを使ってリアルタイム反映 JSON-APIが用意されていて、Javascriptから叩く 使用できるサーバは5台 画像を扱うお題と聞いて、会場がざわめきました。
MySQLのクエリを見てみる 開始直後、鍵を用意したり、gitのレポジトリを立てたりなんだりした後、 一回目の計測。
topコマンドで走っているプロセスを見ていると、大量のconvertが！！ プロセス名とお題から考えるに、こいつら確実にImage Magickだ・・・。 CPUのほとんどが画像の変換にくわれていたので、 まずは「どこかでキャッシュする」作戦をとることに。 キャッシュするならフロントに近いほうがいいだろうということで、 フロントのnginxでキャッシュする作戦をとることにしました (アクセス制限があるimageは難しいかもしれないけど、全部publicなiconならすぐできるだろうとこのときは思ってました)。
僕はnginxがconvertを駆逐してくれると信じて、MySQLに投げているクエリを中心にPerlのコードを見てました。 役割分担はこんな感じ。
サーバの設定とか(@mackee_wさん) nginxでキャッシュする設定(@9reさん) コード読む、主にMySQLに投げてるクエリとか(@shogo82148) 毎回、ひどいクエリが仕込まれているようなイメージがあったけど、 今回はそこまでひどくない。 クエリチューニング全然効果なさそうと判断して、次の作戦を考えることにしました。
No Image Magick, use Imager! やっぱり一番のボトルネックは画像変換。 nginxでキャッシュするとはいえ軽いほうがいいよね、ということで、 外部プロセスで実行している画像変換をImagerを使ってPerlと同じプロセスでやる作戦。
Imagerに置き換え後ベンチにかけたら、若干スコアが・・・上がった・・・ような・・・？ しかし、画像が変化していると怒られて、スコアは無効。 画像エラーを修正するコストと、スコアの上がり具合を見て、Image Magickのままにすることにしました。
予選でも同じように外部プロセス起動している部分をPerlのライブラリにしたけど、 その時はあっさり動いた。 あれは外部プロセス起動をやめたらスコア上がると思い込ませるための布石だったんだ・・・。 (今回の場合、プロセスの起動より画像の変換のほうが重いので、スコアが上がらないのは当たり前)
いろいろ諦めてPerl側でファイルキャッシュ Imagerはテストを通らず、nginxの設定キャッシュ設定も上手く動作しなかったので、 Perlでファイルキャッシュする方針に変更。 convertの結果にmvで適当な場所にコピーして保存。 これだけでスコアが5倍くらいに跳ね上がり、一気に上位に浮上！ 最初からやっておくべきだった・・・。 もうちょっと早ければ特別賞もらえたかもしれないのに。
rsync! rsync! ファイルキャッシュの作業をやっている間に、@mackee_wさんがnfsの設定をやってくれたので、 アップロードされたファイルやキャッシュファイルの保存先をnfsに変更。
あとは物量作戦でいくしかないだろうということで、rsyncで他のサーバにコピーして調整を繰り返してた。 (並行してnginxのキャッシュ設定にも再チャレンジしてたけど、nginx力が足りなかった)
最終結果 テストFAILした!! No Score!!
なんかこんなの前もあった！
反省点 画像変換をGETでやってたけど、POSTでやったほうがよかったかも nginxについて勉強しよう nfsについて勉強しよう </description>
    </item>
    <item>
      <title>第10回６さいカンファレンス「C言語のポインタ復習」</title>
      <link>https://shogo82148.github.io/blog/2013/10/30/6saiconf-10/</link>
      <pubDate>Wed, 30 Oct 2013 23:42:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2013/10/30/6saiconf-10/</guid>
      <description>気づかぬ間に第10回６さいカンファレンスが開催されていました。
第10回６さいカンファレンス「C言語のポインタ復習」 くいなちゃんSNS上で行われ、ログも残っているのでそちらを参照。 「６さいカンファレンス」のカテゴリから辿れるように記事にしておきます。</description>
    </item>
    <item>
      <title>Redis::NamespaceとRedis::Keyをリリースしました</title>
      <link>https://shogo82148.github.io/blog/2013/10/18/redis-namespace-and-redis-key/</link>
      <pubDate>Fri, 18 Oct 2013 23:21:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2013/10/18/redis-namespace-and-redis-key/</guid>
      <description>こんばんは、最近シングルトン恐怖症になっているいっちーです。 Redis::Namespaceと Redis::Keyをリリースしました。
Redis::Namespace 「Redis::NamespaceのPerl版書いた」 で紹介したモジュールをCPANizeしました。 コマンドのキー名に当たる部分に、自動にプレフィックスをつけてくれる賢い奴です。
use Redis; use Redis::Namespace; my $redis = Redis-&amp;gt;new; my $ns = Redis::Namespace-&amp;gt;new(redis =&amp;gt; $redis, namespace =&amp;gt; &amp;#39;fugu&amp;#39;); $ns-&amp;gt;set(&amp;#39;foo&amp;#39;, &amp;#39;bar&amp;#39;); # $redis-&amp;gt;set(&amp;#39;fugu:foo&amp;#39;, &amp;#39;bar&amp;#39;); my $foo = $ns-&amp;gt;get(&amp;#39;foo&amp;#39;); # my $foo = $redis-&amp;gt;get(&amp;#39;fugu:foo&amp;#39;); RedisにはKey-Value Storeなんてかっこいい名前が付いているけど、 結局はシステム全体で使えるグローバル変数なわけです。 グローバル変数は駆逐するべきです。 いちいちプレフィックスつけて名前の衝突を回避するなんて人間のやることとは思えません。
せめてモジュールローカルとか、クラスローカルとかある程度スコープを制限したいですよね。 Redis::Namespaceを使えば簡単に実現できます。
Redis::Key Redis::Key は Redisのキーの簡単なラッパークラスです。 毎回毎回「接続先のRedisサーバ」と「キーの名前」を指定するのは面倒です。 この2つをセットにして、一つのオブジェクトとして扱うことができます。
use Redis; use Redis::Key; my $redis = Redis-&amp;gt;new; my $key = Redis::Key-&amp;gt;new(redis =&amp;gt; $redis, key =&amp;gt; &amp;#39;hoge&amp;#39;); $key-&amp;gt;set(&amp;#39;fugu&amp;#39;); # $redis-&amp;gt;set(&amp;#39;hoge&amp;#39;, &amp;#39;fuga&amp;#39;); $key-&amp;gt;get; # $redis-&amp;gt;get(&amp;#39;hoge&amp;#39;); 普通に使っている限りは他のキーにアクセスすることができなくなるので、 Redis::Keyのオブジェクトを他のクラスに渡す、とかしても安心です。</description>
    </item>
    <item>
      <title>Redis::Fastをcpanize＆アップデートしました</title>
      <link>https://shogo82148.github.io/blog/2013/10/13/cpanize-redis-fast/</link>
      <pubDate>Sun, 13 Oct 2013 22:39:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2013/10/13/cpanize-redis-fast/</guid>
      <description>Redis::Fastをcpanizeしました！
さらに！早速不具合が見つかったので0.01から0.02にアップデートしました！
CPANに上げてから24時間も経たないうちにpull requestがやってきてCPAN怖いところです。
最初のバージョンである0.01ではタイムアウト処理をちゃんと書いていなかったので、 タイムアウト時に無限ループに陥る不具合がありました。 LinuxとMacとでコネクションを張るのに失敗したときの挙動が違うらしく、 Linuxでは問題なくテストが通るのに、Mac上でのテストでは再現するという面倒バグでした。 さらに面倒なことにRedisの起動のタイミングによって、 Macでもテストが通ったり通らなかったりするという・・・。
主に開発はLinux上でやって、Linux上でしかテスト動かしてなかったので全く気がついていませんでした。 CPANデビューのモジュールがネットワーク関連でXSで少しハードルを上げ過ぎた感じがします。 環境依存な部分が多くてつらいです。
pull requestを送ってくださったsyohexさん、実際にインストールを試みてテストが通らないことを教えてくださったみなさん、ありがとうございました。 アップデートした0.02では、タイムアウト時の処理を少し書きなおして、pull requestも取り込みました。 Mac上でも問題なくテストが通ってインストールできるはずです(きっとね)。</description>
    </item>
    <item>
      <title>ISUCON3の予選に参加してきた</title>
      <link>https://shogo82148.github.io/blog/2013/10/07/isucon3-qualify/</link>
      <pubDate>Mon, 07 Oct 2013 13:03:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2013/10/07/isucon3-qualify/</guid>
      <description>こんにちは、いつの間にかチームぽわわ2のメンバーになっていたいっちーです。
@9reさんと @mackee_wさんとでISUCON3の予選に参加してきました。 主にアプリの書き換えを担当していたので、やったことを残しておきます。 チーム全体の方針とか役割分担とかはまこぴー先生の#isucon 予選でとりあえず10位だったを参照。
お題 gistみたいなWebアプリ。 社内ISUCONのときと似たようなお題ですね。 違いは&amp;hellip;
スターは無い Recent Postsのサイドバーが無い代わりに、ページングしてたどっていけるページがある privateな投稿ができる Markdown形式で投稿できて、表示はHTMLでレンダリングされる 詳しくは、れもんさんの#isucon 2013年予選問題の解説などを参照。
やったこと 一言で言えば、Redisにキャッシュするようにしました。
RecentをRedisのリストで管理 Recentの表示で日付順ソートしているのが重たそうだったので、 公開メモのソート結果をあらかじめRedisのリストに入れておく作戦。
RedisのSORTコマンドが高機能で面白いなーって思ってたので使ってみました。 リストにはメモのIDだけ入れておいて、メモの実体は別のキーを参照する、なんてことができます。 このコマンド、SORTって名前なのに「ソートしない」ってオプションあるところがいいですよね！
MySQLがボトルネックになっているのはこれで解消できました。
bin/markdownを使わない＆レンダリング結果をキャッシュ Markdownのレンダリングを外部コマンド叩いてやっていたので、 Text::Markdown::Discountを使ってレンダリングするように変更。 qx{hoge}って記法はじめて見ました。Perlってやつはいろんな書き方があってよくわからないです。
Markdownの文法って亜種が結構あるので、レンダラをかえるのはちょっと怖かったんですが、全く問題なし。 スコアも3000くらい上がってかなり効果がありました。
さらにレンダリング結果をRedisに入れてキャッシュで+1000くらい。
Recentのレンダリング結果をキャッシュ RecentをRedisでさばくようにしたけど、そもそも100要素もあるHTMLのレンダリングそうとう重いはず。 と、いうわけでここもRedisにキャッシュするようにしました。 公開メモが投稿されたらRecent/:pageのキャッシュを全部削除。 Postのたびにキャッシュクリアされるのであんまり効果ないかなーと思っていたけど、わりと効果あったみたい？ (正確なスコアよく見てなかった)
Redis::Fast!! 残り時間も少なくなり時間内にできることも限られれきたので、最後の最後でRedis::Fastを投入。 これで+1000くらい上がったらしい。(正確なスコアよく見てなかった)
s/Redis/Redis::Fast/ するだけの簡単なお仕事の予定が、githubからのインストールに一番手間取った。 cpanfileにgitのレポジトリを書くと(非公式だけど)インストールできるよ！ってどこかで見た気がするけどなかなかうまく行かず、 自分でgit cloneしてそのディレクトリを指定してインストール(したってまこぴー先生が言ってた)。 (hiredis.hが無い！って叫んでいたから、cartonがsubmoduleをうまく処理できていなかったと予想。 非公式の機能に頼るの良くないね。)
できなかったこと my.cnf？なにそれ美味しいの？ SQLクエリをいじる余裕がなかった Newer/Olderのクエリが残念なのはわかってたけど、結局いじってない Nginxでキャッシュしたい 必要なモジュールは事前にCPANにあげておこう。 まとめ 結果は13192.1点で10位でした。 特に問題がなければこのまま予選突破できるはず・・・！
ところで、魔王軍が学生枠を制圧していて恐ろしいですね。 てか、僕らのチームとの差、500点程度しか無いじゃないですか。怖！！！ これ以上の侵攻はなんとしてでも食い止めなければ。</description>
    </item>
    <item>
      <title>Redis::Fastってモジュールを書いた</title>
      <link>https://shogo82148.github.io/blog/2013/09/28/redis-fast/</link>
      <pubDate>Sat, 28 Sep 2013 00:18:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2013/09/28/redis-fast/</guid>
      <description>hiredisをPerlから扱うためのライブラリとして Redis::hiredisってのがあるけど、 なんだか微妙だって聞いたので自分でPerlのhiredisバインディング書いてみたよ。
https://github.com/shogo82148/Redis-Fast (READMEからRedis.pmをそのまま持ってきたことがまるわかりですね。なんとかしよう。)
使い方 Redis.pmと全く同じインターフェースなので、 そのまま置換できる、はず。
use Redis::Fast; my $redis = Redis::Fast-&amp;gt;new; ### synchronize mode $redis-&amp;gt;set(&amp;#39;hoge&amp;#39;, &amp;#39;piyo&amp;#39;); print $redis-&amp;gt;get(&amp;#39;hoge&amp;#39;); # piyo ### asynchronize mode $redis-&amp;gt;get(&amp;#39;hoge&amp;#39;, sub { my ($result, $error) = @_; print $result; # piyo }); $redis-&amp;gt;wait_all_responses; ### pubsub $redis-&amp;gt;publish(&amp;#39;fugu&amp;#39;, &amp;#39;fuga&amp;#39;); $redis-&amp;gt;subscribe(&amp;#39;fugu&amp;#39;, sub { my ($message, $topic, $subscribed_topic) = @_; }); my $timeout = 10; $redis-&amp;gt;wait_for_messages($timeout) while 1; 以前作った、Redis::Namespaceにもそのまま使えます。
use Redis::Fast; use Redis::Namespace; my $redis = Redis::Fast-&amp;gt;new; my $ns = Redis::Namespace(redis =&amp;gt; $redis, namespace =&amp;gt; &amp;#39;fugu&amp;#39;); $ns-&amp;gt;set(&amp;#39;foo&amp;#39;, &amp;#39;bar&amp;#39;); # $redis-&amp;gt;set(&amp;#39;fugu:foo&amp;#39;, &amp;#39;bar&amp;#39;); my $foo = $ns-&amp;gt;get(&amp;#39;foo&amp;#39;); # my $foo = $redis-&amp;gt;get(&amp;#39;fugu:foo&amp;#39;); ベンチマーク Redis.</description>
    </item>
    <item>
      <title>YAPCへ行ってきた(二日目)</title>
      <link>https://shogo82148.github.io/blog/2013/09/24/yapc-second-day/</link>
      <pubDate>Tue, 24 Sep 2013 07:52:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2013/09/24/yapc-second-day/</guid>
      <description>前回のポストにつづいてYAPC二日目。 聞いたトークの内容を簡単にメモ。
Perl で書く結合テスト 前半はSWET(Software Engineer in Test), TE(Test Engineer)といった業種の話。 後半はテスト手法の分類(誰がする？テストの対象は？方法は？目的は？)について。
スライドはこちら→[Perlで書く結合テスト(]http://ikasama.hateblo.jp/entry/2013/09/22/234521)
これからのPerlプロダクトのかたち 世界一高速な処理系を目指して開発中のgperlと、 その過程でできたツールの紹介。 PerlをLLVMにコンパイルすることがで、高速動作するらしい。 恐ろしい・・・。
Perlは文脈によってトークンの意味が変わってしまうから、トークナイザーを作るのに苦労したとのこと。 (例えば、hoge * fuga とあったときに、*が掛け算なのかブロブなのかわからない) コンパイルの高速化のために文法を工夫しているKuinを見習って欲しいですね。
Emacs実践入門 Perl編 typester先生によるEmacs入門。 PerlCompletion とか helm とか便利そう。 あんまりEmacsカスタマイズできていないので、今度いろいろ入れて遊んでみよう。
Perlでレコメンデーション 登壇者はJubatusのPerlモジュールを書いたりしているらしい。 Jubatus に触ってみようと考え始めてからどれだけの月日が経っただろう・・・ そのうち触ってみます。そのうち。
中規模チャットサービスの運用事例 handlename先生のLobi運用のお話。 今日もcronのメールが迷惑メールフィルタによって闇に葬りさられる悲しいことがあったので、 cronの結果をIRCに飛ばすのとか参考にして何とかしたい。
PhantomJSによる多岐にわたる広告枠の確実な表示テスト 最近の広告はJavascriptを使った遅延読み込みをするので、 ちゃんと表示されるかを静的に判断することができない。 そこで PhantomJS を使ってテストするお話。
フルテストも50msで終わらせたい 〜 FreakOutの取り組み 〜 さすがにフルテストは50msで終わりません。 Ukigumoを使って複数台のサーバでテストを分散実行する取り組みを紹介。
スライド→http://yapcasia.org/2013/talk/show/767463b0-d8fd-11e2-971a-72936aeab6a4
LT 前日にアイデアだけLTで紹介したHTTP::Body::Builderが、別の人の手によって実現されていたのには驚いた。 YAPC恐ろしいところだ・・・。
HUB 懇親会参加しない組だったので、 @sasaplus1 さん, @kazuph さん, @aokcub とHUBで飲み会。 なぜ学内にHUBがあるんだ・・・？
NDS勢やNiigata.pm勢、あと何故かスタッフになっていた @jewel_x12 とも会えて楽しかったです！</description>
    </item>
    <item>
      <title>YAPCへ行ってきた(一日目)</title>
      <link>https://shogo82148.github.io/blog/2013/09/20/yapc-first-day/</link>
      <pubDate>Fri, 20 Sep 2013 21:48:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2013/09/20/yapc-first-day/</guid>
      <description>YAPCの一日目に行ってきたよ。
いまどきのカジュアルなデータベース関連開発 Songmu先生のセッション。
DBIx::Schema::DSL とか GitDDL::Migrator とかの説明や、 DBのスキーマ設計、Redisの紹介なんかがありました。 自分もMySQLやRedisを触る機会が増えて、DB周りでつらい思いをしたことが何度かあるので (外部キー制約でデッドロック起こしたり、無駄なインデックスを必死に削除したり・・・) 大いに参考に参考にさせていただきます。
スライドはこちらから→いまどきのカジュアルなデータベース関連開発
学術分野におけるPerlの活用例 Perlを使ったアンケートの結果と、PerCUDAの紹介。 GPGPUをPerlのコードで実現しようとのお話。
大規模Perl初心者研修を支える技術 :DeNAさんが行った研修の紹介です。 顔覚えられない、 研修生の状況把握が大変、 信頼関係を作るのが大変 といった問題をどうやって解決したかについてのお話がありました。
トークの中で紹介された本何冊か持っているけど、全然読んでない・・・。 というか研修生みんなこれ読んだんですか。
スライドはこちらから→大規模Perl初心者研修を支える技術
mod_perlの展望とApacheの超絶技巧 最近僕の周辺ではあまり Apache の話題を聞かなくなってしまいましたね。 しかし、その知名度の高さからか、他のオープンソースのプロダクトはダメでも、 Apache はOKという案件があるらしい。 「Apache使いました！」っていうために、mod_perl で代替品を作ろう、というお話。 おそろしい・・・。
スライドはこちらから→mod_perlの展望とApacheの超絶技巧
0から学んだポストモダンPerl ルーティングとかORMはWAFにはいらない。 blessで十分！これぞ、ポスト・モダンPerl！とのことでした。
僕もフルスタックのフレームワークより、 各機能が別になっているほうが好きですね。 (でもblessよりはクラスを扱うためのライブラリ使ったほうがよいと思う) まあ、あんまり大規模なWebアプリ作ったこと無いので、 実際に作ってみると意見が変わるかもしれませんが。
スライドはこちらから→0から学んだポストモダンPerl
Dist::Zilla 英語のトークに紛れ込んでしまい、正直良くわからなかった。 英語能力全く向上していない。
モジュールを作成、テスト、アップロード等の管理をするためのプログラムらしい。 Redis::Namespace でつらい思いをしたので、 次モジュールを作りたくなったら試してみよう。
perl な web application のためのテスト情報 スライドの順番が正しいか、今使っているのは本当にマイクなのかのテストが必要ですね！ 335さん自らテストの必要性を教えてくれました。 「なぜテストが必要か」言葉では語らず行動で示す335さんかっこいい。
Test::Deep は Redis::Namespace のテストでも一部使っていますが、これ便利ですね。 Test::More の is_deeply はちょっと不便だと思っていたので、今後も使っていこうと思います。</description>
    </item>
    <item>
      <title>Redis::NamespaceのPerl版書いた</title>
      <link>https://shogo82148.github.io/blog/2013/09/14/redis-namespace-perl/</link>
      <pubDate>Sat, 14 Sep 2013 18:36:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2013/09/14/redis-namespace-perl/</guid>
      <description>Redis のキーにプリフィックスつけるの面倒だなー自動的につけてくれないかなーと思い、 調べてみると Ruby に Redis-Namespace というものがあるらしい。 だけども、Perl では探しても見つからなかったので書いてみた。
レポジトリはこちら→Redis::Namespace
使い方 インターフェースは Perl Redis と一緒。 コマンドのキー名に当たる部分に、自動的にプレフィックスをつけてくれる。
use Redis; use Redis::Namespace; my $redis = Redis-&amp;gt;new; my $ns = Redis::Namespace(redis =&amp;gt; $redis, namespace =&amp;gt; &amp;#39;fugu&amp;#39;); $ns-&amp;gt;set(&amp;#39;foo&amp;#39;, &amp;#39;bar&amp;#39;); # $redis-&amp;gt;set(&amp;#39;fugu:foo&amp;#39;, &amp;#39;bar&amp;#39;); my $foo = $ns-&amp;gt;get(&amp;#39;foo&amp;#39;); # my $foo = $redis-&amp;gt;get(&amp;#39;fugu:foo&amp;#39;); 大体のコマンドには対応したつもり。 別のプレフィックスがついたキーには基本的にアクセスできなくなるので、 キー名の管理が少し楽になると思います。
でも、flushdb とか flushall すると全部消えるので気をつけてね！</description>
    </item>
    <item>
      <title>Perl の Redis ライブラリを調べた</title>
      <link>https://shogo82148.github.io/blog/2013/08/24/perl-redis-libraries/</link>
      <pubDate>Sat, 24 Aug 2013 17:51:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2013/08/24/perl-redis-libraries/</guid>
      <description>最近Redis を使ったコードを書くようになったのですが、 キー名を毎回指定するのがだるいです。 Ruby には redis-objects というのがあって、 Redisのキーをオブジェクトとして扱うことができるようです。 きっと、Perl にも似たようなのあるだろ、って思って調べてみました。
ほしいもの 低レベルなRedisのライブラリはたいていメソッドとRedisのコマンドが一対一対応していて、 次のようなコードになると思います。
$redis-&amp;gt;set(&amp;#39;key-name&amp;#39;, &amp;#39;piyopiyo&amp;#39;); $redis-&amp;gt;get(&amp;#39;key_name&amp;#39;); でも、Redisに何か操作をしたいわけじゃなくて、 Redisのキーに対して操作をしたいので、 次のように書けるべきだと思うんです。
my $key = key($redis, &amp;#39;key-name&amp;#39;); $key-&amp;gt;set(&amp;#39;piyopiyo&amp;#39;); $key-&amp;gt;get(); Redis::Hash, Redis::List Redis::Hashと Redis::Listは Perlのハッシュや配列と同じ操作で Redis にアクセスできるようにするライブラリ。
use utf8; use warnings; use strict; use 5.014; use Redis::Hash; tie my %my_hash, &amp;#39;Redis::Hash&amp;#39;, &amp;#39;hash_prefix&amp;#39;, (server =&amp;gt; &amp;#39;localhost:6379&amp;#39;); # set hash_prefix:hogehoge piyopiyo # set hash_prefix:fugafuga fugufugu $my_hash{hogehoge} = &amp;#39;piyopiyo&amp;#39;; $my_hash{fugafuga} = &amp;#39;fugufugu&amp;#39;; # get hash_prefix:hogehoge piyopiyo say $my_hash{hogehoge}; # piyopiyo # keys hash_prefix:* say join &amp;#39;,&amp;#39;, keys %my_hash; #fugafuga,hogehoge # keys hash_prefix:* # get hash_prefix:fugafuga # get hash_prefix:hogehoge say join &amp;#39;,&amp;#39;, values %my_hash; #fugufugu,piyopiyo # del hash_prefix:hogehoge delete $my_hash{hogehoge}; tie とかよくわかない。 Perl の黒魔術を見た気がしました。</description>
    </item>
    <item>
      <title>ランダム抽出アルゴリズムについて考える</title>
      <link>https://shogo82148.github.io/blog/2013/07/13/random-sample/</link>
      <pubDate>Sat, 13 Jul 2013 22:13:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2013/07/13/random-sample/</guid>
      <description>数日前に社内IRCで「スマートな非復元抽出の方法はないか」と話題になったので、 ランダムサンプリングのアルゴリズムについて調べたり考えたりしてみた。
復元抽出 非復元抽出の手法って調べてもなかなか出てこない・・・。 ひとまず、復元抽出についてまとめてみましょう。
線形検索 一番簡単な実装方法。 どの区間に入るかを線形検索して求める。 選択肢の個数nとすると計算量はO(n)。
use strict; use warnings; use List::Util qw(sum); sub linear_search_method { my $weights = shift; my $num = shift; my $sum = sum @$weights; my $length = @$weights; my @a; for (1..$num) { my $r = rand($sum); for my $i(0..$length-1) { $r -= $weights-&amp;gt;[$i]; if($r &amp;lt; 0) { push @a, $i; last; } } } return \@a; } print join &amp;#39;, &amp;#39;, @{linear_search_method [1,2,3], 100}; バイナリサーチ あらかじめ累積分布表を作っておき、どの区間に入るかをバイナリサーチ。 準備にO(n)、選択に O(log n)かかる。</description>
    </item>
    <item>
      <title>Google Cloud Messaging for Chrome を試してみた</title>
      <link>https://shogo82148.github.io/blog/2013/05/15/google-cloud-messaging-for-chrome/</link>
      <pubDate>Wed, 15 May 2013 11:26:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2013/05/15/google-cloud-messaging-for-chrome/</guid>
      <description>少し前にGoogle Cloud Messaging for Chrome が発表されました。 Android向けに提供されていた Push 通信の仕組みである GCM の Chrome 版です。 ちょうど GCM for Android に触っていたところだったので、 for Chrome のほうも試してみることにしました。
拡張機能の登録 公式ページの説明にしたがって、 APIを使えるようにします。 GCMはOAuth2.0で認証を行うので、
クライアントIDを作る Refresh Token を作る という2ステップが必要。
クライアントIDを作る まず、新しい OAuth2.0 のアプリを作成。 拡張機能をアップロードする予定のGoogleアカウントで以下の作業して Client IDを作ります。
Google APIs Console にログインする ** Create&amp;hellip; ** メニューから新しいプロジェクトを作成 &amp;ldquo;Services&amp;rdquo; を開いて ** Google Cloud Messaging for Chrome API ** を有効化 &amp;ldquo;API Access&amp;rdquo; を開いて ** Create an OAuth 2.0 cliend ID&amp;hellip; ** というボタンをクリック branding information を適当に入力 &amp;ldquo;Application Type&amp;rdquo; という項目の &amp;ldquo;Web application&amp;rdquo; を選択 &amp;ldquo;Create client ID&amp;rdquo;！！ Client ID と Client Secret が表示されるのでメモしておきましょう。</description>
    </item>
    <item>
      <title>RaspberryPiからメールを送る</title>
      <link>https://shogo82148.github.io/blog/2013/05/12/mail-from-raspberrypi/</link>
      <pubDate>Sun, 12 May 2013 21:50:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2013/05/12/mail-from-raspberrypi/</guid>
      <description>RaspberryPi に cron を仕込んで定期実行をやってみようと考えました。 cron の設定自体は crontab -e コマンドを実行すれば簡単にできます。 ただ、これだけだとちゃんと動いているか少し心配なので、 エラーが起きた時に何か通知して欲しい。 普通なら設定ファイルに MAILTO=hogehoge@example.com と書いておくと メールが送られるはずなのですが、 メールサーバが動いてないのでうまくいかない・・・。
そういうわけで、RaspberryPiからメールを送るための設定をしたのでメモ。
MTAをインストールする Raspberry Pi には標準でMTA(Message Transfer Agent)が入ってないようなのでインストール。 今回はPostfixを採用
sudo apt-get install postfix 最初、Sendmailも試してみたんだけど、送信者マスカレードがなぜかうまく行かなったので断念。 後述するように、この設定がないとスパムフィルタに引っかかってしまうのです。
プロバイダのSMTPにリレーしてもらう 実際にメールを送りには以下の条件を満たす必要があるようです。
送信元のドメインを引ける 固定IPからのアクセス 固定IPなんて自前で持ってないし、 cron からのメールは送信元が pi@raspberrypi になってしまいドメインを引けません。 そのためそのままではスパムメールとして扱われてしまい、メールが届きません。
そこで、プロバイダが提供しているSMTPサーバにメールをリレーしてもらいます。 /etc/postfix/main.cfに以下の行を追加します。
sender_canonical_maps = regexp:/etc/postfix/canonical relayhost = [smtp.example.com]:587 smtp_sasl_auth_enable = yes smtp_sasl_password_maps = hash:/etc/postfix/relay_password smtp_sasl_security_options = noanonymous プロバイダにリレーしてもらうには SMTP-Auth で認証する必要があるので、 ユーザ名とパスワードを設定しておきます。
smtp.example.com hogehoge:your-password postmapコマンドを使って、Postfixから扱える形式に変換します。
$ postmap hash:/etc/postfix/relay_password さらに、エンベロープのFromがプロバイダから提供されたメールアドレスでないと メールをリレーしてくれないので、 すべてのメールのFromをすべて書き換えるよう設定します。</description>
    </item>
    <item>
      <title>RaspberryPiでhttps通信が失敗するのを何とかする</title>
      <link>https://shogo82148.github.io/blog/2013/05/12/raspberry-pi-https-connection/</link>
      <pubDate>Sun, 12 May 2013 16:48:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2013/05/12/raspberry-pi-https-connection/</guid>
      <description>RaspberryPiをネットつないでみたので、PythonからいろんなURLを叩いて遊んでいたんだけど、 一部のhttps通信が Connection Timed Out で失敗しちゃう。 プログラムの問題かと思ったけど、curlで叩いてもやっぱりタイムアウト。 Macで全く同じ事をするとうまくいく・・・。 いろいろ調べて、何とかしてみたお話。
原因 接続先がTLSv1にしか対応していないのにSSLv3でアクセスしようとしていたことが問題だったらしい。 明示的にTLSv1を使うように指定して curl を叩いてみるとうまくいった。
$ curl --tlsv3 https://hogehoge なぜRaspberryPiではダメで Macでは成功するのか、という根本的な原因はよくわからなかった。 SSLv3に対応していないなら自動的にフォールバックしてくれてもよさそうなものだけど、 なぜうまく行かないんだろう・・・？
Pythonでの対処 PythonでもTLSv3を使えばうまくいくはずなんだけど、 暗号化方式を指定するオプションは見当たらない(2.7での話)。 どうやら標準ライブラリのファイルを直接書き換えるか、 実行時に中身を入れ替えるかしないとできないみたいだ。 この問題普通のUbuntuでも起こるらしく、 そのフォーラムで置き換えコードを見つけた。
import httplib from httplib import HTTPConnection, HTTPS_PORT import ssl class HTTPSConnection(HTTPConnection): &amp;#34;This class allows communication via SSL.&amp;#34; default_port = HTTPS_PORT def __init__(self, host, port=None, key_file=None, cert_file=None, strict=None, timeout=socket._GLOBAL_DEFAULT_TIMEOUT, source_address=None): HTTPConnection.__init__(self, host, port, strict, timeout, source_address) self.key_file = key_file self.cert_file = cert_file def connect(self): &amp;#34;Connect to a host on a given (SSL) port.</description>
    </item>
    <item>
      <title>tweepyでApplication-only authenticationしてみた</title>
      <link>https://shogo82148.github.io/blog/2013/05/09/application-only-authentication-with-tweepy/</link>
      <pubDate>Thu, 09 May 2013 23:29:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2013/05/09/application-only-authentication-with-tweepy/</guid>
      <description>Twitter の API リファレンスを久しぶりに見たら、 Application-only authenticationとかいうのを発見。 特定のユーザと関連付けられない代わりに、普通に認証するより制限が緩いみたい。 3月に追加されてたらしい。
知らなかった・・・。 最近API叩いてなかったからな・・・。
便利そうなので、Python用のTwitterライブラリであるTweepyから使ってみた。
AuthHandler Tweepy用のAuthHandler。 認証部分は TwitterのApplication-only authenticationを試してみた のページからほぼコピペ。
import tweepy import urllib import urllib2 import base64 import json class AppAuthHandler(tweepy.auth.AuthHandler): TOKEN_URL = &amp;#39;https://api.twitter.com/oauth2/token&amp;#39; def __init__(self, consumer_key, consumer_secret): token_credential = urllib.quote(consumer_key) + &amp;#39;:&amp;#39; + urllib.quote(consumer_secret) credential = base64.b64encode(token_credential) value = {&amp;#39;grant_type&amp;#39;: &amp;#39;client_credentials&amp;#39;} data = urllib.urlencode(value) req = urllib2.Request(self.TOKEN_URL) req.add_header(&amp;#39;Authorization&amp;#39;, &amp;#39;Basic &amp;#39; + credential) req.add_header(&amp;#39;Content-Type&amp;#39;, &amp;#39;application/x-www-form-urlencoded;charset=UTF-8&amp;#39;) response = urllib2.urlopen(req, data) json_response = json.loads(response.read()) self.</description>
    </item>
    <item>
      <title>社内ISUCONに参加した</title>
      <link>https://shogo82148.github.io/blog/2013/04/13/isucon/</link>
      <pubDate>Sat, 13 Apr 2013 17:17:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2013/04/13/isucon/</guid>
      <description>先日、社内 ISUCON(良い感じにスピードアップコンテスト) に参加してきました。 Livedoorで開催されたISUCONのミニ版で、 Webアプリをひたすら高速化するコンテストです。
高速化の対象はNoPaste。 テキストを共有するWebアプリです。 テキストの投稿・投稿の閲覧・投稿にスターをつける の3つの動作ができる簡単なアプリです。
新卒 vs 先輩ということで、それぞれ4チームが参戦。 チームは二人一組で僕は @Maco_Tasu くんと一緒でした。 @Maco_Tasuくんのブログも参照。
Recent Posts 生成クエリの高速化 高速化前のアプリのベンチマークの結果、スコアは77(≒1分あたりの捌いたリクエスト数)。 何も考えずにデータベースの全行を舐めるクエリを書いていたので、まあ、妥当なスコアですね。
重いのはサイドバーに表示される Recent Posts。 Recent Posts は表示回数が多く、 複数の行、複数のテーブルへのアクセスが発生するため、 きっとここがボトルネックになるだろうと予測してました。 そこで最初にこの部分を解決することにしました。
とりあえずインデックスを張る クエリを修正してアクセスする行を最小化 スターのカウントした結果をテーブルに格納 オリジナルのデータベース構成では、スターした回数だけ行が増えてました 必要なのは投稿ごとのスター数なので、独立したテーブルに この時点で早くも重大なバグを組み込んでしまったことに、この時はまだ気がついていなかった・・・ nginxによる静的ファイル配信 僕がクエリをいじっている間、@Maco_Tasuくんには サーバの設定をお願いしました。
ログの様子を眺めてみると、cssとかjsとかの静的ファイルが結構な量ありました。 最初のスクリプトでは静的ファイルの配信もアプリでやってたので、 これをnginxを使って配信するように変更。 その他のリクエストはリバースプロキシを設定してアプリに投げます。
Starlet と Server::Starter リバースプロキシを設定する際にアプリの起動スクリプトを編集する必要があったので、 ついでに起動時の設定を色々変更。 PSGI実行のStarletというのが速いと聞いてこれを採用。 Starlet使い方調べてたら、Server::Starterを使った例が出てきたので一緒にインストール。 ワーカーの数の数は適当に10個にしました。
ここで2回目のベンチマークを実行。 スコア1300程度で、その時点のトップ！
SSIを使ったサイドバーの埋め込み お昼を挟んで、さらなる高速化を目指します。
topコマンドを眺めているとPerlで作ったアプリの負荷が大きい。 ほとんどテンプレートエンジンを呼び出しているだけの単純なコードなので、 ここを高速化するのは面倒くさい。 そこで、前段のnginxでキャッシュする作戦を採用することにしました。
もっともキャッシュが有効なのはサイドバーだろうと予想。 クエリの最適化をしたとは言え、サイドバーには100件程度の投稿が表示されるので、 クエリ実行にもレンダリングにも時間がかかるはず。 さらにすべてのページでサイドバーは共有できるので、大幅な高速化が期待できるはずです。
過去のISUCONの記事にSSI(Server Side Include)を使った例があったのを思い出し、 これを使ってサイドバーのみキャッシュ、nginx内でサイドバーを埋め込むように。
僕が SSIのタグ埋め込み、 @Maco_Tasu くんにnginxのキャッシュ設定を行ってもらうという役割分担で作業を再開しました。</description>
    </item>
    <item>
      <title>出、出〜〜〜〜wwww emacsをふたつ以上実行奴〜〜〜〜www(emacsclient編)</title>
      <link>https://shogo82148.github.io/blog/2013/03/05/emacsclient/</link>
      <pubDate>Tue, 05 Mar 2013 12:35:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2013/03/05/emacsclient/</guid>
      <description>emacsを使って編集している最中にシェル操作をしたくなって， C-z を押してバックグラウンドにしてシェル操作． その後，emacsに戻ってくるには fg コマンドを打つ必要があるんだけど， 間違えてもう一回 emacs を新しく立ち上げるというミスを何度もやってしまう・・・．
これに対し，猫型さんが複数起動しようとすると警告を出してくれるようにしてくれました． (出、出〜〜〜〜wwww emacsをふたつ以上実行奴〜〜〜〜www)
警告してくれるのはありがたいんだけど， これだとシェル操作中に別のファイルの編集をしたいと思っても，警告が返ってくるだけ． emacs をフォアグラウンドに出して，ファイルの指定をやり直さなきゃいけない． 僕はファイルの編集をしたいんだ！！ わかったから早く編集させろ！！！
emacsclient 単なる警告じゃなくて， 「裏で動いていたemacsを復帰させ，新しいバッファを開く」 ところまで自動的にやってくれると嬉しいですね．
まず，emacs をデーモンモードで起動しておきます．
emacs --daemon emacsclient コマンドでファイルを開くと， emacs デーモンさんが新しいバッファで開いてくれます． オプションに -nw を指定しておくと現在の端末で閲覧編集することができます．
emacsclient -nw hoge.txt 終了するにはC-x 5 0． C-x C-cでも終了できるけど， デーモンにバッファが残ってしまうみたい．
aオプションでemacs デーモンが起動してないときに 編集に使うエディタを指定できる． 空っぽにしておくと，emacs をデーモンモードで起動してくれる．
emacsclient -nw -a &amp;#39;&amp;#39; hoge.txt emacs デーモンを終了させるのは以下のコマンド．
emacsclient -e &amp;#39;(kill-emacs)&amp;#39; emacsclient に対して alias を作っておけば， 複数起動かどうか意識せずに使えますね．
alias emacs=&amp;#39;emacsclient -nw -a &amp;#34;&amp;#34;&amp;#39; 参考 emacsclientを使おう emacsclient の使い方の種類と、便利な使い方 emacsclientを終了する方法 </description>
    </item>
    <item>
      <title>LaTeX2EPUBで電子書籍を作ってみる</title>
      <link>https://shogo82148.github.io/blog/2013/03/02/latex2epub/</link>
      <pubDate>Sat, 02 Mar 2013 16:20:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2013/03/02/latex2epub/</guid>
      <description>LaTeXで書いた文章を電子書籍にしたくなったので， LaTeX2EPUBを使ってみました．
LaTeX2EPUBはLaTeXMLとReVIEWに依存しているようなので， それぞれインストールしていきます． あと，数式の変換とかにLaTeXを使っているので別途用意する必要あり． いろんなディストリビューションがあるけど， ここでは TeX Live 2012 を使いました．
LaTeXML のインストール LaTeXMLはLaTeXの文章をXML形式に変換するソフト． そこからさらにXSLTを使ってXHTMLへ変換できる． ドキュメントに従って 依存するライブラリをインストール．
perl -MCPAN -e shell cpan&amp;gt; install DB_File, Parse::RecDescent, File::Which cpan&amp;gt; install XML::LibXML, XML::LibXSLT ドキュメントが少し古いらしく，これだけでは不十分だった． 追加でParse::RecDescentとImage::Magickもインストールしておく．
cpan&amp;gt; install Parse::RecDescent cpan&amp;gt; quit yum install ImageMagick-perl 後はソースを取ってきてmakeするだけ． 現時点での最新版0.7.0をインストールした．
wget http://dlmf.nist.gov/LaTeXML/releases/LaTeXML-0.7.0.tar.gz tar zxvf LaTeXML-0.7.0.tar.gz cd LaTeXML-0.7.0 perl Makefile.PL make make test make install ReVIEW のインストール ReVIEWは簡単なマークアップ言語で書かれたテキストから PDFやEPUBを作成するためのスクリプトです． このなかのEPUB作成機能に依存しているようなのでインストールしておきます． ReVIEWはgemで簡単インストール．
gem install review LaTeX2EPUB のインストール LaTeX2EPUB本体をインストール． 本家の日本語化対応が少し不十分だったので 改造版を上げといた． これをダウンロードしてパスの通ったところに置けばインストール完了．</description>
    </item>
    <item>
      <title>AWSをはじめてみた</title>
      <link>https://shogo82148.github.io/blog/2013/02/21/starting-aws/</link>
      <pubDate>Thu, 21 Feb 2013 01:01:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2013/02/21/starting-aws/</guid>
      <description>Amazon Web Services(AWS)でEC2でも使ってみようかと， 登録を試みました．
が，しかし，電話認証の段階で何度やってもシステムエラー・・・．
An Error Has Occured システムエラー 電話確認要求を処理できません。後でもう一度お試しください。
こういう時は，とりあえずエラーメッセージでググってみましょう． なんだかそれっぽい記事が見つかりました．
AWSアカウント開設で”電話確認要求を処理できません。後でもう一度お試しください。”と怒られ続けた Amazon Developer Forums: 電話による身元確認でエラー発生 どうやら，登録時に入力した「支払い方法」と「アドレス情報」が正しく反映されていないことが原因のようです．
アカウントの管理 画面から，「支払い方法」を選び，クレジットカードや請求先を記入します． アドレス情報は「登録内容の変更」から変更可能です．
AWSをはじめてみたというエントリだけど， 実はじょりぼっとの「買うべき？」機能を実装するために， AWSのProduct Advertising APIを前々から使っていたのでした． このAPI使うだけなら支払い方法などの入力は不要だったので， 必要最低限の情報しか入力していませんでした． 住所とかの入力もしなかったのですが， 自分が確認したときはアドレス情報の国設定が何故かアメリカになってました． これのせいですかね？
詳しい原因はよくわかりませんが，とりあえず，「支払い方法」と「登録内容の変更」の全項目を正しく入力したら認証が出来ました． 1年は無料でいろいろ遊べるらしいので，何か動かして遊んでみましょう．</description>
    </item>
    <item>
      <title>じょりぼっとが起動して一年がたちました</title>
      <link>https://shogo82148.github.io/blog/2013/01/22/jo-ri-bot-1st-anniversary/</link>
      <pubDate>Tue, 22 Jan 2013 13:57:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2013/01/22/jo-ri-bot-1st-anniversary/</guid>
      <description>じょりぼっとが初めてつぶやいてから 今日でちょうど一年となりました．
突然の凍結，74回にも及ぶバルスなどなどを乗り越え， 今日まで生き延びられたことを嬉しく思います．
ちなみに一番最初のツイートはこんなのでした．
自分の教科にしましたというわけで終わりー。どっちも一部の断面図
&amp;mdash; 狼とボット (@JO_RI_bot) 2012年1月22日 学食メニュー じょりぼっとが一周年を迎えるということは， 起動当初から続けてきた学食メニュー表示機能も一周年ということです． 一年分のメニューはこちらにストックしてあります． どんなメニューが出されることが多いのか，簡単な統計を取って見ました．
1食昼食A定 回鍋肉 13 鶏肉と味噌漬け焼き 9 チキン唐揚げ 8 豚肉キムチ炒め 7 ちきんカツ 7 チキン唐揚げ&amp;lt;スパイシーカレー&amp;gt; 7 豚肉朝鮮焼き 7 焼肉とピーマン肉詰めフライ 7 チキンソテーさわやかソース 7 チキンマスタード焼き 7 鶏肉キムチ焼き 7 チキンピザソース焼 7 1食夕食A定 チキンピザソース焼 13 酢豚 11 豚カツ 9 チキンソテーさわやかソース 9 グリルドチキンイタリア風 9 鶏肉と味噌漬け焼き 8 エッグ焼肉 8 Bigメンチ 8 焼肉と春巻き 8 チキンステーキタルタルソース 8 1食昼食B定 筑前煮 16 いりどり 13 八宝菜 12 白身魚フライの卵とじ 11 白身魚のピリピリ漬け 10 鯖の生姜焼き 9 白身魚フライチーズ焼き 9 うずら卵と野菜の五目煮 8 鶏肉の酢豚風 8 シューマイの中華風旨煮 8 チキンブラウンソース煮 8 サーモンシチュー 8 アジフライとツナサラダ 8 白身魚の磯辺揚げ 8 1食夕食B定 すき焼き風旨煮 19 うずら卵と野菜の五目煮 13 スペイン風オムレツとコロッケ 13 ピザ卵とコロッケ 12 鶏肉と野菜の七味炒め 12 鮭の野菜あんかけ 11 鶏肉とヤングコーンの豆板醤炒め 10 アジフライとツナサラダ 9 チキンブラウンソース煮 9 白身魚のピリピリ漬け 9 1食昼食セット オムライス 16 五目あんかけ焼きそば 13 鮭チャーハン 12 ねぎトロ丼 12 鶏肉ときのこのチャーハン 11 トルコライス 11 三色丼 9 鶏の照り焼き丼 9 ビビンバ丼 9 親子丼 9 麻婆丼 9 1食夕食セット キーマカレー 13 ビビンバ丼 10 肉たれうどんとぶっ玉丼 10 海の幸うどん 9 すき焼き丼 8 肉うどんとカレーライス 8 ねぎトロ丼 8 イタリア風チキンカツ丼 8 鶏の照り焼き丼 6 とろろそばとミニカツ丼 6 鮭茶漬け 6 1食昼食単品 鶏肉とブロッコリー炒め 16 さつま汁 15 揚ギョーザ 13 のっぺ 13 イカ野菜カツ 13 揚げ豆腐の旨煮 13 かぼちゃのそぼろあんかけ 12 ハムチーズサンドフライ 12 エビ風味グラタンコロッケ 12 鶏肉とタケノコの旨煮 12 ブロッコリーとカリフラワーの炒め 12 茄子の中華風旨煮 12 豚肉と野菜の煮込み 12 卵と玉ねぎのソテー 12 1食夕食単品 鶏肉とチーズ焼き 17 レバニラ炒め 15 豆腐きのこあんかけ 13 ゆで卵 13 ちくわの二色揚げ 12 鶏肉と里芋の煮物 11 蒸シューマイ 11 けんちん汁 11 五目金平 11 五目肉じゃが 10 シューマイのカレー揚げ 10 ブロッコリーとカリフラワーの炒め 10 2食お昼ごはん定食 ピーマン肉詰めフライ 13 ちきんチーズ焼き 13 ハッシュドビーフ 12 鶏肉のピリカラ味噌焼き 10 カレーコロッケ 8 春巻き 7 野菜コロッケ 7 鰹の刺し丼 7 ちきんカツ 7 豚玉丼 7 レッドホットチキン 7 きじ焼き丼 7 ちきん南蛮漬け 7 ハンバーグ 7 海老グラタンコロッケ 7 2食晩御飯定食 545円定食 34 545円丼 16 フライアンドフライ 13 ちきん南蛮 11 新潟タレカツどん 11 中華角煮丼 10 ねぎトロ丼 9 スパイシードライカレー 9 レッドほっとマヨ 9 545丼 8 2食に関しては，集計か3月からなのでまだ一年たっていません． それにしても圧倒的な545円定食の出現頻度． 結局何が食べられるのか全くわからないのですが・・・．</description>
    </item>
    <item>
      <title>UDPのパケットをSSHを通してトンネルする</title>
      <link>https://shogo82148.github.io/blog/2012/12/28/tunneling-udp-via-ssh/</link>
      <pubDate>Fri, 28 Dec 2012 16:38:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2012/12/28/tunneling-udp-via-ssh/</guid>
      <description>SSHには標準でTCPのトンネリング機能は付いているのですが， UDPはトンネリングしてくれません． なんとかできないものかと試行錯誤してみました．
TCP をトンネル TCPのトンネリングの復習から． 以下のコマンドでクライアントの8080番ポートを，リモートの80番ポートに転送することができます．
ssh -L 8080:localhost:80 remote SOCKS proxyとして動作させることも出来ます． ブラウザのプロキシとして設定すれば，リモートのサーバがすべての通信を中継してくれます．
ssh -D 8080 remote UDP をトンネル NetCatを使うと TCP/UDP の通信内容と標準入出力をつなげることが出来るらしいです． これを使って，クライアント側で UDP サーバを立て，その通信内容をSSH経由でリモートの UDP クライアントに送ってあげます． 最後にリモートからクライアント側へのパケットを名前付きパイプで転送してあげればトンネル完成です．
mkfifo tunnel nc -ul 8080 &amp;lt; tunnel | ssh remote nc -u localhost 8080 &amp;gt; tunnel Mosh をトンネル なんでこんなことをしようと思ったかというと，Moshをファイヤーウォール越しに使いたかったから． MoshはUDPで通信しているので，SSHしか通らない環境では使えません． そこでUDPをSSHでトンネリングしてできないかとやって見ました． セッションの確立にSSHも使っているので，以下のようにして Mosh用のUDPトンネルと SSH用のTCPトンネルを作ります．
mkfifo tunnel nc -ul 60000 &amp;lt; tunnel | ssh -L 10000:localhost:22 remote nc -u localhost 60000 &amp;gt; tunnel &amp;amp; mosh -p 60000 --ssh=&amp;#34;ssh -p 10000&amp;#34; localhost 外部からのSSH通信が遅かったので，Moshのローカルエコーでなんとかならないかと挑戦してみました． 実際の効果は未確認．またあとで試してみます．</description>
    </item>
    <item>
      <title>JavaScript版WaveZutaZuta作ってみた</title>
      <link>https://shogo82148.github.io/blog/2012/12/24/wavezutazutajs/</link>
      <pubDate>Mon, 24 Dec 2012 13:51:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2012/12/24/wavezutazutajs/</guid>
      <description>「WaveZutaZutaというおもちゃを書いている話」 という記事を見ていたら，誰かがツイッターで 「いっちーがJavaScriptに移植してくれる」と発言．
あ，はい．やってみましょう．
どんな感じのものなの？ 音声ファイルをテキトーに切り貼りできるライブラリです． WaveZutaZutaJSにブラウザで実行出来るサンプルを置いたので 実際試してみるのが一番わかりやすいと思います． 適当な音声ファイルをドラッグ＆ドロップして，playボタンを押すと音が流れるので，いろいろ遊んでみてください．
テキストボックスには楽譜が書かれています． 楽譜の書き方は「WaveZutaZutaというおもちゃを書いている話」 と同じです．
ちなみに、楽譜ファイルの読み方、書き方ですが、aからzまでの文字それぞれにずたずたにされたwaveファイルの&amp;quot;破片&amp;quot;がアサインされていて、-は音をのばす(タイ)を意味し、0は休符を意味します。*を指定すると、a-zのうちどれかをランダムで鳴らします。1文字が64分音符ひとつ分の長さです。空白文字は無視されます。
使い方 リポジトリの WaveZutaZutaJS.js がライブラリの本体です． 次のように使います．
var data = new ArrayBuffer(); // ずたずたにしたい音声データを入れておく var context = new AudioContext(); var zuta = new WaveZutaZuta(context); zuta.onSuccess = function(self, source) { // 元の音声の先頭5秒から3秒間流す zuta.setNote(&amp;#39;a&amp;#39;, 5); var node = zuta.getAudioNode([{sound: &amp;#39;a&amp;#39;: length: 3}]); node.connect(context.destination); }; zuta.loadAudio(data); data には入力音声のバイナリデータを入れておきます． 形式はブラウザが対応していれば何でもOKです． Chromeなら wav, mp3, mp4 など，メジャーな形式はたいてい読めると思います．
getAudioNodeで返ってくるのは AudioNode なので，WaveZutzZutaJS の出力にさらにエフェクトをかけることができます． 例えば，次のコードで周波数フィルタを通すことができます．
var data = new ArrayBuffer(); // ずたずたにしたい音声データを入れておく var context = new AudioContext(); var zuta = new WaveZutaZuta(context); zuta.</description>
    </item>
    <item>
      <title>TinySegmenterをLaTeXに移植してみた</title>
      <link>https://shogo82148.github.io/blog/2012/12/16/tinysegmenter-for-tex/</link>
      <pubDate>Sun, 16 Dec 2012 13:11:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2012/12/16/tinysegmenter-for-tex/</guid>
      <description>この記事はTeX &amp;amp; LaTeX Advent Calendarの傘下記事です． 15日はk16.shikanoさんの「TeX がむかついたので実装したけど挫折してる話」, 17日は@egtraさんの「LCDF TypetoolsでOpenTypeフォントを使う(DVIPDFMXで)」です．
neruko3114が参加しているのを見てなんだか楽しそうだったで参加してみました． とはいってもネタも思いつかなったので，過去に作ったものをTeXに移植してみました． ターゲットはTinySegmenter． 以前作ったTinySegmenterMakerでLaTeXを出力できるようになったよ！
使ってみる TinySegmenterMakerのレポジトリをダウンロードするなりgit cloneするなりして 落としてきます． レポジトリに入っているのはモデルファイルとスクリプトだけです． これらを使ってTeXのスタイルファイルを作ります．
$ cd /path/to/TinySegmenterMaker/ $ ./maker tex &amp;lt; RWCP.model カレントディレクトリにtinysegmenter.styができます． TeX から見えるところにおいておきましょう． これを使うソースコードは次のようになります．
\documentclass{jarticle} \usepackage{tinysegmenter} \begin{document} \TinySegmenter{-}{私の名前は中野です} \end{document} platexで処理するとこんな感じに表示されるはず．
私-の-名前-は-中野-です 仕組み TinySegmeneterは元の文章の一部を切り取ってハッシュに入れる動作をしている． でも，LaTeXにはハッシュみたいなデータ構造がないのでコントロールシーケンスで代用． \@ifundefinedで有無を確認し，\csname\endcsnameで置き換え． コントロールシーケンスの一部に日本語を使わないといけないので，日本語LaTeX環境でしか動かない． ただ，一部句点などの扱いが違う？よくわからない．
あとは，文字種の取得が必要なんだけど，ここでも同じことをしてます． すべてのアルファベット・ひらがな・カタカナ・数字について，その文字種をベタ書き． それ以外は全部漢字扱い． そのため，それ以外の文字を使うとオリジナルとは違う結果になるかも．
最後は足し算．これはカウンタを使えば簡単ですね．
応用編 TinySegmenterMakerでは自由にモデルを差し替えることができます． 以前JavaScript版のTinySegmenterを使って， 聞こえますか…自動生成…してみた…よ… ということをしてみました． LaTeXだってできるはず．
聞こえますか… に心に呼びかけるためのモデルファイルが含まれています． これをダウンロードして読み込ませます．
$ ./maker tex &amp;lt; model これを自分のドキュメントに読み込ませてみます．
\documentclass{jarticle} \usepackage{tinysegmenter} \begin{document} (…\TinySegmenter{…}{聞こえますか聞こえますかあなたの心に直接語りかけています}…) \end{document} 私の声が聞こえましたか・・・？</description>
    </item>
    <item>
      <title>MeCabをPythonから使う注意点とか</title>
      <link>https://shogo82148.github.io/blog/2012/12/15/mecab-python/</link>
      <pubDate>Sat, 15 Dec 2012 17:38:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2012/12/15/mecab-python/</guid>
      <description>日本語の文章をコンピュータで色々いじるときに， 必ずと言っていいほどよく使うのが形態素解析器． スペースなどの明示的な区切りの無い日本語を単語に分割してくれるツールです． 中でもMeCabが非常に有名で，さまざまなところで使われています．
MeCabはいろいろな言語から呼び出すことができます． 自然言語処理の分野ではPythonが人気のようですね．僕も使っています． しかし，MeCabをPythonから使う場合，注意する点がいくつかあります． そこにハマっている後輩を見かけたので，文章として残しておくことにします． Python2系が対象です(3系はよくわからない)． 注意するのは以下の二点です．
MeCabに渡す文字列はencode，戻ってきた文字列はdecodeする MeCabに渡した文字列は必ず変数に入れておく EncodeとDecode Python2系の文字列には，バイト列として扱われる文字列(str)と，Unicodeで表現された文字列(unicode)があります． 日本語を扱う場合，strだといろいろ問題があるので，特に理由がなければunicodeを使うべきです． しかし，MeCabはstrしか受け付けません． そこでMeCabに渡す直前・直後でencode・decodeするようにします．
import MeCab tagger = MeCab.tagger(&amp;#39;-Owakati&amp;#39;) text = u&amp;#39;MeCabで遊んでみよう！&amp;#39; result = tagger.parse(text) # エラー！ encoded_text = text.encode(&amp;#39;utf-8&amp;#39;) # encodeが必要 encoded_result = tagger.parse(text) result = result.decode(&amp;#39;utf-8&amp;#39;) # 必ずdecode &#39;utf-8&#39;の部分は辞書の文字コードに合わせて適宜書き換えてください． デフォルトはeuc-jpですが，utf-8の方が幸せになれると思います．
必ず変数に入れる 次にMeCabの作ったノードに直接アクセスして，品詞情報などを取ってくることを考えます． 適当に書いてみるとこんな感じでしょうか．
import MeCab tagger = MeCab.tagger(&amp;#39;&amp;#39;) text = u&amp;#39;MeCabで遊んでみよう！&amp;#39; node = tagger.parseToNode(text.encode(&amp;#39;utf-8&amp;#39;)) while node: #printはstrを渡す必要があるのでdecodeは不要 print node.surface + &amp;#39;\t&amp;#39; + node.feature node = node.</description>
    </item>
    <item>
      <title>聞こえますか…自動生成…してみた…よ…</title>
      <link>https://shogo82148.github.io/blog/2012/12/05/kikoemasuka/</link>
      <pubDate>Wed, 05 Dec 2012 23:07:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2012/12/05/kikoemasuka/</guid>
      <description>聞こえますか…あなたの心に直接…で始まるこのテンプレート． 誰かが「文章入力したら…を自動で入れてくれるのないかな」って呟いてたのでつくってみた．
サクッと作成 TinySegmenterで単語分割， ランダムに…を単語の間に挿入して出力してみた．
聞こえますか… この程度なら数十分あれば作れますね．
挿入位置を学習してみる さて，実際やってみるとちょっと挿入位置が不自然な気がします． 世の中に出回っているツイートでは単語間ではなく文節の間に挿入しているのが多いように見えます．
しかし，TinySegmenterは品詞情報をつけてはくれないので文節の判定は少し面倒ですね．
・・・待てよ・・・このテンプレートを使ったツイートなんて大量に手に入る・・・これから学習すればいいんじゃね？
はい，やってみましょう．
ツイートを集める Twitter APIを使ってテンプレートを使っているようなツイートを拾ってきます． ** 「聞こえますか OR きこえますか -RT」** で検索してみました．
普段Twitter APIを叩くときはTweepyを使っているのですが，これで検索するとあまり古いツイートは取れません． API 1.1 を使うと古いツイートも取ってこれるらしいので，強引にTweepyを書き換えて1.1対応． ** 72,529ツイートの取得に成功しました． ** プログラムについてはTweepyの書き換えでゴチャゴチャしているのでまた今度．
TinySegmenterMakerに放り込む カッコで囲まれている部分を抽出，点々を空白に置換，パクリツイッタラー消去などの処理をした後， TinySegmentermakerに放り込みます． 実際に学習に使ったツイートは49,573ツイートです． 10000回の繰り返しで，学習結果は以下のようになりました．
Result: Accuracy: 94.794% (3466578/3656961) Precision: 90.9504% (526277/578642) Recall: 79.2234% (526277/664295) System/Answer p/p p/n n/p n/n: 526277 52365 138018 2940301 約95%の精度という非常に高い性能を示してくれましたが， 区切るところ(p)よりも区切らないところ(n)のほうが多いためですね． Recallが8割しかありませんが，人によるばらつきが大きそうなので，まあこんなもんでしょう．
学習が終わったら最後にオリジナルのTinySegmenterを学習後のもので置き換えるだけ． チェックボックスで単語分割とツイートの学習結果，どちらを使うか選択できます． なんだかそれっぽくなりましたかね・・・？
元ネタについて ところでこのテンプレートの元ネタについて調査している方がいらっしゃるようです．
「聞こえますか…心に直接…」のオリジナル検証 ゲームが元ネタだ，っていう人を時々見かけたけど， 検証してみると微妙に内容が違うらしい． もちろん影響は受けているんだろうけどね． マンガとかゲームで始めて心に直接語りかけたのって何なんだろう？</description>
    </item>
    <item>
      <title>OAuthの認証にWebViewを使うのはやめよう</title>
      <link>https://shogo82148.github.io/blog/2012/11/24/no-more-webview/</link>
      <pubDate>Sat, 24 Nov 2012 23:06:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2012/11/24/no-more-webview/</guid>
      <description>AndroidからTwitterへアクセスするためのライブラリとして，Twitter4Jが有名です． これを使ってみようと，「Android Twitter4J」と検索すると 認証にWebViewを使った例がたくさん出てきます．
・・・いや，ちょっとまて． それはちょっとまずいだろう．
そういうわけでもうちょっと賢い方法を探してみました．
何がまずいのさ 「Android Twitter4J」と検索すると，上位にこんなページが出てきます．
Twitter4jを使ってOAuth認証をアプリ内で行う方法 Twitter4j-2.2.xを使ったOAuth認証のコーディング例 twitter4jでツイートする Android+Twitter4JでOAuthするためのソースコード 上のサイトでは次の様は方法をとっています．
アプリ内にWebViewを貼り付け WebViewでTwitterの認証画面を表示 onPageStarted や onPageFinished をオーバーライドして callback URL へのアクセスを検出 URL に入っている認証コードで認証 アプリ内でWebViewを使うとURLが表示されません． つまり ** 本当にツイッターにアクセスしているかわからない ** のです． もし，表示されるのが偽の認証画面だったら，アプリから簡単にパスワードがわかってしまいます．
じゃあ，URL を表示させればいいかというとそういうわけでもありません． 画面上のURL表示なんて簡単に偽装できてしまいます． どんな工夫をしても ** アプリがパスワードの要求をしていることには変わりありません ** ． アプリはパスワードを簡単に取得できます．
アプリのユーザはTwitterに限らずSNSへのログイン時にブラウザを開かないアプリは信用しないようにしましょう． どこかでパスワードの抜かれている可能性があります． (ただし，公式アプリは除く．公式アプリが信用できないならそもそもサービスを利用できないもんね．)
じゃあどうするのさ じゃあ，開発者はどうするのかって話ですが，もう少し詳しく検索してみましょう． 他の方法を使っているページもでてきます．
PINコードを利用 TwitterでPIN番号認証を行う Intent Fileterを利用しコールバック twitter4jを使用したAndroid Twitterアプリケーション作成 Twitter4Jを使ってAndroidアプリでStreamingAPIのUserTimelineを取得する TwitterでOAuth認証を行う Twitterへのアプリケーション登録 Twitterの認証ページをブラウザで開く Access Tokenを取得する PIN コードを利用 一つ目の方法はPC版クライアントでよく使われる方法． 認証後にPINコードと呼ばれる数字が表示されるので，それをアプリに入力します． twiccaなんかでも使われてますね． Twitter へのアプリケーション登録のときにコールバックURLを入力しないとこの認証方式になります．
認証画面に，ブラウザを開くボタン，PINコードの入力ボックス，ログインボタンを用意しておきます．
&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;utf-8&amp;#34;?</description>
    </item>
    <item>
      <title>TinySegmenterの学習ツールを作ってみた</title>
      <link>https://shogo82148.github.io/blog/2012/11/23/tinysegmentermaker/</link>
      <pubDate>Fri, 23 Nov 2012 14:37:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2012/11/23/tinysegmentermaker/</guid>
      <description>TinySegmenterは工藤さん作のJavaScriptだけで書かれたコンパクトな分かち書きソフトウェアです． わずか20kバイト程度のサイズしかなく，お手軽に使える分かち書きソフトウェアですが， 当たり前のことながら学習データに使った新聞記事以外の文章の精度はイマイチ． 改善しようにも学習用のプログラムが公開されていないのでモデルの修正が大変です．
ないなら作ってしまいましょう！
ダウンロード ソースはgithubで公開しています．cloneするなりzipファイルを落としてくるなりしてください．
TinySegmenterMaker 学習方法 スペースで分かち書きしたコーパスをあらかじめ準備しておきます． コーパスから分かち書きの情報と素性を取り出します．
$ ./extract &amp;lt; corpus.txt &amp;gt; features.txt AdaBoostを用いて学習します． 新しい弱分類器の分類精度が0.001以下，繰り返し回数が10000回以上となったら学習を終了します．
$ g++ -O3 -o train train.cpp # コンパイル $ ./train -t 0.001 -n 10000 features.txt model # 学習 きちんと分割できるが実際に試してみます．
$ ./segment model 私の名前は中野です 私 の 名前 は 中野 です ライブラリの作成 TinySegmenterは実装が簡単なためいろいろな言語へ移植されています． モデルの更新のたびにそれらへの言語の移植バージョンを作るのは大変です． というわけで，makerコマンドで各種言語用のライブラリを作れます． 学習結果のモデルはライブラリのなかに組み込まれ，ファイル単体で簡単に使用することができます． allを指定することで，対応しているすべての言語向けのライブラリを出力します．
$ ./maker javascript &amp;lt; model $ ./maker perl &amp;lt; model $ ./maker ruby &amp;lt; medel $ .</description>
    </item>
    <item>
      <title>6さいカンファレンス 第9回「マスタリングの技法 ～音圧を上げよう～」まとめ</title>
      <link>https://shogo82148.github.io/blog/2012/11/09/6saiconf-9/</link>
      <pubDate>Fri, 09 Nov 2012 00:13:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2012/11/09/6saiconf-9/</guid>
      <description>2012/11/8にくいなちゃんさん主催で開催された6さいカンファレンスのまとめ。 第9回は「マスタリングの技法 ～音圧を上げよう～」です。
勝手にまとめてしまったので、何か問題があれば@shogo82148まで。
よるほー くいなちゃん: みなさん、自分が作った曲が、市販のCDの曲にくらべ、 音量が小さい (最大まで波形を上げたにも関わらず)と悩んだことはありませんか？
くいなちゃん: しかし、心配はいりません。 今回のことを実践していただくと、 みなさんの曲も、市販の楽曲並みに、音圧をあげることができるですん！ では次の波形をご覧ください。
くいなちゃん: http://kuina.tes.so/6saiconf_9/img0.png はい、さっき作った曲です。 いい曲ですね！ しかし、なんだか音量が小さいですね… それでは、波形に注目してください。 この図では、波形が-1.0～1.0 の範囲で 示されていますが、この範囲に比べ、明らかに波形が小さいです。 余白が空きすぎです！
くいなちゃん: え、mp3ファイルがどこにあるかって？ ｷﾆｼﾅｲ! では、とりあえず、この波形を -1.0～1.0 まで拡大してみましょう。 http://kuina.tes.so/6saiconf_9/img1.png はい、赤い矢印で示されたところが、確かに-1.0～1.0 の範囲に到達していますね。 素人さんは、この状態で完成、と思うでしょう。 しかし、それではダメダメですん☆
くいなちゃん: なぜなら、緑の2本線で示された範囲がメインの波形であって、 そこから飛び出た いわゆる魚の骨は、音量を上げる邪魔をするものだからです。 この魚の骨さえなければ、もっと音量が上がるのに…そう考えてください。
くいなちゃん: 市販のCD の音楽なんかは、こんな波形をしています。 http://kuina.tes.so/6saiconf_9/img2.png これは、全体が波形で埋まった、いわゆる海苔みたいなことになっているので、 業界でもしばしば 海苔 と言われます。 ここまで来ると、相当 音量が大きく聞こえます。 波形のピークは、魚の骨と同じなんですけどね。
くいなちゃん: で、素人さんは、この状態にしようと、魚の骨を無視して、 波形のレベルを上げるわけです。 しかし、これには問題があるのです。
くいなちゃん: http://kuina.tes.so/6saiconf_9/img3.png この図を見ればわかるのですが、青のラインが -1.0 ～ 1.0 の範囲をしめしています。 で、無理やり波形を拡大すると、青のラインを超えた部分が潰されて、 右の波形のようなことになってしまいます。これは、元の波形から変わっているので、 当然音も変わります。大抵、ノイズが入った汚い音になってしまいますですー
くいなちゃん: じゃあ、どうするのか。 それは、波形を潰すことなく、波形のピークを下げて -1.0 ～ 1.</description>
    </item>
    <item>
      <title>VirtualBoxでHadoop環境を作ってみる</title>
      <link>https://shogo82148.github.io/blog/2012/11/06/hadoop/</link>
      <pubDate>Tue, 06 Nov 2012 23:20:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2012/11/06/hadoop/</guid>
      <description>隣の人がHadoopいじって遊んでたので，自分もちょっとやっておこうかなと思い少し触ってみました． 実際にマシンを借りて大規模な計算をするのは大変なので， 仮想マシンを作って遊んでみました．
仮想Hadoop環境の構築 巷ではVMWareが人気だったりしますが，今回はVirtualBoxを使ってみたいと思います． なぜかというとVirtualBoxをコンソールから扱えるVagrantで遊んでいたので， ちょうどパソコンにインストールされていたから． 以下，VirtualBoxは既にインストールされているものとして話を進めます．
Cloudera&amp;rsquo;s Hadoop Demo VM for CDH4に VMWare, KVM, VirtualBox用の各種イメージが置いてあるので， VirtualBox用のものをダウンロードしてきます． tar.gzで圧縮されているので解凍しましょう． 中にcloudera-demo-vm.vmdkというファイルが入ってます．
VirtualBoxを起動してHadoop用のマシンを新規作成します． 設定は以下のとおりに
デモイメージはCentOSベースらしいのでOSタイプとして RedHat**(64bit版)** を選択 メモリは3Gバイト以上 ハードディスクは後で設定するので，「起動ディスク」のチェックを外し割り当てしない 新規作成したら設定を少しいじります．
IO APICが有効化されていることを確認 ストレージにcloudera-demo-vm.vmdkを追加．この時 IDEコントローラ の下にいれること． ネットワークアダプタをホストオンリーアダプタに設定 これで実行できるようになります．
遊んでみる せっかくなので少し遊んでみる事にします． イメージの置いてあったページにあるHadoop Tutorialをやってみましょう． Hadoopの例として必ず最初に出てくるであろう，Word Countです．
まずソースコードを入力します．
package org.myorg; import java.io.IOException; import java.util.*; import org.apache.hadoop.fs.Path; import org.apache.hadoop.conf.*; import org.apache.hadoop.io.*; import org.apache.hadoop.mapred.*; import org.apache.hadoop.util.*; public class WordCount { public static class Map extends MapReduceBase implements Mapper&amp;lt;LongWritable, Text, Text, IntWritable&amp;gt; { private final static IntWritable one = new IntWritable(1); private Text word = new Text(); public void map(LongWritable key, Text value, OutputCollector&amp;lt;Text, IntWritable&amp;gt; output, Reporter reporter) throws IOException { String line = value.</description>
    </item>
    <item>
      <title>PythonでCaboChaを美味しくいただく</title>
      <link>https://shogo82148.github.io/blog/2012/11/01/cabocha/</link>
      <pubDate>Thu, 01 Nov 2012 23:02:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2012/11/01/cabocha/</guid>
      <description>日本語構文解析器CaboChaをPythonから使ってみたメモ．
インストール CaboCha自体のインストールは公式のドキュメントを参照． ググれば他の人のレポートも出てくるはず．
CaboChaのソースコードを展開したディレクトリの中の pythonディレクトリにPython-bindingが入ってます． そこに移動した後，管理者権限で以下のコマンドを実行すればインストール完了．
python setup.py install 食べ方 解析結果を文字列出力 python/test.py に書いてあるとおり．
#!/usr/bin/python # -*- coding: utf-8 -*- import CaboCha # c = CaboCha.Parser(&amp;#34;&amp;#34;); c = CaboCha.Parser() sentence = &amp;#34;太郎はこの本を二郎を見た女性に渡した。&amp;#34; print c.parseToString(sentence) tree = c.parse(sentence) print tree.toString(CaboCha.FORMAT_TREE) print tree.toString(CaboCha.FORMAT_LATTICE) 以下のような結果が得られれば成功．
&amp;lt;PERSON&amp;gt;太郎&amp;lt;/PERSON&amp;gt;は-----------D この-D | 本を---D | 二郎を-D | 見た-D | 女性に-D 渡した。 EOS &amp;lt;PERSON&amp;gt;太郎&amp;lt;/PERSON&amp;gt;は-----------D この-D | 本を---D | 二郎を-D | 見た-D | 女性に-D 渡した。 EOS * 0 6D 0/1 2.</description>
    </item>
    <item>
      <title>Togetterの編集作業便利にしたい</title>
      <link>https://shogo82148.github.io/blog/2012/10/28/togetter-helper/</link>
      <pubDate>Sun, 28 Oct 2012 01:11:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2012/10/28/togetter-helper/</guid>
      <description>TogetterはTwitterの投稿をまとめられる非常に便利なサイトですが， 編集画面が異様に使いにくいです． そんなわけで前回は 自動的に検索ボタンを押してくれるブックマークレットを書いてみました．
それをユーザスクリプトにして， ついでに編集画面の不便なところを修正してみました．
編集を便利にするユーザスクリプト スクリプトはGistにあげておきました．
https://gist.github.com/3953476 インストールはこちら Chrome拡張Tampermonkey で動作を確認しました． この拡張，ユーザスクリプトの管理ができてオススメです．
変更内容 ユーザスクリプトは編集画面に対して次のような変更をします．
画面レイアウトの変更 自動検索機能 重複削除・ソートの高速化 選択動作の変更 元に戻す機能 ショートカットキーの追加 画面レイアウトの変更 Togetterの編集画面のレイアウト，非常に使いにくいです． ツイート一覧をスクロールしようとしたら画面全体がスクロールしてしまって， 編集用のボタンが隠れてしまう，ということが編集中に何度もあってイライラします．
** 余計なものでごちゃごちゃし過ぎなんだ！ **
** 僕は編集に集中したいんだ！ **
編集と関係の無いヘッダやナビゲーションは要らないので消えてもらうことにしました． ツイートの一覧が画面いっぱいに表示され， 編集用のボタンは常常に画面上に表示されます．
自動検索機能 前回ブックマークレットで実現した機能です． 検索キーワードと一回あたりの読み込み回数を設定し， 「自動検索開始」ボタンを押しましょう． すると，繰り返し間隔を聞いてくるので秒単位で時間を指定しましょう． カウントダウンが始まり，周期的に検索・ソート・重複削除が行われます．
重複削除．ソートの高速化 Togetterのソートのスピードはびっくりするほど遅いです． 例えば，「劇的ビフォーアフター佐世保高専ラグビー部部室をリフォーム」には 1190個のツイートが含まれています． これを時間順にソートしてみたところ， 三回の平均で9.978秒(それぞれの結果は10.118秒, 9.925秒, 9.892秒)かかりました． 1000ツイート程度のソートに約10秒です．遅い！
ソート自体は数ミリ秒で終わるのになんでこんなに遅いというと，結果を画面に反映するのにjQueryのセレクタを大量に呼び出しているから． ソートのときに一回読み込んだものをキャッシュしておけばもっと速くなるはず．
ってことで自前で実装してボタンを置き換えました． 結果0.171秒(0.174, 0.177, 0.161)まで短縮することができました． 約58倍の高速化！
高速化とは直接関係ないけど， 「選択したところだけソート」にしました． ツイートを内容ごとに分類してるときとかに， 一部分だけソートできます(例:ロボコン死亡かるた)． 何も選択されてないときは何もしません． 全体をソートしたい時は明示的に全選択する必要があります．
重複削除とかも実装しなおしました． 約200ミリ秒かかってたのが約20ミリ秒に高速化！
選択動作の変更 もともとの編集画面では，ツイートをクリックするとクリックしたツイートの選択状態が切り替わります． 他に選択しているツイートがある場合，そのツイートは選択されたままです． Excelとかではセルをクリックすると他のセルは非選択状態になるので， それに慣れているとなんだか違和感があるんですよね． そういうわけで，ツイートをクリックしたときはクリックしたツイートのみ選択されるようにしました． 複数選択ができないのも困るので， Ctrlキーと同時クリックでクリックしたツイートを全部選択， Shiftキーと同時クリックで範囲内のツイートを全部選択にしました． Excelとかと一緒ですね．</description>
    </item>
    <item>
      <title>6さいカンファレンス 第7回「Windowsのアプリをクラックしよう！(再)」まとめ</title>
      <link>https://shogo82148.github.io/blog/2012/10/27/6saiconf-7/</link>
      <pubDate>Sat, 27 Oct 2012 18:21:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2012/10/27/6saiconf-7/</guid>
      <description>2012/10/25にくいなちゃんさん主催で開催された6さいカンファレンスのまとめ。 第7回は「Windowsのアプリをクラックしよう！(再)」です。
第4回「Windowsのアプリをクラックしよう！」はどこへいってしまったのでしょう？ 頑張って探したけどこれしか情報が無い・・・？
昨日の ６さいカンファレンスは盛り上がりましたね (第４回 「Windowsのアプリをクラックしよう！」)　来週は、作曲講座をしようと思っています。　お楽しみに☆　#6saiconf
&amp;mdash; くいなちゃんさん (@kuina_tesso) 9月 28, 2012 厳しい緘口令が敷かれているのか，参加者がくいなちゃんさんしか居なかったのか，そもそもそんなのなかったのか・・・．
勝手にまとめてしまったので、何か問題があれば@shogo82148まで。 (カンファレンスの内容にはくいなちゃんライセンスが適用されるらしいです．怖！)
&amp;mdash;&amp;ndash;ｷﾘﾄﾘｾﾝ&amp;mdash;&amp;ndash; くいなちゃん: 10/25(木) 21:00 から、第７回 ６さいカンファレンスを開催します。 テーマは、「Windowsのアプリをクラックしよう！(再)」 です。 ** (再) と付いていますが、前回やった記憶はございません。 ** 参加されない方は、今のうちにご退場お願いします。 ROMでの参加も歓迎ですん☆ それでは、もうしばらくお待ちください。
くいなちゃん: それでは、第７回　６さいカンファレンスを開催します。 テーマは、「Windowsのアプリをクラックしよう！(再)」　ですん☆ しかし、これを開始する前に、いくつかの免責事項をお伝えしなければなりません。 (６さい的な事情)
くいなちゃん: まず、実際に既存の Windowsアプリをクラックする、という流れで 話を進めていきますが、実際にクラックを行っているわけではなく、 また画像も合成です。 実際に既存のアプリに対してクラックする行為は、 場合によっては犯罪となりますので、** 決してマネしないでください **。 本講座は、犯罪を助長する意図があるわけではなく、 むしろ攻撃側を知ることで、防衛スキルを身に着けようというものです！
マインスイーパ！ くいなちゃん: はい、よろしいでしょうか。 では、本日クラックするアプリはこちらです！ http://kuina.tes.so/6saiconf_7/img0.png
くいなちゃん: みなさん大好きな、マインスイーパですん☆ くいなちゃんは、マインスイーパが得意ではないので、上級をクリアする頃には、 時間が999になってしまいます。 そこで、この時間が経過しないよう、改造することを今日の目標としましょう。
くいなちゃん: まず、ollydbg というフリーソフトを起動します。 これは、主に アプリをクラックするのに使われるソフトです[要出典] http://kuina.tes.so/6saiconf_7/img1.png 画像は、ollydbg 上でマインスイーパを起動したところです。</description>
    </item>
    <item>
      <title>Twitter公式クライアントのコンシューマキー流出について考える</title>
      <link>https://shogo82148.github.io/blog/2012/10/22/twitter-key/</link>
      <pubDate>Mon, 22 Oct 2012 20:46:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2012/10/22/twitter-key/</guid>
      <description>コンシューマキー流出？ 朝のTLにTwitter公式クライアントのコンシューマキーなるものが流れてきたので， なにか面白いことに使えないか セキュリティ的に何か問題になるのか 考えてみました．
コンシューマキーとは コンシューマキーとはクライアントの身分証眼書のようなものです． Twitterはコンシューマキーを使用してクライアントを識別します．
このコンシューマキーがどのように使われるのかを知るために， Twitterの認証方式であるOAuthについて簡単なスライドを描いてみました．
OAuthの認証は大きく分けて次の6ステップからなります．
認証開始 Twitterの使用を開始するためにユーザはクライアントに認証の開始を指示します 鍵の使用申請書の要求 開始指示を受けたクライアントは，コンシューマキーを利用して身分証明を行います 証明できたクライアントに対してTwitterは鍵の使用申請書を渡します ユーザの使用許可をもらう クライアントはユーザに使用申請書を渡し使用許可を求めます 使用申請書はウェブページのアドレスの形で渡されるので，多くの場合ここで自動的にブラウザが立ち上がります Twitter認証 ユーザはTwitterにパスワードを渡し，クライアントに使用許可することを伝えます ハンコを受け取る 使用許可の証としてPINコード(ハンコ)を受け取ります PINコードをクライアントに渡します 申請書を鍵を交換 クライアントは使用申請書とTwitterに渡し，鍵をもらいます 次回以降，クライアントは鍵を利用してTwitterにアクセスすることができます コンシューマキーが流出したということは， ステップ2のクライアントの身分証明の際に「自分は公式クライアントだ！」と名乗ることができてしまうという事です．
一般ユーザに対する影響 さて，これによる一般ユーザへの影響について考えてみましょう．
認証画面の偽装 ステップ4のTwitter認証の際，画面にはクライアント名が表示されます． 公式クライアントのコンシューマキーを使えばここに「Twitter for iPhone」「Twitter for Android」等， 公式クライアントの名前を表示することができてしまいます． これは間違えて認証してしまいそうですね！
・・・でも，ちょっと待ってください． ステップ4にたどり着くには，ユーザ自身が「ステップ1.認証開始」をする必要があります． これをするには，ユーザ自身がソフトをダウンロードして，解凍して，実行する必要があります． ** まともな ** な情報リテラシーを持ったユーザであれば，怪しいソフトは実行すらしませんよね？
偽装Webアプリ Webサイトであれば，アクセスしただけで「ステップ1.認証開始」をしたことにするのは技術的に難しくありません． ステップ1をクリアしてしまえば，流出したクライアントキーを使ってステップ4まで進むことができてしまいます． この時表示されるクライアント名は公式クライアントのものなので，悪意のあるサイトなのか本物なのか見分けが付きません．
ここで間違えてパスワードを入力し，使用許可を出してしまったとしましょう． Twitterにはクライアントアプリ(自分のPCで実行するもの)と Webアプリ(ブラウザを使うもの)の2種類があり，この違いによってステップ5での動作が少し変わります．
公式クライアントアプリに偽装していた場合， ステップ5でPINコードが表示されます． ** まともな ** なTwitterユーザであればこの時点で気が付きますよね？ 一般的なWebアプリではPINコードが表示されることはまずありません． WebアプリのくせにPINコードが表示されたら認証を中止しましょう．
Webアプリに偽装していた場合， PINコードに当たるものが自動的にWebアプリに送られます． この送り先はアプリの作者にしか指定することができないため， 悪意のあるサイトの手にわたることはありません．
一般ユーザに対する影響まとめ コンシューマキーが漏れたからといって特別なことをする必要はありません．
** 怪しいアプリは実行しない ** ** 怪しいサイトでTwitterの認証をしない ** という，当たり前のことさえ気をつけていれば大丈夫です． このことさえ注意していれば鍵が盗まれることはありません． なんか最近犯罪予告の冤罪事件も発生しているので気を付けないといけませんね．</description>
    </item>
    <item>
      <title>半自動トゥギャりスクリプトを書いてみた</title>
      <link>https://shogo82148.github.io/blog/2012/10/13/semiauto-togetter/</link>
      <pubDate>Sat, 13 Oct 2012 17:35:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2012/10/13/semiauto-togetter/</guid>
      <description>togetterでたくさんツイートをまとめたい Twitterは手軽に情報収集ができ他人とのコミニュケーションができる楽しいSNSですが、 古いツイートはしばらく経つとタイムラインや検索結果からはたどれなくなってしまいます。 過去のイベントに関するつぶやきを後から見たい、といった場合に不便です。
そこで登場するのがtogetterというサービス。 Twitterのツイートを引用して、「まとめ」を作ることができます。 Twitter上での議論やイベントに対するみんなの反応がわかりやすく見れるので便利です。 僕もJO_RI_botのツイートをまとめたりといろいろとお世話になってます。
簡単なまとめを作るのには非常に便利なtogetter。 しかし、ツイート数が多くなると少し大変です。 例えば何かのイベントのハッシュタグのついたツイートをまとめたい場合、 検索に現れるツイートの数には上限があるので、 漏れ無くツイートを集めるにはイベントの最中にまとめを作る必要があります。 togetterには自動更新機能がないので、数分毎に「検索」ボタンを押さなければなりません。 これは面倒だ・・・
ブックマークレットを書いてみたよ 面倒なので、自動的に検索ボタンを押すブックマークレットを書いてみた。
** ユーザスクリプトで書き直してみたよ！ **
上のリンクをブックマークに登録しておき、togetterのまとめ作成ページを開くと、 検索ボックスのしたにテキストボックスとボタンが追加されます。 テキストボックスに検索ボタンを押す間隔(秒単位)を入れ、開始ボタンを押すと、 自動的に検索・移動・重複ツイートの削除・ソートをしてくれます。
スクリプト 元のスクリプトをgistにあげておきます。
{% gist 3883841 %}
ブラウザ拡張のほうが便利だろうけどブックマークレットとして実装しているのは、togetterのスクリプトやjQueryを自前のスクリプトから呼びたかったから。 ブラウザ拡張でも実現する方法はあるんだろうけど、調べるの面倒だからやってない。 DOMの操作だけでもなんとかなりそうだから、余力があれば書きなおすかも。
これ作るにあたって、togetterのソース見てたけど、重複削除やソートアルゴリズムがなんだか残念な感じ。 ツイート数に比例した回数だけjQueryのセレクタを呼び出している。 jQueryのセレクタって結構重い処理だし、オーダーが O( n^2 ) になるわけで・・・。 単なるソートにしては重すぎだろ、とは思ってはいたんだ。まさかこんな中身だとは。</description>
    </item>
    <item>
      <title>6さいカンファレンス 第6回「幼女を描いてみよう！　～原画から彩色まで～」まとめ</title>
      <link>https://shogo82148.github.io/blog/2012/10/12/6saiconf-6/</link>
      <pubDate>Fri, 12 Oct 2012 00:28:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2012/10/12/6saiconf-6/</guid>
      <description>2012/10/11にくいなちゃんさん主催で開催された6さいカンファレンスのまとめ。 第6回は「幼女を描いてみよう！　～原画から彩色まで～」です。
勝手にまとめてしまったので、何か問題があれば@shogo82148まで。 (カンファレンスの内容にはくいなちゃんライセンスが適用されるらしいです．怖！)
ゆるふわ☆タイム くいなちゃん: 今日も、前回と引き続き、プログラミングのプの字も出てこない、ゆるふわ講義ですん☆
くいなちゃん: テーマは 「幼女を描いてみよう！　～原画から彩色まで～」 ということなので、今回描いてみた絵を、いきなり完成形からご覧いただくことにします。 ３時間で描いたです。 http://kuina.tes.so/6saiconf_6/img0.jpg
構図を描いてみるです！ くいなちゃん: では、順を追って、描いていくことにしましょう。 最初はもちろん、カンヴァスは白紙です。 そこに、まずは構図をﾃｷﾄｰに描いてみるです： http://kuina.tes.so/6saiconf_6/img1.jpg はい、ここまではみなさん描けますね。 まるで６さいが描いたようなﾃｷﾄｰな落書きです。
くいなちゃん: ここでのポイントは、脳内に立体をイメージすることです。 構図をイメージしやすいように、背景に線を引いていますが、無くてもイメージできるなら描く必要はありません。 注意してほしいのは、2D絵を描くからといって、2Dで捉えないことです。 アニメ絵でも同様ですん
くいなちゃん: はい、キャラに、顔と髪を追加してみました。 http://kuina.tes.so/6saiconf_6/img2.jpg えっ、完成形と絵が違う？ キニシナイ！ あと、独りでは寂しいので、小鳥も追加しました。
色を塗っていくです！ くいなちゃん: アニメ調の絵を描く場合は、ここからアニメ塗りをしていただけば完成しそうなんですが、せっかくなので、油彩画っぽく塗っていくことにします。
くいなちゃん: まずは、べた塗りです。 http://kuina.tes.so/6saiconf_6/img3.jpg
くいなちゃん: なんてことはありません。 太いブラシで、ﾃｷﾄｰに塗っただけです。 はみ出しまくってますね。　しかし、ブラシが太いので、細かな部分はそもそも塗れません。 このくらいﾃｷﾄｰでもキニシナイでok
くいなちゃん: 人物に影が、若干付けられていますが、原画を描くときに立体を意識したならば、光源を意識すればある程度付けられると思います。 物理学的に考えるのです！
細部を塗っていくです！ くいなちゃん: はい、次は、もう少し細いブラシで、細部を塗っていきます。http://kuina.tes.so/6saiconf_6/img4.jpg 基本的には、最初に太いブラシで大まかに塗り、徐々にブラシを細くしていき、細部を描きこんでいく流れですね。 ブラシの目安は、半々にしていくと良さそうです
くいなちゃん: この時点で、服に謎の模様が描かれていますが、ﾃｷﾄｰです。 その太さのブラシで表現できる粒度のものを塗ってください。
くいなちゃん: で、更に細いブラシで塗っていきます(3段階目)　そして、このあたりまで塗ったら、試しに線画(原画)を外してみましょう。 http://kuina.tes.so/6saiconf_6/img5.jpg おや、線画が無くても 綺麗に見えますね！
くいなちゃん: 目を描きこんでいなかったのは、意図的です。 最初のアニメ調の絵で完成させたい場合は、目も塗ってあげてください。
顔を描くです！ くいなちゃん: はい、それでは、もう線画が無くても輪郭が解りますので、線画は非表示にしたまま塗っていきましょう。 更に細いブラシで塗ります。</description>
    </item>
    <item>
      <title>6さいカンファレンス 第5回「６さいからの作曲講座」まとめ</title>
      <link>https://shogo82148.github.io/blog/2012/10/11/6saiconf-5/</link>
      <pubDate>Thu, 11 Oct 2012 12:37:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2012/10/11/6saiconf-5/</guid>
      <description>2012/10/04にくいなちゃんさん主催で開催された6さいカンファレンスのまとめ。 第5回は「６さいからの作曲講座」です。
勝手にまとめてしまったので、何か問題があれば@shogo82148まで。 (カンファレンスの内容にはくいなちゃんライセンスが適用されるらしいです．怖！)
THE END くいなちゃん: みなさん、楽譜は読めますね！(ﾁﾗｯ
くいなちゃん: 今回は、作曲理論などの難しい講義というよりも、実際にどうすれば綺麗な曲が作れるのか、という実践的な内容になっています。 くいなちゃんの独自理論ですん
くいなちゃん: では、さっそく、曲を作ってみましょうー
コード くいなちゃん: はい、まず曲に必要なのは、　&amp;ldquo;コード&amp;rdquo;　です。　「えっ、メロディじゃ？」 と言った あなたは素人です。 コードをしっかり押さえない曲は、聴くに堪えない感じになってしまいます。 くいなちゃんは、コードもメロディも全部同時に浮かぶことのできる天才肌ですが、とりあえず今回はコードを中心に創っていきましょう！
くいなちゃん: コードのルール： ** 「あるコードには、移りやすい次のコードが ある程度決まっている」 ** です！ たとえば、C(ド・ミ・ソ) のコードからは、G(ソ・シ・レ) や F(略) や Am(略) に移りやすいです。　逆に、G や F から、 C にも移りやすいです。
くいなちゃん: ということなので、C → G → C → G　は移りやすいコードのルールで作ったので、自然なコードということになりますね。　このコードで曲を作っていきましょ！
くいなちゃん: はい、この楽譜をご覧ください。　C(ドミソ) と G(ソシレ) が交互に来ているのが解るかと思います。　わからない人は、じっくり読んでね。 http://kuina.tes.so/6saiconf_5/img0.png(魚拓)
くいなちゃん: はい、コード完成です！ せっかくなので、これを鳴らしてみましょう。 http://kuina.tes.so/6saiconf_5/snd0.mp3
くいなちゃん: 自然ですね！
メロディをのせる くいなちゃん: では、コードが完成したので、メロディを乗せて行きましょう。 メロディのルール： ** 「拍子の部分には、コードの音を使う」 ** です！ さっきの、音が鳴っているタイミングの部分に、コードの音を使って、メロディを配置してみましょう。</description>
    </item>
    <item>
      <title>6さいカンファレンス 第3回「アルゴリズムを自力で生み出すプログラムを作ろう！」まとめ</title>
      <link>https://shogo82148.github.io/blog/2012/10/04/6saiconf-3/</link>
      <pubDate>Thu, 04 Oct 2012 16:58:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2012/10/04/6saiconf-3/</guid>
      <description>2012/09/06にくいなちゃんさん主催で開催された6さいカンファレンスのまとめ。 第3回は「アルゴリズムを自力で生み出すプログラムを作ろう！」です。
勝手にまとめてしまったので、何か問題があれば@shogo82148まで。
WELCOME TO HEAVEN!! くいなちゃん: ところでみなさん、次の( ) に入る数を当ててください
0, 1, 1, 2, 3, 5, 8, 13, 21, 34, ( ) くいなちゃん: はい、正解です！ これは、フィボナッチ数列と呼ばれ、 前の2つの値の和が、次の値になっているという数列です
くいなちゃん: これを、f(0) = 0, f(1) = 1, f(2) = 1, f(3) = 2, f(4) = 3, f(5) = 5, … と書いていくことにしましょう。　f(10) = 55　ですね！
くいなちゃん: もっと汎用的に考えて、f(x) の x を与えると、フィボナッチ数が返ってくることを考えましょう。 x = 10 のとき、f(x) が 55 になる、といった感じです
くいなちゃん: ではみなさん、この f(x) を、プログラムで書くことはできますでしょうか。 言語は何でも構いません。
くいなちゃん: やり方は、いくつかあります。 x = 100 と与えられれば、0, 1, 1, 2, 3, 5, …　と 約100回繰り返して、x = 100 の値を求めるというものです。</description>
    </item>
    <item>
      <title>リアルタイムにテンションを上げてみた</title>
      <link>https://shogo82148.github.io/blog/2012/10/03/tension-upper/</link>
      <pubDate>Wed, 03 Oct 2012 11:42:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2012/10/03/tension-upper/</guid>
      <description>昨日，Twitterで猫型さんのアイコンのテンションが上がっている話をしていたら， こんな無茶ぶりをされたんですよ．
明日には、いっちーがWebRTCでリアルタイムテンション上がってきたサービス作ってくれるだろうし、猫型さんがアプリの申請出してるだろう
&amp;mdash; Takashi Sasakiさん (@civic) 10月 2, 2012 いいだろう，その挑戦受けてやる！
WebRTCって？ WebRTCというのはブラウザ上で Real Time Communication を行うAPI群のことことです．
ローカルデバイス(Webカメラとかマイクとか)へのアクセス ブラウザ同士が(サーバを介さずに)直接通信 なんてことができるようになるらしいです． つまり WebRTCを使えば Skype っぽいものをプラグインのインストールなしにブラウザ上で実現できるってわけですね． Chrome の最新安定版で、ウェブの最先端に触れてみようから いろいろなWebRTCを使ったデモを見ることができます． 僕も似顔絵描いてもらったりしてみました．
getUserMedia API を使ってみる まだまだ仕様策定中で対応ブラウザがほとんどない状況ですが， 2012年10月現在，最新版の Chrome 21 で前者のローカルデバイスへアクセスするAPIである getUserMedia API が使えるようです． 早速遊んでみましょう．
navigator.getUserMedia( {video: true}, // constrains: 接続先のデバイス function successCallback(stream) { // アクセス成功 // stream に LocalMediaStream オブジェクトが入ってる // &amp;lt;video id=&amp;#34;video&amp;#34;&amp;gt;&amp;lt;/video&amp;gt; 要素を取ってくる var video = document.getElementById(&amp;#39;video&amp;#39;); // BlobURLに変換してsrcに入れる video.src = URL.createObjectURL(stream); // 再生 video.</description>
    </item>
    <item>
      <title>6さいカンファレンス 第2回「数学の定理を自動で発見するAI を Haskellで作ろう！」まとめ</title>
      <link>https://shogo82148.github.io/blog/2012/10/02/6saiconf-2/</link>
      <pubDate>Tue, 02 Oct 2012 13:07:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2012/10/02/6saiconf-2/</guid>
      <description>2012/09/13にくいなちゃんさん主催で開催された6さいカンファレンスのまとめ。 第2回は「数学の定理を自動で発見するAI を Haskellで作ろう！」です。
勝手にまとめてしまったので、何か問題があれば@shogo82148まで。
WELCOME TO HELL!! くいなちゃん: それでは、まず、数学の「定理」とは何か、について説明したいと思います。 みなさん、日常的に「定理」という言葉を使っていると思いますが、「定理」とは何か、説明できますか
くいなちゃん: 「教科書に載っている公式が、定理だ！」と思うかもしれませんね。 確かに、教科書にも定理は載っています。
くいなちゃん: では、曖昧な理解の方のために、厳密かつ ゆるふわに説明しましょう。
くいなちゃん: 定理とは、次のように定義できます。
公理であるならば、定理である。 定理を推論規則によって推論したものは、定理である。 以上。
くいなちゃん: はい、みなさんこれで定理が何かを理解したと思いますので、数学の定理を自動で発見するAIを作ろうと思います。
くいなちゃん: Haskellで。
Haskell! くいなちゃん: そもそも、Haskellって何？ という方もおられるかと思いますので、まずは Haskell について簡単に説明しておきたいと思います。
くいなちゃん: Haskell は、関数型言語です。 宣言的プログラミングによって、プログラムしていくプログラミング言語です。「○○は××である！」というのを繰り返してプログラミングする感じですね。　「まずは○○して、次に××しろ！」という C言語(手続き型言語)とはかなり異なります。
くいなちゃん: では具体的に、今回定理を発見するための数学の体系を説明しながら、同時に Haskell で実装してみることにしましょう。
くいなちゃん: 最終的には 大規模な数学体系の定理を発見するとしても、まずは試しに小さな体系で定理を発見してみることを考えます。 今回は、命題論理を対象としてみます。
定義 くいなちゃん: では、今回対象とする命題論理を、厳密に定義していきましょう。 まず、この体系で用いられる記号は、P　Q　R　￢　⇒　の5種類です。 この5種類をうまく並べると、この数学体系でのあらゆる式や命題が記述できます。
くいなちゃん: まあ、たとえば、　P⇒P　(PならばPである)　といった感じですん。 わかりますね。
くいなちゃん: ￢　は数学における否定によく使われる記号ですが、いまのところ、単なる記号にすぎず、意味は定義されていません
くいなちゃん: ちなみに、くいなちゃんはポーランド記法が好きなので、　P⇒P　を、　⇒PP　と書くことにしましょう</description>
    </item>
    <item>
      <title>6さいカンファレンス 第1回「C言語で作る、はじめてのDAW制作」まとめ</title>
      <link>https://shogo82148.github.io/blog/2012/09/30/6saiconf-1/</link>
      <pubDate>Sun, 30 Sep 2012 20:33:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2012/09/30/6saiconf-1/</guid>
      <description>だいぶ時間がたってしまったけど、2012/09/06にくいなちゃんさん主催で開催された6さいカンファレンスのまとめ。 第1回は「C言語で作る、はじめてのDAWソフト制作」です。
勝手にまとめてしまったので、何か問題があれば@shogo82148まで。
BATTLE START!! くいなちゃん: みなさんは、既にC言語の基本的なところはマスターしていると思いますが、念のために軽く復習しておきましょう。　まずは、このソースコードをご覧ください。 http://kuina.tes.so/6saiconf/a.png(魚拓)
#include &amp;lt;stdio.h&amp;gt; #include &amp;lt;math.h&amp;gt; int main(void) { return 0; } くいなちゃん: 右下の100% は気にしなくてOKです。　このプログラムは、「何もせず終了するだけ」のプログラムとなっています。　ソースコードを順に解説しましょう。
くいなちゃん: まず、1行目と2行目に書かれている #include ですが、これはおまじないです。　プログラムの本質は、4行目からとなります。
くいなちゃん: int main(void) { } が、プログラムの本質となります。　コンピュータがこのプログラムを起動すると、int main(void) { } の { と } に囲まれた部分を上から順に実行していきます。 } に辿り着いたら終了です。
くいなちゃん: よって、このプログラムは、 return 0; を実行するだけのプログラムとなります。　return 0; とは、おまじないです。　えへへ☆
DAWを作ってみる くいなちゃん: はい、もう、C言語の基本的なところは全てマスターできましたね。　では、早速 DAWソフトを作ってみましょう。
くいなちゃん: DAWとは、簡単にいいますと、曲を作るソフトです。　それでは、int main(void) { } の中に、DAWっぽいプログラムを書いていきましょう。　とりあえず、int i, j; を書きます。</description>
    </item>
    <item>
      <title>NDS28に参加してきた #nds28</title>
      <link>https://shogo82148.github.io/blog/2012/09/24/nds28/</link>
      <pubDate>Mon, 24 Sep 2012 14:29:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2012/09/24/nds28/</guid>
      <description>先週土曜日は第28回NDS(長岡技術者勉強会)でした。
スーツ vs ギーク Togetterのまとめを見ながら、内容を頑張って思い出してみる。 (せっかくローカルでブログ書ける環境作ったんだから、ちゃんとメモっとくべきですね・・・と思いつつ毎回できない)
プログラマは誰でもいい？ 人に依存しないことはいいこと でも、本当にそれでいいの？ 能力があれば誰もいいのかも 社長の方が誰でもいい (自称)ギークなスーツ 「これからはHadoopらしいよ」 ギークにもユーザの対応して欲しい 「技術的な制限で無理」なことを説明するときとか 浅い知識だけでは矛盾点を突かれて、Yesと言わざる負えない時も 「ときどき行く→ギーク行くといいじゃんってなる→ときどきが毎回になる」と困るよね 判断を全部ギークに丸投げしないで！ 例えば、初期コストを取るか、拡張性を取るか、とか 技術的な利点・欠点は説明するけど、実際どっち使うかの判断はスーツな人にお願いしたい スーツを手玉に取るコミュ力 コミュ力の低いギークは技術力を生かせなくてもったいない！ ギークもコミュ力を身につけるべき 名選手と名監督は両立しない 技術者からの叩き上げでマネージメントする側になった人は他人を上手く使えない マネージメント系は手足のように他人を使えなければならない 社会は怖いところです。
通常セッション マッチョ見積もり by @hiro55bsさん 「つまり、見積りは予想ではなく、帳尻をあわせるものなんだよ！」 見積もりはリスク管理、プロジェクト初期だけでなく随時やっていくもの プロジェクト初期では見積もりに幅があって当然 もる いろんな統計データからざっくり見積もれるんですね。勉強になります。 ワンライナーでノイズミュージック by @neko_gata_sさん Experimental music from very short C programsに触発されたというお話 RIFFヘッダつけるとこは Perl でやってます！ 波といえば正弦波の組み合わせで・・・と思っていたので、ビット演算で音を出してみるというのはおもしろいです。ぜひやってみたいです。 LT SIの現場から感じた未来 by @nemuzukaさん 現在の契約形態に対する問題提起 皆さんで考えて行きましょう RubyMotionでiOSゲームを作るっきゃない by @jewel_x12さん Pythonが主人公のゲーム Android版はまだですか？ Echigo Network Operators&amp;rsquo; Group について by @yyasuyukiさん コイントスで決めよう お姉さんのコンピュータを高速化したお話 補足とか スライド上げようと思ったんですけど、よく考えたら半分他人さまの画像使ってるのであまりよろしくないですね。 検索アルゴリズムの紹介などは「おねえさんのコンピュータを作ってみた」を ご覧ください。</description>
    </item>
    <item>
      <title>おねえさんのコンピュータを作ってみた</title>
      <link>https://shogo82148.github.io/blog/2012/09/22/letscount/</link>
      <pubDate>Sat, 22 Sep 2012 11:08:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2012/09/22/letscount/</guid>
      <description>まだやってたのか、と言われてしまいそうですが、おねえさんが計算にかけた時間と比べればまだまだです。
『フカシギの数え方』 おねえさんといっしょ！ みんなで数えてみよう！
この動画で出てくるおねえさんのコンピュータを作ってみた、というお話。
おねえさんのコンピュータからアクセスできます。
検索アルゴリズム HTML+CSSでコンピュータの画面を再現してみました。Javascriptを組むより、そっちの方に時間がかかった気がする。 経路の描画にはCanvasを使ってます。
この問題は自己回避歩行(Self-avoiding walk)と呼ばれるものらしいです。 単にグラフ上を移動するだけなので、小さいなサイズなら単純な深さ優先検索(DFS)で解けます(大きなサイズで何が起こるのか・・・それは動画で)。 実装では、DFSによる検索プログラムをWeb Workerを使って走らせ、スタートとゴールを結ぶ経路を見つけたらメッセージを飛ばしてます。
さすがに全部は表示できないので、実際に表示するのは50ms秒程度の間隔。 4×4以下ではそれだと速すぎて何が何だかわからないので、待ち時間を入れてある。
さあ、君も10×10にチャレンジだ！！
おねえさんに教えて上げよう！ しかしながらDFSだけだとなんだか負けた気がして悔しいので、高速化したアルゴリズムも試してみた。 「おねえさんに教えてあげる」のチェックボックスにチェックを入れると高速化したアルゴリズムで問題を解きます。
ゼロサプレス型二分決定グラフ 自分が色々試行錯誤している間に他の人が解いてしまった(「フカシギの数え方」の問題を解いてみた) ので、それを参考に実装してみた。
今回の問題は「グラフ上の経路問題」ですが、どの枝を通ってどの枝を通らないかという「枝の選択問題」として考えることができます。 その組み合わせを効率良く表すための方法が、ゼロサプレス型二分決定グラフ(ZDD; Zero-Suppressed Binary Decision Diagram)。 ZDDは数学の組み合わせでよく使う樹形図の一種で、 同じ結果になる枝を集めることで樹形図を効率良く表したものです。 概要はBDD/ZDDを基盤とする離散構造と処理演算系の最近の展望 を参照。 もっと詳しい説明はThe Art of Computer Programmingに書いてあるらしい(まだ読んでない)。
ZDDを考えた湊先生は最初の動画の企画・監修も努めている方なので、 動画中の数値もZDDを使って求めたものと思われます。
Simpath ZDDは単なる組み合わせの表現方法なので、別途グラフからZDDを求める手法が必要になります。 これに関する簡単な解説がZDDを用いたパスの列挙と索引生成 から見られます。
上のセミナー資料ではZDDの基本演算を使った列挙の方法が紹介されているけど、 今回はクヌース先生のSimpathを採用。 Simpathでは(既約でない)ZDDを作ることができます。 経路の両端にのみ着目し、この情報をmateという配列で管理。 frontierと呼ばれる頂点のmateを用いてZDD上のノードを共有することで簡略化を行います。
実際使ったアルゴリズム セミナー資料では幅優先でノードを作ってみるように見えるけど、今回の実装では深さ優先で経路数だけカウント。 ZDDのノードを作るのが面倒だったんです。 しかし、覚えなければならないmateが大量になってしまいメモリがああああ！！ すべて覚えるのは諦め、一部のmateだけ覚えるようにしました。
「おねえさんに教えてあげる」のチェックを入れると、適当実装のSimpathで計算します。 計算中一部の枝が灰色になるのは、ZDD上でノードの共有化が行われたため、実際には枝が処理されなかったためです。 格子上の点に丸がついているのはfrontier。 この点の継続情報を用いて共有化を行います。
まとめ おねえさんのコンピュータの実装と高速化を行いました。 高速化の結果、処理に数分かかっていた6×6の計算が200msで終わるようになりました。 10×10も1分程度で終わります。
ただ、表示のためのオーバーヘッドがあるとはいえ、他の人と比べると少し遅いような。 なにか実装間違っているかも。 The Art of Computer Programmingを読んで勉強しないとかな。</description>
    </item>
    <item>
      <title>VeeWeeでVagrantのboxを作ってみた</title>
      <link>https://shogo82148.github.io/blog/2012/09/01/veewee/</link>
      <pubDate>Sat, 01 Sep 2012 15:26:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2012/09/01/veewee/</guid>
      <description>Vagrant VagrantはコマンドラインからVirtualBoxを扱えるようにするツール。 仮想マシンの起動・再起動をコマンドライン上から行えるのはもちろん、Chefや Puppet と連携することで必要なソフトウェアのインストールを行なってくれます。
Vagrantを使うには仮想マシンのひな形であるBase Boxが必要です。 Vagrantbox.esにいろんなOSのBoxがあるけど、 インストールされているOSのバージョンが古かったり、タイムゾーンがUTCになっていたりして 不具合発生。 そこでBoxを自分で作ってみようと思い立ち、やってみたのでそのメモ。
作ったBoxは GitHub にあげておいたので使いたい方はどうぞ。 Ubuntu 12.04.2 Server + VirtualBox 4.2.10 で作ってあります。
vagrant box add myubuntu https://shogo82148.github.io/boxes/ubuntu-12.04.2-amd64.box VeeWee VeeWeeはBoxの作成を自動化してくれるツール。 OSのインストール、不要なパッケージの削除、Box化なんかを自動でやってくれるらしい。
VagrantとVeeWeeのインストール Rubyの実行環境とVirtualBoxのインストールを済ませたら、 gemを使ってVagrantとVeeWeeをインストール。
gem install vagrant gem install veewee 使ってみる vagrant basebox templates と打つとテンプレートの一覧が出てくる。 現時点でのUbuntu最新版であるUbuntu 12.04をテンプレートとして使ってみる。
vagrant basebox define myubuntu ubuntu-12.04-server-amd64 これでdefinitions/myubuntuの中に設定ファイルができる。
そのままだとisoのダウンロードで404が帰ってくるので設定ファイルを書き換え。 加えて日本語が使えるようにLocaleをja_JPに、タイムゾーンをAsia/Tokyoにしておく。
--- templates/ubuntu-12.04-server-amd64/definition.rb 2012-08-31 18:23:28.000000000 +0900 +++ definitions/myubuntu/definition.rb 2012-08-31 21:17:52.000000000 +0900 @@ -6,8 +6,8 @@ :hostiocache =&amp;gt; &amp;#39;off&amp;#39;, :os_type_id =&amp;gt; &amp;#39;Ubuntu_64&amp;#39;, :iso_file =&amp;gt; &amp;#34;ubuntu-12.</description>
    </item>
    <item>
      <title>Octopress用OEmbedプラグインを作ってみた</title>
      <link>https://shogo82148.github.io/blog/2012/08/09/oembed/</link>
      <pubDate>Thu, 09 Aug 2012 18:43:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2012/08/09/oembed/</guid>
      <description>Octopressでツイートを引用しようと思ったけど 使えそうなプラグインがなかったので作ってみた。 ツイートに限らずいろんなものを挿入できるよ！
OEmbed 調べてみるとツイートの表示はOEmbedというのを使うとできるらしい。 これはURLを埋め込み適した形に変換してくれるプロトコル。 ツイートのURLから引用のためのHTMLを作ったり、YouTubeのURLから動画再生用のHTMLを作ることができる。
せっかくだからOEmbedに対応してしまえばいろんなものを埋め込めて便利だよね！ってことでやってみた。
インストール ruby-oembedをインストール。
gem install ruby-oembed ruby-oembedは名前から想像できる通り、RubyでOEmbedプロトコルを扱うためのライブラリ。 Provider(OEmbedの提供者)を自分で追加したり、Discovery(HTMLドキュメントにProviderの情報を入れる)にも対応している。 しかし、プロキシ環境下で動かなかったり、文字コードのエラーを吐いて死んだりしたので、 フォークして改造版ruby-oembedを作った。 もしオリジナルで不具合が出るようなら、こちらもどうぞ。
oembed_tagからoembed_tag.rbをダウンロードして、pluginsフォルダに置く。
Gemfileを適当なテキストエディタで開き、「gem &amp;lsquo;ruby-oembed&amp;rsquo;」の行を追加
source &amp;#34;http://rubygems.org&amp;#34; group :development do gem &amp;#39;rake&amp;#39; gem &amp;#39;rack&amp;#39; gem &amp;#39;jekyll&amp;#39; gem &amp;#39;rdiscount&amp;#39; gem &amp;#39;pygments.rb&amp;#39; gem &amp;#39;RedCloth&amp;#39; gem &amp;#39;haml&amp;#39;, &amp;#39;&amp;gt;= 3.1&amp;#39; gem &amp;#39;compass&amp;#39;, &amp;#39;&amp;gt;= 0.11&amp;#39; gem &amp;#39;rubypants&amp;#39; gem &amp;#39;rb-fsevent&amp;#39; gem &amp;#39;stringex&amp;#39; gem &amp;#39;liquid&amp;#39;, &amp;#39;2.2.2&amp;#39; gem &amp;#39;ruby-oembed&amp;#39; #追加 end gem &amp;#39;sinatra&amp;#39;, &amp;#39;1.2.6&amp;#39; これでとりあえずは動くはず。 以上の作業に加えて、キャッシュファイルがリポジトリに含まれないよう.gitignoreに.oembed-cacheを追加しておく。
使い方 以下の様に書くと、適切な埋め込み方法をWebから取得して変換してくれる。
&amp;amp;#123;% oembed URL %&amp;amp;#125; 例 Twitter &amp;amp;#123;% oembed https://twitter.</description>
    </item>
    <item>
      <title>OMakeの使い方復習</title>
      <link>https://shogo82148.github.io/blog/2012/08/09/omake/</link>
      <pubDate>Thu, 09 Aug 2012 11:13:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2012/08/09/omake/</guid>
      <description>久しぶりにOMakeを使おうと思ったら、使い方を忘れてしまったので復習。
基本的な流れ 初期化 OMakeのインストールはaptitudeやyumやDownload OMakeあたりで頑張る。 OMakeがインストールできたら、まずは初期化のおまじない。
omake --install カレントディレクトリにOmakefileとOmakerootが作られる。 自分のプロジェクト内容に合わせてOmakefileを編集。 具体的な例は後述。
ビルドする 単に「omake」と打つとビルド
omake 継続監視ビルド 「-P」オプションで継続監視ビルド
omake -P 関連するファイルを監視して、変更があれば自動的にビルドしてくれる。
キャッシュの削除 OMakeでビルドすると環境依存なパスの設定とかを書き込んだファイルが作成される。 Dropboxなどの同期ソフトはこれらの設定ファイルも同期してしまうので、 別環境で作業しようとするとエラーを吐いて止まってしまう。
次のコマンドでキャッシュファイルを無視すれば大丈夫。
omake --flush-includes Omakefileの例 TeXの文章をビルドするOMakefileの例。 LinuxとWindowsでデフォルトの文字コードが違って面倒なので、文字コードはutf-8に統一。 PDF出力はA3サイズ。
{% gist 3300749 OMakefile %}
prosperを使ってプレゼン資料を作った時のOMakefile。 dvipdfmでは処理できない場合があるので、一度PostScriptにしてからPDFに変換するようにルールを上書き。 数式を多用するようなプレゼン資料だと便利。
{% gist 3300749 OMakefile-slide %}
参考 OMake つかったらC言語でプログラム書く手間がバカみたいに減った OMake つかって LaTeX コンパイルしたら簡単すぎて身長が5cm伸びた OMake マニュアル日本語訳 omakeが動かない &amp;hellip;. 動いた [卒論] LaTeXのビルドにOMakeを使ってみた おまけ Dropboxと連携するとこんなことも。
Dropboxで同期しているフォルダで、「omake -P」を実行して自動コンパイルする設定のまま放置してきちゃった。別のPCでソース書き換えると、Dropboxが同期→リモートのomakeが自動コンパイル→Dropbox経由でコンパイル結果が帰ってきた。
&amp;mdash; Ichinose Shogoさん (@shogo82148) 9月 27, 2011 </description>
    </item>
    <item>
      <title>夏だ！花火だ！Androidで遊ぼう！</title>
      <link>https://shogo82148.github.io/blog/2012/08/02/fireworks/</link>
      <pubDate>Thu, 02 Aug 2012 14:43:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2012/08/02/fireworks/</guid>
      <description>さあ、皆さん！今年も長岡の大花火大会の季節がやって参りました！
花火大会といえば、 光と音の速度差を体感できる絶好の機会です。 というわけで、去年もこんなアプリを作って遊んでました。 このアプリを頑張って改良したので、改めて紹介したいと思います。
アプリをダウンロード
使い方 起動すると、こんな画面が表示されます。
花火が開いたら画面をタップ！ そして、花火が画面中央に来るよう素早く端末を動かします。 (※画像ははめ込み合成です)
花火の音がしたら、目標をセンターに入れてタップ！
タップの間隔から花火までの距離を計算し表示してくれます。 さらに、加速度センサの値から端末の仰角を読み取り、花火の高さや水平距離などを算出してくれるという機能もついてます。
去年からの変更点 と、ここまでは、去年と一緒。 今年はさらにパワーアップしました。
地図へのマッピング スマートフォンには磁気センサがついており、方位が分かります。 加えて、GPSもついているので、スマートフォンの現在位置も分かります。 これだけの情報が揃えば、地図にプロットできるはず！
結果表示の画面で「地図を表示」を選ぶとマッピングしてくれます。 この画面でメニューキーを押すと、TwitterやGoogle+などで、花火の位置をみんなに知らせることもできます。
GPS測位ができない場合は、デフォルトの位置を使用します。 この位置は設定画面で変更できます。
自動花火検出 去年からの課題であった、花火の自動検出も試みてみました。 初期画面でメニューキーを押すと設定画面へ飛べます。
ここで「花火を自動的に検出する」「花火の音を検出する」を選択すると、自動検出してくれるはずです(※理論値)。
花火が開いたことは、画面が明るくなったことで検出します。 明るさの検出は初期画面中央の四角の中が使われます。 設定画面でこの四角の大きさを変えることができます。 明るさの変化が閾値を超えたら測定開始です。
音は音量で検出します。 音声にDFTをかけて、周波数フィルタリングをかけてあります。 これで人ごみにまぎれても花火の音が検出できる・・・はず。 周波数0Hzにすると、周波数フィルタを通さずに振幅のみで判定します。
検出した値は、画面の右上に表示しているので、設定の時の参考にしてください。
ダウンロード アプリをダウンロード
野良アプリなので、「設定→アプリケーション→提供元不明のアプリ」をチェックする必要があります。 スマートフォンの機能をフル活用するので権限をたくさん要求してきますが、きっとだいじょうぶ。 そろそろマーケットでの公開も試してみたいですね。
** Google Play にリリースしました！ ** Google Play からアプリをダウンロード まとめ それでは、大幅に機能UPしたアプリと一緒に、長岡の大花火大会をお楽しみください。
打ち上げはこのあたりらしいです。 ちゃんとマッピングできますかね？</description>
    </item>
    <item>
      <title>Gitでプロキシを使う</title>
      <link>https://shogo82148.github.io/blog/2012/07/30/git-proxy/</link>
      <pubDate>Mon, 30 Jul 2012 21:10:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2012/07/30/git-proxy/</guid>
      <description>背景・目的 なぜだか研究室のWiFi経由でSSHが通らないので、 GithubがBitbucketに繋がらない＞＜。 有線LAN経由なら通るので、ネットワークの問題だと思うのですが、 よくわからないのでとりあえずHTTPS経由で頑張ることにしました。
うちの学校ではHTTPSで外部に出るにはプロキシの設定が必要です。 そういうわけで、Gitでプロキシを使う方法を調べて見ました。
方法 .ssh/config に以下の設定をしました。
Host github.com User git Port 22 # or 443 Hostname github.com # or ssh.github.com IdentityFile /path/to/ssh.key TCPKeepAlive yes IdentitiesOnly yes ProxyCommand nc -X connect -x proxy.example.com:8080 %h %p 参考文献 git pull/push to github.com in proxy environment http proxy 越えの ssh SSHでプロキシ経由でアクセス </description>
    </item>
    <item>
      <title>NDS27に参加してきた</title>
      <link>https://shogo82148.github.io/blog/2012/07/29/nds27/</link>
      <pubDate>Sun, 29 Jul 2012 23:45:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2012/07/29/nds27/</guid>
      <description>第27回NDS(長岡技術者勉強会)に参加してきました。
Gitハンズオン 今回はNiigata.scmとのコラボで GitハンズオンといつものLTの二本立てでした。
@masaru_b_clさんのGitの歴史や利点についての解説の後、 @dictavさんによる解説・演習。
addしてcommitする logやreflogでログ確認 reset &amp;ndash;hard で元に戻す merge rebaseでコミットログを一本道に あたりをやりました。
一つのファイルの同じ行を20人でいじるという怖いこともしました。 凄まじいコンフリクト発生頻度と、すごい勢いで分岐していくログ。 実際の現場であったら恐ろしいですね。 gitはプラグインが使えるので、いろんなプラグインが出てます。 今回紹介があったのはgit-nowとgit-master。名前だけは聞いたことあるんだけど、使ってみますかね。
git-now masuru_b_clさんバージョン git-master あと、コミットログ英文の書き方とか
Changelogのための英文テンプレート集
ust Gitの説明
ust 午前の演習その1
ust 午前の演習その2
ust 午後の部 push戦争
いつものLT 電子国土と地形図(その後) (@yu_hori)[http://twitter.com/yu_hori]さん NDS23での電子国土地図の発表の続き。 利用者にとって価値ある使いやすい電子国土基本図を目指して(中間提言) 電子国土ポータル 長岡にギークハウスを @geek_niigataさん やったーPICで作曲できたよー＼(^o^)／ @aokcub うおおおおおおおおおお！！！！ 期待の21世紀枠最後の昭和枠 NDS27に参加してきたよ！よ！ git-svn @masaru_c_blさん svnのリポジトリをgitにしてしまう奴。 ソフトウェアメトリクス調査2012を読み解く @hiro55bsさん ソフトウェアメトリックス調査2012 COBOL&amp;hellip; 品質が低いと顧客満足度も低いけど、逆に品質が高すぎても顧客満足度は低い お客さんの要望に十分に答えられないのが原因？ やったーPerlでにゃん読化ツールできたよー＼(^o^)／ @neko_gata_sさん Niigata.pm 遊びに来てね NDSから大切なお知らせ @civicさん プロジェクトアンブレラ Niigata.pmはNDSの傘下 SRNDS(それNDSでできるよ) PSO aokcubさんの使ってたPSO面白そうだったので現実逃避に実装。 実際の効果はよくわからない。 初期値の時点でミニマムの近辺から外れると、ローカルミニマムに落ちることもしばしば。 それなら最急降下法でも・・・という気もしないでもない。 問題設定が悪いのか、パラメータが悪いのか。</description>
    </item>
    <item>
      <title>CやC&#43;&#43;でのincludeの優先順位</title>
      <link>https://shogo82148.github.io/blog/2012/06/26/c-include/</link>
      <pubDate>Tue, 26 Jun 2012 11:13:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2012/06/26/c-include/</guid>
      <description>こんにちは、gccのオプションを十個も言えない、非人のshogoです。
工藤氏作のTinySVMで遊ぼうとしていたところ、 ヘッダファイルの読み込み順序ではまったのでメモ。
2つのinclude文 皆さんご存知の通り、Cプリプロセッサの#include文ではファイルの指定方法が2種類あります。
#include &amp;lt;somefile&amp;gt; // システムにインストールされたライブラリを使う場合 #include &amp;quot;somefile&amp;quot; // 自作のヘッダファイルなどを読み込む場合 大抵はコメントで書いたような使い分けをするんじゃないかと思います。 両者の違いはファイルの検索対象となるディレクトリの違いにあります。 前者はコンパイラが知っているディレクトリのみを検索するのに対して、 後者はカレントディレクトリを検索したのち、&amp;lt;&amp;gt;と同じディレクトリを検索します。
コンパイラが知っているディレクトリは具体的に書くと次のようになっています。
-I オプションで指定されたディレクトリ 環境変数 C_INCLUDE_PATH や CPLUS_INCLUDE_PATH で指定されたディレクトリ システムによって予め決められたディレクトリ(/usr/local/includeとか) 上にあるものほど優先順位高く、同名のファイルがあった場合、優先順位の高いディレクトリにあるものが読み込まれます。
標準のヘッダを使いたい 次のようなCのプログラムを考えてみます。
/* sample.c */ #include &amp;lt;stdio.h&amp;gt; // 標準ヘッダのstdio.hを取り込んでほしい！ #include &amp;#34;stdio.h&amp;#34; // ../userheaderディレクトリ内のstdio.hを取り込んでほしい！ 最初のincludeではシステムに用意された標準ヘッダのstdio.hを、 2つ目のincludeでは自前で用意したstdio.hを読み込もうとしています。 しかし、自前で用意したstdio.hはuserheaderという別ディレクトリにあるので このままでは参照できません。
別ディレクトリにあるヘッダファイルを参照する場合、一般的には-Iオプションを使って次のようにコンパイルすると思います。
gcc -I../userheader sample.c しかしこの例の場合はこの方法は上手く行きません。 &amp;lt;&amp;gt;で囲った場合も&amp;quot;&amp;ldquo;で囲った場合も、カレントディレクトリにはstdio.hは見つからないので、 先の優先順位に従って次のような順番で検索を行います。
userheader 標準ヘッダstdio.hが入ったディレクトリ どちらの書き方でもuserheader内のstdio.hを先に発見してしまうので、 標準ヘッダのstdio.hにはどう頑張ってもアクセスすることができません。
解決策 iquoteオプションを使うと、&amp;quot;&amp;quot;で囲った場合のみuserheaderを見に行くようになります。
gcc -iquote../userheader sample.c TinySVMの場合 TinySVM0.09(現時点での最新版)は一部環境でgetoptの違うというエラーが発生するようです。 これは-Iオプションを使ってしまったため、標準ヘッダのgetopt.hと、自前で用意したgetopt.hの使い分けができていないのが原因です。
TinySVMに同梱されたgetopt関数の引数を書き換えることで対処している例がほとんど (himorogiの日記, RとLinuxと&amp;hellip;,etc) ですが、大抵の環境にgetoptはあると思うのでgetopt.hを削除してしまったほうがいいかもしれません。 (TinySVM最近更新されていないのでgetoptが古いし)
参考 C言語のヘッダ読み込み順について Directory Options - Using the GNU Compiler Collection (GCC) The C Preprocessor pp.</description>
    </item>
    <item>
      <title>第1回 意味知識勉強会</title>
      <link>https://shogo82148.github.io/blog/2012/04/20/semantic-knowledge/</link>
      <pubDate>Fri, 20 Apr 2012 15:12:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2012/04/20/semantic-knowledge/</guid>
      <description>なんだか誘われたので、行ってきた。 メモメモ。
紹介された論文とか、スライドは自然言語処理研究室の意味知識勉強会のページからどうぞ。
関連学会 ACL AAAI IJCNLP Coling JIST 人工知能学会誌 自然言語処理(学会誌) 背景 人工知能の目指すところ 常識知識(common-sense knowledge)が必要 知識表現 オントロジー(ontology) 上位オントロジー 具体的な事象を対象としないオントロジー 常識オントロジー(Common-Sence Ontology) OpenCyc 語彙オントロジー(e.g. WordNet) 形式オントロジー OpenCyc 常識知識をデータベース化するCyc Project の一部。 専門家の手によって、手作業で構築されているオントロジー。 Open Mind Common Sense(OMCS) 機械的な常識知識獲得プロジェクト。 獲得した知識は ConceptNet というデータベースに取り込まれる。 GithubにデータベースアクセスのためのAPIが上がってるよ。 Recognizing Textual Entailment(RTE) テキスト含意関係認識 テキスト(Text)に対する仮定(Hypothesis)が含意している・矛盾している・Uknownであるかを判定するタスク RTEの初期のデータセットは無料で公開されている 論文紹介:Types of Common-Sense Knowledge Needed for Recognizing Texual Entailment RTE-5データセットから常識知識がなければ解けないものを「人手」で選択 単語の単純な言い換えなどで解決できないもの 600あるデータセットから108個見つけた 仮説が含意していると判定されるために必要な根拠を考える 分類して整理したよ！ 必要とされる回数が多いカテゴリは重要だよね！(ホント？元のデータセットに偏りない？) 言語処理でよく使うpart-of, is-a の様な関係が使われるのは、全体の40%でしかない 分類が正しさを表す指標としてκ値(Fleiss&amp;rsquo;s κ)を使って評価 20のカテゴリは大きく3つ分けられる
Form-based Categories 因果関係とか Content-based Categories 計算しないといけない奴とか 地理関係とか Miscellaneous Categories みんなやっているから、この人もやっているはず！みたいな根拠のない関係 Omniscience(全知) </description>
    </item>
    <item>
      <title>Linuxでプロキシの除外設定</title>
      <link>https://shogo82148.github.io/blog/2012/04/09/no-proxy/</link>
      <pubDate>Mon, 09 Apr 2012 13:40:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2012/04/09/no-proxy/</guid>
      <description>僕の学校では、学校のネットワークから外へ出ていくためにはプロキシと通す必要があります。 しかし、学内にあるサーバへは直接接続しなければなりません。
これを行うには no_proxy という環境変数を設定すればよいようです。
# Proxy 設定 export http_proxy=http://example.com:port/ export ftp_proxy=http://example.com:port/ export HTTP_PROXY=http://example.com:port/ export FTP_PROXY=http://example.com:port/ # 除外したいドメイン export no_proxy=localhost,.example.com no_proxyにカンマ区切りで除外したいホストを列挙します。 この設定を .bash_profile などに書いておけば、起動時に反映されるようになります。
全く・・・プロキシ面倒・・・。</description>
    </item>
    <item>
      <title>NDS25に参加してきた</title>
      <link>https://shogo82148.github.io/blog/2012/04/02/nds25/</link>
      <pubDate>Mon, 02 Apr 2012 00:44:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2012/04/02/nds25/</guid>
      <description>第25回NDS(長岡技術者勉強会)に参加してきました。 どこかの誰かが、ブログを書くまでが勉強会だ、と言っていた気がするので簡単に書いてみます。
Togetterまとめ
負荷テストことはじめ(JMeterハック) (@nemuzuka)
JMeterはサーバにたくさんリクエストを送って、その時の挙動を見るためのJava製ツール サーバ-クライアント間の通信を読み取ってそのまま再現したり、CSVからデータを吸いだしてリクエストに埋め込んだり、レスポンスからデータを吸い出したり、JavaScriptで挙動をカスタマイズできたりするらしい slideshare「負荷テストことはじめ」 ust「負荷テストことはじめ」 雪のシミュレーション(一部ハッキングが入ります) (@piras4)
気象庁が提供しているアメダスのデータなどから、雪の状態(温度とか密度)を計算するお話 熱伝導方程式とか微分とか忘れました ust「雪のシミュレーション」 Remember the MilkでGTD（RTMハック） (@masaru_b_cl) LT
Remember the Milk は ToDo 管理のための Web サービス Webフォームからはもちろん、メールやTwitterからもToDoを作成できる slideshare「GTD on RTM」 ust「Remember the MilkでGTD」 JavaerがiPhoneアプリ開発入門してミタ（Objective-Cハック）　(@makomegane)
Keynote はアイコンを作るためのツール App Store のアプリのスクリーンショットは、自分の子供の可愛さを伝える場 Java と Objective-C の比較(メモリ管理の仕方とか) [ust「JavaerがiPhoneアプリ開発入門してミタ」]http://www.ustream.tv/recorded/21483875 「やったーGAでDTMできたよー＼(^o^)／」 (@neko_gata_s)
遺伝的アルゴリズムで簡単な作曲をやってみようというお話 メロディを機械的にどう評価するかが難しい 評価関数が解析的に簡単に解けてしまって面白くないな・・・今後の検討課題ですね スライド ust「やったーGAでDTMできたよー＼(^o^)／」 ブログ CSharperがWindows Phoneアプリ開発入門してミタ（C#ハック） (@ailight)
C# はモテ言語 LT1 花火アプリを作りたい
作る前からパクられた LT2 HTMLからePub(@civic)
数あるHTMLで書かれたWebページをePubにして、iPadとかで見やすくしよう！というライブラリ 残念ながら、相手方にDOS攻撃を仕掛ける危険なプログラムのため、公開はできないとのこと </description>
    </item>
    <item>
      <title>JavascriptでIME</title>
      <link>https://shogo82148.github.io/blog/2012/03/28/igoime/</link>
      <pubDate>Wed, 28 Mar 2012 22:00:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2012/03/28/igoime/</guid>
      <description>この前いじったChrome17対応版AjaxIMEは 実際の変換を行うのに本家AjaxIMEが提供している変換サーバをそのまま使用しています。 そのため、すべての入力内容は本家サーバに送信されてしまいます。 どんな入力をしたのか作者さんにバレバレです。 この送信内容、暗号化すらされていないので、作者以外の人に見られる可能性もあります。 自分の書いた文章が勝手にインターネットに送信されているっていうのはあんまり嬉しくないですね。 ローカルのみで完結するのが理想です。
本家サーバはどうやらmecab-skkservと同じエンジンを使っているようです。 このバックエンドで動いているのは実はMeCab。 ということは、MeCabと互換性のあるigo-javascriptでも同じことができるはず・・・！ これはならブラウザ上ですべてが完結する！
はい、そういうことで作ってみました。
IgoIME 使い方は本家と一緒です。Alt-o (Ctrl-9)でモード切替。 ローマ字で日本語を入力することができます。
日本語入力をするためには変換候補をいくつか出力する必要がありますが、 本来Igoにはその機能はありません。 そのため、複数候補を出す部分だけ独自実装してあります。 しかし、まだなんか変換候補が怪しいですね・・・。 長い文章を入力したのに一文字しか結果が帰ってこないことがあります。 なんでだろう・・・・
まだまだ改良が必要なようです。</description>
    </item>
    <item>
      <title>Javascriptでの関数宣言</title>
      <link>https://shogo82148.github.io/blog/2012/03/23/javascript-function/</link>
      <pubDate>Fri, 23 Mar 2012 18:22:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2012/03/23/javascript-function/</guid>
      <description>Chrome17対応版AjaxIME Ajaxを使ってIMEを実現したAjaxIMEがFireFoxでは動くのに最新版のChromeで動かない。 動くように少しいじってみた。
Chrome17対応版AjaxIME 原因 Chromeで動かなかった原因はここ。
if(typeof getComputedStyle == &amp;#39;undefined&amp;#39;) { function getComputedStyle() { //中身は省略 } } FireFoxやChromeには getComputedStyle という関数が定義されているけど、 IEには定義されていない。 if文で有無を判定して、無い場合は動作をエミュレートする関数を定義している。
実行の様子をデバッガで追って見ると、Chromeではエミュレートする必要が無いのになぜか自前で定義した関数が呼び出されていた。 どうやら、Chromeでは 自作 getComputedStyle 関数が if文の中にあったとしてもコード読み込み時に作成されてしまうみたい。 FireFox だと if文の中が実行されない場合には作成されない。
結果だけ書くと、次のように書きなおしたら動いた。
if(typeof getComputedStyle == &amp;#39;undefined&amp;#39;) { getComputedStyle = function() { //中身は省略 } } あと Chrome だと、Input要素にフォーカスがあたった時に余計な装飾がついてしまうので、CSS上書きして抑制。 IE8でTextRangeが使えない問題は「IE8でのTextRange.moveToPoint()」を参考にして解決。 IE7のエミュレートモードにしているだけで、根本的な解決にはなってないけど、まあIEだしいいでしょ。
どっちが正しいの？ とりあえず問題は解決したんだけど、FireFoxとChromeで動作が違うけど、どちらの動作が正しいの？ 気になったので調べてみた。
「mixi Engineers&amp;rsquo; Blog &amp;raquo; 詳細 ECMA-262-3 第5章 関数」に関数の定義法についてわかりやすい解説が載っていた。 結論からいうと、一番初めの書き方は「誤り」で実際の動作は実装依存、つまり FireFox の動作も Chrome の動作も正しいとのこと。
関数定義と関数式 関数の定義法は大きく分けて、次のような関数定義と関数式に分かれている。 関数式は更に名前なしと名前付きがある。
//関数定義 function foo() { } //名前なしの関数式 var foo = function() { }; //名前付きの関数式 var foo = function _foo() { }; 普通の関数定義と無名関数があるのは知っててけど、単なるシュガーシンタックスみたいなものかと思った。 mixiのブログによると全くの別物。 関数定義と関数式の大きな違いは、実行時に呼び出し可能になっているかどうか。 関数定義は実行時に呼び出し可能になっているから、定義と呼び出しの順番は関係ない。</description>
    </item>
    <item>
      <title>GitHubにブログを設置してみたよ</title>
      <link>https://shogo82148.github.io/blog/2012/03/21/test/</link>
      <pubDate>Wed, 21 Mar 2012 19:29:00 +0900</pubDate>
      <guid>https://shogo82148.github.io/blog/2012/03/21/test/</guid>
      <description>TLにGitHubでブログのホスティングしている人がいたので、 「githubとjekyllとoctopressで作る簡単でモダンなブログ」 を参考に作ってみましたよ。
RVM のインストール 自分の環境には Ruby 1.9.2.2 が入っているんだけど、Ocropressでは Ruby 1.9.2 が必要らしい。 そのままでもいけるかと思ったけど、怒られた。 rake コマンドを全部 bundle exec rake に置き換えると一応実行はできるけど、なんだか警告がでる。
こういう時は複数のバージョンの Ruby を切り替えて管理できる、 rvm というのを使うといいらしい。 公式サイトの「Installing RVM」通りにコマンドを打てばOK。
bash -s stable &amp;lt; &amp;lt;(curl -s https://raw.github.com/wayneeseguin/rvm/master/binscripts/rvm-installer) echo &amp;#39;[[ -s &amp;#34;$HOME/.rvm/scripts/rvm&amp;#34; ]] &amp;amp;&amp;amp; . &amp;#34;$HOME/.rvm/scripts/rvm&amp;#34; # Load RVM function&amp;#39; &amp;gt;&amp;gt; ~/.bash_profile source ~/.bash_profile rvm install 1.9.2 &amp;amp;&amp;amp; rvm use 1.9.2 rvm rubygems latest Octopress のインストール あとはgitでクローンして、インストールコマンドを叩くだけ。
git clone git://github.com/imathis/octopress.git octopress cd octopress gem install bundler bundle install rake install rake setup_github_pages 最後のコマンドは GitHub Pages に公開するためのもの。公開用のレポジトリを聞いてくるので予め登録しておこう。</description>
    </item>
  </channel>
</rss>
