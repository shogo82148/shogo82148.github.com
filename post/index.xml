<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Shogo&#39;s Blog</title>
    <link>https://shogo82148.github.io/post/</link>
    <description>Recent content in Posts on Shogo&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <lastBuildDate>Wed, 24 Mar 2021 21:57:00 +0900</lastBuildDate><atom:link href="https://shogo82148.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AWS_SECRET_ACCESS_KEY を GitHub Actions secrets へ突っ込むのに疲れた俺達は</title>
      <link>https://shogo82148.github.io/blog/2021/03/24/actions-check-permissions/</link>
      <pubDate>Wed, 24 Mar 2021 21:57:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2021/03/24/actions-check-permissions/</guid>
      <description>「GitHub Actions から継続的デプロイをしたい！」と思ったときに、 僕の扱うデプロイ先は AWS なことが多いので AWS のキー (AWS_ACCESS_KEY, AWS_SECRET_ACCESS_KEY ) を GitHub Actions secrets へ突っ込む必要があります。 まあ一回や二回ならやるんですが、デベロップメント、ステージング、プロダクション、と複数環境あったり、 プロジェクトも複数あったりして、中々の回数設定を行わなければなりません。 設定するだけでつらいのに、AWS はキーのローテーションを勧めてきます。つらい。
と言うわけで、シークレットの管理を極力しなくて済む方法を考えて、設定用の Action を作成しました。
 shogo82148/actions-aws-assume-role Configure AWS Credentials by Assuming Roles  使い方 まずは AWS 側に IAM Role を作成します。 IAM Role の信頼関係(trust policy) には以下の内容を記載します。 信頼する AWS アカウントには 053160724612 を指定してください。 これは僕の管理している AWS アカウントなので、僕を信頼できる方だけこの先に進んでください。 外部 ID(ExternalId) にはこのロールを使用する予定のレポジトリ名を入れます。
{ &amp;#34;Version&amp;#34;: &amp;#34;2012-10-17&amp;#34;, &amp;#34;Statement&amp;#34;: [ { &amp;#34;Effect&amp;#34;: &amp;#34;Allow&amp;#34;, &amp;#34;Principal&amp;#34;: { &amp;#34;AWS&amp;#34;: &amp;#34;arn:aws:iam::053160724612:root&amp;#34; }, &amp;#34;Action&amp;#34;: &amp;#34;sts:AssumeRole&amp;#34;, &amp;#34;Condition&amp;#34;: { &amp;#34;StringEquals&amp;#34;: { &amp;#34;sts:ExternalId&amp;#34;: &amp;#34;your-name/your-repo&amp;#34; } } } ] } IAM Role に付与するパーミッションは、用途に合わせてご自由に設定してください。</description>
    </item>
    
    <item>
      <title>Dependabot が起動する GitHub Actions Workflow から write 権限が無くなった件</title>
      <link>https://shogo82148.github.io/blog/2021/03/17/actions-check-permissions/</link>
      <pubDate>Wed, 17 Mar 2021 19:14:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2021/03/17/actions-check-permissions/</guid>
      <description>Dependabot から送られてくるプルリクエストのテストが最近良くコケるようになったなあと思ったら、 3 月 1 日から GitHub Actions Workflow 内の GITHUB_TOKEN のパーミッションが変更になったそうです。
 GitHub Actions: Workflows triggered by Dependabot PRs will run with read-only permissions  更新されたパッケージに secrets を盗み見るような危険なコードが含まれているかもしれません。 そのようなコードでも安全に実行できるよう read-only のパーミッションで実行されるようになりました。
その結果以下のようなワークフローが失敗するようになってしまいました。
 プルリクエストにラベルをつけるような、レポジトリに対して write パーミッションが必要なワークフロー 外部サービスとのインテグレーションテストをやっていて、連携のためにシークレットを読む必要があるワークフロー  対応 pull_request_target トリガーを使うと、 フォークされたレポジトリからのプルリクエストも、Dependabot からのプルリクエストも、 write 権限がついた状態で実行されます。 プルリクエストにラベルをつけるようなワークフローはこれで十分です。
問題はインテグレーションテストのためのワークフローです。 シークレットへのアクセスをともなうので、内容を確認してからインテグレーションテストを実行する必要があります。 これに関しては Dependabot によってトリガーされたワークフローを re-run したら write パーミッションで走り出した (2021-03-17 現在) ので、面倒だけどまあ毎回 re-run するか・・・と現状なってます。 (そもそもこれって意図した挙動なんだろうか？)
もっといい解決方法をご存じの方は教えて下さい。
GITHUB_TOKEN のパーミッション判定の難しさ さて、失敗するとわかっているインテグレーションテストを実行する意味はないので、 read-only パーミッションで実行されていることを早い段階で検知してワークフローを即失敗させたいですよね。
しかし、今回のこの変更により GITHUB_TOKEN のパーミッションが read/write なのか read-only なのか区別することが非常に難しくなりました。 今までは「フォークされたレポジトリからのプルリクエストか？」で判定できたものが、「Dependabot から送られてきたプルリクエストか？」という条件が加わり、 さらに 「Dependabot から送られてきたプルリクエストを re-run したか？」という判定の難しい条件が加わります。</description>
    </item>
    
    <item>
      <title>AWS Lambda Perl Runtime Layer in 大阪リージョン を公開しました</title>
      <link>https://shogo82148.github.io/blog/2021/03/02/perl-lambda-in-ap-northeast-3/</link>
      <pubDate>Tue, 02 Mar 2021 14:50:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2021/03/02/perl-lambda-in-ap-northeast-3/</guid>
      <description>AWS 大阪リージョンが一般利用可能になりました！
 AWS Asia Pacific (Osaka) Region Now Open to All, with Three AZs and More Services [AWS] 日本 2 番目となる大阪リージョン ap-northeast-3 が利用可能になりました ［速報］「AWS 大阪リージョン」正式オープン。大阪ローカルリージョンを拡張し 3 つのアベイラビリティゾーンから構成、事前申し込みなど不要に  というわけで、 AWS Lambda Perl Runtime AWS::Lambda in Osaka を公開しました。
 ランタイム本体: arn:aws:lambda:ap-northeast-3:445285296882:layer:perl-5-32-runtime-al2:1 AWS SDK for Perl: arn:aws:lambda:ap-northeast-3:445285296882:layer:perl-5-32-paws-al2:1 Zip Archive: https://shogo82148-lambda-perl-runtime-ap-northeast-3.s3.amazonaws.com/perl-5-32-runtime-al2.zip Zip Archive: https://shogo82148-lambda-perl-runtime-ap-northeast-3.s3.amazonaws.com/perl-5-32-paws-al2.zip  大阪の Perl Monger の皆さん、ぜひご利用ください。</description>
    </item>
    
    <item>
      <title>ghq list が interrupted system call で死ぬ問題を直した</title>
      <link>https://shogo82148.github.io/blog/2021/02/28/fix-ghq-list-fails-with-interrupted-system-call/</link>
      <pubDate>Sun, 28 Feb 2021 23:42:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2021/02/28/fix-ghq-list-fails-with-interrupted-system-call/</guid>
      <description>常用している Mac Book Pro の OS を Big Sur に上げたんだけど、 ghq list が以下のエラーを吐くようになってしまった。
$ ghq list error failed to filter repos while walkLocalRepositories(repo): interrupted system call  ghq list sometimes fails with interrupted system call #311  結論からいうと Go 1.14 から入った以下の変更が原因だったんだけど、 実際に遭遇したのは初めてだったのでメモ。
 Go 1.14 でシステムコールが EINTR エラーを返すようになった  Go 1.14 でランタイムに入った変更 根本的な原因は Go 1.14 リリースノート のこの辺の変更です。
 A consequence of the implementation of preemption is that on Unix systems, including Linux and macOS systems, programs built with Go 1.</description>
    </item>
    
    <item>
      <title>改: PerlとGolangで実行できるPolyglot書いてみた</title>
      <link>https://shogo82148.github.io/blog/2021/02/23/improve-go-and-perl-polyglot/</link>
      <pubDate>Tue, 23 Feb 2021 18:00:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2021/02/23/improve-go-and-perl-polyglot/</guid>
      <description>仕事をしているときにふとひらめいた。
 Perl と Golang で実行できる Polyglot 書いてみた  文字列置換の s/// に使う記号はダブルクオーテーションでも行ける！
package main; import (s&amp;#34;fmt&amp;#34;/*&amp;#34;); sub import { print &amp;#34;Hello macotasu&amp;#34;; } __END__ */) func main() { s.Println(&amp;#34;Hello macotasu&amp;#34;) } package main; import (s&amp;#34;fmt&amp;#34;/*&amp;#34;); sub import { print &amp;#34;Hello macotasu&amp;#34;; } __END__ */) func main() { s.Println(&amp;#34;Hello macotasu&amp;#34;) } Go で dot import をしなければならない、という制限がなくなるので、自由度が上がりました。
package main; import (s&amp;#34;fmt&amp;#34;/*&amp;#34;); sub import { print &amp;#34;Hello macotasu&amp;#34;; } __END__ */) import &amp;#34;math&amp;#34; func main() { s.</description>
    </item>
    
    <item>
      <title>AWS Lambda &#43; S3 を使ってyumレポジトリを作った</title>
      <link>https://shogo82148.github.io/blog/2021/02/21/private-yum-repo-on-s3/</link>
      <pubDate>Sun, 21 Feb 2021 08:11:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2021/02/21/private-yum-repo-on-s3/</guid>
      <description>世の中にはたくさんの OSS が公開されていて、それを Linux 上で動かす選択肢も多様になってきました。 今まで通り自前でビルドするのはもちろん, Go のようにシングルバイナリになってるならバイナリ落としてくるだけのものもあります。 DockerHub で公開されているものなら Docker でコンテナイメージをダウンロードするという手もあります。 Homebrew on Linux なんてものも登場しましたね。
選択肢が増えて動かすだけなら楽になったんですが、 事前の環境構築が最小限で済んで、バージョン管理もできて、依存もいい感じに解決してくれて、 といろいろ考えると結局は Red Hat 系なら標準のパッケージマネージャーである yum が楽なんですよね。
そういうわけで JFrog Bintray にバイナリをあげて、yum レポジトリを公開していました。 ところが今月になって 突然の Bintray 終了のお知らせ！！！
 Into the Sunset on May 1st: Bintray, JCenter, GoCenter, and ChartCenter  前置きが長くなりましたね。 要するに Bintray からのお引越しを考えないといけなくなったので、 yum レポジトリを AWS S3 上に移行した、というお話です。
標準的な yum レポジトリの作り方 yum レポジトリを作るには、まず公開したい rpm パッケージが必要です。 Bintray だろうが S3 だろうが、rpm 作成の手順は一緒なので省略します。
rpm さえできてしまえば、レポジトリの作成は非常に簡単です。 createrepo コマンドをインストールして実行するだけ。</description>
    </item>
    
    <item>
      <title>Setup Perl Environment Action のストレージを Azure Blob Storage に移行しました</title>
      <link>https://shogo82148.github.io/blog/2021/02/03/setup-perl-uses-azure-blob-storage/</link>
      <pubDate>Wed, 03 Feb 2021 21:33:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2021/02/03/setup-perl-uses-azure-blob-storage/</guid>
      <description>GitHub Actions が一般公開された際に Perl をセットアップするアクションを書きました。
 Setup Perl GitHub Action を公開しました  セットアップのたびに毎回コンパイルすると遅いので、コンパイル済みのバイナリを事前に Amazon S3 にアップロードしていました。 アップロード先に S3 を選んだのは単に自分が AWS に慣れているからなのですが、最近になってちょっとした問題に直面してます。 解決へ向けて S3 から Azure Blob Storage へ移行した、というお話です。
利用する分には全く影響ないはずなんですが、Azure Blob Storage を使ってみたメモも兼ねてやったことを書いておきます。
S3 の問題点 もちろん S3 自体が悪いわけじゃなくって、単に自分の見積もりが甘かっただけなんですが、 ネットワークのアウト向きのデーター転送料が高い！！！！
これまでの僕のユースケースではせいぜい数 MB のバイナリをアップロードするだけだったのが、perl のバイナリは 1 バージョン当たり 100MB 以上あります。 Perl Monger の方々は互換性に気を使うので、いろんな OS、バージョン、コンパイルオプションでテストを実行します。 各 OS(Linux, Windows, macOS)、Perl 5.6〜5.32、multi-thread オプションありなし、という条件でマトリックスのワークフローを組むと 84 ジョブ。 単純計算で 1 ワークフローを実行するだけで、約 8GB の転送が発生するわけです。 2021-02-05 現在のアウトデーター転送料は 0.09USD/GB なので、1 ワークフローあたり 0.72USD です。</description>
    </item>
    
    <item>
      <title>スーパー楕円をベジェ曲線で近似してみる</title>
      <link>https://shogo82148.github.io/blog/2021/01/29/super-ellipse/</link>
      <pubDate>Fri, 29 Jan 2021 22:01:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2021/01/29/super-ellipse/</guid>
      <description>最近アプリの UI で角丸アイコンを見ることが多くなりました。 この角は完全な円ではなく、スーパー楕円というものだという情報を入手しました。
 スーパー楕円 UI を iOS+Swift で実装する 丸よりも丸みを感じる!? スーパー楕円の魅力とデザイン  記事の中ではベジェ曲線で近似する方法が書かれています。 なるほど、こうすれば描けるのか！と関心したので、自分でもベジェ曲線で描いてみることにしました。
スーパー楕円 スーパー楕円というのは円の方程式を以下のように拡張したものです。
{% math %} \left|\frac{x}{a}\right|^n + \left|\frac{y}{b}\right|^n = 1 {% endmath %}
n は曲線を制御するパラメーターで n=2 は円となり、n&amp;gt;2 の場合は円と四角形のあいだのような形になります。 n が大きいほど四角形に近づいていきます。
3 次のベジェ曲線 Illustrator のようなベクターツールではおなじみのベジェ曲線です。 ベジェ曲線は任意の次数に拡張することができますが、コンピューターグラフィックスで多く用いられるのは 3 次ベジェ曲線です。
制御点を {% m %} \boldsymbol{B}_0, \boldsymbol{B}_1, \boldsymbol{B}_2, \boldsymbol{B}_3 {% em %} とした場合の 3 次ベジェ曲線の数式を具体的に書き下すと以下のようになります。
{% math %} \boldsymbol{P}(t) = \boldsymbol{B}_0(1-t)^3 + \boldsymbol{B}_1 3t(1-t)^2 + \boldsymbol{B}_2 3t^2(1-t) + \boldsymbol{B}_3 t^3 {% endmath %}</description>
    </item>
    
    <item>
      <title>Perl Runtime for AWS Lambda の Docker コンテナ対応を公開しました</title>
      <link>https://shogo82148.github.io/blog/2021/01/02/perl-runtime-supports-docker-format/</link>
      <pubDate>Sat, 02 Jan 2021 00:00:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2021/01/02/perl-runtime-supports-docker-format/</guid>
      <description>いつかやろうと思っていた AWS::Lambdaの Docker コンテナ対応、 年を越してしまったけど、ようやく手を付けました。
 AWS Lambda の新機能 – コンテナイメージのサポート  使い方 以下の handler.pl を Docker コンテナとして AWS Lambda デプロイする例です。
use utf8; use warnings; use strict; sub handle { my $payload = shift; return +{&amp;#34;hello&amp;#34; =&amp;gt; &amp;#34;lambda&amp;#34;}; } 1; ビルド済みイメージを使う Amazon Linux 2 ベースの Perl Runtime 入りイメージをDocker Hub で公開しています。 これをベースにデプロイしたいファイルを追加し、CMD に実行したい関数名を指定するだけ。 簡単ですね。
FROMshogo82148/p5-aws-lambda:base-5.32-paws.al2COPY handler.pl /var/task/CMD [ &amp;#34;handler.handle&amp;#34; ]Docker Hub からのダウンロードに Rate Limit が適用されるようになったので、 同じイメージを Amazon ECR Public Gallery でも公開しました。 こちらを利用することも可能です。</description>
    </item>
    
    <item>
      <title>排他制御を行う GitHub Action を作った</title>
      <link>https://shogo82148.github.io/blog/2020/12/30/github-actions-mutex/</link>
      <pubDate>Wed, 30 Dec 2020 00:00:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2020/12/30/github-actions-mutex/</guid>
      <description>弊社では GitHub のレポジトリ管理に Terraform GitHub provider を使用しています。 いちいち手元で terraform plan や terraform apply を叩くのは面倒なので、 GitHub Actions を利用することを考えました。 tf ファイルと現実のリソースとの不整合を避けるために、 これらのコマンドは排他的に実行する必要があります。 例えば terraform apply を実行している最中に terraform plan を実行することはできません。
ここで問題になってくるのが GitHub Actions のジョブ並列数です。 2020-12-30 現在、GitHub Actions は同時に 20 並列まで実行可能ですが、逆に並列数を制限できないという贅沢な悩みがあります。 一応 Matrix Build の並列数を制限するオプションはありますが、 ワークフローをまたいだ並列数の制限はできません。
これを解決するために作ったのが actions-mutex です。
 shogo82148/actions-mutex actions-mutex Marketplace  使い方 ただワークフローから uses を使って呼び出すだけ。 面倒なアクセスキーの設定等は必要ありません。簡単ですね。
on:push:branches:- mainjobs:build:runs-on:ubuntu-lateststeps:- uses:actions/checkout@v2- uses:shogo82148/actions-mutex@v1- run:&amp;#34;: 排他的に実行する必要のあるタスク&amp;#34;仕組み actions-mutex と同様のことを実現する Action として GitHub Action Locks があります。 これの使用も考えたのですが、GitHub Action Locks はバックエンドに AWS DynamoDB を使用しています。 DynamoDB のテーブルを作成した上で AWS IAM を適切に設定する必要があり、セットアップが面倒です (まあ単に DynamoDB 食わず嫌いしているだけ、というのもあります)。</description>
    </item>
    
    <item>
      <title>2020年に書いた GitHub Action &#43; α</title>
      <link>https://shogo82148.github.io/blog/2020/12/03/github-actions-in-2020/</link>
      <pubDate>Thu, 03 Dec 2020 00:00:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2020/12/03/github-actions-in-2020/</guid>
      <description>この記事はフラーAdvent Calendar 2020の3日目の記事です。 2日目はid:gibachan03 さんで「Androidアプリエンジニアになって気づいたiOSとの違い」でした。
 さて、公開当初色々して遊んだ GitHub Actions ですが、今年も引き続き遊んでました。 いくつか新しい Action を作ったものの、このブログでは紹介していなかったので、2020年作ったものを紹介したいと思います。
actions-upload-release-asset  Yet Another Upload Release Asset Action  一言で表すのならば、 Yet Another actions/upload-release-asset GitHub Action です。 GitHub の Releases にファイルをアップロードする Action です。 このアクションは GitHub 公式という安心感はあるのですが、一度のステップで1個のファイルしかアップロードできません。
ソースファイル本体と、ビルド済みバイナリと・・・と色々アップロードしたいものがあったので、新しく作りました。 actions-upload-release-asset は @actions/glob の Glob Pattern に対応しているので、一つのステップで複数のファイルをアップロードすることができます。
例えば、カレントディレクトリにあるテキストファイルを全てアップロードする例は以下のようになります。
on:release:types:- createdjobs:build:runs-on:ubuntu-lateststeps:- uses:actions/checkout@v2# steps for building assets- run:echo &amp;#34;REPLACE ME!&amp;#34; &amp;gt; assets.txt- uses:shogo82148/actions-upload-release-asset@v1with:upload_url:${{ github.event.release.upload_url }}asset_path:&amp;#34;*.txt&amp;#34;actions-setup-mysql  actions-setup-mysql  MySQLをインストールしてくれる Action です。 GitHubが提供している Linux イメージに MySQL はインストールされているのですが、MySQL 8.</description>
    </item>
    
    <item>
      <title>AWS SDK for Go v2 の今後が不安な件について</title>
      <link>https://shogo82148.github.io/blog/2020/10/24/aws-sdk-go-v2-broken/</link>
      <pubDate>Sat, 24 Oct 2020 01:06:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2020/10/24/aws-sdk-go-v2-broken/</guid>
      <description>なんだか今日はもうコードを書く気がしないので、最近思っていることをつらつらと・・・
タイトルの通り、最近 AWS SDK for Go v2 の行く末がちょっと気になっています。 あんまり話題になっているのを観測できていないので、少し現状を書いてみます。
背景 最近あったビッグイベントが v0.25.0 のリリースです。
 Client Updates in the Preview Version of the AWS SDK for Go V2  パッケージの構成が見直され、APIの呼び出し方法も変わりました。 まあ、プレビュー版なのでよくあること・・・なんですが、ちょっと変更点が多すぎて追いきれない。
v0.25.0 移行で入った変更の数々 ちょっと一例を見てみましょう。
設定の読み込み Before: v0.25.0 より前は external パッケージを使って設定を読み込んでいました。
import ( &amp;#34;github.com/aws/aws-sdk-go-v2/aws/external&amp;#34; ) func loadConfig() (aws.Config, error) { return external.LoadDefaultAWSConfig() } After: これが config パッケージに変更になりました。
import ( &amp;#34;github.com/aws/aws-sdk-go-v2/config&amp;#34; ) func loadConfig() (aws.Config, error) { return config.LoadDefaultConfig() } API の呼び出し Before: Requestオブジェクトを作って、そのSendメソッドを呼ぶ形式でした。</description>
    </item>
    
    <item>
      <title>GitHub Actions を使って簡単なボットを作る</title>
      <link>https://shogo82148.github.io/blog/2020/10/23/github-bot-using-actions/</link>
      <pubDate>Fri, 23 Oct 2020 22:03:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2020/10/23/github-bot-using-actions/</guid>
      <description>リリース当初は git push など GitHub 上のイベントしかトリガーにできなかった GitHub Actionsですが、 workflow_dispatch イベント の登場により手動実行ができるようになりました。
社内でもこの機能を利用してワークフローの手動実行をしていたのですが、人間とは欲深いもので「毎回ワークフローを選択してポチポチするのだるい」という声があがってきました。 そういうわけで、Pull Request のコメントをトリガーにしてワークフローを実行する簡単なボットを作ってみました。
方針 workflow_dispatch と issue_comment をトリガーにしたワークフローを作ればいいだけの気もしますが、 以下のような理由からワークフローからワークフローを呼び出す形にしました。
 workflow_dispatch を使った既存のワークフローがあるので、それを流用したい  トリガーが複数あると、イベントの種類に応じてペイロードの形式が異なるので、地味に処理が大変 issue_comment は全部のコメントに反応するので、本当に見たいログが埋もれてしまう   コメントを投稿した Pull Request のHEADでワークフローを実行して欲しい  issue_comment はイベントの発生元として、デフォルトブランチのHEADが渡ってきます イベントのペイロードには、プルリクエストへのリンクが入っているだけで、HEADの情報はわからない    実装 jfurudo1 がサードパーティのアクションを使ってゴニョゴニョやっていたものの、 あんまりうまく行ってなさそうだったので、bash script でエイヤッと書き直しました。
「build」 とコメントすると、.github/workflows/build.yml のワークフローを実行するサンプルです。
name:comment hookon:issue_comment:types:[created]jobs:distribute:runs-on:ubuntu-lateststeps:- name:dispatch workflowrun:| # イベントに関する詳細情報を取ってくる PAYLOAD=$(cat &amp;#34;$GITHUB_EVENT_PATH&amp;#34;) NUMBER=$(echo &amp;#34;$PAYLOAD&amp;#34; | jq -c &amp;#39;.issue.number&amp;#39;) # Issue と Pull Request のコメントが混ざってくるので、Issueは無視する if [[ &amp;#34;$(echo &amp;#34;$PAYLOAD&amp;#34; | jq -c &amp;#39;.</description>
    </item>
    
    <item>
      <title>AWS Lambda Perl Runtime on Amazon Linux 2 を公開しました</title>
      <link>https://shogo82148.github.io/blog/2020/08/15/perl-lambda-runtime-on-amazon-linux2/</link>
      <pubDate>Sat, 15 Aug 2020 20:44:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2020/08/15/perl-lambda-runtime-on-amazon-linux2/</guid>
      <description>Amazon Linux 2 への移行が進む AWS Lambda ですが、 ついに Custom Runtime にも Amazon Linux 2 がやってきました。
 AWS Lambda now supports custom runtimes on Amazon Linux 2  同時に provided.al2 の Docker Image も公開されたので、 それを利用して Amazon Linux 2 対応の Perl Runtime Layer を作成しました。
 AWS::Lambda  ビルド済み公開 Perl Runtime Layer リージョン毎のArn一覧はこちら
 Perl 5.32  arn:aws:lambda:af-south-1:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:ap-east-1:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:ap-northeast-1:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:ap-northeast-2:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:ap-south-1:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:ap-southeast-1:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:ap-southeast-2:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:ca-central-1:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:eu-central-1:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:eu-south-1:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:eu-west-1:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:eu-west-2:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:eu-west-3:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:me-south-1:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:sa-east-1:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:us-east-1:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:us-east-2:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:us-west-1:445285296882:layer:perl-5-32-runtime-al2:1 arn:aws:lambda:us-west-2:445285296882:layer:perl-5-32-runtime-al2:1    --runtime provided.</description>
    </item>
    
    <item>
      <title>Yet Another AWS X-Ray Go SDK でログの関連付けをサポートした</title>
      <link>https://shogo82148.github.io/blog/2020/07/06/aws-xray-yasdk-go-supports-logs-correlation/</link>
      <pubDate>Mon, 06 Jul 2020 22:49:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2020/07/06/aws-xray-yasdk-go-supports-logs-correlation/</guid>
      <description>僕が管理しているサービスでは、ALB が発行する Trace ID を調査時の手がかりとして使えるようログに出力しています。 これのおかげで、Nginx, アプリケーション, その他AWSのマネージドサービス, etc. といった異なるコンポーネントであっても、関連するログを抽出ができ、 障害発生時の役に立っています。 しかし、肝心の抽出作業がマネージドコンソールぽちぽちなため、完全に職人芸になっているというのが現状でした。
解決のための良いツールがないかな、と目をつけたのが CloudWatch ServiceLens です。 CloudWatch メトリックとログ、AWS X-Ray からのトレースを結び付けて、直感なインターフェースで分析できるというもの。
 Amazon CloudWatch ServiceLens の発表  AWS X-Ray のトレース結果を送るのは、以前開発した Yet Another AWS X-Ray SDK for Go でできます。 CloudWatch Logs への出力方法は色々ありますが、僕は自作の cloudwatch-logs-agent-lite を使っています。
材料はそろった、さあ、ServiceLens で分析だ！と行きたいところですが、 ただ単にこれらの情報を送りつけるだけでは、得られる情報は X-Ray 単体、CloudWatch Logs 単体で使ったときと大差ありません。 X-Ray のトレース結果とログの関連付けが行われていないので、結局 Trace ID を使って CloudWatch Logs を検索する必要が出てきてしまいます。
ドキュメントを見る限り、2020-07-06現在 AWS X-Ray SDK for Java だけがログ関連付け機能に対応しているようです。 JavaにできてGoにできないわけがないだろう・・・ということで移植してきました。
使い方 aws-xray-yasdk-go の v1.1.1 移行で対応しているので、そのバージョンを落としてきます。</description>
    </item>
    
    <item>
      <title>RE: Pull Request Title Injection とその対策</title>
      <link>https://shogo82148.github.io/blog/2020/04/02/re-pull-request-title-injection/</link>
      <pubDate>Thu, 02 Apr 2020 06:37:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2020/04/02/re-pull-request-title-injection/</guid>
      <description>@furusax が書いてくれた GitHub Action からの Slack 通知機能について以下のようにコメントしたところ、 対策案を考えてくれました。
 そういえばこれって Pull Request Title Injection できないですかね？ まあ、タイトル書くの社員なのでいいんですが。
 対策してみました #はてなブログ
Pull Request Title Injection とその対策 - なまえは まだ ないhttps://t.co/hIkMykFUr8
&amp;mdash; ふるさっくす (@furusax) March 31, 2020   Pull Request Title Injection とその対策  なるほど、こう来ましたか。しかし、まだまだ甘いですね・・・。
Pull Request Title Injection について まずはこの記事に出てくる「Pull Request Title Injection」についておさらいです。 以下のような Slack への通知を行う GitHub Actions があります。 github.event.pull_request.title はプルリクエストを送った本人が自由に設定できるので、 ここにうまいこと細工をすれば Slack への投稿内容を自由に改変できてしまうのでは？という問いかけでした。
jobs:notify:name:Slack Notificationruns-on:ubuntu-lateststeps:- name:&amp;#39;Send Notification&amp;#39;run:| jq -n &amp;#39;{ attachments: [{ pretext: &amp;#34;Swagger が更新されたよ！&amp;#34;, color: &amp;#34;good&amp;#34;, title: &amp;#34;${{ github.</description>
    </item>
    
    <item>
      <title>Yet Another AWS X-Ray Go SDK を作った</title>
      <link>https://shogo82148.github.io/blog/2020/03/30/aws-xray-yasdk-go/</link>
      <pubDate>Mon, 30 Mar 2020 06:37:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2020/03/30/aws-xray-yasdk-go/</guid>
      <description>AWS X-Ray Go SDK の地雷処理をしている話 で投げたSQLのプルリクエスト も無事マージしてもらい、 その後もちょくちょくプルリクエストを投げて地雷処理をしていたんですが、我慢できずにやってしまいました・・・。
 Yet Another AWS X-Ray SDK for Go  そもそも AWS X-Ray ってなんだ、という方は以下のリンクから @fujiwara さんの記事へ飛べるのでどうぞ。
 AWS Lambda Perl Runtime で AWS X-Ray を使えるようになりました  使い方 だいたいオフィシャルSDKと一緒です。 ただし、パッケージ分割をしたので、呼び出す関数名等はちょっと変わってます。 他にも微妙に挙動が違う箇所があります。
環境変数の設定 AWS_XRAY_DAEMON_ADDRESS, AWS_XRAY_CONTEXT_MISSING 等の環境変数の設定項目は本家と合わせました。 ただし、以下の点が本家とは異なります。
 コード内の設定が優先されます。 環境変数はコード内で明示的に設定が行われなかった場合のフォールバックです。 AWS_XRAY_CONTEXT_MISSING のデフォルト値は LOG_ERROR です。  セグメントの作り方 オフィシャルSDKは seg.Close(err) のようにセグメントを閉じるときにエラーを渡します。 Go には defer という便利な機能があるので、セグメントを閉じるときもこれを使いたいところです。 だたエラーを正しく受け取るには、以下のように戻り値に名前をつけて、defer 部分を無名関数の呼び出しにする必要があります。
// オフィシャルSDKの場合 import &amp;#34;github.com/aws/aws-xray-sdk-go/xray&amp;#34; func DoSomethingWithSubsegment(ctx context.Context) (err error) { ctx, seg := xray.</description>
    </item>
    
    <item>
      <title>AWS X-Ray Go SDK の地雷処理をしている話</title>
      <link>https://shogo82148.github.io/blog/2020/02/11/aws-xray-golang/</link>
      <pubDate>Tue, 11 Feb 2020 06:37:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2020/02/11/aws-xray-golang/</guid>
      <description>AWS Lambda Perl Runtime で AWS X-Ray を使えるようになりました で紹介した AWSの分散アプリケーションの分析サービス AWS X-Ray。 Perl から使えるようにしたももの、自分自身は最近 Perl をあまり使っていないことに気がついた！！ので、AWSが提供しているGo実装である aws/aws-xray-sdk-goに 手を出してみることにしました。
結果、X-Rayのサービスマップやトーレスが見れるようになって便利！・・・にはなったんですが、そこまでの道のりが長かった。 「 @fujiwara さんのYAPC::Tokyo 2019での発表 から1年近く経ってるしそろそろ安定してきているでしょ！」と 軽い気持ちで始めたのが良くない。 色々と地雷(？)を踏んだので、記録として残しておきます。
依存ライブラリのcontext対応が地味に辛い X-Ray で実行をトレースするには、「今実行している関数がどこから呼ばれたのか？」という情報をうまいこと伝える必要があります。 Perlで使われているような黒魔術はGoでは使えないので、 context.Context を地道に引数に渡していくことになります。
まあ、こんなこともあろうかと、context.Context にはバッチリ対応してあるからサクッと行けるでしょ！
と思ってたんですが、現実はそうは甘くなかった。 X-Rayを入れようとしたプロジェクトではWebフレームワークとしてgoadesign/goaを使っています。 GoaのHTTPハンドラーには context.Context が渡ってくるので油断していたのですが、 contextの親をたどっていくと行き着く先は context.Background() (HTTPハンドラーなので request.Context() であってほしい)。 なんとなく context.Context 対応詐欺にあった気分です。
Goaは現在 v2, v3 の開発がメインで現在使っているのは v1 です。 v1からv3へのアップグレードには大幅な書き換えが必要なこと、アップグレードしたとしても直っている保証がないこと、 最近 Goa v1 のリリースが滞りがちなこと、などなどの理由から結局フォークしてくることにしました。
 shogo82148/goa-v1  AWS X-Ray Go SDK 自体の問題ではないのですが、 Contextってタイムアウトをうまく処理するための仕組みなので、実装漏れがちですよね。 皆さん実装するときやライブラリの選定には気をつけましょう。
SQLクエリを実行する関数のシグネチャーが微妙に違う これに関しては @acidlemon 先生の kamakura.</description>
    </item>
    
    <item>
      <title>元Yahoo!ジオシティーズ利用者のかたへ、GitHub Pagesのすゝめ</title>
      <link>https://shogo82148.github.io/blog/2020/02/01/goodbye-geocities/</link>
      <pubDate>Sat, 01 Feb 2020 00:00:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2020/02/01/goodbye-geocities/</guid>
      <description>TL;DR  今GitHubにアップロードした内容は1000年残る！ デッドラインは 2020年2月3日(月) 午前7時(日本時間) Yahoo!ジオシティーズのデータがダウンロードできるのは2020年3月31日まで  つまりYahoo!ジオシティーズから移行するなら、今！ GitHubが一番！
Yahoo!ジオシティーズは終了しました Yahoo!ジオシティーズ 公開停止からはや10ヶ月。 ちょっと古いリンクをたどると「Yahoo!ジオシティーズは終了しました」というページを目にすることが多くなりました。
 Yahoo!ジオシティーズは終了しました
2019年3月31日をもちましてYahoo!ジオシティーズのサービス提供を終了いたしました。長らくご愛顧いただき誠にありがとうございました。
ホームページをお持ちのお客様につきましては、2020年3月31日までFTPによるファイルダウンロードのみご利用可能となっております。ホームページやドメインの移行方法などはサービス終了のお知らせをご確認ください。
https://info-geocities.yahoo.co.jp/
 それ見てこんなツイートをしたのですが、なぜ GitHub への移行がいいのか知らない人が多いようなのでちょっと説明しますね。
みんな！FTP経由ならまだジオシティーズからホームページのダウンロードはできる！！今のうちにGitHubへ上げてその黒歴史を1000年後まで残すんだ！！！
&amp;mdash; Ichinose Shogo (@shogo82148) January 31, 2020  GitHub Arctic Code Vault なぜ今 GitHub なのかというと、 GitHub Universe 2019 で GitHub Archive Programというプログラムが発表されたからです。
 今から1,000年後にソフトウェアはどのようになっているのか、また人類はどうなっているのか、推測することしかできません。しかし、今日の時点で最も重要なビルディングブロックを、確実に明日に残せるようにすることは可能です。私たちの世界は、オープンソースソフトウェアで動いています。この文明の隠れた基盤であり、全人類の共有財産です。GitHub Archive Programの使命は、次世代のためにオープンソースソフトウェアを保護することです。
GitHubは、スタンフォード大学図書館、Long Now Foundation、 Internet Archive、Software Heritage Foundation、Piql、Microsoft Research、オックスフォード大学ボドリアン図書館などの機関や団体と連携し、世界のオープンソースコードを保護していきます。この貴重な知識を保護する方法として、あらゆるデータ形式でさまざまな場所に、継続的に複数のコピーを保存していきます。保存場所には、GitHub Arctic Code Vaultと呼ばれる、少なくとも1,000年は存続する非常に長期的なアーカイブも含まれます。
https://github.blog/jp/2019-11-14-universe-day-one/
 このプログラムで最長の保存場所である GitHub Arctic Code Vault は、北極圏に広がる永久凍土の深さ250mに建設されたアーカイブ施設「Arctic World Archive」。</description>
    </item>
    
    <item>
      <title>CloudFormationのテンプレートのLinter actions-cfn-lint のご紹介</title>
      <link>https://shogo82148.github.io/blog/2019/12/06/actions-cfn-lint/</link>
      <pubDate>Fri, 06 Dec 2019 00:00:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2019/12/06/actions-cfn-lint/</guid>
      <description>この記事はフラーAdvent Calendar 2019の6日目の記事です。 5日目は@shogo82148 さんで「GitHub Goveralls Action を公開しました」でした。
 さて、最近 GitHub Actions を作るのにハマっているので、今日も GitHub Actions の紹介です。
 GitHub Action for CloudFormation Linter with reviewdog shogo82148/actions-cfn-lint  Amazon CloudFormation Infrastructure as Code の盛り上がりも一段落し、今では当たり前のように使っている人も多いと思います。 フラー共創スタジオはAWSがメインなので、CloudFormationをメインに使っています。 色々とクセは強いですが、少なくともtfstateが行方不明になったりはしないので、まあまあ仲良くやっています。
CloudFormation Linter テンプレートを書いている上で地味にややこしいのが、プロパティーの名前や型の統一感が微妙にない、ということです。
例を挙げると、AWS::ApplicationAutoScaling::ScalableTarget の MaxCapacity は整数型です。 これはまあ、納得できますね。
ところが AWS::AutoScaling::AutoScalingGroup の MaxSize は 文字列型 なんです。説明文には「Auto Scaling グループの Amazon EC2 インスタンスの最大数」とあるのに！ オートスケールという似たような機能を持っていて、どちらもスケーリンググループの最大数を表しているの、名前も違えば型が全く違う。
この手のミスは aws cli に付属している テンプレートの validation 機能では見つけられす、実際に反映してみるしかありません。 すぐに失敗してくれればいいんですが、失敗するまでにも十数分かかったりしてかなり面倒です。
 そこでおすすめなのが CloudFormation Linter。 この手の名前のミスや型のミスを指摘してくれるコマンドラインツールです。 各種エディタ用の拡張もあり、VSCodeでも使える ので、ぼくはいつもこれを使っています。</description>
    </item>
    
    <item>
      <title>GitHub Goveralls Action を公開しました</title>
      <link>https://shogo82148.github.io/blog/2019/12/05/actions-goveralls/</link>
      <pubDate>Thu, 05 Dec 2019 00:00:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2019/12/05/actions-goveralls/</guid>
      <description>この記事はフラーAdvent Calendar 2019の5日目の記事です。 4日目はふるふる先生の「GoでJSONを良い感じに使おうと思ってハマった話」でした。
 さて、首を長くして待っていた GitHub Actions がついにGAになりましたね。 (日本語版ヘルプだとまだbetaになってますが)
さっそくActionを自作してちょっと前に公開してたんですが、この機会に紹介しようと思います。
 actions-goveralls - Actions GitHub Marketplace shogo82148/actions-goveralls  使い方 coveralls.io はコードカバレッジの可視化サービスです。 実は公式でGitHub Actionsを提供しており、Coveralls GitHub Action を使うと 「JavaScriptのプロジェクトであれば」簡単にカバレッジを送信することができます。
しかし、Goが出力するカバレッジはJavaScriptと形式が違うので、そのままは使えません。 他のCIではmattn/goverallsにお世話になっていたので、 これを GitHub Actions として簡単に使えるようにしました。 最小限の設定はこれだけです。
# ここらへんにテストとかの設定ば別途描く# coveralls.io に送信- uses:shogo82148/actions-goveralls@v1with:github-token:${{ secrets.GITHUB_TOKEN }}path-to-profile:profile.cov簡単ですね。
マトリックスビルド され、後発なだけあって GitHub Actions では他のCIの便利な機能を簡単に使えます。 その中でも最も便利(偏見)なのがマトリックスビルドです。 例えば以下のように設定するだけで、Linux, macOS, Windows で同じテストを実行できます。
strategy:fail-fast:falsematrix:os:- ubuntu-latest- macos-latest- windows-latestruns-on:${{ matrix.os }}・・・と、ここまではいいんですが、カバレッジをとって coveralls に送ると残念なことになります。 (例:https://coveralls.io/builds/27037772)
どれかがLinuxでどれかがmacOSで残った最後がWindowsの実行結果なのですが、 ジョブの名前が一緒なので区別が付きません。
parallel build webhook coveralls にはこの問題を解決してくれるparallel build webhookというものがあります。 travis-ci だと coveralls側がいい感じにフックを挟んで処理してくれるんですが、GitHub Actions では自前でやらないといけません。 全部自前でやるのは面倒なので、actions-goveralls には補助する機能をいれてあります。</description>
    </item>
    
    <item>
      <title>Setup Perl GitHub Action を公開しました</title>
      <link>https://shogo82148.github.io/blog/2019/09/18/actions-setup-perl/</link>
      <pubDate>Wed, 18 Sep 2019 23:14:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2019/09/18/actions-setup-perl/</guid>
      <description>GitHub Actions の公式レポジトリには Perl のセットアップアクションが無いぞ！ ということで三連休+αで書きました。
 actions-setup-perl on GitHub Marketplace  使い方 Marketplaceの設定例は間違えているので以下を参照。(これ書いていて気がついた) 必要な Perl のバージョンを渡すだけです。簡単！
steps:- uses:actions/checkout@master- uses:shogo82148/actions-setup-perl@v1with:perl-version:&amp;#39;5.30&amp;#39;- run:cpanm --installdeps .- run:prove -lv tUbuntu, macOS, Windows 各種OSにも対応しています。
jobs:build:runs-on:${{ matrix.os }}strategy:matrix:os:[&amp;#39;ubuntu-18.04&amp;#39;,&amp;#39;macOS-10.14&amp;#39;,&amp;#39;windows-2019&amp;#39;]perl:[&amp;#39;5.30&amp;#39;,&amp;#39;5.28&amp;#39;]name:Perl ${{ matrix.perl }} on ${{ matrix.os }}steps:- uses:actions/checkout@v1- name:Setup perluses:shogo82148/actions-setup-perl@v1with:perl-version:${{ matrix.perl }}- run:perl -V- run:cpanm --installdeps .- run:prove -lv t動作サンプル
 https://github.com/shogo82148/p5-Acme-OkMacopy/blob/master/.github/workflows/test.yml https://github.com/shogo82148/p5-Acme-OkMacopy/commit/15bf2162a26a1ea8bfe748ddc980164f049a1c67/checks  ok macopy をこんな形で使うことになろうとは、あの当時は思っていなかった・・・
裏方の話 Actionでインストールされるperlについて GitHub Actions の Runner にはキャッシュ領域が用意されていて、こういうバイナリはそこに入れるのがお作法のようです。 perlは付属するCPANモジュールのパスがバイナリに組み込まれているので、パスを変更したい場合は再ビルドが必要です。
そういうわけで、perl 5.8.5 から perl 5.</description>
    </item>
    
    <item>
      <title>AWS Lambda Perl Runtime で AWS X-Ray を使えるようになりました</title>
      <link>https://shogo82148.github.io/blog/2019/08/21/aws-xray-with-perl-lambda-runtime/</link>
      <pubDate>Wed, 21 Aug 2019 19:53:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2019/08/21/aws-xray-with-perl-lambda-runtime/</guid>
      <description>AWS Lambda 上で Perl を動かす AWS::Lambda で、 AWSの分散アプリケーションの分析サービスである AWS X-Ray をサポートしました！
AWS X-Ray って何？ Perl からどう使うの？ という人は @fujiwara さんの記事とYAPC::Tokyo 2019での発表スライドをどうぞ。
 第56回　AWS X-Rayによる分散トレーシング―マイクロサービスのボトルネック，障害箇所の特定（1） 第56回　AWS X-Rayによる分散トレーシング―マイクロサービスのボトルネック，障害箇所の特定（2） 第56回　AWS X-Rayによる分散トレーシング―マイクロサービスのボトルネック，障害箇所の特定（3）   使ってみる Perl Runtime だけでなくX-Ray SDK 側でも対応が必要だったので、プルリクエストを送って取り込んでもらいました。 このプルリクエストがマージされた最新の AWS::XRay を Perl Runtime Layer にプリインストールしたので、あなたのアプリケーションですぐに使えます。
例えばこんな感じのコードを書いて、
use utf8; use warnings; use strict; use AWS::XRay qw/ capture /; sub handle { my ($payload, $context) = @_; capture &amp;#34;myApp&amp;#34; =&amp;gt; sub { capture &amp;#34;hogehoge&amp;#34; =&amp;gt; sub { sleep 1; }; capture &amp;#34;fugafura&amp;#34; =&amp;gt; sub { my $segment = shift; $segment-&amp;gt;{metadata} = $payload; }; }; return +{&amp;#34;hello&amp;#34; =&amp;gt; &amp;#34;lambda&amp;#34;}; } 1; Layer に X-Rayに対応した最新の Perl Runtime arn:aws:lambda:ap-northeast-1:445285296882:layer:perl-5-30-runtime:3 を追加、 マネージドコンソールの「Debugging and error handling」セクションにある「Enable AWS X-Ray」を有効化し、実行してみます。</description>
    </item>
    
    <item>
      <title>Goのバイナリに静的ファイルを埋め込むツール assets-life を書いた</title>
      <link>https://shogo82148.github.io/blog/2019/07/24/assets-life/</link>
      <pubDate>Wed, 24 Jul 2019 20:54:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2019/07/24/assets-life/</guid>
      <description>日本語の Go コミュニティだと go-bindata (なんか乗っ取り騒動とか色々あってメンテナンスされてない), go-assets (最近メンテナンス滞りがち) が有名(要出典)なやつです。 これらのライブラリに関してたくさん日本語記事が書かれて、今もたくさん検索に引っかかるのですが、残念ながら最近はメンテナンスが滞っています。
最近は statik の名前もよく見るようになりました。 その他は Resource Embedding - Awesome Go からどうぞ。
で、まあ、今回も完全に車輪の再発明なんですが、他の実装には色々と思うところがあり書いてみました。
 shogo82148/assets-life  USAGE なにはともあれ、まずは go get してきます。
$ go get github.com/shogo82148/assets-life assets-life というコマンドがインストールされるので、 バイナリに組み込みたいディレクトリと出力先を指定します。
$ assets-life /path/to/your/project/public public 出力先のディレクトリは Go のパッケージとしてインポートできるようになってます。 Root という変数のなかにファイルが埋め込まれており、http.FileSystem インターフェースを介してアクセスできます。
import ( &amp;#34;net/http&amp;#34; &amp;#34;example.com/your/project/public&amp;#34; ) func main() { http.Handle(&amp;#34;/&amp;#34;, http.FileServer(public.Root)) http.ListenAndServe(&amp;#34;:8080&amp;#34;, nil) } 特長 コードの再生成にコマンドのインストールが不要 これが一番の特長です。 バイナリにファイルを埋め込む都合上、静的ファイルを修正した場合にコードの再生成が必要です。 assets-life は go:generate ディレクティブを埋め込んだコードを出力するので、コードの再生成は go generate でできます。
# /path/to/your/project/public に修正を加える # コードの再生を行う $ go generate example.</description>
    </item>
    
    <item>
      <title>Goで指数的バックオフをやってくれるgo-retryを書いた</title>
      <link>https://shogo82148.github.io/blog/2019/07/22/go-retry/</link>
      <pubDate>Mon, 22 Jul 2019 07:33:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2019/07/22/go-retry/</guid>
      <description>完全に車輪の再発明なんですが、他の実装には色々と思うところがあり書いてみました。
 shogo82148/go-retry  MOTIVATION カッコいいインターフェースが欲しい インターフェースは lestrrat さんのこの資料を参考にしています。
  GoらしいAPIを求める旅路 (Go Conference 2018 Spring)  from lestrrat  「これ、Loop Condition だ」のあたりで、なるほど！と思ってインターフェースを真似てみました。 このインターフェースに沿って、lestrratさん自身が実装した lestrrat-go/backoff があります。 しかし、個人的にちょっと実装が複雑だなと感じたので、もうちょっとシンプルに書けないかとやってみました。
Context サポート 先行実装たちは Context がGoに取り込まれる前からあるので、 Contextに対応したインターフェースが後付だったり、 そもそもContextに対応していなかったりします。 Context未対応の Go 1.5 はすでにサポート対象外なので、もう Context が存在しない実行環境は考えなくてよいはずです。
SYNOPSIS Loop Condition Interface 使い方は lestrrat-go/backoff と大体一緒。 指数的バックオフに必要な各種パラメーターをポリシーとして与え、リトライのためのループを回します。
// 指数的バックオフの各種パラメーターをポリシーとして定義 var policy = retry.Policy{ // 初回待ち時間  MinDelay: 100 * time.Millisecond, // 最大待ち時間  MaxDelay: time.Second, // 最大試行回数  MaxCount: 10, } func DoSomethingWithRetry(ctx context.</description>
    </item>
    
    <item>
      <title>AWS SDK for Perl Lambda Layerを公開しました</title>
      <link>https://shogo82148.github.io/blog/2019/07/16/aws-lambda-paws-layer/</link>
      <pubDate>Tue, 16 Jul 2019 22:43:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2019/07/16/aws-lambda-paws-layer/</guid>
      <description>ハイラルからこんにちは。
AWS LambdaでCGIを蘇らせる で作成した Perl Custom Runtime 用の AWS Lambda Layer ですが、 中でイベントのハンドリングをしているモジュールを AWS::Lambda として CPAN で公開したところ、 AWS SDKを入れて欲しい との要望が来ました。 完全にネタとして作成したモジュールですが、いるんですね使う人。 というわけで AWS SDK を含んだ AWS Lambda Layer を公開しました。
使い方 公開レイヤーを使う AWS公式ではPerl用のSDKは提供していないので、Pawsという非公式SDKを使いました。 何も考えずにテキトウにインストールしてみたらSDKだけで121MBありました。 Perl本体が85MBなのでSDKのほうがでかい。 AWS Lambdaで作成できる関数は250MBが上限なので、流石に半分SDKに持っていかれるのはつらかろうと、Perl本体とは別のレイヤーに分けてあります。
レイヤーは最大5つまで登録できるので、Perl本体(例: arn:aws:lambda:ap-northeast-1:445285296882:layer:perl-5-30-runtime:2 )に加えて 以下のレイヤーを追加することで、Paws を呼び出すことができるようになります。
 arn:aws:lambda:ap-east-1:445285296882:layer:perl-5-30-paws:1 arn:aws:lambda:ap-northeast-1:445285296882:layer:perl-5-30-paws:1 arn:aws:lambda:ap-northeast-2:445285296882:layer:perl-5-30-paws:1 arn:aws:lambda:ap-south-1:445285296882:layer:perl-5-30-paws:1 arn:aws:lambda:ap-southeast-1:445285296882:layer:perl-5-30-paws:1 arn:aws:lambda:ap-southeast-2:445285296882:layer:perl-5-30-paws:1 arn:aws:lambda:ca-central-1:445285296882:layer:perl-5-30-paws:1 arn:aws:lambda:eu-central-1:445285296882:layer:perl-5-30-paws:1 arn:aws:lambda:eu-west-1:445285296882:layer:perl-5-30-paws:1 arn:aws:lambda:eu-west-2:445285296882:layer:perl-5-30-paws:1 arn:aws:lambda:eu-west-3:445285296882:layer:perl-5-30-paws:1 arn:aws:lambda:sa-east-1:445285296882:layer:perl-5-30-paws:1 arn:aws:lambda:us-east-1:445285296882:layer:perl-5-30-paws:1 arn:aws:lambda:us-east-2:445285296882:layer:perl-5-30-paws:1 arn:aws:lambda:us-west-1:445285296882:layer:perl-5-30-paws:1 arn:aws:lambda:us-west-2:445285296882:layer:perl-5-30-paws:1  いつの間にかマネージドコンソールから編集ができるようになっていたので、開発がはかどりますね。
カスタムランタイムでもAWS Lambdaのマネージドコンソールから内容の編集ができる・・・？ Perl も編集できるぞ・・・ pic.twitter.com/4228rG0hca
&amp;mdash; Ichinose Shogo (@shogo82148) July 16, 2019  ZIP アーカイブを使う ビルド済みのZIPアーカイブも公開しています。 以下のURLを指定して新規レイヤーを作成することで利用できます。</description>
    </item>
    
    <item>
      <title>GoのバイナリをRubyスクリプトとしても扱う</title>
      <link>https://shogo82148.github.io/blog/2019/07/02/go-build-polyglot/</link>
      <pubDate>Tue, 02 Jul 2019 21:55:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2019/07/02/go-build-polyglot/</guid>
      <description>$ ruby --help Usage: ruby [switches] [--] [programfile] [arguments] (中略) -x[directory] strip off text before #!ruby line and perhaps cd to directory (後略) なんか Ruby にも -x あるらしいので。
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;runtime&amp;#34; ) const script = ` #!ruby puts &amp;#34;Hello Ruby World!!\n&amp;#34; __END__ ` func init() { runtime.KeepAlive([]byte(script)) } func main() { fmt.Println(&amp;#34;This is Go world!!&amp;#34;) } はい。
$ go build -o main main.go $ ./main This is Go world!</description>
    </item>
    
    <item>
      <title>サーバーの時刻を伝える time wellknown uri を実装してみた</title>
      <link>https://shogo82148.github.io/blog/2019/05/27/time-over-https/</link>
      <pubDate>Mon, 27 May 2019 12:10:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2019/05/27/time-over-https/</guid>
      <description>インターネットをさまよっていたら、 /.well-known/time の存在を知ったので、雑に実装してみました。
使い方 うまいこと共存できそうだったので、HTTP/WebSocketで時刻同期するWebNTPを書いた で作成した WebNTP の一部として実装してあります。
 shogo82148/go-webntp  $ go get github.com/shogo82148/go-webntp/cmd/webntp $ webntp -serve :8080 $ curl -I localhost:8080/.well-known/time HTTP/1.1 204 No Content X-Httpstime: 1558915632.285965 Date: Mon, 27 May 2019 00:07:12 GMT 仕様 HTTPには「予約済みのURI」というものが定義されています。(RFC5785)。
 Well-Known URIs  Let&amp;rsquo;s Encrypt でドメインの所有権確認に使用される ACMEプロトコル(RFC8555) や、 Mastodon のユーザーディスカバリーに使用する WebFinger(RFC7033)等々、 近年話題になったサービスの裏方で使われています。
 /.well-known/acme-challenge ACMEプロトコル(RFC8555) /.well-known/webfinger WebFinger(RFC7033)  Time over HTTPS も Well-Known URIs を利用するプロトコルのひとつです。
 /.well-known/time Time over HTTPS specification  仕様としては非常に単純で、サーバー側は HTTP の HEAD に対して、 Date ヘッダーをつけたリクエストを返すだけ。 より高精度な時刻を得るために X-HTTPSTIME ヘッダーに秒未満の情報を入れた Unix タイムスタンプ を返すこともできます。</description>
    </item>
    
    <item>
      <title>CloudFormationのMackerel用インテグレーションを作ってる話</title>
      <link>https://shogo82148.github.io/blog/2019/04/17/cfn-mackerel-macro/</link>
      <pubDate>Wed, 17 Apr 2019 18:26:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2019/04/17/cfn-mackerel-macro/</guid>
      <description>Mackerel は mkr コマンドを用いて cli から操作ができます。 mkr コマンドを用いると 監視ルールを GitHub で管理 したり、 カスタムダッシュボードを管理したり、といったことができます。 しかし、個人的に以下のような不満があります。
 サービス、ロール、ホスト、新ダッシュボード等々、監視設定以外のリソースに対応していない  旧ダッシュボードは対応しているんだけど、新ダッシュボード対応がまだ 新ダッシュボードのUIは使いやすくてすごくいいんだけど、コピペや一斉置換ができないので、テキストで管理したい   出力がJSONなのつらい  JSON手で書くの難しくないですか？   メトリックスの送信設定と監視設定の管理が別になってしまう  カスタムメトリックス送っているのに監視設定を忘れた、みたいなことが起こる    メトリックスの送信設定については、以前 サーバーレスでCloudWatchメトリクスをMackerelに転送する で CloudFormation上での管理を実現しました。 ここにさらに Mackerel の監視設定を追加できれば、最強なのでは？とやってみました。
例 あれこれ説明する前に例を見てもらったほうがわかりやすいと思うので、こんなことができますよ、という設定例から。
例1: レスポンスタイムの99%パーセンタイルを監視する Mackerel の AWSインテグレーション は ALB に対応していますが、 レスポンスタイムのメトリックスは平均レスポンスタイムだけです。 「平均」は代表的な統計値ですが、全体としては速いんだけど一部のリクエストだけ遅い、という状況を見逃してしまいます。 レスポンスタイムの大まかな分布をパーセンタイルで把握したい、ということはよくありますよね？ (K社でZabbixを使って監視していたときによくお世話になった)
今回作ったインテグレーションを使えば、以下のように「Mackerelのサービス定義」「メトリックスの転送設定」「監視設定」が CloudFormation のテンプレートとして表現できます。
AWSTemplateFormatVersion:2010-09-09# Type: Mackerel::* を使うためのおまじないTransform:- AWS::Serverless-2016-10-31- Mackerel- JSONStringResources:MackerelService:Type:Mackerel::ServiceProperties:Name:&amp;#34;awesome-service&amp;#34;# メトリックスを転送する Lambda 関数MetricsForwarder:Type:AWS::Serverless::ApplicationProperties:Location:ApplicationId:arn:aws:serverlessrepo:us-east-1:445285296882:applications/mackerel-cloudwatch-forwarderSemanticVersion:0.0.9Parameters:ParameterName:&amp;#34;/api-keys/api.mackerelio.com/headers/X-Api-Key&amp;#34;ForwardSettings:!GetAtt MetricsForwarderSettings.Query# CloudWatch から99%パーセンタイルを取得するMetricsForwarderSettings:Type:JSON::StringProperties:Query:- service:!GetAtt MackerelService.</description>
    </item>
    
    <item>
      <title>新元号の候補約4510万件が漏洩！！</title>
      <link>https://shogo82148.github.io/blog/2019/02/28/leak-gengo/</link>
      <pubDate>Thu, 28 Feb 2019 18:26:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2019/02/28/leak-gengo/</guid>
      <description>平成の次の元号候補、4510万4656件の漏洩が確認された。
 テキスト形式 (301MB) gz圧縮版 (108MB)  政府は「新元号、情報管理を徹底へ　漏洩なら差し替え」との方針を示しており、 早急な差し替え対応を行うと思われる。
 2019-04-01 追記:
$ curl -s https://t.co/OCaFAriJIt | cat -n | grep 令和
726041令和
無事漏洩してました！！！
&amp;mdash; Ichinose Shogo (@shogo82148) 2019年4月1日  追記ここまで
 と、まあ、二番煎じなわけですが。
新元号は漏洩すると変更されるということなので常用漢字2文字の全組み合わせ約228万通りをすべて記載したテキストファイルを作成しました。漏洩させていきましょう。https://t.co/G06utDbgka pic.twitter.com/8UcPDqNdXo
&amp;mdash; いんぐらむ (@kazuokiriyama) 2019年2月26日  ただ、このツイートのリプライのもあるとおり漏洩漏れがあるようですし、 新元号に使われる可能性のある漢字は常用漢字ではない可能性だってあると僕は考えいます。 だって、お国のやることですからね。下手したら改元に合わせて「常用漢字の見直しもやる」ということだって考えられます。
というわけで、僕は ShiftJIS, EUC-JP で表現可能な文字列まで範囲を広げることにしました。 Unicodeへの統一が進んでいるとはいえ、 ShiftJIS, ECU-JP で動いているレガシーなシステムもあるでしょうし、この範囲に収めるだろうなという予想です。
ShiftJISからUnicodeへの変換には規則性がないので、変換テーブルを使う必要があります。 Goのコードを漁った ら以下の変換表を参照していたので、これを利用しました。
 https://encoding.spec.whatwg.org/index-jis0208.txt  非漢字も含まれているので、雑に漢字を絞ったあと、
curl https://encoding.spec.whatwg.org/index-jis0208.txt | grep CJK | cut -f3 | cut -d&#39; &#39; -f1 | sort | uniq &amp;gt; kanji.</description>
    </item>
    
    <item>
      <title>外部サービスでもIAM Roleで認証がしたい！</title>
      <link>https://shogo82148.github.io/blog/2019/02/12/ssm-sign-proxy/</link>
      <pubDate>Tue, 12 Feb 2019 12:46:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2019/02/12/ssm-sign-proxy/</guid>
      <description>背景 外部サービスのAPIやWebHookを叩くときには、多くの場合 API トークンが必要になります。 もちろん API トークン無しでも叩けるサービスはありますが、GitHub APIのようにトークン無しではリクエスト数が大きく制限されたり、 一部機能が制限されてしまう場合があります。
外部連携サービスが増えてくると、このAPIトークンをどうやって管理するかが問題になってきます。 プロダクションに投入されているサービスは普通複数のサーバーから構成されており、各サーバーにAPIトークンを配布するのはちょっと面倒です。 この問題に対して、以下のようなことが行われて来ました。
 プライベートネットワークからのアクセスに限定した Proxy を立てる APIトークンの管理は Proxy に任せる  DevOpsが注目され、Slackの利用が広まったころに、このような目的で書かれたProxyサーバーがよく登場しました。
 社内IRCをSlackに移行した時にやったこと  この記事で紹介されている kayac/nopaste   Slackboard〜Slackプロキシサーバ in Go〜 Slackプロキシサーバ〜slackboard〜を利用したメルカリのSlack活用法 App::Ikachan - 様々なサーバのバッチ処理の結果等を IRC のチャンネルに通知するサーバ  (IRCはHTTPで動いているわけではないし、大本の目的もコネクション維持だけど、認証も代理でやってくれる)    しかし、これらのサーバーはSlack専用だったりIRC専用だったりします。 Slackだけじゃなくって、GitHubにコメント登録したり、Mackerelのグラフアノテーションを投稿したり、 他のサービスとも連携したい！
最近はどんなAPIもHTTPで提供されるようになったので(IRCは・・・ウッ・・・そんなのなかった)、もっと汎用的に書けるのではとやってみました。
実装 APIトークンの保管場所として AWS Systems Manager Parameter Store を採用しました。 Parameter Store からAPIトークンを取り出す部分と、実際にAPIを叩く部分は AWS Lambda を使用します。 各サーバーに Forward Proxy デーモンを立てておき、APIを使いたいアプリケーションはこのProxyを経由するようにします。
この図ではEC2インスタンスを例にしていますが、IAM Roleを付与できるAWSのサービスであれば何でも (ECS, Lambda, CodeBuild, etc.) APIにアクセスすることができます。</description>
    </item>
    
    <item>
      <title>Let&#39;s Encrypt の証明書取得を AWS Lambda でやってみた</title>
      <link>https://shogo82148.github.io/blog/2019/02/07/acme-cert-updater/</link>
      <pubDate>Thu, 07 Feb 2019 19:22:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2019/02/07/acme-cert-updater/</guid>
      <description>背景 ここ数年で暗号化されていないHTTPは減り、常時TLSが当たり前になってきました。 公開用のページはもちろん、開発段階のページでもTLSは必須です。 普段はAWS上で開発をしているので、AWS Certificate Managerを利用することが多いのですが、 ちょっとしたお遊びにELBやCloudFormationを使うのはオーバーキルです。 そこで EC2 にもインストールできて、無料で使える Let&amp;rsquo;s Encrypt を使って証明書を発行することを考えました。
Let&amp;rsquo;s Encrypt で発行できる証明書は期間が90日と短く、60日ごとの自動更新が推奨されています。 証明局とAPIとAPIクライアントの実装例は提供するから、あとの自動化部分は自前で頑張ってねという感じなので、自動化部分を頑張らないといけません。 今回は実行環境として AWS Labda、ACME(Automatic Certificate Management Environment)クライアントとして certbot、 認証方法に dns-01、認証に必要なDNSレコードの書き換えに AWS Route 53 を使用する、という構成にしました。
ソースコードをGitHubに挙げたのと、前回と同様に AWS Serverless Application Repository へ上げたので、ぜひご利用ください。
 shogo82148/acme-cert-updater shogo82148/acme-cert-updater on AWS Serverless Application Repository  関連手法 Amazon Linux 2 に certbot をインストールして使う Amazon Linux 2 のドキュメントに TLS 対応のウェブサーバーを立てる例が載っています。 Let&amp;rsquo;s Encrypt で証明書を取る方法も紹介されているので、まずはこれを利用することを考えました。
 付録: Amazon Linux 2 での Let&amp;rsquo;s Encrypt と Certbot の使用 - チュートリアル: Amazon Linux 2 で SSL/TLS を使用できるように Apache ウェブサーバーを設定する  この方法は以下の理由から見送りました。</description>
    </item>
    
    <item>
      <title>サーバーレスでCloudWatchメトリクスをMackerelに転送する</title>
      <link>https://shogo82148.github.io/blog/2019/01/31/mackerel-cloudwatch-transfer/</link>
      <pubDate>Thu, 31 Jan 2019 17:44:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2019/01/31/mackerel-cloudwatch-transfer/</guid>
      <description>背景 サーバーの監視にMackerelを使っているのですが、 用意されているメトリクスでは足りずカスタムメトリクスを追加することが多々あります。 Mackerel Agent Pluginsを利用すればメトリクスを増やすこと自体は簡単なのですが、 Agentを設置するインスタンスが増えるので、サーバー保守の手間が増えてしまいます。
僕のユースケースでは監視対象はたいていAWSのマネージド・サービスなので、 AWS CloudWatch に投稿されたメトリクスが Mackerel で見れれば十分なことが多いです。
そこで、以下の記事を参考に AWS Lambda と CloudWatch Events を組み合わせて、Mackerelへメトリクスを転送するスクリプトを書いてみました。
 Amazon LambdaでCloudWatchのメトリクスをMackerelに監視させる  デプロイしてみる 今回はなんと！皆さんの AWSマネジメントコンソールから、クリックひとつでデプロイできるようにしてみました！
 mackerel-cloudwatch-forwarder  ・・・と、その前に下準備が必要です。 MackerelのダッシュボードからAPIキーをコピーしてきて、 AWS Systems Manager パラメータストアに Secure String として登録しておきます。 スクショでは Mackerel のものだと分かりやすいよう /development/api.mackerelio.com/headers/X-Api-Key という名前をつけました。 この名前を後で使うので覚えておきましょう。
次に AWS Lambda の画面を開き、「関数の作成」をクリックします。
「一から作る」「設計図」「AWS Serverless Application Repository」の3つの選択肢が表れるので、 「AWS Serverless Application Repository」 を選択します。 検索BOXに「Mackerel」と入れると、mackerel-cloudwatch-forwarderが 出てくるので、それを選択します。 なお、この選択肢はデフォルトでは表示ないので、「Show apps that create custom IAM roles or resource policies」にチェックを入れましょう。</description>
    </item>
    
    <item>
      <title>CloudFormationでECSタスクのドレインをやる</title>
      <link>https://shogo82148.github.io/blog/2019/01/30/drain-ecs-task-with-cloudformation/</link>
      <pubDate>Wed, 30 Jan 2019 17:44:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2019/01/30/drain-ecs-task-with-cloudformation/</guid>
      <description>やってみたはいいものの、1年後には仕組みを忘れていそうなのでメモ。
背景 昔はサービス毎にポコポコEC2インスタンスを立てていたのですが、 幸か不幸かインスタンスのリソースが余り気味でした。 そこで、最近流行りのコンテナ技術に乗っかって Amazon ECS (Amazon Elastic Container Service) を使って、 ひとつのインスタンスに複数のサービスを載せようと目論みました。
ちょうどその頃、Spot Fleetというものを使うと、 スポットインスタンスをお手軽に借りられるという話を聞いたので、 Spot Fleet + ECS で格安クラスターを作ってみよう！と手を出してみました。
 (・・・もちろん、Fargateが東京リージョンで使えるようになったことは知っているけれど、スポットインスタンスの価格に負けてしまった・・・)
 AWS Fargate 東京リージョン サービス開始のお知らせ AWS Fargate で最大 50% の値下げを発表  ECS最適化インスタンスの更新問題 クラスターを作るだけなら、そう難しくはなく、インスタンス起動時にAmazon ECS-Optimized Amazon Linux AMIを使うだけです。 問題はこのイメージは定期的に更新される、ということです。 更新情報を流しているSNSトピックがあるので、これをサブスクライブしておくと、時たま更新通知が来ます。
 Amazon ECS-Optimized Amazon Linux AMI の更新の通知のサブスクライブ  この更新には機能追加はもちろん、セキュリティーフィックスも含まれているので、 なるべく早く新しいイメージに移行する必要があります。 移行は大まかに以下の手順で進めます。
 新しいAMIイメージに更新した Spot Fleet を作成する 古いインスタンスに残っているタスクをいい感じに終了する(ドレイン)   突然殺すとユーザーにエラーが見えてしまうので、受付中のリクエストを捌き切ってから終了しないといけない ドレインが始まるとECSがタスク数を調整するために、新しいインスタンスにタスクをお引越ししてくれる  ドレインが終了したら、古いインスタンスをシャットダウンする  ここで問題になってくるのが「古いインスタンスに残っているタスクをいい感じに終了する(ドレイン)」の部分。 コンソールからポチポチするのも面倒なので、自動化したいところ。 しかし、いろいろとドキュメントをあさってみたのですが、「APIかawscliを叩く」「SNSとAWS Lambda をうまいこと組み合わせて頑張る」みたいな方法しか見当たらない・・・ しかもAWSの公式ブログ</description>
    </item>
    
    <item>
      <title>IAM認証でAWS RDSへ接続するMySQLドライバを作った</title>
      <link>https://shogo82148.github.io/blog/2019/01/13/rdsmysql/</link>
      <pubDate>Sun, 13 Jan 2019 17:44:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2019/01/13/rdsmysql/</guid>
      <description>AWS RDS には IAM 認証を使って接続する機能があります。
 MySQL および PostgreSQL に対する IAM データベース認証 IAM 認証情報を使用して Amazon RDS への接続をユーザーに許可する方法を教えてください。  これを使って接続するGo言語のSQLドライバを書いてみました。
 https://github.com/shogo82148/rdsmysql  使い方 IAMデータベース認証はデフォルトで無効になっているので、まずはこれを有効化します。 次に AWSAuthenticationPlugin を認証方式に指定して、新しいユーザーを作りましょう。
 IAM データベース認証の有効化と無効化 データベースアカウントの作成  CREATE USER jane_doe IDENTIFIED WITH AWSAuthenticationPlugin AS &amp;#39;RDS&amp;#39;; 他のSQLドライバはimportするだけで使えるのですが、 rdsmysqlではAWSへの権限情報を設定しなければならない都合上、 sql.Register を自前で呼び出す必要があります。 とは言っても、AWS SDKがいい感じに設定ファイルとか環境変数とか読んでくれるので、 rdsmysql.Driver にAWSセッションを渡すだけです。
c := aws.NewConfig().WithRegion(&amp;#34;ap-northeast-1&amp;#34;) s := session.Must(session.NewSession(c)) d := &amp;amp;Driver{ Session: s, } sql.Register(&amp;#34;rdsmysql&amp;#34;, d) db, err := sql.Open(&amp;#34;rdsmysql&amp;#34;, &amp;#34;jane_doe:@tcp(db-foobar.ap-northeast-1.rds.amazonaws.com:3306)/&amp;#34;) if err != nil { log.</description>
    </item>
    
    <item>
      <title>AWS LambdaでCGIを蘇らせる</title>
      <link>https://shogo82148.github.io/blog/2018/12/16/run-cgi-in-aws-lambda/</link>
      <pubDate>Sun, 16 Dec 2018 17:44:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2018/12/16/run-cgi-in-aws-lambda/</guid>
      <description>この記事は Perl Advent Calendar 2018の15日目の記事です。 (キリの良いところまでできたのと、記事が書かれていなかったので代打投稿)
 Custom Runtime のリリースにより、AWS Lambda 上でPerlが動くようになりました。
 PerlをAWS Lambdaで動かす  次は AWS Lambda + CGI でサーバーレスだな...
&amp;mdash; Ichinose Shogo (@shogo82148) 2018年12月8日  ということで、やっていきましょう。
できたもの 動かすのはもちろん、 CGIアクセスカウンター 。 なんと嬉しいことに、最近になって WwwCounter の新バージョン(Ver3.16)がリリースされ、 Perl 5.26 に対応しました！
 2018-11-11 perl 5.26に対応。(Ver3.16)
 更新履歴によれば一つ前の Ver 3.15 のリリースは2003-03-23なので、なんと15年ぶりのアップデートです。 杜甫々さんの AWS Lambda で動かしてくれ！！ という声が聞こえてきそうですね・・・！！！
動いたーーーー！！！！
実装はこちら
 AWS::Lambda   ちなみにWwwCounterのアップデートはPerl 5.26で「@INCからカレントディレクトリが削除」された件への対応だと思います(コミットログがないので予想)。
 第46回　Perl 5.26で変わること（1） - Perl Hackers Hub  実装説明 「そもそもCGIってなんだ？」っていう人も多くなってきたと思うので、そこらへんの歴史の話にも軽く触れます。 この辺の歴史をリアルに体験したわけではないので、誤り等あればご指摘ください。</description>
    </item>
    
    <item>
      <title>PerlをAWS Lambdaで動かす</title>
      <link>https://shogo82148.github.io/blog/2018/11/30/perl-in-lambda/</link>
      <pubDate>Fri, 30 Nov 2018 17:44:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2018/11/30/perl-in-lambda/</guid>
      <description>AWS Lambda で Custom Runtime が発表されました！
 新機能 – AWS Lambda :あらゆるプログラム言語への対応と一般的なコンポーネントの共有 New for AWS Lambda – Use Any Programming Language and Share Common Components AWS Lambda Now Supports Custom Runtimes, and Enables Sharing Common Code Between Functions  Custom Runtime により好きなプログラミング言語でLambda関数を書くことができ、 いくつかの言語についてはAWSおよびパートナーから bootstrap が提供されます。
提供される言語にCOBOLが入って話題になっていますが、 当然ながら(？)Perlはありません。
Custom Runtimeは shell script でも書ける簡単なものなので、Perlでも書いてみました。
Perl in AWS Lambda 以下のスクリプトを bootstrap という名前で保存します。
#!/usr/bin/env perl use utf8; use warnings; use strict; use lib &amp;#34;$ENV{LAMBDA_TASK_ROOT}/local/lib/perl5&amp;#34;; use Furl; use JSON; my $furl = Furl-&amp;gt;new; my ($handler, $function) = split /\.</description>
    </item>
    
    <item>
      <title>Goのnil,true,falseは変数名に使えるという話</title>
      <link>https://shogo82148.github.io/blog/2018/11/22/go-nil/</link>
      <pubDate>Thu, 22 Nov 2018 17:44:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2018/11/22/go-nil/</guid>
      <description>@Linda_pp さんのツイートをみて
Go 言語の nil って NilLit じゃなくて Ident &amp;quot;nil&amp;quot; としてパースされるのか．それで気付いたけど nil := 42 みたいに普通に変数宣言できる（unused でエラーになるけど）
&amp;mdash; ドッグ (@Linda_pp) 2018年11月22日  なるほど、これは面白い。 と少し遊んでみたメモ。
 言語仕様にある通り、Goのキーワードは以下の25個です(Go1.11.2)。
break default func interface select case defer go map struct chan else goto package switch const fallthrough if range type continue for import return var この一覧に nil や true, false は入っていません。 これらは builtinという扱いになっており、識別子として利用可能です。
そのため、変数名等に利用可能というわけですね。面白い。
package main import ( &amp;#34;fmt&amp;#34; ) func main() { nil := 42 fmt.</description>
    </item>
    
    <item>
      <title>PHPer向けGoのJSONデコーダーを作った</title>
      <link>https://shogo82148.github.io/blog/2018/09/24/go-phper-json/</link>
      <pubDate>Mon, 24 Sep 2018 17:44:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2018/09/24/go-phper-json/</guid>
      <description>必要に迫られて作りました。 PHPでエンコードしたJSONをいい感じにデコードしてくれるGoのパッケージです。
 shogo82148/go-phper-json  背景 さて、PHPerの方々には当たり前のことかもしれませんが、PHPの言語仕様について少しおさらいです。 それがどうしてGoで問題になるか見ていきます。
PHPのarray問題 PHPはとても便利なプログラミング言語なので、配列を扱うことができます。 ここでPHPの配列のマニュアルを読んでみましょう。
 http://php.net/manual/ja/language.types.array.php
PHP の配列は、実際には順番付けられたマップです。マップは型の一種で、 値をキーに関連付けます。 この型は、さまざまな使い道にあわせて最適化されます。 配列としてだけでなく、リスト (ベクター)、 ハッシュテーブル (マップの実装の一つ)、辞書、コレクション、スタック、 キュー等として使用することが可能です。 PHP の配列には他の PHP 配列を値として保持することができるため、 非常に簡単にツリー構造を表現することが可能です。 (強調部分は筆者によるもの)
 重要なことなのでもう一度。
 配列としてだけでなく、リスト (ベクター)、 ハッシュテーブル (マップの実装の一つ)、辞書、コレクション、スタック、 キュー等として使用することが可能です。
 他の言語でリスト、ハッシュテーブル、辞書等と呼ばれているものは、PHPにおいてはいずれも配列です。 PHPにとっては、整数を添字にしているか、文字列を添字にしているかの違いでしかありません。 (PHP7.xから整数が添字の場合に最適化が入るようになったらしいけど、大きな挙動の変更はないはず)
そのため、以下のスクリプトは true を返します。
&amp;lt;?php $a = array(&amp;#34;apple&amp;#34;, &amp;#34;banana&amp;#34;); $b = array(0 =&amp;gt; &amp;#34;apple&amp;#34;, 1 =&amp;gt; &amp;#34;banana&amp;#34;); var_dump($a == $b); // bool(true) この仕様のため、JSONにエンコードすると最初は配列だったのに、 処理を進めていくうちにうっかり文字列のキーを作ってしまって、 JSONのオブジェクトに変わってました、ということが起こりえます。 Goにおいて両者は全く違う型なので、デコードの際に非常に困ります。
&amp;lt;?php $a = array(1, 2, 3); print json_encode($a); // [1,2,3]  $a[&amp;#34;foo&amp;#34;] = &amp;#34;bar&amp;#34;; print json_encode($a); // {&amp;#34;0&amp;#34;:1,&amp;#34;1&amp;#34;:2,&amp;#34;2&amp;#34;:3,&amp;#34;foo&amp;#34;:&amp;#34;bar&amp;#34;} このような悲劇を防ぐために、 JSON_FORCE_OBJECT というオプションがあるのですが、 オプションの名前通りに全部JSONのオブジェクトになってしまいます。 この要素だけJSONの配列にして欲しい！といった細かな操作はできません。</description>
    </item>
    
    <item>
      <title>〜夏休みの自由研究〜 電波時計のサマータイム対応状況を調べてみた</title>
      <link>https://shogo82148.github.io/blog/2018/08/20/summer-time-homework/</link>
      <pubDate>Mon, 20 Aug 2018 09:29:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2018/08/20/summer-time-homework/</guid>
      <description>僕は知っています。
ぜひ、みなさんもお手元の電波時計で試してみてください！
と書いても、試してくれる人なんていないことを。
僕は知っています。
説明書や仕様書に書いてあったとしても、書いてあるとおりに動作する機械なんて、ほんの一握りだということを。
というわけで、楽しい夏休みの自由研究です。 秋葉原で適当に買った1000円から3000円くらいの電波時計に、サマータイムのフラグを有効にした電波を受信させてみて、どういう挙動になるか調査してみました。
TL;DR 10機種(SEIKO, CITIZEN, CASIO, MAG, ELECOM, その他)に対して、サマータイムフラグを有効にした状態で Web JJY の電波を送信しました。
 今回の調査範囲では、夏時間の時刻(1時間 or 2時間ズレた時刻)を表示する時計は見つからなかった 夏時間実施中(DST)と表示 する時計は実在する 室内で使うならCASIOの電波時計はクオーツ時計だと思ったほうがいい  電波受信の様子をYouTubeにあげておいたので興味のある方はどうぞ。
 背景 2018年、日本は記録的な猛暑に見舞われ、 観測史上最高の気温41.1度を記録し、 熱中症とみられる症状で90人以上が亡くなるという甚大な被害を被った。
 今週の天気　記録的な猛暑　底知れぬ暑い夏 日本で猛暑　気温41.1度で観測史上最高 気象庁「災害と認識」熱中症死の疑い６日で９０人超  この記録的猛暑を受け、政府・与党によって2020年の東京五輪・パラリンピックの酷暑対策として、夏の期間だけ時間を2時間繰り上げる「サマータイム(夏時間)」の導入が検討されている。
 酷暑対策でサマータイム導入へ　秋の臨時国会で議員立法　３１、３２年限定  これに対して、「電波時計が狂うのではないか」「日本中の電波時計がゴミになる」等、電波時計が正しい時刻を示さなくなるとの指摘が相次いでいる。
 サマータイム導入で「電波時計が狂う」？　メーカーに聞いた サマータイムで日本中の電波時計がゴミになる(かも)という話  電波時計は、NICT(情報通信研究機構)が提供している標準電波(JJY)を受信し、時刻の同期を行っている。 この標準電波には、時、分、通算日、年、曜日といったタイムコード情報に加え、 将来の拡張性のための「予備ビット」が設けられている。 この予備ビットに関して、「標準電波の出し方について」には、夏時間情報として意味を持たせる場合の例が記載されているが、これはあくまでも例であり、告示などで正式に決まっているものではない。 しかし、現実に市販されている電波時計のなかにも、仕様上予備ビットの状態を認識する機種がする。
標準電波の送信周波数40kHzを提供する「おおたかどや山標準電波送信所」は1999年6月運用開始、送信周波数60kHzを提供する「はがね山標準電波送信所」は2001年10月運用開始である。 日本でサマータイムが導入されたのは1948年から1951年の期間だけなので、 今後サマータイムが導入されることとなれば、標準電波の運用が始まってから初のサマータイム導入となる。
 夏時刻法 - Wikipedia 長波帯標準電波施設 パンフレット(PDF)  そのため、仕様上はサマータイムへ対応している電波時計であっても、初のサマータイム実施によって未知の挙動を示すことが十分に想定される。 そこで、本記事では、実際にサマータイム実施中の電波を電波時計に受信させ、 どのような挙動を示すのかを明らかにする。
目的 2018年8月現在日本で市販されている電波時計が、サマータイムの情報を含んだ標準電波(JJY)を受信した場合の挙動を調査し、 仮に、2019年、2020年にサマータイムが導入された場合の影響を明らかにする。</description>
    </item>
    
    <item>
      <title>GoAst ViewerをWebAssemblyへビルドしてみた</title>
      <link>https://shogo82148.github.io/blog/2018/08/19/goast-viewer-using-wasm/</link>
      <pubDate>Sun, 19 Aug 2018 07:29:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2018/08/19/goast-viewer-using-wasm/</guid>
      <description>もうすぐリリースのGo1.11ではWebAssemblyのサポートが予定されています。 (2018/08/19現在の最新版はGo1.11rc1)
 Go言語がWebAssemblyをサポートへ。GOARCHは「wasm」、GOOSは「js」に  正式リリース前に少し遊んでみようということで、@yuroyoroさんのGoAst ViewerをWebAssemblyへビルドしてみました。
 GoAst Viewer WebAssembly Version shogo82148/goast-viewer  JavaScriptの連携方法 コードをASTに変換し、JSONとしてエンコードする部分(ast.go)に関しては、一切変更しなくても動きました。素晴らしい。
ただし、さすがにブラウザ上でHTTPサーバーは動かない(そういえば試してないけど、動かないよね？？)ので、JavaScriptとの連携部分を実装してあげる必要があります。 syscall/jsパッケージはまだ実験段階というステータスで機能が限られているので、 連携には少し工夫が必要です。
JavaScriptからGoの関数を呼ぶ JavaScriptからGoの関数を呼ぶには window にコールバック関数として必要な関数を登録します。
// GoASTParse 関数を定義(Go言語) js.Global().Set(&amp;#34;GoASTParse&amp;#34;, js.NewCallback(func(args []js.Value) { source := args[0].String() // ...ASTへの変換処理... })) 戻り値をGoからJavaScriptへ返す js.NewCallback なのですが、もともとは addEventListener にわたすコールバック関数なので、 関数の戻り値を受けわたす方法がありません。 回避方法はいろいろあるでしょうが、今回はコールバック関数の引数にコールバック関数指定してもらうことにしました。
// GoASTParse 関数を定義(Go言語) js.Global().Set(&amp;#34;GoASTParse&amp;#34;, js.NewCallback(func(args []js.Value) { source := args[0].String() // ...ASTへの変換処理...  args[1].Invoke(string(body)) })) // GoASTParseを呼び出す(JavaScript) GoASTParse(&amp;#34;package main; func main() {}&amp;#34;, function(body) { // ASTの表示処理 }) まとめ Goのバイナリ全般に言えることですが、WASMになってもやっぱりサイズが大きい(3.</description>
    </item>
    
    <item>
      <title>Web JJY が夏時間に対応しました</title>
      <link>https://shogo82148.github.io/blog/2018/08/11/web-jjy-summer-time-support/</link>
      <pubDate>Sat, 11 Aug 2018 07:29:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2018/08/11/web-jjy-summer-time-support/</guid>
      <description>サマータイムなんて日本人には関係ないと思っていた時期が僕にもありました。 ところが何やら日本にもサマータイムがやってくる動きがあるようです。
 酷暑対策でサマータイム導入へ　秋の臨時国会で議員立法　３１、３２年限定  さて、長波JJY(市販の電波時計のための電波)には夏時間の情報が含まれています。 「将来の拡張性のための予備ビット」という扱いなので、対応している時計なんてないだろう、と思っていたら、 なんと対応している時計が存在しているらしいということを知りました。
その事実を確かめるため、Webブラウザを使って電波を出してみたで紹介した JJYシミュレータWeb版に夏時間を有効にするチェックボックスを追加しました。
CITIZEN 8RZ152 の動作例 夏時間への同期、完了しました 😂😂😂 pic.twitter.com/3tMcCYdXpP
&amp;mdash; Ichinose Shogo (@shogo82148) 2018年8月9日  念の為書いておきますが、今は午前8時です
&amp;mdash; Ichinose Shogo (@shogo82148) 2018年8月9日  DST(Daylight Saving Time)の表示が出て、夏時間に切り替わったことがわかりますが、なぜか6時間もズレています・・・。
もう、こんな時間だ……そろそろ寝よう……
？？？お前24時間表記だっただろ？どうしたんだ？？？
(今は20時です) pic.twitter.com/8PViLOaj85
&amp;mdash; Ichinose Shogo (@shogo82148) 2018年8月10日  悲報 11日を迎えることができず pic.twitter.com/pw0k0Qo8RY
&amp;mdash; Ichinose Shogo (@shogo82148) 2018年8月10日  もはや数字ではないものが出てきた。
まとめ 夏時間に対応した電波時計の存在は事実でした。 しかし、機種によっては挙動がおかしくなるようです(N=1)。
ぜひ、みなさんもお手元の電波時計で試してみてください！
 JJYシミュレータWeb版  ※ 利用の結果生じた損害について、一切責任を負いません。
参考  標準電波の出し方について 酷暑対策でサマータイム導入へ　秋の臨時国会で議員立法　３１、３２年限定 Webブラウザを使って電波を出してみた サマータイムで日本中の電波時計がゴミになる(かも)という話 サマータイム導入で「電波時計が狂う」？　メーカーに聞いた 「サマータイム導入はコンピュータシステム的に難あり」は本当か    サマータイム実施は不可能である  from UEHARA, Tetsutaro  僕もサマータイム実施は不可能だと思います・・・。</description>
    </item>
    
    <item>
      <title>S3からファイルを落とすだけのツールを作った</title>
      <link>https://shogo82148.github.io/blog/2018/06/20/s3cli-mini/</link>
      <pubDate>Wed, 20 Jun 2018 07:29:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2018/06/20/s3cli-mini/</guid>
      <description>S3からファイルを落とすだけのツールを作りました。
 s3cli-mini  目的 流行りのCD(継続的デリバリー)を実践するために、専用のデプロイツールをダウンロードする目的で作りました。
主なデプロイ先はAWSなので、デプロイ操作には awscli が必要です。 しかしCDに使用しているCircleCIが公式に提供しているコンテナイメージにはawscliがインストールされていません。 もちろん apt-get install awscli であとからインストールすることは可能ですが、そのぶんジョブの実行時間が長くなってしまいます。 また、インストールされる awscli のバージョンが古く、ローカル環境ではうまく動くけど、 CircleCI上では最新の機能が使えず失敗するということがありました。
そこでもう awscli を使うことは諦めて、Goで AWS API を叩いてデプロイするバイナリを作ってしまうことを考えました。 Goであればシングルバイナリでインストール可能で、CI/CD環境とローカルでバージョンが一致せず悩まされることはありません。 また並行処理が得意なので、デプロイの時間短縮も図れます。
しかし、このデプロイ用のバイナリをどこに置くか・・・プロジェクト固有の処理が入っているので外部には公開したくない。 かといってプライベートなS3バケットに置くと、ダウンロードに awscli が必要になってしまう・・・。 awscli を使うのは諦めたはずでは・・・という、いわゆる「鶏が先か、卵が先か」問題に陥ってしまいました。
そこでS3からのダウンロードの処理に特化したミニawscliが欲しくなって作成したのが s3cli-mini です。
使い方 現状v0.0.1でサポートしているのは cp コマンドのみです。 S3バケットからファイルをダウンロードしたり、S3バケットへファイルをアップロードしたり、 別のS3バケットへファイルを転送することができます。
# download from a S3 bucket s3cli-mini cp s3://your-bucket/foobar.zip . # upload to a S3 bucket s3cli-mini cp foobar.zip s3://your-bucket/ # copy the file from a S3 bucket to another S3 bucket.</description>
    </item>
    
    <item>
      <title>GoでHTTPとS3を透過的に扱う</title>
      <link>https://shogo82148.github.io/blog/2018/06/09/go-s3-protocol/</link>
      <pubDate>Sat, 09 Jun 2018 07:29:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2018/06/09/go-s3-protocol/</guid>
      <description>Goの http.Transport には RegisterProtocol というメソッドが生えていて これを使うと、 HTTP以外のプロトコルを透過的に扱うことができます。 代表的なのは http.NewFileTransport で、これを使うと、file://path/to/file.txt みたいなURLでファイルにアクセスすることができます。 (Goオフィシャルの例) この仕組を使って、S3へのアクセスも透過的にできるようにしてみたので、メモ。
新しいプロトコルを作成するのは非常に簡単です。 http.RoundTripperインターフェースを実装し、リクエストに応答するレスポンスを作ってあげればいいだけです。 S3の場合以下のようになります。(エラー時の扱いが雑だけど・・・)
package main import ( &amp;#34;net/http&amp;#34; &amp;#34;github.com/aws/aws-sdk-go/aws&amp;#34; &amp;#34;github.com/aws/aws-sdk-go/aws/session&amp;#34; &amp;#34;github.com/aws/aws-sdk-go/service/s3&amp;#34; ) type s3RoundTripper struct { s3 *s3.S3 } func newS3RoundTripper(session *session.Session) http.RoundTripper { return &amp;amp;s3RoundTripper{ s3: s3.New(session), } } func (rt *s3RoundTripper) RoundTrip(req *http.Request) (*http.Response, error) { host := req.Host if host == &amp;#34;&amp;#34; { host = req.URL.Host } path := req.URL.Path ctx := req.Context() out, err := rt.</description>
    </item>
    
    <item>
      <title>Goの構造体のコピーを防止する方法</title>
      <link>https://shogo82148.github.io/blog/2018/05/16/macopy-is-struct/</link>
      <pubDate>Wed, 16 May 2018 07:29:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2018/05/16/macopy-is-struct/</guid>
      <description>去年仕込んだネタが見つかってしまったので、macopy構造体について一応解説。
https://t.co/mHq6oWY3rj
macopyさん構造体だったのか・・・
&amp;mdash; serinuntius (@_serinuntius) 2018年5月14日  目的 深淵な理由でGoの構造体のコピーを禁止したい場合があると思います。 kuiperbeltのケースでは、sync/atomicパッケージを使ってフィールドを更新しているので、 フィールドへの読み書きは必ずsync/atomicパッケージを使わなければなりません。 sync/atomicパッケージを使わずに構造体をコピーするとレースコンディションが発生してしまうので、コピーを禁止する必要がありました。
// https://github.com/kuiperbelt/kuiperbelt/blob/e3c1432ed798716c8e88183518f9126951c227f3/stats.go#L20-L28 type Stats struct { connections int64 totalConnections int64 totalMessages int64 connectErrors int64 messageErrors int64 closingConnections int64 noCopy macopy } // atomic.AddInt64 を使っているので、s.connections の読み取り時には必ずこのメソッドを呼んで欲しい。 func (s *Stats) Connections() int64 { // return s.connections ではレースコンディションになってしまう。 	return atomic.LoadInt64(&amp;amp;s.connections) } func (s *Stats) ConnectEvent() { atomic.AddInt64(&amp;amp;s.totalConnections, 1) atomic.AddInt64(&amp;amp;s.connections, 1) } macopy構造体の使い方 そこで登場するのがmacopy構造体です(いや、もちろん別の名前でもいいんですが)。
// https://github.com/kuiperbelt/kuiperbelt/blob/e3c1432ed798716c8e88183518f9126951c227f3/stats.go#L12-L18  // macopy may be embedded into structs which must not be copied // after the first use.</description>
    </item>
    
    <item>
      <title>OctopressからHugoに乗り換えた</title>
      <link>https://shogo82148.github.io/blog/2018/04/10/migrate-to-hugo/</link>
      <pubDate>Tue, 10 Apr 2018 07:49:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2018/04/10/migrate-to-hugo/</guid>
      <description>OctopressからHugoに乗り換えました。 以下のような理由からです。
 Rubyの環境をメンテナンスし続けるのが面倒 最近Octopress自体の更新が滞っている ビルド時間が長い  一番最初の理由が大きくて、いつもビルドしていた環境を壊してしまって修復が面倒になってしまいました。 そこでようやく重い腰を上げて移行したというわけです。
移行手順 OctopressからHugoへの移行は先人たちがたくさんいるので、それを参考にします。
# 記事のコピー cp octopress-site/source/_posts/* hugo-site/content/post/ # 画像のコピー cp -r octopress-site/source/images/* hugo-site/static/images/ # 記事のタイムスタンプの形式を変える # Hugoでは、&amp;#34;2016-09-25T15:09:57&amp;#34;のような形式のタイムスタンプでないとパースに失敗します find . -type f -exec sed -i &amp;#34;&amp;#34; -e &amp;#39;s/date: \([0-9]\{4\}-[0-9]\{2\}-[0-9]\{2\}\) \([0-9]\{2\}:[0-9]\{2\}\)$/date: \1T\2:00+09:00/g&amp;#39; {} \; パーマネントリンクを維持するために OctopressからHugoへ移行する方法 のRubyスクリプトを利用させていただきました。
dir = &amp;#39;content/post/&amp;#39; Dir::foreach(dir) do |filename| if filename =~ /\.markdown$/ slug = filename.gsub(/\d{4}-\d{2}-\d{2}-/, &amp;#39;&amp;#39;).sub(&amp;#39;.markdown&amp;#39;, &amp;#39;&amp;#39;) puts &amp;#34;#{filename}: #{slug}&amp;#34; lines = [] File::open(dir + filename) do |f| f.</description>
    </item>
    
    <item>
      <title>Mackerel AWS Integration 用の CloudFormation テンプレートを書いた</title>
      <link>https://shogo82148.github.io/blog/2018/01/02/cloudformation-template-for-mackerel-integration/</link>
      <pubDate>Tue, 02 Jan 2018 12:36:51 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2018/01/02/cloudformation-template-for-mackerel-integration/</guid>
      <description>昨年の年末から Mackerel の本格導入を始めました。 それに当たって AWS Integration 用の CloudFormation テンプレートを書いたので、 他のプロジェクトでも導入が簡単になるよう公開しました。
 shogo82148/cf_mackerel  使い方 GitHub Pages でテンプレートを公開しているので、 template-body にテンプレートのURLを指定して、 新しいスタックを作成するだけです。
aws cloudformation create-stack --stack-name &amp;quot;MackerelIntegrationIamUser&amp;quot; \ --template-body https://shogo82148.github.io/cf_mackerel/mackerel.yaml \ --capabilities CAPABILITY_NAMED_IAM 新しい名前付きIAMロールを作成するので CAPABILITY_NAMED_IAM が必要です。
作成がうまくいくとOutputに以下のようなARNが出力されるので、 MackerelのAWS Integrationの設定画面へ入力しましょう。
arn:aws:iam::xxxxxxxxxxxx:role/MackerelAWSIntegrationRole-ap-northeast-1 ロール名について ロール名が意図せずに変わってしまって連携が切れてしまうのを防ぐため、 ロール名は決め打ちです。
 MackerelAWSIntegrationRole-ap-northeast-1
 ロール名にリージョン名(この場合は ap-northeast-1)が含まれていますが、 作成されたロールはグローバルなリソースなので、他のリージョンでも使用可能です。 わざわざリージョン名含めているのは CloudFormation の警告にしたがったためです。
 警告
IAM リソースに名前を付けると、複数のリージョンで同じテンプレートを再利用した場合に、回復不能なエラーが発生する場合があります。 これを防止するために、Fn::Join と AWS::Region を使用して、次の例のように地域固有の名前を作成することをお勧めします RoleName
 回復不能なエラー！！
コワイので実際に何が起こるかは試してませんが、警告には素直に従っておくことにします。
参考  AWS::IAM::Role - AWS CloudFormation - mackerelのAWSインテグレーション用IAM Userをcloudformationで作る Tomohiro/tf_mackerel 同じことをするTerraformのモジュール  </description>
    </item>
    
    <item>
      <title>MeCabをAWS Lambdaで動かす(2017年版)</title>
      <link>https://shogo82148.github.io/blog/2017/12/06/mecab-in-lambda/</link>
      <pubDate>Wed, 06 Dec 2017 05:39:57 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2017/12/06/mecab-in-lambda/</guid>
      <description>AWS Lambda上で鯖(Mackerel)の曖昧性問題を機械学習で解決しようの記事の中で、 Lambda上でMeCabを動かすことについて以下のように触れられています。
 日本語を扱う自然言語処理ではMeCabを扱うことが多いですが、Lambda上でMeCabを動かすのは一手間必要なようです。
 確かにLambda上でMeCabを動かすのは一手間必要です。 しかし、参照している記事は少し古くて、今はもう少し手軽にできるようになっています。
ブコメでも言及しましたが、改めて記事として残しておこうと思います。
ビルド方法(2017年版) 結論から言うと Norio Kimura さんのコメント 通りにビルドするのが、2017年12月現在一番楽な方法です。 (お返事すっかり忘れていてスイマセン・・・情報提供ありがとうございます)
 調べてみると、AWS Lambda では環境変数 LD_LIBRARY_PATH が既に設定されていて /var/task/lib を含んでいました。元記事で ./configure &amp;ndash;prefix=$PROJECT_HOME/local ではなく ./configure &amp;ndash;prefix=$PROJECT_HOME とすればライブラリとの動的リンクは何もしなくても実現できます。さらにコードが展開されるディレクトリ /var/task を固定値だと決め打ちして PROJECT_HOME を /var/task にして開発すれば MeCab に渡すパラメーターの設定（-d, -r）も不要になります。undocumented な仕様に２つも依存していて気持ち悪いですが、MeCab を呼ぶ側のコードを Lambda 用に変更する必要がなくなります。
 コメント中の元記事というのは、こちらの記事のことです。
 AWS Lambda で MeCab を動かす  export PROJECT_HOME=/var/task # LAMBDA_TASK_ROOT # 1. プロジェクト用にディレクトリを作成 mkdir -p &amp;#34;$PROJECT_HOME&amp;#34; # 2. MeCabのダウンロードとインストール # googlecodeサービス終了に伴い、ダウンロードURLが元記事と変わっていることに注意 cd &amp;#34;$HOME&amp;#34; curl -fsSL &amp;#34;https://drive.</description>
    </item>
    
    <item>
      <title>Go言語の浮動小数点数のお話</title>
      <link>https://shogo82148.github.io/blog/2017/10/28/golang-floating-point-number/</link>
      <pubDate>Sat, 28 Oct 2017 20:12:48 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2017/10/28/golang-floating-point-number/</guid>
      <description>元ネタ:
[JavaScriptの問題]
var a = 0.3 - 0.2;
var b = 0.2 - 0.1;
var c = a==b;
cの中身はどれ？
&amp;mdash; RAO(らお)@けもケP-31 (@RIORAO) 2017年10月24日  正確な実数計算をやらされるJavaScriptくん #擬竜戯画 pic.twitter.com/ipE56C2YbV
&amp;mdash; RAO(らお)@けもケP-31 (@RIORAO) 2017年10月26日  コンピューターで浮動小数点数を扱ったことのある人なら一度は経験する、 数学上の計算とコンピューター上の計算が合わない計算の一例ですね。
この件に関して、Go言語では正しく(=数学的な結果と同じように)計算できるとの情報が。
おそらくGoはコンパイラがa=0.1とb=0.1に変換していると思われます。
添付した画像のコードだとtrueになりますが、constをvarに変更するとfalseになります。constはコンパイル時に計算されますが、varは実行時に計算されるためです。 pic.twitter.com/LpKZF2kOjH
&amp;mdash; morikuni (@inukirom) 2017年10月27日  しかしながら、inukiromさんのこの推察、半分はあってますが、半分は間違っていると思います。 なぜGo言語でこのような結果になったのか、検証してみました。
Goの数値定数の型について 以前Go言語でコンパイル時フィボナッチ数列計算で紹介した Better C - Go言語と整数 #golangにもあるように、 Goの定数には「型がない(場合がある)」「任意の精度で計算してくれる」という特徴があります。
このため、普通はどう考えてもオーバーフローしそうなこんな演算も・・・
package main import ( &amp;#34;fmt&amp;#34; ) func main() { var i uint64 = 31415926535897932384626433832795028841971693993751058209749445923078164062862089986280348253421170679 % 1000000007 fmt.</description>
    </item>
    
    <item>
      <title>ACMのドメイン検証をシミュレートするやつ書いた</title>
      <link>https://shogo82148.github.io/blog/2017/10/22/aws-certification-manager-validation/</link>
      <pubDate>Sun, 22 Oct 2017 15:45:02 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2017/10/22/aws-certification-manager-validation/</guid>
      <description>始まりは一件のメールから。
 Title: Action Required - Your certificate renewal
Greetings from Amazon Web Services,
You have an AWS Certificate Manager (ACM) provided SSL/TLS certificate in your AWS account that expires on Nov 04, 2017 at 12:00:00 UTC. That certificate has the following domains: example.com, *.example.com
AWS account ID: xxxxxx AWS Region name: us-east-1 Certificate identifier: arn:aws:acm:us-east-1:xxxxxx:certificate/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
Therefore, ACM has initiated the process to renew this certificate. You must take the action below before Nov 04, 2017 at 12:00:00 UTC to avoid certificate expiration, which might cause your website to become unreachable.</description>
    </item>
    
    <item>
      <title>Perl 5.26 &amp; Unicode 9.0 で変わる書記素クラスタ(grapheme cluster)のお話</title>
      <link>https://shogo82148.github.io/blog/2017/08/25/unicode9-grapheme-cluster/</link>
      <pubDate>Fri, 25 Aug 2017 07:08:44 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2017/08/25/unicode9-grapheme-cluster/</guid>
      <description>WEB+DB PRESS Vol.100が発売されましたね。 記念すべき Vol.100 おめでとうございます！
WEB+DB PRESS の連載「Perl Hackers Hub」今回のテーマは「【第46回】Perl 5.26で変わること」です。 Perl 5.26 で追加になった機能、アップグレードの際に気をつけなければならないところ( 特に @INC 問題とか )などに触れられているので、 Perl Monger の方はぜひ読むとよいと思います。
追加された機能のひとつとして Unicode 9.0 サポートが挙げられているのですが、以下のような簡単な紹介に留まっています。
 Unicode 9.0にはオリンピックで活躍するであろう金銀 銅メダルの絵文字などが追加されました。
 Unicode 9.0 で変わるのはそれだけではありません！ Unicode 9.0 での 書記素クラスタ(grapheme cluster) の扱いを少し前に調査したので紹介します。
書記素クラスタ(grapheme cluster)とは 書記素クラスタ(grapheme cluster)とは、人間にとって自然な1文字を表すものです。
たとえば &amp;ldquo;é&amp;rdquo; という文字は一見1文字に見えますが、 length で文字数をカウントすると2文字としてカウントされます。
$ perl -Mutf8 -E &#39;say length &amp;quot;é&amp;quot;&#39; 2 これは length がUnicodeのコードポイント数を数えており、 &amp;ldquo;é&amp;quot;が&amp;quot;e&amp;rdquo;(U+0065) + アクセント記号(U+0301) の2つのコードポイントで構成されているためです。
他にも異字体セレクタというのがあったり、 絵文字シーケンスというのがあったりして、 コードポイントの数＝文字数とは限りません。
これらの文字たちを1文字として数えるための概念が書記素クラスタ(grapheme cluster)です。
Unicode 9.</description>
    </item>
    
    <item>
      <title>Go1.9から使える Monotonic Clocks を試してみた</title>
      <link>https://shogo82148.github.io/blog/2017/06/26/go19-monotonic-clock/</link>
      <pubDate>Mon, 26 Jun 2017 09:21:42 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2017/06/26/go19-monotonic-clock/</guid>
      <description>先日Go1.9beta1がリリースされました。
Go 1.9 Beta 1 is released!
Announcement:https://t.co/lV5nvXwOoR
Get it!https://t.co/2LhlOo2EtX#golang pic.twitter.com/zm09DwX93q
&amp;mdash; Go (@golang) 2017年6月14日   Go 1.9 Release Notes  型エイリアスのサポート、math/bitsパッケージ、 sync.Map型など、 今回のアップデートでも便利そうな機能が追加されます。 詳しくはtenntennさんのGopher Fest 2017参加レポートをどうぞ。
今回のリリースノートを見て、個人的に注目しているのはMonotonic Clocksのサポートです。 他の機能追加はTwitterとかで見かけるけど、 Monotonic Clocksはなぜかあまり見ない・・・。 beta1がでて手軽に試せるようになったので、試してみました。
Monotonic Clocks Go1.8以前で取得していた時刻は「wall clock」といい、現在の正しい時刻を知るために使います。 一方「monotonic clock」は、時間を計るために使うものです。 Go1.9からはtime.Nowで取得できる時刻に「wall clock」と「monotonic clock」が含まれるようになります。
timeパッケージのドキュメントから コード片を引用します。
t := time.Now() ... operation that takes 20 milliseconds ... u := time.Now() elapsed := t.Sub(u) 上のコードで elapsed は 20ms となるはずですが、 実際はそうはならないケースがあります。 具体的には以下のようなケースです。
 ntpdなどによってOSの時刻が変更された場合 うるう秒が挿入・削除された場合  Go1.</description>
    </item>
    
    <item>
      <title>ぼくのかんがえたさいきょうのcontext対応版go-mysql-driverをマージしてもらった</title>
      <link>https://shogo82148.github.io/blog/2017/06/16/mysql-driver-and-context/</link>
      <pubDate>Fri, 16 Jun 2017 07:11:15 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2017/06/16/mysql-driver-and-context/</guid>
      <description>go-sql-driverにcontext.Context対応するプルリクエスト go-sql-driver/mysql#608 を送って取り込んでもらいました！！ 現時点ではまだ正式リリースされていませんが、次のリリース(version 1.4)から使えるようにはずです。 masterブランチではすでに使えるようになっているので、引き続き人柱募集中です。
コネクションプーリングを実装していて、自分も「context.Contextサポートしたい！」というかたのために、 実装の概要をメモとして残しておきます。
おおまかな仕組み  「contextの監視のみを行うgoroutine(以下、watcher goroutine)」をあらかじめ起動しておく 「やりたい処理を実際に実行するgoroutine(以下、executor goritune)」とchannelを経由してcontext.Contextをやり取りする  watcher goroutineがこの実装で一番重要な部分です。
watcher goroutine の実装 一番重要な watcher goroutine の実装例から見てみましょう (実際には細かい最適化などが入るため、マージされたコードとは異なります)。
func (mc *mysqlConn) startWatcher() { // executor goritune と `context.Context` のやり取りをするための channel 	watcher := make(chan context.Context, 1) mc.watcher = watcher // executor goritune で処理が完了したことを知るための channel 	finished := make(chan struct{}) mc.finished = finished // コネクションがCloseされたことを知らせるための channel 	mc.closech = make(chan struct{}) // ここから watcher goroutine 本体 	go func() { for { // executor goritune から `context.</description>
    </item>
    
    <item>
      <title>Re: GoとPythonとGrumpyの速度ベンチマーク</title>
      <link>https://shogo82148.github.io/blog/2017/05/30/grumpy/</link>
      <pubDate>Tue, 30 May 2017 17:53:32 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2017/05/30/grumpy/</guid>
      <description>GoとPythonとGrumpyの速度ベンチマーク ～Googleのトランスパイラはどれくらい速い？～という記事を拝読したのですが、 もう一歩踏み込んで検証して欲しい・・・。
 並列処理性能が優れているほか、PythonコードからGoのパッケージをPythonモジュールのように呼び出して利用することもできるという特徴がある。
 とGoogle、すごくスケールするPython実行環境をGoで開発から引用しているのに、 この件に全く触れていないんですよね。 Twitterに呟いたってどうせ誰もやってくれない気がするので、自分で試してみました。
環境 この記事を書いている2017年5月30日現在の最新バージョンで検証しました。
 go version go1.8.3 darwin/amd64 CPython 2.7.13 Grumpy d8d01899f5  Grumpyのインストール方法はREADMEにある通り。
make export GOPATH=$PWD/build export PYTHONPATH=$PWD/build/lib/python2.7/site-packages ただ個人的な環境問題としてPythonのバージョン管理に利用しているpyenvとの相性が悪いらしく、 pyenvが管理しているPythonへのパスを直接通す必要がありました。 (これがないとPythonスクリプトがなぜかbashに処理される。なんかこの問題最近Twitterで見たような・・・)
export PATH=$HOME/.pyenv/versions/2.7.13/bin:$PATH モンテカルロ法を並列実行してみる まず、並列処理性能について検証してみましょう。 モンテカルロ法の各試行は独立しているので、並列実行にするのは容易です。 Python2のthreadingモジュールを使って並列実行してみましょう。
コード #coding:utf-8 # モンテカルロ法 Pure Python 並列版 import threading import random import sys class MyThread(threading.Thread): def __init__(self): super(MyThread, self).__init__() self.c = 0 def run(self): r = random.Random() c = 0 for _ in xrange(num): x = r.</description>
    </item>
    
    <item>
      <title>String::RandomのGo移植を書いてみた</title>
      <link>https://shogo82148.github.io/blog/2017/05/04/go-rerand/</link>
      <pubDate>Thu, 04 May 2017 10:57:37 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2017/05/04/go-rerand/</guid>
      <description>golangkyotoでString::RandomのGo移植についての発表があったと聞き、 これに対抗して以前途中まで書いていたString::RandomのGo移植をちょっといじって公開しました。
 shogo82148/go-rerand  背景 ナイーブな実装の問題点 実はgolangkyoto以前にもGoの正規表現エンジンを使ってランダムな文字列を生成する試みはあって、 たしかにこれは面白そうだと記事を読んでいました。
 「Goの正規表現エンジンを使ってファジング用ツールを書いてみる」  しかし、gocha同様、この実装では文字列の長さが幾何分布に従うため、短い文字が多めにでてしまいます。
% gocha -n 100000 &amp;#39;a*&amp;#39; | sort | uniq -c 50054 24894 a 12633 aa 6278 aaa 2994 aaaa 1517 aaaaa 809 aaaaaa 400 aaaaaaa 206 aaaaaaaa 109 aaaaaaaaa 54 aaaaaaaaaa 22 aaaaaaaaaaa 15 aaaaaaaaaaaa 7 aaaaaaaaaaaaa 4 aaaaaaaaaaaaaa 3 aaaaaaaaaaaaaaa 1 aaaaaaaaaaaaaaaa 正規表現のパターンを数え上げとその問題点 この問題を解決するために 「この先何パターンあるかを調べておけば、正規表現が表す文字列の集合からランダムに文字列を取り出せるのでは？」 と考え、golangkyoto以前からちょこちょこ実装を進め、不完全ながらも一応動作するところまでは書いていたのです。 有向グラフの経路数えあげ問題なので、メモ化再帰を使って頑張れば解けます。 少々面倒ですが、おねえさんの問題と比べれば簡単です。
パターンを数え上げる都合上、組み合わせが無限にある a* ような正規表現は扱えません。 a{1,10} のように明示的に範囲を指定する必要があります。 たとえば a{1,10} は10パターン組み合わせがあるので、20万個ランダムに生成すると、それぞれのパターンがおおよそ2万個ずつ生成されます。 (-d オプションについては後述)</description>
    </item>
    
    <item>
      <title>Re: PostgreSQLで排他制約がめっちゃ便利！！</title>
      <link>https://shogo82148.github.io/blog/2017/04/22/postgresql-exclusion-constraint/</link>
      <pubDate>Sat, 22 Apr 2017 19:10:21 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2017/04/22/postgresql-exclusion-constraint/</guid>
      <description>PostgreSQLで排他制約がめっちゃ便利！！を拝見したのですが、 とても些細なミスがあるのに気がついてしまいました。 本題とは関係ない重箱の隅をつつくような話なので、わざわざコメントするほどのことでもないかと考えていたのですが、 どうしても試してみたいクエリを思いつき、 偶然にもRedis、PostgreSQL、MySQLで近傍検索したときに セットアップしたPostgreSQL環境が残っていたのでやってみました。
試したかったこと そーだいさんの記事からSQLの実行結果を一部引用します。
demo=# SELECT * FROM schedule; schedule_id | room_name | reservation_time -------------+-------------+----------------------------------------------- 1 | soudai_room | [&amp;#34;2017-04-16 11:30:00&amp;#34;,&amp;#34;2017-04-16 12:00:00&amp;#34;) 4 | soudai_room | [&amp;#34;2017-04-16 12:00:00&amp;#34;,&amp;#34;2017-04-16 12:30:00&amp;#34;) 5 | soudai_room | (&amp;#34;2017-04-16 12:30:00&amp;#34;,&amp;#34;2017-04-16 12:40:00&amp;#34;) 8 | soudai_room | [&amp;#34;2017-04-16 14:30:00&amp;#34;,&amp;#34;2017-04-16 16:00:00&amp;#34;) (4 行) schedule_idの5をよく見て下さい。 他のスケジュールは半開区間[)(開始時刻は期間に含むが、終了時刻は期間に含まない)になっているのですが、 schedule_idの5だけ開区間()(開始時刻も終了時刻も期間に含まない)になっています。 つまり 2017-04-16 12:30:00 ジャストに空き時間があるのです。
ここに予約を入れてみたい！！！
試してみた 環境再現 以下のSQLを実行して、そーだいさんの記事と同じ内容を含んだテーブルを作成します。
CREATE TABLE schedule ( schedule_id SERIAL PRIMARY KEY NOT NULL, room_name TEXT NOT NULL, reservation_time tsrange NOT NULL ); INSERT INTO schedule (schedule_id, room_name, reservation_time) VALUES (1, &amp;#39;soudai_room&amp;#39;, &amp;#39;[&amp;#34;2017-04-16 11:30:00&amp;#34;,&amp;#34;2017-04-16 12:00:00&amp;#34;)&amp;#39;), (4, &amp;#39;soudai_room&amp;#39;, &amp;#39;[&amp;#34;2017-04-16 12:00:00&amp;#34;,&amp;#34;2017-04-16 12:30:00&amp;#34;)&amp;#39;), (5, &amp;#39;soudai_room&amp;#39;, &amp;#39;(&amp;#34;2017-04-16 12:30:00&amp;#34;,&amp;#34;2017-04-16 12:40:00&amp;#34;)&amp;#39;), (8, &amp;#39;soudai_room&amp;#39;, &amp;#39;[&amp;#34;2017-04-16 14:30:00&amp;#34;,&amp;#34;2017-04-16 16:00:00&amp;#34;)&amp;#39;); -- schedule_idが1から始まってしまい、INSERTした内容と重複してしまうので調整 SELECT setval (&amp;#39;schedule_schedule_id_seq&amp;#39;, 8); SELECTを実行すると同じ内容になっていることを確認できます。</description>
    </item>
    
    <item>
      <title>Perl&#43;List::Utilの64bit整数の罠にはまった話</title>
      <link>https://shogo82148.github.io/blog/2017/04/13/perl-int64/</link>
      <pubDate>Thu, 13 Apr 2017 19:52:13 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2017/04/13/perl-int64/</guid>
      <description>先日 Google Code Jam Qualification Round 2017 が開催されました (って何？というひとはAboutのページを確認。本題では無いので説明略)。
僕もこれに参加して、D以外の問題A,B,Cを解いて、無事Round1へ進むことができました。 しかしPerlで解いたC-largeだけ何故か間違いの判定。 原因を探ってみたところ、PerlおよびList::Utilの64bit整数の罠にはまっていたことに気が付いたので、その備忘録として残しておきます。
問題が発生したコード 問題が発生するのは以下の計算をするコードです。
 max: 250000000000000000と249999999999999999で大きい方を返す div: 249999999999999999を2で割った商を求める  この計算をそれぞれ二通りの計算方法で実装してみます。
use 5.24.0; use List::Util qw(max); say &amp;#34;max:&amp;#34;; say max(250000000000000000, 249999999999999999); say max(249999999999999999, 250000000000000000); say &amp;#34;div:&amp;#34;; say int(249999999999999999/2); say 249999999999999999 &amp;gt;&amp;gt; 1;  max: 順番を変えただけなので、同じ結果をになるはず div: 割り算と等価なビットシフトに置き換えたので、同じ結果になるはず  僕は「同じ結果になるはず」と期待していました。 しかし、これを実行してみると以下のようになります。
 [Wandbox]三へ( へ՞ਊ ՞)へ ﾊｯﾊｯ https://wandbox.org/permlink/5fUBzLmBCRKUo4xZ  max: 249999999999999999 250000000000000000 div: 125000000000000000 124999999999999999 原因 250000000000000000は大体2^57.8なので、64bitの整数で十分表現できます。 しかし倍精度浮動小数点数として扱われると、精度が53bit分しかないので正確に表現できないのです。
例えば以下のコードは&amp;quot;true&amp;quot;を出力します(ここだけ何故かGo)。
package main import ( &amp;#34;fmt&amp;#34; ) func main() { fmt.</description>
    </item>
    
    <item>
      <title>Go言語のヒープに確保するデータの初期化コストについて調べてみた(Go1.8.1版)</title>
      <link>https://shogo82148.github.io/blog/2017/04/13/go1-8-allocation/</link>
      <pubDate>Thu, 13 Apr 2017 08:23:08 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2017/04/13/go1-8-allocation/</guid>
      <description>golangで
p := new(Type)
と
p := &amp;amp;Type{}
の使い分けってどうするべきだろう?
&amp;mdash; MURAOKA Taro (@kaoriya) 2017年4月12日  こちらのツイートに対して、以下のベンチ結果が紹介されていました。
 Go言語のヒープに確保するデータの初期化コストについて調べてみた  しかしhnakamur2さんも言及しているように、 これはGo1.2.2時の結果。 その後、GoのコンパイラがGo実装になったり、SSAが導入されたりと、 今のコンパイラの実装は当時とは全く違うものになっています。
というわけで、現時点での最新のバージョン(Go1.8.1)で、同様の検証をおこなってみました。
検証コード 検証に使用したコードはGo1.2.2のときと全く同じものです。
// alloc_overhead.go  package main type container struct { v [64]byte } func MakeContainer() *container { c := container{} return &amp;amp;c } func MakeContainerOneLine() *container { return &amp;amp;container{} } func MakeContainerNew() *container { return new(container) } func main() { _ = MakeContainer() _ = MakeContainerOneLine() _ = MakeContainerNew() } // alloc_overhead_test.</description>
    </item>
    
    <item>
      <title>Redis、PostgreSQL、MySQLで近傍検索</title>
      <link>https://shogo82148.github.io/blog/2017/03/28/database-gis/</link>
      <pubDate>Tue, 28 Mar 2017 19:59:49 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2017/03/28/database-gis/</guid>
      <description>「サーバーで付近の情報を通知するサービスのつくり方」 という、Geohashを使って近傍検索を実現する記事をみつけました。 最近Redisに関する記事を書いた関係で、 この記事をみて「GeohashはRedisと一緒に使うともっと便利だよ！」と思わず宣伝したくなったのですが、 MySQL5.7でInnoDBに空間インデックス(Spatial Index)のサポートが入ったので 「MySQLでももっと簡単にできるのでは？」と思い、 RedisやMySQLを含めたいろんなDBで近傍検索を実現する方法を調べてみました。
以前、スマートフォンのセンサを活用して花火の打ち上げ場所を推定するアプリを作った関係で、 地球上での距離計算の実装も気になったので、それについても調査してみました。
関連知識 GeoHash Geohash（ジオハッシュ） は緯度・経度を短い文字列に変換する方法です。 距離が近い2地点のGeohashは似たような文字列になるという特徴があります(一部例外あり)。 この特徴を利用すると、文字列検索だけで近傍検索が実現できます。
地球上の二点間の距離 地球は完全な球体ではなく、回転楕円体であることが知られています。 地球の形がわからないと緯度・経度などを決められないので、 地球楕円体が定義されています。 近似方法によっていくつか種類があるのですが、GPSなどで使われているWGS84がよく使われているようです。
国土地理院が提供している測量計算サイトでは 距離と方位角の計算を使って緯度・経度から距離を計算できます。 回転楕円体上の距離の厳密解は求められない(要出典)ので、 数値計算によって求めることになります。 計算式を見て分かる通り非常に複雑なので、なんらかの近似をしている実装がほとんどです。
各種DBでの実現方法 Redis Redisでは3.2からGEO関連の機能をサポートしています。 ソート済みセットにGeohashを組み合わせて実現しています。
簡単に試してみました。データは以下の記事から拝借したものを使用します。
 MySQLで指定した緯度経度から半径nメートル内検索っぽいのを実現するSQL PostgreSQLとOracleで緯度経度から半径nメートル内検索を実行してみる。  GEOADDでデータ挿入です。 ちなみにデータを削除するGEODELは用意されていないとのこと。 中身はソート済みセットなので、ZREMでいいんですね。
$ cat command.txt GEOADD geotable 139.777254 35.713768 上野駅 139.774029 35.711846 西郷隆盛像 GEOADD geotable 139.774744 35.712737 上野の森美術館 139.770872 35.712351 不忍池弁財天 GEOADD geotable 139.775696 35.716293 野口英世博士像 139.775803 35.715420 国立西洋美術館 GEOADD geotable 139.776544 35.716319 国立科学博物館 139.</description>
    </item>
    
    <item>
      <title>Go言語のchanはいったいいくつ付けられるのか試してみた</title>
      <link>https://shogo82148.github.io/blog/2017/03/17/how-many-chan-can-i-write-in-golang/</link>
      <pubDate>Fri, 17 Mar 2017 21:10:25 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2017/03/17/how-many-chan-can-i-write-in-golang/</guid>
      <description>pecoに入った修正をみて、果たしてchanはいくつまで付けられるのか気になったので、 雑に試してみました。 先に断っておきますが、全く有用ではないですよ。
背景 pecoに入った修正はこちら(一部抜粋)。
 Make Resume a blocking operation #411  diff --git a/interface.go b/interface.go index 3d4472f..fff446c 100644 --- a/interface.go +++ b/interface.go @@ -162,8 +162,8 @@ type Screen interface {  // Termbox just hands out the processing to the termbox library type Termbox struct { mutex sync.Mutex -	resumeCh chan (struct{}) -	suspendCh chan (struct{}) +	resumeCh chan chan struct{} +	suspendCh chan struct{}  } // View handles the drawing/updating the screen diff --git a/screen.</description>
    </item>
    
    <item>
      <title>HTTP/WebSocketで時刻同期するWebNTPを書いた</title>
      <link>https://shogo82148.github.io/blog/2017/03/11/go-webntp/</link>
      <pubDate>Sat, 11 Mar 2017 18:48:09 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2017/03/11/go-webntp/</guid>
      <description>Go1.8からhttp/httpgtraceが追加され、 HTTP通信にフックを差し込めるようになりました。 以前触った時はパフォーマンス測定に利用しましたが、 他に面白い活用法はないかとWebNTPというのを作ってみました。
 webntp  HTTP/HTTPS/Websocket上でNTP(Network Time Protocol)っぽいことをするプログラムです。
HTTP/HTTPSで時刻同期 日本標準時はNICTの管理する原子時計が基準になっており、 NICTでは原子時計に直結したNTPサーバー(ntp.nict.jp)の提供を行っています。 それに加えて、https/httpサービスも提供しており、 ブラウザを使って現在時刻を取得できます。
APIは簡単でミリ秒単位のtimestampを返してくれるだけです。 その情報からサーバーとクライアント間の時間のズレを算出するわけですが、 HTTP通信では、DNSの名前解決、TCPハンドシェイク、TLSハンドシェイク等々の時間が入ってしまうため、 正確なズレを求めることは困難です。
そこでhttp/httpgtraceを使って、ハンドシェイクを除いたリクエストの送信時刻、レスポンスを最初に受信した時刻から、 より正確なズレを知ることができるのではと作ったのがWebNTPです。 NICTのJSON形式のAPIに対応しており、 以下のように時刻を取得できます。
$ go get github.com/shogo82148/go-webntp/cmd/webntp $ webntp https://ntp-a1.nict.go.jp/cgi-bin/json server https://ntp-a1.nict.go.jp/cgi-bin/json, offset -0.006376, delay 0.024411 2017-03-11 16:08:06.150393313 +0900 JST, server https://ntp-a1.nict.go.jp/cgi-bin/json, offset -0.006376 WebNTPはNICTのAPIと同様の内容を返すサーバーにもなれます。 本家のフォーマットにしたがい、しっかりとうるう秒の情報も返すようになっているので、 ntpdのSLEWモードを切った状態でお試しください。
$ webntp -serve :8080 $ curl -s http://localhost:8080/ | jq . { &amp;#34;id&amp;#34;: &amp;#34;localhost:8080&amp;#34;, &amp;#34;it&amp;#34;: 0, &amp;#34;st&amp;#34;: 1489217288.328757, &amp;#34;time&amp;#34;: 1489217288.328757, &amp;#34;leap&amp;#34;: 36, &amp;#34;next&amp;#34;: 1483228800, // 今年の1/1にあったうるう秒の情報 &amp;#34;step&amp;#34;: 1 } ところで、URLにcgi-binが入っているのは、過去との互換性を保つためにそうなっているのか、 今もCGIで動いているのか、気になる・・・ (少なくとも初期実装はPerlのCGIだったみたいですね)。</description>
    </item>
    
    <item>
      <title>go-JSONStoreの高速化と機能追加</title>
      <link>https://shogo82148.github.io/blog/2017/03/05/tune-up-go-jsonstore/</link>
      <pubDate>Sun, 05 Mar 2017 16:19:25 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2017/03/05/tune-up-go-jsonstore/</guid>
      <description>以前mattnさんが紹介していたschollz/jsonstore。 時間が経ってしまいましたが「ここは高速化できそうだなー」といじってみたので、 やってみたことをメモ。
本来は上流にフィードバックしたほうがよいのですが、 本家のほうも修正が入ってコンフリクトして面倒になったので、 フォーク版をそのまま置いておきます。
 shogo82148/jsonstore  高速化 まだまだ高速化できそうなところがあったので、いじってみた部分です。
ロックの範囲を最小にする ロックの範囲を小さくすることで、並列処理時の性能が上がります。 例えば、jsonstoreに値を入れるSetメソッドは、 以下のようにSet全体がロックの対象になっていました。
func (s *JSONStore) Set(key string, value interface{}) error { // Set の中全体がロックの対象になっている 	s.Lock() defer s.Unlock() b, err := json.Marshal(value) if err != nil { return err } if s.data == nil { s.data = make(map[string]*json.RawMessage) } s.data[key] = (*json.RawMessage)(&amp;amp;b) return nil } jsonのエンコード処理はjsonstoreの中身を触らないので並列実行可能です。 次のように s.data だけをロックの対象にすれば十分です。
func (s *JSONStore) Set(key string, value interface{}) error { // json.</description>
    </item>
    
    <item>
      <title>Redisを使ってユニークなIDを配布する</title>
      <link>https://shogo82148.github.io/blog/2017/02/26/unique-id-supplier-using-redis/</link>
      <pubDate>Sun, 26 Feb 2017 19:37:45 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2017/02/26/unique-id-supplier-using-redis/</guid>
      <description>スケーラブルにIDを生成する方法として Twitterのsnowflakeが有名です。 1024台までスケールすることが出来ますが、各snowflakeのサーバにユニークなWoker IDを割り振る必要があります。 IDを振るためのサーバにIDを振るのが問題になるとは難しいですね。
各snowflakeサーバにIDを振る親玉Worker ID配布サーバを作るというアイデアはあったのですが、 Worker IDサーバの可用性を考えるのが大変で手を付けていませんでした。 最近になってWorker IDサーバとしてRedisを使い、ソート済みセット型で管理すれば楽できるのでは？ と思いついたので、やってみたというお話です。
概要 レポジトリはこちらです。
 shogo82148/yaraus  他のsnowflake-likeなID発番サーバの実装として katsubushiや sonyflakeなんていうのもあります。 これらのID発番サーバにRedisを使ってWorker IDを割り振るコマンドです。 Redis3.2以上推奨です。
使い方 Go製なのでgo getでインストールできます。
go get github.com/shogo82148/yaraus/cmd/yaraus # 1から1023までのIDが使えるようにRedisを初期化 $ yaraus init -min 1 -max 1023 # ユニークなIDが必要な処理を実行する $ yaraus run -- echo {} 2017/02/25 17:19:16 getting new id... 2017/02/25 17:19:16 client id: YourHostName-1488010756.738-1, id: 1 2017/02/25 17:19:16 sleep 2s for making sure that other generates which has same id expire.</description>
    </item>
    
    <item>
      <title>Rust vs Go の終戦へ向けてPolyglotを作ってみた</title>
      <link>https://shogo82148.github.io/blog/2017/02/25/rust-and-go-ploygolot/</link>
      <pubDate>Sat, 25 Feb 2017 16:58:27 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2017/02/25/rust-and-go-ploygolot/</guid>
      <description>「Golang Rust」とググると、関連項目は「Rust vs Go」のように GolangとRustが対立しているような項目ばかりです。 まあまあ、もっと仲良くやろうじゃないですか、ということで、 どうしたら仲良くなれるかを考えました。 Polyglotにして同じソースコードの中に閉じ込めてやれば、 そのうち仲良くなるのではないかと考え、 RustとGoのPloyglotを作ってみました。
結果 /*/*/ package main import &amp;#34;fmt&amp;#34; func main() { fmt.Print(&amp;#34;Hello Go!!&amp;#34;) _ = `*/*/fn main(){println!(&amp;#34;Hello Rust!!&amp;#34;);//` }/*/*/ package main import &amp;#34;fmt&amp;#34; func main() { fmt.Print(&amp;#34;Hello Go!!&amp;#34;) _ = `*/*/ fn main() { println!(&amp;#34;Hello Rust!!&amp;#34;); //` } 仕組み 一番のポイントは最初の行の /*/*/ です。 RustもGoも/* */形式の複数行コメントに対応していますが、 Rustはネストに対応しており、Goはネストはできないという違いがあります。 この違いにより、Rustは/*/*/を/* /* /のように「二重にネストしたコメントの開始部分」として扱いますが、 Goは/* / */のように「/をコメントアウトしたもの」と見なします。 これにより2行目package main以降はGoには普通のコードに見えますが、 Rustからは単なるコメントとして認識されます。
次はGoからRustへの切り替えです。 Goではバッククオートで複数行文字列を定義できるので、その中にRustのコードを書きます。 この中ではバッククオートさえ使わなければ自由にRustのコードを書くことが出来るので、 あとはGoのコードだけ上手くコメントアウトされるよう調整すれば完成です。
せっかくなのでリンクしてみた GoからRustのコードを呼び出すサンプルコードを見つけたので、 せっかくなのでリンクしてみました。
 medimatrix/rust-plus-golang  main.</description>
    </item>
    
    <item>
      <title>WEB&#43;DB PRESS Vol.97にPerlとRedisの記事を寄稿しました</title>
      <link>https://shogo82148.github.io/blog/2017/02/23/perl-webdb-vol97/</link>
      <pubDate>Thu, 23 Feb 2017 18:27:53 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2017/02/23/perl-webdb-vol97/</guid>
      <description>昨年末にSongmuさんからお話を頂き、 WEB+DB PRESS Vol.97内の連載「第43回Perl Hackers Hub」に 「PerlでのRedis活用法」というタイトルで寄稿しました。 発売日は2月24日です。
内容 簡単に内容を紹介しておきます。 Perl使いではじめてRedisを使う人向けに書いたつもりです。
Redisの簡単な説明 Redisのインストール方と、Perlからの接続方法、そしてRedisの型の説明です。 記事の中でも紹介していますが、Redisはその豊富な型が特長です。 読者はきっとPerl使いだろうということで、Perlの型(Perlにも型はあるんだよ！！)と 比較しながら簡単に紹介しています。
Redisの応用例とCPANモジュールの紹介 Redisを使うとこんなことができるよ、という紹介です。 CPANで公開されているRedis関連のモジュールも合わせて紹介しています。
Redis自体の注意点 以前Redisを使ったサービスの運用に携わっていたのですが、 そのなかで実際に起きたことを元に、Redisの注意点について書きました。 さいわいサービスが停止するような事故にはありませんでしたが、 メトリックスを眺めながらエンジニア勢でヤバイヤバイ騒いでましたね・・・。 みなさんも気をつけて下さい。
執筆してみての感想 昔から文章を書くのにはだいぶ苦手意識があり、 今回の執筆も非常に苦労しました。 一文の前半を書いた時点で 「今から書こうとしている情報は本当に必要なのか」 「自分の記憶違いで間違った情報なのでは」と不安になり、 色々考えているうちに、何書こうとしてたのかわからなくなるんですよね。 まずは適当に書き上げて、後からちゃんと推敲しよう、 とは思いつつもなかなか進められず・・・。 スループットを上げたい。
細かい表現とかも気になってなかなか進まないので、 こういうの入れて頑張ろうと思います！
 VS Codeでtextlintを使って文章をチェックする gitbookで技術書を書く環境の構築手順  (執筆が進まないと、こういう環境構築に時間をかけてしまうのもよくないと思うんだ・・・)
余談 ところで、Vol.97と第43回ってどっちも素数ですね！ 雑なプログラムを書いて調べてみたところ、 両方素数になるのはVol.83, 第29回以来、7回目(これも素数だ！)。 次はVol.101, 第47回です。 そのときのPerl Hackerは誰になるのでしょうか。楽しみですね！
use warnings; use strict; sub is_prime { my $n = shift; return 0 if $n &amp;lt; 2; my $i = 2; while($i*$i&amp;lt;=$n) { return 0 if $n % $i == 0; $i++; } return 1; } my $i = 1; for my $n(1.</description>
    </item>
    
    <item>
      <title>Go言語でコンパイル時フィボナッチ数列計算</title>
      <link>https://shogo82148.github.io/blog/2017/02/19/golang-compile-time-fib/</link>
      <pubDate>Sun, 19 Feb 2017 09:06:05 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2017/02/19/golang-compile-time-fib/</guid>
      <description>整数の公式でフィボナッチ数列を求めるという記事を読んで、 「これコンパイル時ならGoでも簡単に計算できるのでは？」と思いやってみたメモ。
背景 みんな大好きフィボナッチ数列(要出典)。 漸化式で定義されているため、再帰やループを使って書くことが多いと思いますが、 閉じた式で書くことが知られています。 ただし、この一般式には無理数の演算が入るので、コンピュータで厳密に扱うことはできません。 ところが、さきほど紹介した記事で紹介された方法を使うと、整数の演算のみで実現できるそうです。
原理などはネタ元の記事を参照してもらうとして、 Python3では以下のように書けるらしいです。
def fib(n): return (4 &amp;lt;&amp;lt; n*(3+n)) // ((4 &amp;lt;&amp;lt; 2*n) - (2 &amp;lt;&amp;lt; n) - 1) &amp;amp; ((2 &amp;lt;&amp;lt; n) - 1) ある程度大きなフィボナッチ数を求める場合、 計算途中の値が非常に大きくなるため、多倍長整数が必要となります。 Python3は多倍長整数に組み込みで対応していますが、 Goではmath/bigパッケージを利用する必要があります。
なんか面倒だなGolangと思っていたのですが、 Better C - Go言語と整数 #golangを読んで、 「Goの定数には型がない(場合がある)」「任意の精度で計算してくれる」ということを知り、 「つまりコンパイル時に定数として計算すれば楽にいけるのでは！！」と考えたわけです。
結果 ちょっと複雑な式ですが、個々の演算自体はPython3もGoも変わらないので、 翻訳は簡単ですね。
package main import &amp;#34;fmt&amp;#34; const Fib0 = 1 // 0だけはうまくいかない  const ( _ = (4 &amp;lt;&amp;lt; (iota * (3 + iota))) / ((4 &amp;lt;&amp;lt; (2 * iota)) - (2 &amp;lt;&amp;lt; iota) - 1) &amp;amp; ((2 &amp;lt;&amp;lt; iota) - 1) Fib1 Fib2 Fib3 Fib4 Fib5 Fib6 Fib7 Fib8 Fib9 Fib10 Fib11 Fib12 Fib13 Fib14 Fib15 Fib16 Fib17 Fib18 Fib19 Fib20 Fib21 ) func main() { fibs := []int{ Fib0, Fib1, Fib2, Fib3, Fib4, Fib5, Fib6, Fib7, Fib8, Fib9, Fib10, Fib11, Fib12, Fib13, Fib14, Fib15, Fib16, Fib17, Fib18, Fib19, Fib20, Fib21, } for i, fib := range fibs { fmt.</description>
    </item>
    
    <item>
      <title>go-sql-proxyがcontextに対応しました</title>
      <link>https://shogo82148.github.io/blog/2017/02/16/go-sql-proxy-in-go18/</link>
      <pubDate>Thu, 16 Feb 2017 07:16:44 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2017/02/16/go-sql-proxy-in-go18/</guid>
      <description>Go1.8ではdatabase/sqlのcontextサポートが入ります。 (きっと今日のGo 1.8 Release Partyで詳しく説明があるはず、たぶん) それにともないGo言語でSQLのトレースをするで紹介した shogo82148/go-sql-proxyでもcontextを扱えるようにしました。
Go1.8新機能のサポート Golang 1.8 でやってくる database/sql の変更点で mattnさんが紹介しているように、Go1.8ではdatabase/sqlにいくつか新機能が追加されます。 (mattnさんの対応が早すぎて、メソッド名とか微妙に変更が入っているので注意)
特に大きなのがcontextのサポートでしょう。以下のようなコードでクエリのキャンセルが可能になります。
ctx, cancel := context.WithCancel(context.Background()) go func() { // 1秒待ってからキャンセル  time.Sleep(1 * time.Second) cancel() }() rows, err := db.QueryContext(ctx, &amp;#34;SELECT name FROM test where id = ?&amp;#34;, id) if err != nil { log.Fatal(err) } go-sql-proxyでもcontext対応を行ったので、 proxyを経由した場合でも、キャンセルが可能になります。 (もちろん、originとなるドライバの対応も必要です)
Go1.8ではcontextサポート以外にもいくつか新機能が追加される予定です。 これらについても、originとなるドライバが対応していれば、go-sql-proxy経由でも全く同じように扱えます。
contextとHookの関連付け contextにHookを関連付けて、一部のクエリにだけHookを付けることができるようになりました。 例えば以下のようなコードでctxに関連したクエリだけログを出力できます。
package main import ( &amp;#34;context&amp;#34; &amp;#34;database/sql&amp;#34; &amp;#34;github.com/shogo82148/go-sql-proxy&amp;#34; ) var tracer = proxy.</description>
    </item>
    
    <item>
      <title>Go1.8のGraceful Shutdownとgo-gracedownの対応</title>
      <link>https://shogo82148.github.io/blog/2017/01/21/golang-1-dot-8-graceful-shutdown/</link>
      <pubDate>Sat, 21 Jan 2017 12:44:32 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2017/01/21/golang-1-dot-8-graceful-shutdown/</guid>
      <description>Go1.8beta1が出た時に、Go1.8で追加される予定のGraceful Shutdownについて書く！ とTwitterに書き込んで早1ヶ月。 この前の金曜日にGo1.8rc2がリリースされ、正式リリースも間近になってきて、 さすがに書かねばという気持ちになって来たので、がんばって検証してみます。
公式サポートで増える予定の機能 以前Go言語でGraceful Restartをするときに取りこぼしを少なくするで 紹介したようにshogo82148/go-gracedownというものを書きました。 あれから時は経ち、ついにGo1.8からはGraceful Shudownがbuild-inの機能として提供される予定です。 公式サポートが入ることによって、以下のような機能を使えるようになります。
HTTP/2のGraceful Shutdownができる HTTP/2ではGOAWAYフレームという接続を切ることを通知する機能があります。 Go1.8からはシャットダウン時にこのGOAWAYフレームを送ってくれるようになります。 GOAWAYフレームはサーバ側から任意のタイミングで送ることができ、 どこまで正常に処理できたかをクライアントに伝えられるという利点があります。
余談ですが、この機能はx/net/http2を利用している場合は動かないらしいです。 importしたときには動かないけどbundleしたときにだけ動く黒魔術が使われているためです。 覚えておいても今後絶対使うことはなさそう。というか使いたくない・・・。
contextが使える go-gracedownを作った頃は、contextはまだ標準パッケージに取り込まれていなかったので対応していませんでした。 (1.7のリリース時に対応を怠っていただけとも言える) net/httpのシャットダウンはもちろんcontextに対応しています。 これにより、Graceful Shutdownを中断して強制終了する、 ということが簡単にできるようになります。
公式サポートで変更になる予定の挙動 Keep-Aliveでのリクエストの挙動が少し変わります。 1.7以前のgo-gracedownでは、クライアントにKeep-Aliveが無効になったのを伝え、 クライアント側から接続を切るのを待つように実装してしました。 多少接続時間が延びたとしてもクライアント側でよくわからないエラーになるよりはマシだろ、との考えからです。
1.8からはシャットダウン時にIdle状態(TCP接続は有効だけど、リクエストは処理していない状態)な接続は切断されます。 内部で使っているServer.SetKeepAlivesEnabledの 挙動が変更になったためです。
Goの中の人的には「この挙動が原因で万が一トラブルになっても、クライアントがリトライしてくれるから大丈夫でしょ」とのことのようです。 サーバシャットダウン以外にもネットワークトラブル等でも接続は切れるので、 クライアント側で頑張ってというのは正論ですが、 どの程度エラーが増えるのかは気になるところです。
go-gracedownの対応 go-gracedownはGo1.8でコンパイルされたときはbuild-inの機能を直接使うようになります。 中身はほとんどがインターフェースの互換性を保つためのコードなので、 機能的なメリットは完全になくなってしまいました・・・。 HTTP/2サポートも問題なく動くはずです。 逆にパッケージの依存が増えること以外はデメリットはないともいえます。
Go1.7以下では今までの方法にフォールバックしてくれます。 というわけで、以下のような人には有用です。
 深淵な理由でGo1.7以下しか使えない人 Go1.8とGo1.7以下のサポートがどうしても必要な人 Go1.8にアップグレードしたけど、graceful shutdownの処理を書き換えるのがめんどくさい人  ところで、環境が悪いときに性能を落としたり機能を制限することをフォールバック(fall back)というわけですが、 逆に環境が良いときに性能を上げたり機能を拡張することはなんていうんですかね？ モデムでは通信環境が良いときに高速な通信方式に切り変えることを「フォールフォワード(fall forward)」というらしいです。 「Go1.8ではbild-inのGraceful Shutdownにフォールフォワードする」で使い方あってます？
使い方 Server.Shutdownを使う Go(その3) Advent Calendarの 最終日の記事でも扱ってますが改めて。
package main import ( &amp;#34;context&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;log&amp;#34; &amp;#34;net&amp;#34; &amp;#34;net/http&amp;#34; &amp;#34;os&amp;#34; &amp;#34;os/signal&amp;#34; &amp;#34;syscall&amp;#34; &amp;#34;github.</description>
    </item>
    
    <item>
      <title>Re:golang の http.Client を速くする</title>
      <link>https://shogo82148.github.io/blog/2017/01/14/re-golang-dns-cache/</link>
      <pubDate>Sat, 14 Jan 2017 17:02:12 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2017/01/14/re-golang-dns-cache/</guid>
      <description>先日mattnさんの記事を読みました。
 golang の http.Client を速くする  nettというパッケージを使って 名前解決の結果をキャッシュすることで、http.Clientを早くするというものです。 この記事に関して、ちょっと疑問に思ったことがあったので、検証してみました。
疑問 疑問に思ったのは以下の点です。
名前解決遅すぎでは？ ベンチマークの結果を見ると5億ns(=500ms)ほど速度が改善しています。 3つのURLに対してリクエストを投げているので、初回を除く2回DNSのキャッシュがヒットし、 名前解決2回分の速度改善になるはずです。 と、いうことは、名前解決1回あたり250msかかっている計算になります。 googleのsearchは302でリダイレクトがかかるので、Client.Getの呼び出し1回あたり2回リクエストが飛ぶ、 ということを計算に入れても100msほどかかる計算です。
Google先生の謎テクノロジーによってかなりの最適化がされているはずですし、 ネットワークプロバイダのDNSキャッシュにヒットする可能性も高いでしょう。 名前解決程度にこんなに時間がかかっていたらスプラトゥーンが出来ない！ (mattnさんがスプラトゥーンをプレイしているかは知らない)
2017/01/16追記: mattnさんはスプラトゥーンをプレイしていないそうです。残念。
あとスプラトゥーンしてません。。。
&amp;mdash; mattn (@mattn_jp) 2017年1月14日  もちろん、ネットワークが混雑していたり、 モバイルネットワークを利用していたり、という可能性もありますが、 ちょっと不自然な印象を受けました。
Keep-Aliveされてるのでは？ スキーマがhttpsになっているので、Google先生相手ならHTTP2で通信していてもおかしくありません。 HTTP2は基本的にドメイン毎にコネクションを1つだけ張って、それを使いまわします。 もし仮にHTTP1.1で通信していたとしても、http.ClientはデフォルトでKeep-Aliveが有効になっているので、 普通に使うとコネクションを再利用してくれます。
そういうわけで、名前解決以前にそもそもTCPのコネクション確立もスキップされている可能性が高いのでは？ と思ったわけです。 この予想が正しければ、名前解決は初回リクエストでしか行われないので、ベンチマークに差はでないはずです。
HTTPリクエストの様子をトレースしてみる これらの疑問を解消するために、HTTPリクエストの様子をさらに詳細に解析してみることにしました。
DNSキャッシュなし版をトレースする Go1.7からnet/http/httptraceというパッケージが追加され、 名前解決やコネクション確立etcのタイミングにフックを仕込めるようになりました。 これを利用すれば各段階でどの程度時間がかかっているかが具体的に分かるはずです。
頑張って自前でフックを差し込んでもよいのですが、 deeeetさんのgo-httpstatという便利パッケージがあるので、 これをありがたく利用させていただきます。 go-httpstatを使うと時間計測を行うコードを簡単に差し込むことができます。
package main import ( &amp;#34;io&amp;#34; &amp;#34;io/ioutil&amp;#34; &amp;#34;log&amp;#34; &amp;#34;net/http&amp;#34; &amp;#34;time&amp;#34; &amp;#34;github.com/tcnksm/go-httpstat&amp;#34; ) var ( urls = []string{ &amp;#34;https://shogo82148.github.io/blog/2016/12/20/redis-fast-0-dot-19-released/&amp;#34;, &amp;#34;https://shogo82148.github.io/blog/2016/12/15/leap-second-in-datetime-dot-pm/&amp;#34;, &amp;#34;https://shogo82148.</description>
    </item>
    
    <item>
      <title>Redis::Fast 0.19リリースのお知らせ</title>
      <link>https://shogo82148.github.io/blog/2016/12/20/redis-fast-0-dot-19-released/</link>
      <pubDate>Tue, 20 Dec 2016 22:38:27 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2016/12/20/redis-fast-0-dot-19-released/</guid>
      <description>Redis::Fast 0.19 をリリースしました。 主な変更点は以下の通りです。
 reconnect_on_error オプションの追加 Sentinelのノード一覧が更新されない不具合の修正 IPv6の実験的サポート  reconnect_on_error オプションの追加 @yoheimutaさんからのプルリクエストです。 今まではネットワークエラーが発生した時のみ再接続処理が走っていましたが、 Redisがエラーを返した場合にも再接続を行うようになります。 マスタースレーブ構成をしているときに、 何らかの原因によりRedis::Fastからのコネクションを維持したまま、 マスターがスレーブに降格してしまった場合に対処するための機能です。 以下のように設定することで、新しいマスターに再接続を行うことが可能になります。
my $r = Redis::Fast-&amp;gt;new( reconnect =&amp;gt; 1, # 0以上で再接続有効 reconnect_on_error =&amp;gt; sub { my ($error, $ret, $command) = @_; if ($error =~/READONLY You can&amp;#39;t write against a read only slave/) { return 1; # 再接続を行う。次の再接続まで最低1秒空ける } return -1; # 再接続は行わない }, ); Sentinelのノード一覧が更新されない不具合の修正 Redis::FastにはどれかひとつのSentinelノードに接続すると、 他のノードの情報を自動的に収集する機能があります。 この機能が最新のRedisでは動いていなかったので修正しました。 具体的にいつからなのかまでは追ってないのですが、 Redisのバージョン3.0.6から3.2.6の間のどこかで ノード一覧の形式が変わってしまったようです。
(最近Sentinelの話題を聞かないけど、みんな使ってるのかな・・・)
IPv6の実験的サポート サーバの指定にIPv6のアドレスが使えるようになりました。 Redis::Fast-&amp;gt;new(server =&amp;gt; &amp;quot;[::1]:6379&amp;quot;) のような指定ができます。</description>
    </item>
    
    <item>
      <title>DateTime.pmにうるう秒の修正が入った話</title>
      <link>https://shogo82148.github.io/blog/2016/12/15/leap-second-in-datetime-dot-pm/</link>
      <pubDate>Thu, 15 Dec 2016 22:17:47 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2016/12/15/leap-second-in-datetime-dot-pm/</guid>
      <description>こんにちは、DateTime.pm Watcherのいっちーです。 本日面白いパッチがDateTime.pmに取り込まれたので、ご紹介したいと思います。
そのpullreqがこちらです。Closedになっていますが、該当コミットはmasterに取り込まれています。
 The leap second in 2012 was on 2012-07-01 not 2012-06-01. #48   per https://confluence.qps.nl/display/KBE/UTC+to+GPS+Time+Correction the leap second in 2012 was on 2012-07-01 not 2012-06-01. It&amp;rsquo;s is well known that leap seconds only occur directly before Jan 1st or July 1st.
 適当な和訳「2012年に挿入されたうるう秒は2012年6月1日ではなく2012年7月1日です。よく知られているように、今までに挿入されたうるう秒は1月1日と7月1日の直前だけです。」
diff --git a/lib/DateTime/LeapSecond.pm b/lib/DateTime/LeapSecond.pm index 66e1b2b..4a38be2 100644 --- a/lib/DateTime/LeapSecond.pm +++ b/lib/DateTime/LeapSecond.pm @@ -108,7 +108,7 @@ sub _initialize {  1999 Jan. 1 +1 2006 Jan.</description>
    </item>
    
    <item>
      <title>Twitterの二次元コード問題と、QRコード・フレームQRの見分け方</title>
      <link>https://shogo82148.github.io/blog/2016/11/23/qr-code/</link>
      <pubDate>Wed, 23 Nov 2016 10:32:43 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2016/11/23/qr-code/</guid>
      <description>先日Twitterの公式アプリがQRコード® (お店やお友達を簡単にフォローするために) の作成と読み取りに対応しました。 しかし、生成されるQRコードが標準規格に準拠していないため、 「他のリーダーで読めない」「法的に問題があるのでは？」等々の指摘が出ていました。 人事ながらTwitterさんのことが心配になったので少し調べてみました。
なお、僕は法律の専門家ではないため、本記事の正確性は保証できません。 あくまで個人的な見解なので、 実際にQRコード®を使用するさいは各自の判断でお願いします。
指摘ツイート Twitterが生成するQRコード、規格(JIS X 0510・ISO/IEC 18004)を大幅に逸脱しているので「QRコード®」を名乗ること自体に法的なリスクがある。
&amp;mdash; 祥太(4/15レイフレ18 C19+20) (@shota_) 2016年11月17日  「デンソーウェーブは、JIS、ISOの規格に沿ったQRコードに限っては特許権を行使しませんが、規格を逸脱したQRコードについてはこの限りではございませんので、特許権を行使させていただくこともございます。」
(出典: https://t.co/SKXgBGSb8E )
&amp;mdash; 祥太(4/15レイフレ18 C19+20) (@shota_) 2016年11月17日  明暗暗転で読み取らないという話を多数見かけますけど、そちらについては「ISO/IEC 18004からは逸脱」「JIS X 0510には準拠」(規格票7.3.8参照)という微妙な状況なのです。多分ISOには準拠しているのでアプリは悪くないと思います。
&amp;mdash; 祥太(4/15レイフレ18 C19+20) (@shota_) 2016年11月17日  たしかに qrcode.comのFAQには 特許について以下の記述があります。
 色を付けたりイラストを入れるような使い方をしても問題ありませんか？ (中略) また、QRコードにイラストを重ねたりデザインを乗せるということは、QRコードの規格から外れ「QRコードではないもの」となってしまう可能性がございます。 デンソーウェーブは、JIS、ISOの規格に沿ったQRコードに限っては特許権を行使しませんが、規格を逸脱したQRコードについてはこの限りではございませんので、特許権を行使させていただくこともございます。
 問題点 公式アプリの生成する二次元コードは以下のような問題があります。
 データパターンの20%近くがアイコンで上書きされている 「アライメントパターン」がTwitterのロゴで欠けている 明暗暗転している(一応JISには沿っているらしい)  法的リスク以前に、 読み取り性能/互換性が劣化するので使わない方が無難でしょう。
自分のプロフィールのURL (僕の場合は https://twitter.com/shogo82148 )を QRコードに変換すれば公式アプリのリーダーでも読めるので、 こちらの方がオススメです。
QRコード関連の権利 特許 QRコード®のJIS規格JIS X 0510には、 関連する特許として特許第2938338号「二次元コード」があげられています。 ただし、特許の保護期間は20年なので、1994年に出願されたこの特許は2014年で消滅しています。 したがってこの特許を理由に訴えられることはなさそうです。</description>
    </item>
    
    <item>
      <title>GitHub Pagesがhttpsをサポートしたので切り替えてみた</title>
      <link>https://shogo82148.github.io/blog/2016/06/10/github-page-supports-https/</link>
      <pubDate>Fri, 10 Jun 2016 00:53:51 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2016/06/10/github-page-supports-https/</guid>
      <description>このブログを設置しているGithub PagesがHTTPSに正式対応したらしいので、HTTPSを強制するように設定してみました。
 HTTPS for GitHub Pages  やったこと ページ内にHTTP経由で取得したリソースが含まれていると、 警告が出たり取得自体がブロックされたりしてしまうので、 全てHTTPS経由で取得するように書きなおす必要があります。 画像・CSS・Javascript等のURLを、以下のようにnetwork-path referenceへの置き換えましょう。 HTTPでページを開いた場合はHTTPで、HTTPSでページを開いた場合はHTTPSで、リソースを取得してくれます。
&amp;lt;a href=&amp;#34;http://google.co.jp&amp;#34;&amp;gt; &amp;lt;a href=&amp;#34;//google.co.jp&amp;#34;&amp;gt; このサイトはHTTPのレンダリングにOctopressを使っています。 最新版のOctopressではnetwork-path referenceを使ってくれるので特に対応は不要です。 このサイトの場合は古すぎてHTTP参照だったので、 「Octopressをアップデートした」を参考にしてアップデートしました。 はてなブックマーク連携など、自分でカスタマイズした部分に関しては手作業で対応したました。
HTTPS強制の設定 Securing your GitHub Pages site with HTTPS どおりに設定を有効化すればOKです。 ユーザ毎ではなくプロジェクト毎の設定のようなので、 プロジェクト用のページを作っている場合は個別に設定が必要です。
はてなブックマークについて HTTPとHTTPSは別URLとして扱われるようなので、過去の記事に対するはてブ数はリセットされてしまいます。 解決方法は無いかと調べてみたものの、現象無理っぽいです。
自分のブログは http から https に移行したけど、記事についたはてブを移行することは出来なかった（はてなのサポートに聞いた）。分からないでもないけど、https 移行の躊躇材料になるという点においてはイケてない。
&amp;mdash; Takashi Masuda (@masutaka) 2016年6月6日  はてなさんの方で対応してくれないかな・・・
2016/06/30追記: DISQUSのマイグレーション 記事にコメントをつけるのに使っているDISQUSをマイグレーションするのを忘れてて、 過去のコメントが見れなくなっていたので追記。
DISQUSのホームから「Admin」「Edit Settings」で設定画面を開き、 Website URLの近くの「Changing domains? Learn how.」をクリックします。 すると「Migration Tools」が開くので、「Start URL mapper」「you can download a CSV here」をクリック。 5分くらいするとDISQUSがコメントを管理しているURL一覧がメールで届くので、 それを元に新旧URLの対応表を作ります。</description>
    </item>
    
    <item>
      <title>net/httpで安全に静的ファイルを返す</title>
      <link>https://shogo82148.github.io/blog/2016/04/13/serving-static-files-in-golang/</link>
      <pubDate>Wed, 13 Apr 2016 02:29:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2016/04/13/serving-static-files-in-golang/</guid>
      <description>net/httpで静的ファイルを返すで、 http.ServeFileを使っていてアレ？と思ったのでちょっと詳しく調べてみました。 (http.FileServerを使うものだと思ってたため)
結論だけ先に書いておくと
 やはり、特に理由がなければhttp.FileServerを使ったほうが良さそう どうしてもhttp.ServeFileを使う場合は定数でパス指定をする 「自作パスルータを使っている」かつ「Go 1.6.1 未満を使っている」場合はとくに要注意  ディレクトリトラバーサル脆弱性 紹介されているのは以下のコードです。
http.HandleFunc(&amp;#34;/static/&amp;#34;, func(w http.ResponseWriter, r *http.Request) { http.ServeFile(w, r, r.URL.Path[1:]) }) しかし、参照先の「Go Golang to serve a specific html file」には Actually, do not do that. (やっちゃいけない)とコメントされています。 ディレクトリトラバーサルにより 脆弱性の原因となってしまう可能性があるためです。
脆弱性再現のために、以下の様なコードを書いてGo1.5でコンパイルして実行してみました。
package main import ( &amp;#34;net/http&amp;#34; &amp;#34;strings&amp;#34; ) func main() { http.ListenAndServe(&amp;#34;:3000&amp;#34;, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { if strings.HasPrefix(r.URL.Path, &amp;#34;/static/&amp;#34;) { http.ServeFile(w, r, r.URL.Path[1:]) } else { http.NotFound(w, r) } })) } .</description>
    </item>
    
    <item>
      <title>PerlでもGoでも実行できるQuine書いた</title>
      <link>https://shogo82148.github.io/blog/2016/04/06/ployglot-quine-of-golang-and-perl/</link>
      <pubDate>Wed, 06 Apr 2016 10:07:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2016/04/06/ployglot-quine-of-golang-and-perl/</guid>
      <description>昨日のPolyglotを元にPerlでもGoでも実行できるQuine書いた。
package main;import(&amp;quot;fmt&amp;quot;);var(q=`printf&#39;package main;import(&amp;quot;fmt&amp;quot;);var(q%c%c%s%c/*%c);sub import{}sub var{$_%cshift%c~s!%c(.*)%c/\*!$1!gr;eval}%c__END__%c&#39;,61,96,$_,96,61,61,61,96,96,10,10;print&amp;lt;DATA&amp;gt;`/*=);sub import{}sub var{$_=shift=~s!`(.*)`/\*!$1!gr;eval} __END__ */);func main(){s:=`package main;import(&amp;quot;fmt&amp;quot;);var(q=%c%s%c/*=);sub import{}sub var{$_=shift=~s!%c(.*)%c/\*!$1!gr;eval} __END__ */);func main(){s:=%c%s%c;fmt.Printf(s,96,q,96,96,96,96,s,96)} `;fmt.Printf(s,96,q,96,96,96,96,s,96)} Perlで実行してもGoで実行しても自分自身を出力します。</description>
    </item>
    
    <item>
      <title>PerlとGolangで実行できるPolyglot書いてみた</title>
      <link>https://shogo82148.github.io/blog/2016/04/05/polyglot-of-perl-and-golang/</link>
      <pubDate>Tue, 05 Apr 2016 12:27:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2016/04/05/polyglot-of-perl-and-golang/</guid>
      <description>Rubyの会社をPerlの会社に変えてしまおう計画。 Golangのフリをして忍び込ませれば行けるのではという話になったので、 GoでもPerlでも実行できるコードを書いてみた。
出来上がったのがこちら。
package main; import (&amp;#34;fmt&amp;#34;); var (s=0/*==); sub import {} sub var { print &amp;#34;Hello macotasu&amp;#34;; } __END__ */) func main() { fmt.Println(&amp;#34;Hello macotasu&amp;#34;) } 一番のポイントはvar (s=0/*==);の行ですね。 Perlで解釈すると正規表現置換s///として解釈され、/*が無視されます。 Goで解釈すると変数sへの代入として解釈され、/*がコメントとして扱われます。
あとはGoのキーワードをPerlが解釈できないので、ちょっと書き方を工夫します。
 package main はGoでもPerlでも似たような意味で解釈されるのでそのまま Goの import, var はPerlで解釈できないので、()を省略せずに書いてPerlの関数呼び出しっぽくする 省略可能なセミコロンをちゃんと書く  GoとPerlのコードは分かれているのでどんな処理でも自由に書くことができますが、 import だけGoでもPerlでも解釈されてしまうというという制限があります。 import するパッケージが一個だけなら問題ないんですが、 複数書く場合は以下のように２個め以降をすべてドットインポートする必要があって男気あふれる感じです。 (Perlでは文字列結合として解釈される。Goではvarのあとにimportかけないっぽいので、ここに押し込むしかない。)
package main; import ( &amp;#34;fmt&amp;#34; . &amp;#34;math&amp;#34; ); var (s=0/*==); sub import {} sub var { print &amp;#34;Hello macotasu&amp;#34;; } __END__ */) func main() { fmt.</description>
    </item>
    
    <item>
      <title>Webブラウザを使って電波を出してみた</title>
      <link>https://shogo82148.github.io/blog/2016/03/29/web-jjy/</link>
      <pubDate>Tue, 29 Mar 2016 12:19:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2016/03/29/web-jjy/</guid>
      <description>読者の持っている至って普通のコンピューターは、実は電波時計の時刻合わせを行うために必要な標準電波の発信装置が備わっている。
コードは以下から入手できる。
 shogo82148/web-jjy JJYシミュレータWeb版  動かし方 パソコンのイヤホンジャックにアンテナ(普通のイヤホンで十分です)を接続し、電波時計の近くに置きます。 音量を最大にし、「Start」ボタンを押すと信号が送信されます。 電波時計を強制受信モードにし、時刻が設定されるのを待ちましょう。
パソコンの時間を基準にするので、あらかじめntpとかで時刻設定をしておくといいと思います。
原理 標準電波JJYは日本標準時のタイムコードを送信する電波で、 東日本では40kHz、西日本では60kHzの周波数で発信されています。 電波時計はこの信号を使って時刻合わせをしています。
この信号をオーディオデバイスから出力する電波時計用JJYシミュレータというものがあるのを知り、 「今のWebブラウザならjavascriptだけで実装できるのでは？」と思いやってみました。 一般的なオーディオデバイスは、20kHz以上の周波数の再生には適していないため、そのままでは40kHz/60kHzの信号は出せません。 そこで、電波時計用JJYシミュレータは、歪んだ波形に含まれる高調波を利用しています。 ボリュームを大きくして音が割れた状態になると、音声信号は矩形波に近いかたちになります。 矩形波には3倍、5倍、7倍&amp;hellip;の奇数倍の周波数成分が含まれているため、 (世はまさに大フーリエ時代とか見ると楽しい) 13.333kHzの矩形波を出力することで、39.999kHzの信号を出せるというわけです。
元のソフトウェアはWindowsのバイナリ形式でしたが、 WebAudioの登場によりWebブラウザからも同様のことが行えるようになりました。
最後に 少し前にCPUから出るノイズを使ってAMラジオの電波を発信するという記事が話題になりましたね。
 普通のコンピューターからAMラジオを鳴らそう  CPUやオーディオデバイスも電気で動いている以上、電波が出ているのは当たり前のことなのですが、 こうやって改めて確認できると面白いですね。
パソコンから出る程度の電波強度では、電波法に抵触することはないと思いますが、 うっかり強力な電波を発信しないよう気をつけてください。</description>
    </item>
    
    <item>
      <title>数値と文字列がごちゃ混ぜになっているJSONをよしなにParseするやつ作った</title>
      <link>https://shogo82148.github.io/blog/2016/03/23/go-weaktyping/</link>
      <pubDate>Wed, 23 Mar 2016 20:44:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2016/03/23/go-weaktyping/</guid>
      <description>Goは数値と文字列を厳格に区別しますが、他の言語もそうとは限りません。 例えばPerlは数値と文字列を自動変換してくれるので、気をつけていないといつの間にか数値が文字列になっていたりします。 その言語の中に閉じていいれば問題ないのですが、Goとやり取りしようとすると困ります。 そんなときに使えるライブラリを書いてみました。
 shogo82148/go-weaktyping  背景 map[string][]*stringを返してくるライブラリがあって、 そのままだと扱いにくいのでなんとか構造体にできないかと頭を悩ませていました。 JSONに一旦変換すれば楽かなーとも思ったのですが、一部フィールドを数値に変換する必要がありました。 JSONの数値と文字列を区別するため、JSONの文字列をGoの数値型に変換するのは厄介です。 タグにjson:&amp;quot;,string&amp;quot;と指定すると変換可能になりますが、逆にJSONの数値を受け付けなくなりますし、 JSONに変換すると文字列になってしまいます。 変換先の構造体は普通のJSONの操作にも使いたかったので、これでは困ります。 「数値も文字列もUnmarshalできて、Marshalするときには数値になる」ようなJSONライブラリが必要でした。
&amp;quot;encoding/json&amp;quot;に代わる新しいJSONライブラリを・・・とも考えたのですが、 よく考えるとUnmarshal時の挙動は&amp;quot;encoding/json&amp;quot;.Unmarshalerインターフェースを実装することでカスタマイズ可能です。 こうして作ったのが go-weaktyping です。
使い方 builtinの型の先頭を大文字にしたものを用意しているので、 適当にUnmarshalして欲しいところでbuiltinの型の代わりに指定するだけです。 以下は整数型をUnmarshalする例です。
package main import ( &amp;#34;encoding/json&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;log&amp;#34; &amp;#34;github.com/shogo82148/go-weaktyping&amp;#34; ) func main() { ptr := &amp;amp;struct { Foo weaktyping.Int `json:&amp;#34;foo&amp;#34;` }{} if err := json.Unmarshal([]byte(`{&amp;#34;foo&amp;#34;:123}`), ptr); err != nil { log.Fatal(err) } fmt.Println(&amp;#34;Foo:&amp;#34;, ptr.Foo) if err := json.Unmarshal([]byte(`{&amp;#34;foo&amp;#34;:&amp;#34;456&amp;#34;}`), ptr); err != nil { log.Fatal(err) } fmt.Println(&amp;#34;Foo:&amp;#34;, ptr.</description>
    </item>
    
    <item>
      <title>Redisのトランザクション・スクリプト・ランキングを扱うPerlモジュールを公開しました</title>
      <link>https://shogo82148.github.io/blog/2016/03/18/releaes-redis-modules/</link>
      <pubDate>Fri, 18 Mar 2016 22:16:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2016/03/18/releaes-redis-modules/</guid>
      <description>以前Redisでスコアを複数設定できるランキングを作ってみたけど、 Githubの肥やしになっていてもあれなので、CPANizeしました。 あわせて、この実装のために作ったユーティリティモジュールも別モジュールとして公開しました。
 Redis::LeaderBoardMulti Redis::Script Redis::Transaction  Redis::LeaderBoardMulti 最初の基準で順位を決められなかった場合の第二基準が欲しいというときに使うモジュールです。 インターフェースがRedis::LeaderBoard互換になるように調整したので、 前回とインターフェースがちょっと変わっています。
se Redis; use Redis::LeaderBoard; my $redis = Redis-&amp;gt;new; my $lb = Redis::LeaderBoardMulti-&amp;gt;new( redis =&amp;gt; $redis, key =&amp;gt; &amp;#39;leader_board:1&amp;#39;, order =&amp;gt; [&amp;#39;asc&amp;#39;, &amp;#39;desc&amp;#39;], # asc/desc, desc as default ); # Redis::LeaderBoardに合わせて複数指定できるようになりました $lb-&amp;gt;set_score( &amp;#39;one&amp;#39; =&amp;gt; [100, time], &amp;#39;two&amp;#39; =&amp;gt; [ 50, time], ); my ($rank, $score, $time) = $lb-&amp;gt;get_rank_with_score(&amp;#39;one&amp;#39;); Redis::LeaderBoard互換なのでそのまま入れ替えられるはずですが、以下のような実装上の制限があります。
 スコアはすべて64bit符号付き整数  Redis::LeaderBoardのスコアは倍精度浮動小数点型なので小数も扱えるが、Redis::LeaderBoardMultiは整数だけ   Redis 2.8.9以降のみで動きます 同順の場合の出現順  Redis::LeaderBoard は ZRANK, ZREVRANK を使い分けているので、orderパラメータによって昇順/降順が変わります Redis::LaederBoardMulti は ZRANK しか使わないので、必ず昇順になります    一応 Lua Script を使わないオプションもそのまま残してありますが、特に理由がない限りデフォルト(Lua Script を使う)で使うといいと思います。 どうしてもロックの範囲が広くなってしまう場合があり、楽観的ロックでは効率が悪いケースがあるためです。</description>
    </item>
    
    <item>
      <title>ngrokみたいなHTTPプロキシを書いてみた</title>
      <link>https://shogo82148.github.io/blog/2016/03/14/http2-over-websocket/</link>
      <pubDate>Mon, 14 Mar 2016 22:59:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2016/03/14/http2-over-websocket/</guid>
      <description>開発中のWebアプリをみんなに試してほしいけど、 サーバなんてなくて開発環境がローカルにしか無くて公開できないということは、 開発初期段階だとよくあることだと思います。 もちろん本格的にやるならテスト用にサーバを建てるべきですが、 小さなものならngrokを使うと簡単です。 ngrokの公開サーバへのHTTPリクエストをローカルにリレーして、 ローカルのサーバをお手がるに公開できるサービスです。
びっくりするほど簡単に公開できて便利ですが、 一応oAuthで制限とかかけたいなーとかカスタマイズしてみたくなってきたので、 似たようなものを自作できないかといろいろ遊んでみました。
その結果、HTTP2 over Websocketみたいな謎なものが出来上がってしまったというお話です。
HTTP2 over Websocketというアイデア ngrokっぽいものを実現するためには、 サーバが受け取ったHTTPリクエストをローカルの環境に転送する必要があります。 ご存知のとおり通常のHTTPではサーバ側からのプッシュ配信が難しいので、Websocketを使うのが良さそうです。 しかし、複数のコネクションで並列にやってくるHTTPリクエストを、一本のWebsocketに束ねる必要があり、 上手く制御するのは大変そうです。
さて、HTTP2は一つのTCPコネクションで複数のリクエストを並行処理する仕様があります。 「複数のリクエストを一本に束ねる」という点ではなんか似ているので、なんだか流用できそうな気がしてきました。 Golangならきっと上手いことinterfaceを実装すれば、なんとかできるのではとやってみました。
実装 HTTP2は暗号化や複雑なフロー制御を行っていますが、 外から見ればnet.Connインターフェースに読み書きしている何かに過ぎません。 そして、websocket.Connもnet.Connを実装しているので、そのままHTTP2のライブラリに渡せるはずです。
そうしてできたのが以下のサーバです。
package main import ( &amp;#34;errors&amp;#34; &amp;#34;log&amp;#34; &amp;#34;net/http&amp;#34; &amp;#34;net/http/httputil&amp;#34; &amp;#34;sync&amp;#34; &amp;#34;golang.org/x/net/http2&amp;#34; &amp;#34;golang.org/x/net/websocket&amp;#34; ) type transport struct { m sync.Mutex t http.RoundTripper closed chan struct{} } var t *transport func main() { t = &amp;amp;transport{} s := websocket.Server{Handler: websocket.Handler(Handler)} http.Handle(&amp;#34;/&amp;#34;, s) go http.ListenAndServe(&amp;#34;:3000&amp;#34;, nil) http.</description>
    </item>
    
    <item>
      <title>nginx-omniauth-adapterのGolangポート作った</title>
      <link>https://shogo82148.github.io/blog/2016/03/10/go-nginx-oauth2-adapter/</link>
      <pubDate>Thu, 10 Mar 2016 12:51:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2016/03/10/go-nginx-oauth2-adapter/</guid>
      <description>「nginx で omniauth を利用してアクセス制御を行う」という記事で、 ngx_http_auth_request_moduleの存在を知ったので、 Golangでnginx_omniauth_adapterと似たようなものを作ってみました。
 shogo82148/go-nginx-oauth2-adapter  背景 typester/gateは単体でも動くようになっていますが、 例えばIP制限などちょっと高度なことをしたい場合には結局nginxを前段に置く必要があります。 nginxとgateの設定を同時にいじる必要があって煩雑だと感じていました。
そんな中「nginx で omniauth を利用してアクセス制御を行う」という記事で、 ngx_http_auth_request_moduleの存在を知りました。 gateが認証＋Proxyをやってしまうのに対して、認証だけRubyのomniauthモジュールで行いProxyはnginxに任せるという方法です。
以前から記事の存在は知っていたのですが、Rubyの実行環境をそろえるのが億劫で手を出せずにいました。 小さなアプリなので自分の慣れた言語で実装しても大したことないのではと思い、Goで実装してみることにしました。
使い方 go getで落として来れます。 最低限client_idとclient_secretの指定が必要です。 nginx_omniauth_adapterと同じ環境変数名で設定できるほか、YAML形式の設定ファイルを読みこませることができます。 YAMLの形式はREADMEを参照してください。
$ go get github.com/shogo82148/go-nginx-oauth2-adapter/cli/go-nginx-oauth2-adapter $ export NGX_OMNIAUTH_GOOGLE_KEY=YOUR_CLIENT_ID $ export NGX_OMNIAUTH_GOOGLE_SECRET=YOUR_CLIENT_SECRET $ go-nginx-oauth2-adapter $ go-nginx-oauth2-adapter -c conf.yaml # 設定ファイルでの指定も可能 PerlでHTTPサーバ書いているひとにはおなじみのServer::Starterにも対応しているので、 それ経由で立ち上げておくと設定の更新・プログラム自身の更新等が楽になると思います。
start_server --port 18081 -- go-nginx-oauth2-adapter -c conf.yaml nginx側の設定はexamplesディレクトリを参照してください。 ヘッダ名・パス名等を合わせてあるので、nginx_omniauth_adapterと同じ設定で動くはずです。
また、h2oの設定はプログラマブルだからh2oでもちゃんと設定ファイルを書けば動くのではと考え、 h2oの設定も書いてみました。 mrubyからproxyに渡るリクエストを書き換える方法がない(？)っぽいので、アプリ側で認証情報をとることはできないですが、一応制限はできます。 basic認証の実装を見る限りremote-userヘッダだけは渡せるようなので、これを使えばなんとかなるかもしれないですが、未確認です。 (Ruby慣れてないからってGoで実装したけど、結局Rubyを書いていて面白い)
nginx_omniauth_adapterとの違い 厳密に同じ挙動を実装するのが面倒だったため、挙動に若干の違いがあります。 一番大きなものは認証後のリダイレクト先です。
nginx_omniauth_adapterは認証後、一度adapterのURLにリダイレクトしてから、アプリサーバの/_auth/callbackにリダイレクトします。 それに対してgo-nginx-oauth2-adapterは認証後、アプリサーバの/_auth/callbackに直接リダイレクトします。 この違いのため、Google Developers Consoleの「承認済みのリダイレクト URI」に設定するべきURIが異なることに注意してください。 nginx_omniauth_adapterはadapter自身のURI、go-nginx-oauth2-adapterはアプリサーバの/_auth/callbakを指定します。</description>
    </item>
    
    <item>
      <title>転職して一週間がたちました</title>
      <link>https://shogo82148.github.io/blog/2016/03/08/join-fuller/</link>
      <pubDate>Tue, 08 Mar 2016 15:55:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2016/03/08/join-fuller/</guid>
      <description>転職して1週間がたち，新しい生活サイクルにも慣れてきましたので近況報告をします． 面白法人を卒業し、3月1日から Fuller 株式会社で働き始めました！ アプリの視聴率調査のApp Ape Analyticsの提供を中心に、スマフォアプリの開発・分析をやってる会社です。
Pythonの会社なのか？ 私も入るまでみんなPythonを使っている会社だと思っていたのですが、 実際はPythonとjavascript半々くらいで使われています。（若干javascript勢の方が多いかも？） 最近は一部Goが導入されつつあるようでが、残念ながらPerlは影も形もありません。 折角Perlな会社にいたので、Perlの布教活動に勤しみたいと思っています。
業務の感じ チームみんなで改善点を話し合って、みんなで解決していくような感じです。 慣れないツールばっかりで苦労してますが、頑張ります。
会社の雰囲気 ひとことで言うと大学の研究室みたいな感じです。（こう言えば多くの人に伝わるんじゃないかなと） 社員の高専卒の割合が非常に高く僕自身も高専の出身なので、懐かしい感じです。
最後に一言 TLを追ってなかったので全然気が付かなかったけど、退職と転職のタイミングがamacbee氏と完全に一致していてびっくりした。 僕も26日退社、1日入社だったのです。
 転職して一週間がたちました 退職します  折角なので、記事の中身もamacbee氏に合わせてみました。</description>
    </item>
    
    <item>
      <title>グロンギ語翻訳辞書をアップデートしました</title>
      <link>https://shogo82148.github.io/blog/2016/02/27/update-grongish-dictionary/</link>
      <pubDate>Sat, 27 Feb 2016 10:27:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2016/02/27/update-grongish-dictionary/</guid>
      <description>やることがたくさんあるときに限ってどうでもいいことが捗ってこまっているいっちーです。 先日、挑戦状を受け取ったので、グロンギ語翻訳の品質改善に挑戦しました。
《緊急告知》2月26日(金)、何かが起こる!!「仮面ライダークウガ」にまつわる新商品のようですが・・・。ページに書かれているのは、グロンギ語？お客様の中で、リントの言葉に翻訳できる方はいらっしゃいますか～？ https://t.co/hMDQCST6Tz
&amp;mdash; プレミアムバンダイ (@p_bandai) 2016年2月17日   仮面ライダークウガより衝撃の新アイテム登場 ボンジ・ジュグギゾ・ガギバギ・グスと判明!(投げやり)  お手軽に試せるページも作ったので、こちらでお試し下さい。
 グロンギ語翻訳  変換の仕組み 変換の仕組みの詳細は以前書いた記事をどうぞ。 概略だけ書いておくと、 日本語からグロンギ語への変換はMeCabを使った読み・品詞推定の結果もとに、 変換ルールを適用して翻訳しています。 グロンギ語から日本語への翻訳は、この翻訳問題が実は仮名漢字変換と同じ問題だということを利用して、 IMEの辞書をグロンギ語対応したものを使っています。
変換ロジックの修正 旧版の問題点  ボンジジュグギゾガギバギグス: 紺地重視を再開する ゲゲルンギバブゾロヅボパザセザ: ゲームのしなくっ持つのはだれだ ゲゲルゾザジレスゾ: ゲームを始めるぞ  「この日」は「ボンジ」が正しいのですが、「ボボジ」と変換していたため正しく認識できていませんでした。 「の」は通常「ガ」になるのですが、助詞として現れたときは「ン」になります。 さらに連体詞の一部として出てきたときも「ン」になるのですが、こちらのルールが抜けていました。
さらなる改良 旧版はmecab-skkdicを元にした辞書を使っていましたが、 mozcベースに変更しました。 mozcの辞書はクラスタリングや語彙化のような粒度調整が行われており、変換精度の向上が期待できます。 どのようが調整が行われたかはMozcソースコード徹底解説 や 言語処理学会でのMozcの資料を見るとよいと思います。
mozcの変換エンジンをそのまま使えると良かったのですが、すごく面倒なことがわかったのでギブアップしました。 (依存モジュールの関係で32bit版しかビルドできず64bitのプログラムからは直接呼び出せないとか、C++とかC++とかC++とか) mozcとMeCabの辞書構造は非常に似ているので、MeCabの辞書形式に変換して利用しています。 mozcには共起辞書を使った補正機能(例えば同じ「かいたい」という読みでも、「猫を飼いたい」「マグロを解体」を出し分ける機能)など、 MeCabにはない機能も入っているので、そのうち挑戦してみたいですね。 ただし、mozcには機能だけ組み込まれていて辞書が入っていないので、mozcを使っただけだと大差ないかもしれません。
改良の結果  ボンジジュグギゾガギバギグス: この日重視を再開する ゲゲルンギバブゾロヅボパザセザ: ゲームの資格を持つ子は誰だ ゲゲルゾザジレスゾ: ゲームを始めるぞ  だいぶ近くなりました。 「重視」と「遊戯」はグロンギ語で同じ音なので、難しいですね。
変換サーバの実装 ライブラリはPythonで書いてあるので、 PythonのWebフレームワークであるPyramidを使ってAPI化してみました。
デプロイ時のファイル置き換えをアトミックにする sakuraのVPS上でdrootを使って起動しています。 kazuhoさんの「server-starter が SIGHUP 受け取ると pull 型のデプロイツールが起動して、そいつが新しいディレクトリにイメージを展開して、そこに chroot してアプリケーションが動き出すスタイル」を実践してみたくなったので、以下のようなスクリプトを書いてみました。</description>
    </item>
    
    <item>
      <title>MeCabのGolangバインディングを書いてみた</title>
      <link>https://shogo82148.github.io/blog/2016/02/11/golang-mecab-binding/</link>
      <pubDate>Thu, 11 Feb 2016 19:32:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2016/02/11/golang-mecab-binding/</guid>
      <description>GolangからMeCabを呼び出すライブラリ探せばあるにはあるのですが、 なんだかどれもメモリ管理がちょっと怪しいんですよね・・・。
 GolangでMeCabを使う。  yukihir0/mecab-go   Go言語から mecab を使う - Qiita  rerofumi/mecab   Go で Mecab を使ってみた  メモリ管理はbluele/mecab-golangが一番しっかりしているっぽいですが、 libmecabの一番高機能だけど面倒な使い方しか対応していなくて、ちょっとカジュアルに遊ぶにはつらい。
というわけで、カジュアルな用途から高度な使い方まで対応したWrapperを書いてみました。
 shogo82148/go-mecab  使い方 READMEとgodocのexamplesからのコピペになってしまいますが、 簡単に使い方の紹介です。
インストール go getで取ってくることはできますが、事前にlibmecabとリンクするための設定が必要です。
$ export CGO_LDFLAGS=&amp;#34;-L/path/to/lib -lmecab -lstdc++&amp;#34; $ export CGO_CFLAGS=&amp;#34;-I/path/to/include&amp;#34; $ go get github.com/shogo82148/go-mecab mecabコマンドと一緒にmecab-configがインストールされているはずなので、 それを使うのが楽でしょう。
$ export CGO_LDFLAGS=&amp;#34;`mecab-config --libs`&amp;#34; $ export CGO_FLAGS=&amp;#34;`mecab-config --inc-dir`&amp;#34; $ go get github.com/shogo82148/go-mecab MeCabはデフォルトで/usr/local/以下に入るので、他の実装では決め打ちしている例が多いですが、 100%とは言い切れないので面倒ですが都度指定にしてあります。 cgoはpkg-configに対応しているで、MeCab側が対応してくれると環境変数の設定が不要になってもっと楽なんですけどね。
カジュアルに使う Parseを使うとmecabコマンドと同等の結果を文字列として受け取れます。
tagger, err := mecab.New(map[string]string{}) if err !</description>
    </item>
    
    <item>
      <title>AWS Lambda で MeCab を動かす(改)</title>
      <link>https://shogo82148.github.io/blog/2016/02/10/mecab-in-lambda/</link>
      <pubDate>Wed, 10 Feb 2016 14:52:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2016/02/10/mecab-in-lambda/</guid>
      <description>MeCabのPythonバインディングをいじってた関係で、MeCabについてインターネットをさまよっていたら、 AWS Lambda で MeCab を動かすという記事を見つけました。 Lambdaの計算リソースで形態素解析できるのは楽しいですねー。 ただ実装にまだまだ改善できそうな部分があったので修正してみました。
2017/12/06追記 Norio Kimuraさんのコメントを受けて、MeCabをAWS Lambdaで動かす(2017年版)を書きました。 以下の手順でも動きますが、少し簡単に出来るようになっています。
問題点 第一に**「外部プロセスを起動しているので遅い」**という点です。 外部プロセスの起動は非常に重くて数百msかかります。 MeCabは非常に高速で数msもあれば解析が終わるのに、もったいないですよね。
第二に**「OSコマンドインジェクションの危険性がある」**という点です。 解析対象の文字列をコマンドライン引数として渡しており、この際シェルを経由しています。 そのため、{&amp;quot;sentence&amp;quot;: &amp;quot;$(ls)&amp;quot;}のような文字列を渡すと、シェルがコマンドとして実行してしまいます。 API Gatewayなどで外部に公開した場合、第三者が何でもし放題な状態になってしまいます。
頑張ってMeCabをライブラリとして呼ぶ 全ての元凶は外部プロセス起動にあるので、頑張ってMeCabをライブラリとして呼んでみましょう。 そもそもなんで外部プロセス起動をしていたかというと、 LD_LIBRARY_PATHが正しく設定されていないためimport MeCab時にlibmecab.soを発見できないからです。 なんとかならないものかと探したところ、Stack Overflowにそれっぽい記事がありました。
 Setting LD_LIBRARY_PATH from inside Python  「環境変数を設定してから自分自身をexecし直す方法」と「ctypesを使って絶対パス指定で読み込む方法」が紹介されています。 前者の方がvoteは多いですがLambdaでこれをやるのは大変そうなので、後者で試してみます。
# preload libmecab import os import ctypes libdir = os.path.join(os.getcwd(), &amp;#39;local&amp;#39;, &amp;#39;lib&amp;#39;) libmecab = ctypes.cdll.LoadLibrary(os.path.join(libdir, &amp;#39;libmecab.so&amp;#39;)) 一度読み込んでしまったライブラリは再利用されるため、 import MeCabはここで読み込んだライブラリにリンクされます(importの順番が重要なの闇な感じがする)。 LD_LIBRARY_PATHが正しく設定されている必要はありません。
さて、これでlambda_function.pyとtokenizer.pyが分かれている必要がなくなったので、二つを合体してみましょう。
# coding=utf-8 import os import settings import logging logger = logging.</description>
    </item>
    
    <item>
      <title>Redisでスコアを複数設定できるランキングを作ってみた</title>
      <link>https://shogo82148.github.io/blog/2016/02/06/redis-leader-board-multi/</link>
      <pubDate>Sat, 06 Feb 2016 02:30:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2016/02/06/redis-leader-board-multi/</guid>
      <description>ランキングを作っているとスコアを複数設定したいことがよくあると思います。 例えば「得点が同じだったら早くその得点を出した人優先」とか「勝ち点が同じだったら得失点差が大きい方優先」とかのように、 最初の基準で順位を決められなかった場合の第二基準が欲しいみたいな場合です。
ランキングを作るのにはRedisのSorted Setを使うのが便利ですが、残念ながらSorted Setはひとつしかスコアを設定できません。 少し前にどうやったら実装できるかと社内チャットで話題に上ったので、試しにRedis::LeaderBoardMulti(仮名)という名前で書いてみました。
 shogo82148/p5-Redis-LeaderBoardMulti  使い方 メソッドの名前はRedis::LeaderBoardにあわせてありますが、 スコアが複数指定できるようになった関係でちょっと変わってます。
use Redis; use Redis::LeaderBoard; my $redis = Redis-&amp;gt;new; my $lb = Redis::LeaderBoardMulti-&amp;gt;new( redis =&amp;gt; $redis, key =&amp;gt; &amp;#39;leader_board:1&amp;#39;, order =&amp;gt; [&amp;#39;asc&amp;#39;, &amp;#39;desc&amp;#39;], # asc/desc, desc as default ); $lb-&amp;gt;set_score(&amp;#39;one&amp;#39; =&amp;gt; 100, time); # 第二基準は時間=得点が同じだったら早くその得点を出した人優先 $lb-&amp;gt;set_score(&amp;#39;two&amp;#39; =&amp;gt; 50, time); my ($rank, $score, $time) = $lb-&amp;gt;get_rank_with_score(&amp;#39;one&amp;#39;); set_scoreの第二引数以降はすべてスコアとして扱われます。(そのためRedis::LeaderBoardと互換性はない) 上の例では「得点が同じだったら早くその得点を出した人優先」になってます。
制限事項 実装の都合により、以下のような制限があります。
 スコアはすべて64bit符号付き整数です  Redis::LeaderBoardのスコアは倍精度浮動小数点型なので小数も扱えるが、Redis::LeaderBoardMultiは整数だけ   Redis 2.8.9以降のみで動きます  実装の仕組み Sorted Setの同じスコアを持つメンバーは辞書順にソートされます(zaddの同じスコアを持つ要素の項を参照)。 例えば以下の様にメンバー「a」「b」「c」を追加すると、必ず「abc」の順番になることが保証されています。</description>
    </item>
    
    <item>
      <title>Redis::Fast 0.17 をリリースしました</title>
      <link>https://shogo82148.github.io/blog/2016/01/23/redis-fast-0-dot-17-released/</link>
      <pubDate>Sat, 23 Jan 2016 16:20:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2016/01/23/redis-fast-0-dot-17-released/</guid>
      <description>Redis::Fast 0.17 をリリースしました。 主な変更点は以下のとおりです。
 I/Oの待ち合わせに使うシステムコールをselect(2)からpoll(2)に変更 hiredisをv0.13.3にアップデート  macでテストが終わらない問題がありましたが、この変更によって修正されています。
hiredisはconnect(2)をnonblokingモードで呼び出しています。 nonblockingなので接続が未完了であってもすぐに制御を返し、errnoにEINPROGRESSが設定されます。 この場合、manにあるようにselect(2)で書き込み可能になるのを待つことで、接続完了を検知できます。
 select(2) で書き込み可能になった後に、 getsockopt(2) を使って SOL_SOCKET レベルで SO_ERROR オプションを読み出すこ とにより、 connect() が成功したか、失敗したかを判断できる。
 linuxの場合はこれで上手く動くのですが、macだと何故かselect(2)が永遠に制御を返さない場合があるようです。 接続先が存在しない場合に起こるのですが、制御を返す場合もあるので謎です。
いろいろ調べてはみたのですがselect(2)だとどうやっても上手く動かなかったので、poll(2)に変更しました。 poll(2)変更版でテストしてみると、接続先が存在しない場合にPOLLOUTを返すケースとPOLLHUPを返すケースがあるようです。 どうやらPOLLHUPにあたるイベントが来た時の挙動がlinuxとmacとで違うらしい？ 謎です。</description>
    </item>
    
    <item>
      <title>UnityのBitmapフォントの収録文字のdiffを取る</title>
      <link>https://shogo82148.github.io/blog/2015/12/22/diff-of-unity-bitmap-font/</link>
      <pubDate>Tue, 22 Dec 2015 19:04:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/12/22/diff-of-unity-bitmap-font/</guid>
      <description>Unityで文字を描画するには 「BMFont(Bitmap Font Generator)でビットマップフォントを作る方法」等にあるように ビットマップフォントを自分で作ってあげないといけないらしいです。 (ダイナミックフォントというものもあるらしいけど、まだ安定性が検証ができていないので使ってない。)
フォントに入っている全部の文字を収録するとでかくなりすぎるので、一部の文字だけ収録するのが一般的だと思います。 入れる文字は自分で選ぶわけですが、フォントファイルを更新する際に、以前は使えた文字が入っていなくてつらい思いをしたので、 gitで差分をみれるようにしてみました。
gitのいろんなファイル形式の差分を見やすくする方法は Git Diffでcsvの差分を見やすく表示するを参照。
csvのときと同じ要領で、まずはfntファイルをdiffを取りやすい形式に変換するスクリプト(fnt2txt)を用意し
#!/bin/bash  grep &amp;#39;char id=&amp;#39; $1 | cut -d&amp;#39; &amp;#39; -f2 | cut -d= -f2 | perl -MEncode -ne &amp;#39;printf &amp;#34;%04x: %s\n&amp;#34;, $_, encode_utf8 chr($_) if $_ &amp;gt;= 32&amp;#39; fnt2txtを使う設定を.git/configに設定します。
[diff &amp;#34;fnt&amp;#34;] textconv = fnt2txt 最後に拡張子.fntに対してだけこの設定が反映されるようにすればOKです。
*.fnt diff=fnt こんな感じでdiffが見れます。
diff --git a/foo.fnt b/foo.fnt index 79391c0..e262b2d 100755 --- a/foo.fnt +++ b/foo.fnt @@ -93,6 +93,7 @@  007c: | 007d: } 007e: ~ +00a0:  00a1: ¡ 00a2: ¢ 00a3: £ 事故防止に是非ご利用ください。</description>
    </item>
    
    <item>
      <title>MeCabをPython3から使う(続報)</title>
      <link>https://shogo82148.github.io/blog/2015/12/20/mecab-in-python3-final/</link>
      <pubDate>Sun, 20 Dec 2015 01:03:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/12/20/mecab-in-python3-final/</guid>
      <description>Python3からMeCabを扱おうとして挫折していたのですが (MeCabをPython3から使う(中間報告))、 改めて調査して、上手くいかなかった原因が分かったのでご報告します。
おさらい Python3で以下のようにMeCabを使おうとすると
import MeCab tagger = MeCab.Tagger(&amp;#39;&amp;#39;) text = u&amp;#39;MeCabで遊んでみよう!&amp;#39; node = tagger.parseToNode(text) while node: print(node.surface + &amp;#39;\t&amp;#39; + node.feature) node = node.next surfaceが全く読み取れないという現象に遭遇していました。
BOS/EOS,*,*,*,*,*,*,*,* 名詞,一般,*,*,*,*,* 助詞,格助詞,一般,*,*,*,で,デ,デ 動詞,自立,*,*,五段・バ行,連用タ接続,遊ぶ,アソン,アソン 助詞,接続助詞,*,*,*,*,で,デ,デ Traceback (most recent call last): File &amp;#34;m.py&amp;#34;, line 10, in &amp;lt;module&amp;gt; print( node.surface + &amp;#39;\t&amp;#39; + node.feature ) UnicodeDecodeError: &amp;#39;utf-8&amp;#39; codec can&amp;#39;t decode byte 0xa3 in position 1: invalid start byte 解決策 詳しい原因なんてどうでもいいからMeCabを使いたい人向けに、最初に解決方法を書いておきます。 以下のように本当に解析したい対象を解析する前に、一度parseをしておけばOKです。
import MeCab tagger = MeCab.</description>
    </item>
    
    <item>
      <title>PerlのDBIx::Class利用上の注意点</title>
      <link>https://shogo82148.github.io/blog/2015/12/17/dbix-class/</link>
      <pubDate>Thu, 17 Dec 2015 18:35:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/12/17/dbix-class/</guid>
      <description>この記事は、Perl 5 Advent Calendarの17日目の記事です。
Redis::Fast の reconnect についての中で DBIx::Classのreconnectについても触れています。 DBIx::Classの安全にreconnectionが行えるように考慮されていますが、色々と注意点があります。 reconnection周りで調べてみたので、Advent Calendarの枠を借りてまとめたいと思います。
DBIx::Classとは DBIx::ClassはPerlのO/Rマッピングモジュールです。 テーブル間のリレーションを定義でき、JOIN句の入ったクエリもサポートする等、かなり高機能なモジュールです。 もう僕はJOIN句をDBIx::Class以外で書ける気がしません。 詳しくはtypester先生の解説記事をどうぞ。
 Perl Hackers Hub  第3回　DBIx::Classでデータベース操作（1） 第3回　DBIx::Classでデータベース操作（2） 第3回　DBIx::Classでデータベース操作（3）    サンプル サンプルとしてユーザの所持金を管理する簡単なアプリを作ってみます。 Webアプリとか作るの面倒だったので、コンソールアプリです。
package My::Schema::User { use base &amp;#39;DBIx::Class::Core&amp;#39;; __PACKAGE__-&amp;gt;table(&amp;#39;user&amp;#39;); __PACKAGE__-&amp;gt;add_columns( id =&amp;gt; { data_type =&amp;gt; &amp;#39;INTEGER&amp;#39;, is_nullable =&amp;gt; 0, is_auto_increment =&amp;gt; 1, }, username =&amp;gt; { data_type =&amp;gt; &amp;#39;VARCHAR&amp;#39;, size =&amp;gt; 255, is_nullable =&amp;gt; 0, }, ); __PACKAGE__-&amp;gt;set_primary_key(&amp;#39;id&amp;#39;); # userとmoneyは1対1の関係で、userに対応するmoneyが必ず存在しなければならない __PACKAGE__-&amp;gt;has_one( &amp;#39;money&amp;#39; =&amp;gt; &amp;#39;My::Schema::Money&amp;#39;, { &amp;#39;foreign.</description>
    </item>
    
    <item>
      <title>git-mergeの挙動をカスタマイズする</title>
      <link>https://shogo82148.github.io/blog/2015/12/16/customize-git-merge/</link>
      <pubDate>Wed, 16 Dec 2015 22:24:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/12/16/customize-git-merge/</guid>
      <description>最近gitのコンフリクト解消職人みたいになっていてすごくつらいです。 普通のプログラムであれば順番が重要なので手動でのコンフリクト解消は避けられないのですが、 僕が相手にしているのは最終的にMySQLに食わせるデータなのでそこまで順番は重要ではありません。 順番に挿入したところで、MySQLが順番にかえしてくれるとは限りませんからね。 このようなケースではある程度機械的にマージできるのでは？と調べてみました。
merge driver いろいろググってみるとgitattributesでファイル毎にマージの細かい挙動を制御できるようです。 通常マージの方法はgitがよしなに選択してくれますが、merge属性に以下の項目を指定することでマージの方法を強制することができます。
 text  テキストファイルとしてマージする。 コンフリクトすると &amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;, =======, &amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;でコンフリクトした場所を教えてくれる。   binary  バイナリファイルとしてマージする。 コンフリクトするとマージしようとしたファイルを残しておいてくれる。   union  テキストファイルとしてマージする。 textと違ってコンフリクトしてもマーカを付けない。どちらの変更も残すように適当にマージしてくれる。 適当なので コンフリクト時の行の順番は保証されない    text, binaryはコンフリクトしたときによく見る挙動ですね。 unionは初めて知ったので、簡単なレポジトリを作って挙動を確かめてみました。
$ # masterブランチ上でmembers.txtにAliceを追加する $ git init $ echo Alice &amp;gt; members.txt $ git add members.txt $ git commit -m &amp;#39;add Alice&amp;#39; [master (root-commit) 8c39714] add Alice 1 file changed, 1 insertion(+) create mode 100644 members.</description>
    </item>
    
    <item>
      <title>Goでデプロイ神社書いてみた</title>
      <link>https://shogo82148.github.io/blog/2015/12/13/go-deploy-shrine/</link>
      <pubDate>Sun, 13 Dec 2015 10:51:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/12/13/go-deploy-shrine/</guid>
      <description>Go その2 Advent Calendar 2015の13日目の記事です。
 その1 その2 その3  六曜を知ることができる便利コマンドを作ってみたお話です。
Deploy神社とは Maco_Tasuが作ったいつdeployしたら安全かを教えてくれる便利APIです。 詳しくは作者ブログ記事をどうぞ。(Deploy神社APIを作った- 眠すぎて明日が見えない)
便利APIなのですが、依存している外部APIが利用できなくなってしまったため、Deploy神社自体が利用できなくなっています。
作ってみた デプロイする時間が分からないと不便なので、Go実装を作ってみました。
 shogo82148/go-deploy-shrine  go getしてきてお祈りを捧げればデプロイするべき時間を教えてくれます。
$ go get github.com/shogo82148/go-deploy-shrine/cli/pray $ pray 今日は旧暦の11月3日(先勝)です。deployは午前中に済ませましょう。 先勝 - Weblio
 六曜の一。急用や訴訟などによいとされ，早く事を行うのがよく，午前は吉，午後は凶という日。先勝日。せんかち。さきがち。
 今日12月13日は先勝で午前中にデプロイするのが良いようです。便利ですね。
六曜とは むかしのカレンダーには暦注と呼ばれる「今日の運勢」みたいなものが記載されていたらしいです。 六曜はその暦注のひとつで、現在のカレンダーにも記載されることの多い影響力の大きなものです。
詳しくはWikipediaで。
 六曜 - Wikipedia  旧暦の(月＋日)を6で割った余りから簡単に求めることができます。
 0: 大安 1: 赤口 2: 先勝 3: 友引 4: 先負 5: 仏滅  旧暦とは 旧暦の月日を求めることができれば六曜は簡単に出せるのですが、 日本における旧暦である天保暦は月の満ち欠けと太陽の動きを元にした暦法であり、 月と太陽の動きを正確に予測する必要があります。
Go版デプロイ神社では「日の出・日の入りの計算―天体の出没時刻の求め方」で紹介されていた計算式を用いています
 2033年旧暦閏月問題 天保暦をそのまま当てはめると2033年に月を決定できない問題が知られています。 日本カレンダー暦文化振興協会というところが「閏11月を推奨する」との見解を2015年8月に出しています。</description>
    </item>
    
    <item>
      <title>Perl の DateTime 利用上の注意点</title>
      <link>https://shogo82148.github.io/blog/2015/12/09/perl-datetime/</link>
      <pubDate>Wed, 09 Dec 2015 00:00:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/12/09/perl-datetime/</guid>
      <description>この投稿は Perl 5 Advent Calendar 2015 の 9日目の記事です。
Perl の Time::Piece 利用上の注意点 という記事の最後にDateTimeへの言及があったのですが、 DateTimeはDateTimeでいろいろとハマりどころがあるんですよね・・・。 僕も今年いくつか罠にハマりました。ちょうどアドベントカレンダーの季節ですし、この機会にハマりどころをまとめてみることにします。
遅い いろんなところで言われていることですが 遅い です。 試しに代表的な日付を扱うモジュールでベンチをとってみました。 (比較のために時間をとるためのPerlの組み込み関数も入れてあります)
# いろんな形式で今の時間を取得する use Benchmark qw/ cmpthese /; use Time::HiRes (); use Time::Moment; use Time::Piece (); use DateTime; cmpthese 0, { &amp;#39;time&amp;#39; =&amp;gt; sub { time }, &amp;#39;Time::HiRes&amp;#39; =&amp;gt; sub { Time::HiRes::time }, &amp;#39;localtime&amp;#39; =&amp;gt; sub { () = localtime }, &amp;#39;Time::Moment&amp;#39; =&amp;gt; sub { Time::Moment-&amp;gt;now }, &amp;#39;Time::Piece&amp;#39; =&amp;gt; sub { Time::Piece-&amp;gt;localtime }, &amp;#39;DateTime&amp;#39; =&amp;gt; sub { DateTime-&amp;gt;now( time_zone=&amp;gt;&amp;#39;Asia/Tokyo&amp;#39; ) }, }; Rate DateTime Time::Piece Time::Moment localtime Time::HiRes time DateTime 5303/s -- -95% -98% -99% -100% -100% Time::Piece 103765/s 1857% -- -67% -71% -98% -99% Time::Moment 313599/s 5814% 202% -- -11% -93% -98% localtime 354215/s 6580% 241% 13% -- -92% -98% Time::HiRes 4706723/s 88658% 4436% 1401% 1229% -- -72% time 16536995/s 311751% 15837% 5173% 4569% 251% -- それにしてもTime::Moment速いですね。組み込みのlocaltimeと互角とは。</description>
    </item>
    
    <item>
      <title>Go言語でGraceful Restartをするときに取りこぼしを少なくする</title>
      <link>https://shogo82148.github.io/blog/2015/11/23/golang-graceful-restart-2nd/</link>
      <pubDate>Mon, 23 Nov 2015 20:51:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/11/23/golang-graceful-restart-2nd/</guid>
      <description>少し前にStarletにGraceful Restartが時たま上手く動かない問題を修正するpullreqを投げました。 原因は割り込みハンドラ内でexitを呼んでいたからでした。 「割り込みハンドラ内ではフラグを建てるだけ」 「メインのプログラム内でそのフラグを見て分岐する」という原則があるのですが、それを守るのは難しいということですね。 (しかし新たな問題を産んでしまいrevertされてしまいましたが・・・ まあ修正後のコードも考え方は一緒です。割り込みホント難しい・・・)
このpullreqを取り込んでもらうときに再現実験をやってみたのですが、 Goでもちゃんと動くのかな？と気になったので Go言語でGraceful Restartをするで紹介した プログラムに同じテストをやってみました。
2017-01-22追記: Go1.8以降でGraceful Shutdownがbuild-inになるので、この記事で紹介したライブラリは不要となりました。 詳しくはGo1.8のGraceful Shutdownとgo-gracedownの対応を参照。
mannersでテストしてみる 前回の記事ではmannersとgo-server-starterの 組み合わせが良さそうとの結論になったので、この組み合わせでテストしてみます。 以下テストに使用したコードです。 (今回の内容とは直接関係は無いですが、go-server-starterに変更が入ってFallbackのやり方が前回から少し変わってます)
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;log&amp;#34; &amp;#34;net&amp;#34; &amp;#34;net/http&amp;#34; &amp;#34;os&amp;#34; &amp;#34;os/signal&amp;#34; &amp;#34;syscall&amp;#34; &amp;#34;time&amp;#34; &amp;#34;github.com/braintree/manners&amp;#34; &amp;#34;github.com/lestrrat/go-server-starter/listener&amp;#34; ) var now = time.Now() func main() { log.Printf(&amp;#34;start pid %d\n&amp;#34;, os.Getpid()) signal_chan := make(chan os.Signal) signal.Notify(signal_chan, syscall.SIGTERM) go func() { for { s := &amp;lt;-signal_chan if s == syscall.SIGTERM { log.Printf(&amp;#34;SIGTERM!!!!\n&amp;#34;) manners.Close() } } }() listeners, err := listener.</description>
    </item>
    
    <item>
      <title>Goオールスターズで登壇してきました</title>
      <link>https://shogo82148.github.io/blog/2015/10/14/go-all-stars/</link>
      <pubDate>Wed, 14 Oct 2015 08:11:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/10/14/go-all-stars/</guid>
      <description>先週の日曜日に登壇してきました。
  過去に自作したGoプロダクトの紹介 - Goオールスターズ  from Shogo Ichinose   過去に自作したGoプロダクトの紹介 - Goオールスタース  発表の10日くらい前にsongmuさんがKAYACのIRCに現われオールスターを募集に来てくださったものの、 弊社スターの都合がつかないため僕が代わりに発表してきました。
KAYACではGoプロダクトたくさん動いていますが説明は作者にお任せしたほうがいいかなと思い、 自作のGoプロダクトをメインに発表してきました。
 go-rgba4444 androidbinary - Androidのバイナリファイルを解析するgoのライブラリ go-sql-proxy - Go言語でSQLのトレースをする go-dithering - Go言語で画像の減色を行う go-prove/go-tap - Go言語でPerlのテストを早くする go-webtail/go-webtail - Go-webtailってのを書いた  go-prove、CPANに上げればいいんじゃない？w #eventdots
&amp;mdash; songmu (@songmu) 2015年10月11日  Perl Archive Network とはいったい・・・
KAYACではいろんなGoプロダクトが動いているのでこちらもどうぞ。
 go-katsubushi snowﬂake-likeなIDジェネレータ stretcher Consul/Surfと連携したデプロイツール rin AWS-S3に出力されたログをRedshiftへインポートするツール mirage Dockerを使ったテスト用環境構築 alphawing Android/iOSアプリの社内配信ツール  スライドにちょこちょこ修正いれててGopherくん人形もらうの忘れてたけどもらっておけばよかった。
他の人の発表はこちら。
 Goオールスターズ GoオールスターズToggetterまとめ Goオールスターズで登壇してきました - おそらくはそれさえも平凡な日々 Goオールスターズでpackage managementについて話してきました - YAMAGUCHI::weblog Goだけでモバイルアプリを作ろう Goオールスターズ - 考える人、コードを書く人  </description>
    </item>
    
    <item>
      <title>AnySan::Provider::Slackとape-slackを書いた</title>
      <link>https://shogo82148.github.io/blog/2015/09/28/anysan-provider-slack-and-ape-slack/</link>
      <pubDate>Mon, 28 Sep 2015 22:11:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/09/28/anysan-provider-slack-and-ape-slack/</guid>
      <description>先週、今のプロジェクトでのメインのコミュニケーションツールをIRCからSlack切り替えました。 それにともないIRCに済んでいたボットたちもお引越しする必要があったので、 ボットとSlackをつなぐためのライブラリを書きました。
 AnySan::Provider::Slack ape-slack  Perlとgoのボットが住んでいるのでそれぞれの言語で実装してあります。
AnySan::Provider::Slack PerlのAnySan用のモジュールです。
use AnySan; use AnySan::Provider::Slack; my $slack = slack token =&amp;gt; &amp;#39;YOUR SLACK API TOKEN&amp;#39;, channels =&amp;gt; { &amp;#39;general&amp;#39; =&amp;gt; {}, }; $slack-&amp;gt;send_message(&amp;#39;slack message&amp;#39;, channel =&amp;gt; &amp;#39;C024BE91L&amp;#39;); AnySan-&amp;gt;run; AnySanを使うだけでも便利なんですが、 今のプロジェクトではAnySanを対話形式で使いやすくするようにUnazuSanを使っています。 UnazuSanはIRC前提で書かれていて、AnySan::Provider::Slackをインストールしてもそのままは使えません。
UnazuSanを置き換えるもの面倒なので、イベントの名前を書き換えて投げ直すことで、 SlackのメッセージをIRCに見せかける方法をとっています。 またSlackのOutgoing Webhookで@つきのmentionを捕まえるにもあるように、 Slackのメンションは &amp;lt;@U08DGJVJ7&amp;gt;のような形式になってしまい、UnazuSanは自分へのメッセージとして扱ってくれません。 これをUnazuSanが解釈できる形式に置き換えるのがポイントです。
use 5.010; use warnings; use utf8; use Encode qw/encode_utf8/; use UnazuSan; use AnySan; use AnySan::Provider::Slack; my $unazu_san = UnazuSan-&amp;gt;new( host =&amp;gt; &amp;#39;example.com&amp;#39;, password =&amp;gt; &amp;#39;xxxxxxxxxxx&amp;#39;, enable_ssl =&amp;gt; 1, join_channels =&amp;gt; [qw/arcade/], respond_all =&amp;gt; 1, ); my $slack = slack( token =&amp;gt; &amp;#39;YOUR SLACK TOKEN&amp;#39;, channels =&amp;gt; {}, as_user =&amp;gt; 1, ); AnySan-&amp;gt;register_listener( slack =&amp;gt; { event =&amp;gt; &amp;#39;message&amp;#39;, cb =&amp;gt; sub { my $receive = shift; # fake irc privmsg $receive-&amp;gt;{event} = &amp;#39;privmsg&amp;#39;; $receive-&amp;gt;{message} =~ s/&amp;lt;\@xxxxx&amp;gt;:/unazusan:/; AnySan-&amp;gt;broadcast_message($receive); }, } ); $unazu_san-&amp;gt;on_command( help =&amp;gt; sub { my ($receive, @args) = @_; $receive-&amp;gt;reply(&amp;#39;help &amp;#39;.</description>
    </item>
    
    <item>
      <title>ISUCON5の予選に参加して惨敗してきた</title>
      <link>https://shogo82148.github.io/blog/2015/09/28/isucon5-qualifying/</link>
      <pubDate>Mon, 28 Sep 2015 06:16:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/09/28/isucon5-qualifying/</guid>
      <description>こんにちは、チームぽわわ4 feat. ネコトーストラボです。 ISUCON5の予選に参加してきて見事に惨敗してきました。
お題 「ISUxi」という名前の「高負荷に耐えられるSNSコミュニティサイト」。 日記やコメントの投稿ができて、ホーム画面には「あしあと」「あなたへのコメント」「あなたの友だちの日記エントリ」「あなたの友だちのコメント」が表示されています。 日記にはprivateとpublicの公開範囲があって、これの出し分けも必要です。 やることおおい・・・。
やったこと 〜開始 時間余裕でしょと思ったら全くそんなことなかった
&amp;mdash; ひさいち (@hisaichi5518) 2015年9月25日  時間余裕でしょと思ったら全くそんなことなかった
&amp;mdash; Ichinose Shogo (@shogo82148) 2015年9月25日  5時間で決着をつける https://t.co/AbnnSyHuZ8
&amp;mdash; Ichinose Shogo (@shogo82148) 2015年9月26日  バッテリ残量との戦いがすでに始まっている #ISUCON #アダプタ忘れた
&amp;mdash; Ichinose Shogo (@shogo82148) 2015年9月26日  〜午前中 ソースコードをgit管理下に置くとか準備したあと、ソースコードを眺めてスキーマやクエリの改善ができないかを見てました。 主にインデックスに不足は無いか、ループクエリは無いかを見てみました。 インデックスに関しては必要そうなところにはすでに貼ってあって、これ以上することなさそうな感じ。 ループクエリに関しては、ホーム画面の「あなたの友だちのコメント」の部分で、エントリ情報や、関連するユーザの情報を取ってくるところで見つけたので、JOINに書き換えられないか着手。 しかし、実行計画が大きく変わって極端に遅くなってしまい、なんだこれーってなってました。
〜14時 SQLじゃ無理だってことで、Redisに切り替え。 エントリやコメントをRedisのリストで管理して、 エントリやコメントを投稿したときに友だち全員に配信する形式に変更しました。
ある程度書けてこれで動くのでは！ってとこまで書けたんだけど、 「投稿した時に友だちに配信」形式だと、友だち関係があとから変化するケースに対応できないという気がつく。 いろいろ考えてみたものの、友だち関係が変化した場合は元の実装を使うしか思いつきませんでした。
そしてここでバッテリー切れ・・・
あと3%…(ヽ´ω`)
&amp;mdash; Ichinose Shogo (@shogo82148) 2015年9月26日  〜16時 アダプタを借りることができて延命しました。ありがとうございます！
アダプター貸していただけました。ありがとうございます！m(__)m #isucon
&amp;mdash; Ichinose Shogo (@shogo82148) 2015年9月26日  コメント部分のキャッシュが一応は動いたので、エントリ部分についてもRedisを使ったキャッシュ化を進めてました。 200位スコアはあがるものの劇的な改善にはならず・・・(ヽ´ω`)</description>
    </item>
    
    <item>
      <title>テストでも:ok_maopy:したい人へ</title>
      <link>https://shogo82148.github.io/blog/2015/09/19/ok-macopy/</link>
      <pubDate>Sat, 19 Sep 2015 23:44:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/09/19/ok-macopy/</guid>
      <description>shogo82148/p5-Acme-OkMacopy  use strict; use Test::More; use Acme::OkMacopy; ok_macopy &amp;#34;macopy is cool&amp;#34;, &amp;#34;ok_macopy&amp;#34;; done_testing; 様子です pic.twitter.com/sA96GmqKmQ
&amp;mdash; トーカナイザの守護霊 (@mackee_w) 2015年9月17日  :ok_macopy:</description>
    </item>
    
    <item>
      <title>Go言語でPerlのテストを早くする</title>
      <link>https://shogo82148.github.io/blog/2015/09/19/faster-perl-test-with-go-lang/</link>
      <pubDate>Sat, 19 Sep 2015 21:49:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/09/19/faster-perl-test-with-go-lang/</guid>
      <description>Test::mysqld::Multiというモジュールを書いてみたみたいな涙ぐましい努力により5分で終わるようになったテストですが、 プロジェクトのコードも増えて人も増えた影響で、 テスト時間が約7分まで伸び、テストのキューに10個近く並んで順番待ちさせられるという状況になってしまいした。
この状況を解決すべく go-prove というものを書いてみたので、そのご紹介です。
proveが遅い理由 proveがテストの結果を読むところがブロッキングI/Oになっているらしく、そのせいで遅くなっているらしいです。
 Perl-Toolchain-Gang/Test-Harness#30  実際に結果読んでいるところはこの辺ですかね。 selectとか使っていてなるべくブロッキングしないような作りにはなっていそうですが、どこかでブロッキングしてしまっているようです。 今のプロジェクトだと32コアのCPUで32並列で動かしてもCPUを100%使い切ることができませんでした。
Shunme ググるとShunmeというプロジェクトでproveの問題を解決しようという試みが行われているようです。
 Shunmeというperl用のテストハーネスモジュールを書き始めました magnolia-k/p5-Shunme  しかし残念ながらproveのプラグイン機構はサポートしておらず、Formatterの指定オプションもないようです。 今のプロジェクトではプラグインでMySQLを立てたり、JUnitでテスト結果をフォーマットしたりということをしているので、そのままは使えなさそう。 ちょっと改造するにはソースコードの理解が大変そうなので断念。 「(逆に遅くなるときも有ります)」というところも気になりますね・・・。
go-prove いろいろテストの実行方法を調べてはみましたが、どの方法も並行処理に苦労している模様。 テストファイル自体はただのPerlのスクリプトなので、実行して集計する部分は別にPerlにこだわる必要ないのでは？ 並行処理といえば今ならGolangでしょ！ってことでproveのGo実装を書いてみました。
 go-prove  例えば以下のようなテストをかいて、
use Test::More; ok &amp;#34;macopy&amp;#34;; done_testing; go-proveコマンドと実行すると、JUnit形式でテスト結果が出力されます。
$ go-prove 2015/09/19 21:45:44 start t/macopy.t 2015/09/19 21:45:44 finish t/macopy.t &amp;lt;testsuites&amp;gt; &amp;lt;testsuite tests=&amp;quot;1&amp;quot; failures=&amp;quot;0&amp;quot; time=&amp;quot;0.225&amp;quot; name=&amp;quot;t_macopy_t&amp;quot;&amp;gt; &amp;lt;properties&amp;gt;&amp;lt;/properties&amp;gt; &amp;lt;testcase classname=&amp;quot;t_macopy_t&amp;quot; name=&amp;quot;&amp;quot; time=&amp;quot;0.225&amp;quot;&amp;gt;&amp;lt;/testcase&amp;gt; &amp;lt;/testsuite&amp;gt; &amp;lt;/testsuites&amp;gt; go-prove -j 32とするとgoroutineを32個生成して、32並列でテストを実行してくれます。 I/Oの処理をGolangのランタイムがよしなにやってくれるので、楽ちんです。
また、今のプロジェクトではApp::Prove::Plugin::MySQLPoolを使っているので、それ相当の機能をgo-prove -plugin mysqldで使えるようにしました。 プラグインを有効にするとMySQLサーバを立ち上げて、その接続先情報をGO_PROVE_MYSQLD環境変数に設定してくれます。
実際にプロジェクトのコードで試してみたところ7分かかっていたテストが4分を切るようになりました。 CPUの使用率も100%近くになって、有効活用できているようです。</description>
    </item>
    
    <item>
      <title>PerlからGolangを呼び出す</title>
      <link>https://shogo82148.github.io/blog/2015/08/30/golang-to-perl-xs-converter/</link>
      <pubDate>Sun, 30 Aug 2015 22:52:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/08/30/golang-to-perl-xs-converter/</guid>
      <description>GoのコードをPerlから呼び出せるようにするgo2xsを書いてみました。
使い方 Perlから使いたい関数に以下のようにgo2xsで始まるコメントを付けておきます。
package main //go2xs hello func hello(str string) string { return &amp;#34;Hello &amp;#34; + str } go2xsをgo getして、xsのグルーコードを作成。 その後通常のPerlモジュールと同じ手順でコンパイルします。 Go 1.5から入ったShared Libraryの機能を使っているのでGo 1.5が必要です。
go get https://github.com/shogo82148/go2xs/cli/go2xs go2xs -name hoge hoge.go perl Makefile.PL make あとは普通に呼び出すだけ。
perl -Mblib -Mhoge -e &#39;print hoge::hello(&amp;quot;World&amp;quot;)&#39; Hello World 制限事項 今はまだ、整数・浮動小数点型・文字列しか扱えません。
あとGoのShared Libraryを複数回読み込むことができないっぽい？ (ref. https://github.com/golang/go/issues/11100 ) ので、go2xsを使ったコードを二つ以上useすると死にます。
FFI::Rawを使う方法 go2xsはGoをShared Libraryとしてコンパイルしているだけなので、go2xsを使わなくても頑張れば呼び出すことができます。 Golang で Shared Library を出力する。で紹介されているこちらのコードで試してみます。
package main import ( &amp;#34;C&amp;#34; &amp;#34;log&amp;#34; ) //export fib func fib(n int) int { if (n &amp;lt; 2) { return n } return fib(n - 2) + fib(n - 1) } func init() { log.</description>
    </item>
    
    <item>
      <title>YAPC::Asia2015へ行ってきた</title>
      <link>https://shogo82148.github.io/blog/2015/08/23/yapc-asia-2015/</link>
      <pubDate>Sun, 23 Aug 2015 00:48:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/08/23/yapc-asia-2015/</guid>
      <description>YAPC::Asia2015へ行ってきましました。 Blogを書くまでがYAPCらしいので、簡単に
今年の会場は東京ビッグサイトです。 ▼▼みたいになってるところの中にはじめて潜入してきました。 あの中って会議室なんですね。
去年は毎回立ち見ですごく大変だったけど、今年はかなり会場が広くなったおかけで、 大体席を確保できて楽にトークを聴けました。 しかし会場が東京ビッグサイトであっても、人気トークは立ち見になってしまうのがYAPCのすごいところ・・・。 それでも、前の人の頭でスライドが全く見えないみたいなことはなかったので、広い会場は便利です。
以下、今年見たトークです。
 言語開発の現場 はてなブックマークのトピックページの裏側 技術ブログを書くことについて語るときに僕の語ること  タイトルが9割   世界展開する大規模ウェブサービスのデプロイを支える技術  全サーバで一斉にgit pullするつらい話だった と、思ったら途中からstretcherの話になった   HTTP/2時代のウェブサイト設計  CSSスプライトみたいなファイルを一つにまとめてリクエストを減らす技術はHTTP/2ではオワコンになる 何よりもデータ量を減らすことが大事   【sponsored contents】若手エンジニア達の生存戦略 Google Cloud Platformの謎テクノロジーを掘り下げる  朝寝坊して途中からの参加でした(=_=) Googleのコンテナ技術BorgやGoogleのネットワークについての話   我々はどのように冗長化を失敗したのか MySQLで2億件のシリアルデータと格闘したチューニングの話 データ分析基盤を支える技術  いろいろなツールの比較についてのお話でした なんか色々なオープンソースのソフトウェアを紹介していたけど、「自分で構築しようとするな」とのこと D言語みんな使ってね   Parallelism, Concurrency, and Asynchrony in Perl 6  Perl6では並列・並行・非同期処理が簡単に書けるらしいので、その紹介 Promiseやawaitみたいな他の言語で取り入れられている概念がPerlでも使えるらしい 来年Perl6でドローンが飛んでいるのを期待してます   Profiling &amp;amp; Optimizing in Go  Goのプロファイリングと最適化のデモでした sync.</description>
    </item>
    
    <item>
      <title>go-webtailってのを書いた</title>
      <link>https://shogo82148.github.io/blog/2015/06/21/go-webtail/</link>
      <pubDate>Sun, 21 Jun 2015 23:28:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/06/21/go-webtail/</guid>
      <description>Rubyで書かれたwebtailのGo移植を書いてみました。
 go-webtail  オリジナルのwebtailはRubyなので、Rubyistではない僕が使おうとするとまずRubyの実行環境からそろえないといけなくてつらい。 ワンバイナリでダウンロードするだけで使えるやつが欲しいなあと常々思っていたのでGolangです。 htmlやjavasctiptの部分もバイナリに含まれているので、インストールも簡単です。
引数無しで実行すると8080ポートで待ち受けて、標準入力から読み込んだ結果をWebsocketで読めるようにしてくれます。
go get github.com/shogo82148/go-webtail/cmd/webtail # インストール echo hogehoge | webtail ファイルもtailできます。
webtail hoge.log fuga.log それぞれ、http://localhost:8080/hoge.logとhttp://localhost:8080/fuga.logで見れるようになります。
mirageと一緒につかう mirageは待ち受けポートを複数設定できます。 (SEE ALSO Dockerで非エンジニアでも開発環境を上げ下げできる、mirageというツールを作りました) その一つをwebtailに割り当てて以下のようにDockerfileに書いておけば、非(サーバサイド)エンジニアでも開発環境のログが見れるようになります。 (見れても理解できるのか？って疑問もあるけど、まあ、全く見れないよりは・・・)
ADD webtail / CMD ./docker_run.sh 2&amp;gt;&amp;amp;1 | /webtail --prefix webtail # ブラウザで見れる代わりにdocker logsで見れなくなるのでこっちのほうがいいかも CMD ./docker_run.sh 2&amp;gt;&amp;amp;1 | tee hoge.log | /webtail --prefix webtail 残念ながらwebsocket対応はしていないので、websoket対応にしたmirageが必要です。 httputil.NewSingleHostReverseProxy互換のrproxyってのを使ったら簡単にwebsocket対応ができて素晴らしいですね。 (mirage自身に手を加える必要があるなら、mirageにこういう機能をつけるべきだったのでは説はある)</description>
    </item>
    
    <item>
      <title>Test::mysqld::Multiというモジュールを書いてみた</title>
      <link>https://shogo82148.github.io/blog/2015/06/20/test-mysqld-multi/</link>
      <pubDate>Sat, 20 Jun 2015 10:41:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/06/20/test-mysqld-multi/</guid>
      <description>Test::mysqldのインスタンスを一度に大量に作りたい人向けに Test::mysqld::Multiというモジュールを書いてみました。
2016/12/22追記: Test::mysqld::MultiはTest::mysqld 0.20 の一部として取り込まれました (p5-Test::mysqld#13)。 APIは少し変わっているので、詳しくはPODを参照してください。 合わせてApp::Prove::Plugin::MySQLPool 0.06 より、 本記事で紹介した高速化が利用できます。
背景 先日Jenkins EC2 Plugin で Spot Instance を使ってテストを回すというのを、 tkuchikiさんにお願いして僕の関わっているプロジェクトでやっていただきました。 CPUのたくさん載ったインスタンスを安く使えるようになったので、 8並列で動いてたテストを24並列で動かせるようになりました。やった3倍速だ！！！ 9分程かかってたテストが7分で終わるようになりました！！！ あれ・・・思ったほど早くなってない・・・。
ログを眺めているとproveコマンドが立ち上がってから、実際にテストが走り始めるまで数分の時間がありました。 App::Prove::Plugin::MySQLPoolを使っているのですが、 ここで時間がかかっているようです。
App::Prove::Plugin::MySQLPoolはテストの並列度分だけMySQLのインスタンスを立ち上げますが、 一個インスタンスを立ち上げたら、それにアクセスできるようになるまでずっと待っているようです。 MySQLの起動に5秒かかるとして24並列で動かしたら2分かかるわけで無視できない長さになります。
作ったもの n個一度に立ち上げて全部にアクセスできるまで待つ実装にすれば速くなるのでは！ってことでTest::mysqld::Multiというのを書いて、 App::Prove::Plugin::MySQLPoolからそれを使うようにしました。 とりあえずtest-mysql-multiブランチにコミットしてあります。 App::Prove::Plugin::MySQLPoolに取り込んでもらうか別のモジュールとして分離するか、後々のことは未定。 今のプロジェクトで使ってみてちょっとの間様子見してみます。 7分かかってたテストが5分程度で終わるようになったので、効果はあるようです。
ちなみに、並列度が24と半端なのはそれ以上並列度を上げても速くならなかったため。 32コアあるマシンなんだけど使い切れてません。 どこにボトルネックがあるんだろうな・・・。
まとめ プロセス一覧にmysqldが24個並ぶの楽しい</description>
    </item>
    
    <item>
      <title>MeCabをPython3から使う(中間報告)</title>
      <link>https://shogo82148.github.io/blog/2015/06/02/mecab-in-python3/</link>
      <pubDate>Tue, 02 Jun 2015 23:12:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/06/02/mecab-in-python3/</guid>
      <description>先日このようなツイートを見かけて、 「Python3になってGCの挙動変わったのかな？」と疑問に思ったので調査してみました。
MeCabをPythonから使う注意点とか - Shogo&amp;#39;s Blog http://t.co/vJnOqZfUd7 @shogo82148さんから python3だと変数に代入しなくても動くのだけど2.xでは留意しないといけない
&amp;mdash; NOKUBI Takatsugu野首貴嗣 (@knok) 2015年6月1日  Python3へのMeCabインストール 手元のPython3.4.3にMeCab Bindingをインストールします。 MeCabの公式(Google Codeサービス停止にともないgithub pageへ移行している模様)から落とせる Python BindingはPython2.x向けのため、setup.pyがそのままでは動きません。 Python3.xでは非互換な文法の変更が入ったので以下のように書き換える必要があります。
diff --git a/setup.py.org b/setup.py index 4486cbb..657945a 100644 --- a/setup.py.org +++ b/setup.py @@ -7,7 +7,7 @@ def cmd1(str):  return os.popen(str).readlines()[0][:-1] def cmd2(str): - return string.split (cmd1(str)) + return cmd1(str).split()  setup(name = &amp;#34;mecab-python&amp;#34;, version = cmd1(&amp;#34;mecab-config --version&amp;#34;), あとは python setup.py install で入ります。
動かしてみる 以前書いた「MeCabをPythonから使う注意点とか」を見返しながら、 GCされて上手く動かない例 をPython3.4.3で動かしてみます。 文字列の扱いが変わったり、print文の扱いが変わったりしているので、その部分だけ書き換えが必要です。</description>
    </item>
    
    <item>
      <title>各ブランチの最後にコミットした人を知る</title>
      <link>https://shogo82148.github.io/blog/2015/05/21/branch-committer/</link>
      <pubDate>Thu, 21 May 2015 00:50:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/05/21/branch-committer/</guid>
      <description>ブランチが大量にあるので整理したい、けど大人数で開発しているから誰がどのブランチいじってるか分からない、 ということがあったので、出し方のメモ。
githubのbranch一覧も見ればいいじゃん！っていう意見もあると思うんだけど、 「自分のbranch一覧」は見れるんですが「特定のだれかのbranch一覧」が見れない・・・。
git-for-each-refを使うと各ブランチに対していろいろ操作できるようです。 各ブランチの最後にコミットした人一覧を出すには以下のコマンド。
git for-each-ref --format=&amp;#39;%(authordate:short) %(authorname) %(refname)&amp;#39; --sort=-committerdate refs/remotes/origin/ formatは自由にいじれるのでいろいろ遊べます。 例えば、ブランチをたくさん抱え込んでいる人の一覧を表示する例。
git for-each-ref --format=&amp;#34;%(authorname)&amp;#34; refs/remotes/origin/ | sort | uniq -c | sort -nr 参考  git-for-each-ref - Output information on each ref リモートブランチも含め更新日時が新しい順番にソートする ブランチ一覧を更新時刻つきで表示したい場合、gitのfor-each-refが使える。  </description>
    </item>
    
    <item>
      <title>Go言語でSQLのトレースをする</title>
      <link>https://shogo82148.github.io/blog/2015/05/13/golang-sql-proxy/</link>
      <pubDate>Wed, 13 May 2015 01:22:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/05/13/golang-sql-proxy/</guid>
      <description>ぴっぴ先輩が「Go言語で発行したクエリを確認したい」って言ってて、 「MySQL使っているならGeneral Logを吐けばよいのでは？」と返したんだけども、 もっと汎用的な方法はないものかと考えてみました。
Golangの database/sql はどんなDBでも対応できるよう、ドライバを自由に入れ替えることができます。 ドライバは単にdatabase/sql/driverにあるインターフェースを満たしている何かなので、 ユーザが自由に作ることができるし、interfaceを経由して直接呼び出すことも可能です。 この仕組を使って、別のドライバにそのまま渡すプロキシを作れば、ログを吐けるのでは？ということでやってみました。
 go-sql-proxy  使い方 まず最初にgo-sql-proxyをドライバとして登録します。
hooks := &amp;amp;proxy.Hooks{ // Hook functions here(Open, Exec, Query, etc.) } sql.Register(&amp;#34;new-proxy-name&amp;#34;, proxy.NewProxy(&amp;amp;another.Driver{}, hooks)) あとは登録したドライバと使って新しいDBハンドラを開くだけです。
db, err := sql.Open(&amp;#34;new-proxy-name&amp;#34;, dataSourceName) このハンドラを使ってクエリ実行を行うと、Hooksで登録した関数が呼び出されます。 元のドライバを直接使った場合と同じように振る舞うので、既存のコードを一切変えること無くHookを差し込めて便利！
トレーサの例 簡単なトレーサを書いてみるとこんな感じ。 発行したSQLのクエリをログに吐き出します。
package proxy import ( &amp;#34;database/sql&amp;#34; &amp;#34;database/sql/driver&amp;#34; &amp;#34;log&amp;#34; &amp;#34;github.com/mattn/go-sqlite3&amp;#34; &amp;#34;github.com/shogo82148/txmanager&amp;#34; ) func main() { sql.Register(&amp;#34;sqlite3-proxy&amp;#34;, NewProxy(&amp;amp;sqlite3.SQLiteDriver{}, &amp;amp;Hooks{ Open: func(conn *Conn) error { log.Println(&amp;#34;Open&amp;#34;) return nil }, Exec: func(stmt *Stmt, args []driver.Value, result driver.</description>
    </item>
    
    <item>
      <title>Goのトランザクションマネージャ作った</title>
      <link>https://shogo82148.github.io/blog/2015/05/09/go-txmanager/</link>
      <pubDate>Sat, 09 May 2015 15:17:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/05/09/go-txmanager/</guid>
      <description>Golangのdatabase/sqlはBeginとCommitでトランザクションの制御を行うことができます。 クエリの実行が確実に成功するのであれば難しくは無いのですが、 トランザクション内でエラーが発生場合、確実にトランザクションを終了させるのは少し面倒です。 また、ネストができないので、「トランザクションの中から呼び出しても外から呼び出しても、関数の中はトランザクション内」みたいなことができません。 PerlにはDBIx-TransactionManagerというものがあるのですが、 このGolang版が欲しくなったので作ってみました。
 txmanager  簡単な使い方 sql.DB をラップした txmanager.DB を使います。 Begin, Commit する代わりに TxBegin, TxCommit を使ってトランザクションを開始・終了すると txmanagerの管理下になります。 確実にトランザクションが終了させるために、トランザクションを開始したらdefer tx.TxFinish()を忘れないように。
import ( &amp;#34;database/sql&amp;#34; &amp;#34;github.com/shogo82148/txmanager&amp;#34; ) func Example(db *sql.DB) { dbm := txmanager.NewDB(db) // トランザクション開始 	tx, _ := dbm.TxBegin() defer tx.TxFinish() // INSERTはトランザクションの中で実行される 	_, err := tx.Exec(&amp;#34;INSERT INTO t1 (id) VALUES(1)&amp;#34;) if err != nil { tx.TxRollback() } tx.TxCommit() } 実際にはこれに加えてエラー処理も必要です。 txmanager.Do を使うと、トランザクションの開始処理・終了をtxmangerがやってくれるので少し楽になります。
import ( &amp;#34;database/sql&amp;#34; &amp;#34;github.</description>
    </item>
    
    <item>
      <title>Go言語でGraceful Restartをする</title>
      <link>https://shogo82148.github.io/blog/2015/05/03/golang-graceful-restart/</link>
      <pubDate>Sun, 03 May 2015 12:10:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/05/03/golang-graceful-restart/</guid>
      <description>とあるHTTPサーバをGolangで立てようって話になったんだけど、 止まると困るので無停止でサーバ再起動をしたい。 PerlにはServer::Starterという有名モジュールがあるんだけど、 Golangはどうなってるの？ってことで調べてみました。
2017-01-22追記: Go1.8以降でGraceful Shutdownがbuild-inになるので、この記事で紹介したライブラリは不要となりました。 詳しくはGo1.8のGraceful Shutdownとgo-gracedownの対応を参照。
gracefulじゃないバージョン Golangの標準ライブラリを使ってHTTPサーバを立ててみる例。 レスポンスが一瞬で終わってしまうとよくわからないので、sleepするhandlerを追加しておきます。
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;log&amp;#34; &amp;#34;net/http&amp;#34; &amp;#34;os&amp;#34; &amp;#34;time&amp;#34; ) var now = time.Now() func main() { log.Printf(&amp;#34;start pid %d\n&amp;#34;, os.Getpid()) s := &amp;amp;http.Server{Addr: &amp;#34;:8080&amp;#34;, Handler: newHandler()} s.ListenAndServe() } // https://github.com/facebookgo/grace/blob/master/gracedemo/demo.go から一部拝借 func newHandler() http.Handler { mux := http.NewServeMux() mux.HandleFunc(&amp;#34;/sleep/&amp;#34;, func(w http.ResponseWriter, r *http.Request) { duration, err := time.ParseDuration(r.FormValue(&amp;#34;duration&amp;#34;)) if err != nil { http.Error(w, err.Error(), 400) return } time.</description>
    </item>
    
    <item>
      <title>Go言語で画像の減色を行う</title>
      <link>https://shogo82148.github.io/blog/2015/04/25/quantize-image-in-golang/</link>
      <pubDate>Sat, 25 Apr 2015 21:49:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/04/25/quantize-image-in-golang/</guid>
      <description>ちょっとGIFアニメを作りたくなって、最近Go触ってるしGoでやってみよう！とやってみたメモ。 ImageMagikでいいじゃん説もあるけど、最終的にツールとして配布したいなってことでGoです。
主に減色まわりについて。
何はともあれ実装してみる 以前、「ターミナル操作の記録(ttyrec)からGIFアニメを生成するツールを作った」という記事を見たので、 これを参考に実装してみる。
package main import ( &amp;#34;image&amp;#34; &amp;#34;image/color/palette&amp;#34; &amp;#34;image/gif&amp;#34; _ &amp;#34;image/png&amp;#34; &amp;#34;os&amp;#34; ) func main() { reader, err := os.Open(&amp;#34;Lenna.png&amp;#34;) if err != nil { return } defer reader.Close() img, _, err := image.Decode(reader) if err != nil { return } paletted := image.NewPaletted(img.Bounds(), palette.WebSafe) for y := img.Bounds().Min.Y; y &amp;lt; img.Bounds().Max.Y; y++ { for x := img.Bounds().Min.X; x &amp;lt; img.Bounds().Max.X; x++ { paletted.Set(x, y, img.At(x, y)) } } f, _ := os.</description>
    </item>
    
    <item>
      <title>Go言語でshuffleする話</title>
      <link>https://shogo82148.github.io/blog/2015/04/25/shuffle-in-golang/</link>
      <pubDate>Sat, 25 Apr 2015 18:07:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/04/25/shuffle-in-golang/</guid>
      <description>Fisher-Yates shuffleを使ってシャッフルライブラリ作ってみました。
 https://github.com/shogo82148/go-shuffle  標準ライブラリのsortと似たような感じで使えます。 デフォルトでintとfloat64とstringのシャッフルに対応していて、 他の型をシャッフルしたい場合はインターフェースを実装してね、って感じです。 実装が簡単なので、インターフェース定義する手間とシャッフルのアルゴリズム自前で書く手間ほとんど一緒ではという気もするけど、 まあライブラリ作成の練習ってことで。
で、ここからが本題。 Fisher-Yates shuffleの名前は以前から知ってたけど、 この前某プロジェクトで以下のようなshuffleの実装を発見。
package main import &amp;#34;math/rand&amp;#34; func shuffle(a []int) { for i := range a { j := rand.Intn(i + 1) a[i], a[j] = a[j], a[i] } } Fisher-Yates shuffleと似ているけど、なにかが違う。 ちゃんとシャッフルされているのか気になったので検証してみました。
検証 n個の数列をシャッフルすることを考えます。 シャッフルの後i番目の要素がj番目に移動する確率を {% m %}P_n(i, j){% em %} と定義します(golangのコードにあわせて0-originで考えます)。
完全にランダムにシャッフルされていれば、 元の数列のどの要素も0からn-1の範囲に一様分布するはずです。 つまり、以下の式がなりたてば「シャッフルされている」と言えそうです。
{% math %} P_n(i, j) = \frac{1}{n}　(i, j = 0, \dots, n - 1) {% endmath %}</description>
    </item>
    
    <item>
      <title>社内ISUCONにチームぽわわ3.5で参加しました</title>
      <link>https://shogo82148.github.io/blog/2015/04/19/kayac-isucon/</link>
      <pubDate>Sun, 19 Apr 2015 19:12:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/04/19/kayac-isucon/</guid>
      <description>木曜日の社内ISUCONにチームぽわわ3.5として参加してきました。 (今年のISUCON本番に4にアップデート予定) さきに結果だけ書いておくと、 1位はfujiwaraさんとacidlemonさんのチーム、 2位はチームぽわわ3.5、 3位はぴっぴ先輩率いるチーム例の青い紐でした。
オムライスと紐を倒したので僕は満足です。 簡単にやったことを書いておきます。
課題内容 Twitterみたいな短文投稿サイトです。 トップページにアクセスすると全ユーザの発言最新100件がみれて、 ログインすると発言したり自分の投稿履歴を確認したりできます。 僕が新卒で入ってきたときはPerlでしたが、今年の参考実装はGolang製です。 (Rubyもあったらしいけど使った人いたのかな)
やったこと 僕自身は、相方になったたいがさんに「こんなことしてみては〜」と言ってみる係をやってました。 具体的な対応としては以下の通りです。
nginxにレスポンス吐かせる Nginxのレスポンスタイムをパーセンタイル値で計測するMunin plugin とかを参考にしてもらって、レスポンスタイムを吐くようにしてもらいました。
ログをテキトウスクリプトで集計したとろこ、トップページの全ユーザの発言最新100件みれるページが重いみたい。 高速化の第一ターゲットをトップページにしぼりました。
MySQLにSlowQuery吐かせる トップページが重いっぽいというのはわかったものの、 どのクエリが重いかまでは分からない(もちろんコード読んでたので検討はついてたけど)ので、 処理に0.1秒以上かかっているクエリを吐くようにしました。
インデックスの追加 既存のコードに触れずにお手軽ってことで、まずはDBにインデックスを張るところから。 workload10で、99583から101033にスコアアップ！ まあ、他のボトルネックを潰していない段階だとこんなもんでしょうね・・・。
ループクエリ・無駄クエリの削除 明らかに無駄クエリっぽいところがあったのでそこを修正しました。
 投稿100件取得したあとに、100回ユーザ名の取得処理をしている  JOINを使って書き換えました 実行計画が狂って逆に遅くなるという事態に陥ったので、IGNORE INDEXとかして頑張った   ユーザの投稿を全取得してるのに、最新1件の情報しか使ってないところ  LIMITをつけて制限   全投稿をCOUNTしているところ  せっかくGolang使ってるんだから楽しようと、グローバル変数に突っ込んでcount++してみた    「グローバル変数に突っ込んでみた」対策みたいに、下手にアプリサーバで情報を保持すると DBとアプリサーバに差ができてしまうので、実運用では避けるべきテクニックですね。 あとになって考えると、ベンチ回す前にアプリサーバの再起動忘れてたのにベンチ通ってたので、 投稿数数えなくてもよかったのでは・・・。
nginxによる静的ファイルの配信 cssとかjsをGolangでかえしていたので、nginxで返すようにしました。 これで724338から802905(workload:100)にScoreアップ！
画像の縮小 Twitterらしく投稿には100x100程度のサイズのアイコンが表示されるんですが、 元画像が1000x1000程度だったので縮小しました。 ただ、ベンチが画像にアクセスしにこないので、まったくの効果なし。 最終計測では結局元画像に戻しました。 実運用では確かに効果があると思うんですが、まずはログを見て判断しろという教訓ですね。
まとめ あとはworkloadの調整とかやって最終スコアは935519でした。 2位にはなったものの、インデックス追加とかループクエリの削除とか最低限のことが何とか出来たって感じです。 もっと精進します。
tech kayac へのポストまだかな〜</description>
    </item>
    
    <item>
      <title>Perlで文字列の出現回数を調べる</title>
      <link>https://shogo82148.github.io/blog/2015/04/09/count-substrings-in-perl/</link>
      <pubDate>Thu, 09 Apr 2015 23:28:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/04/09/count-substrings-in-perl/</guid>
      <description>Perlで特定の文字列の出現回数を調べたくなって、調べてみたメモ。
ググるとすぐに見つかった。 perlで指定文字列の出現回数を取得する(正規表現)
 指定文字列の出現回数は正規表現を使って
$count++ while($str =~ m/$pattern/g);
もしくは
$count = (() = $str =~ m/$pattern/g);
 が、一瞬何をやっているのか把握できない・・・。 こういう意味なのかなーって予想はしてみたけど、あってるか一応調査。
whileを使った方法 //g をスカラーコンテキストの中でマッチさせると、 前回マッチした場所を覚えておいてくれて、次のマッチでその場所から検索を再開してくれるらしい。 (Using regular expressions in Perl - perlretut) マッチした場所は pos で取得可能。
my $str = &amp;#34;hoge fuga foo bar&amp;#34;; while ($str =~ m/[a-z]+/g) { say pos $str; } whileを後置にして、ループの回数を数えるようにすれば、最初の方法になる。
ループを使わない方法 これが一番謎だった。
//g をリストコンテキストで評価すると、マッチした文字列がリストになって帰ってくるらしい。 (Quote-Like Operators - perlop)
複数の変数に一括して代入するときに ($foo, $bar) = (1, 2) みたいな書き方をするけど、 () = ... の部分はこれの代入先の変数が一個もないケース。 要するに「リストコンテキストで評価してね」という意味のイディオムみたい。</description>
    </item>
    
    <item>
      <title>名前付き引数とオプション引数とオーバーロードを同時に使うとUnityが死ぬ</title>
      <link>https://shogo82148.github.io/blog/2015/03/29/unity-internal-compiler-error/</link>
      <pubDate>Sun, 29 Mar 2015 12:13:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/03/29/unity-internal-compiler-error/</guid>
      <description>オーバーロードの優先順位付けが少しおかしくて、 名前付き引数とオプション引数と一緒に使うと死ぬ場合があるというお話。 ぴーちんが昨日言ってたやつ。 いんたーねっつにも乗っけておく。
問題となるのは以下のようなコード。
class MainClass { void Foo (int fuga) { } void Foo (string hoge, int fuga = 10) { } void Bar() { Foo (fuga: 20); } } このコードは以下のような例外を吐いて死ぬ。
Internal compiler error. See the console log for more information. output was: Unhandled Exception: Mono.CSharp.InternalErrorException: Internal error at Mono.CSharp.MethodGroupExpr.IsApplicable (Mono.CSharp.ResolveContext ec, Mono.CSharp.Arguments&amp;amp; arguments, Int32 arg_count, System.Reflection.MethodBase&amp;amp; method, System.Boolean&amp;amp; params_expanded_form) [0x00000] in &amp;lt;filename unknown&amp;gt;:0 at Mono.CSharp.MethodGroupExpr.OverloadResolve (Mono.CSharp.ResolveContext ec, Mono.</description>
    </item>
    
    <item>
      <title>travisがいつのまにやらcsharpをサポートしていた件</title>
      <link>https://shogo82148.github.io/blog/2015/03/29/travis-supports-csharp/</link>
      <pubDate>Sun, 29 Mar 2015 11:54:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/03/29/travis-supports-csharp/</guid>
      <description>いつもテスト実行でお世話になっているtravisさんがC#をサポートしていました。
以前から C#をサポートして欲しいという要望はあったのですが、 2014年12月あたりからついに使えるようになってたみたいです。
以前はC言語のフリをして、設定ファルで頑張ってmonoをインストールする必要があったのですが、
## Travis CI Integrationlanguage:cinstall:- sudo apt-get install mono-devel mono-gmcsscript:- xbuild hogehoge.sln今はlanguageにcsharpを設定して、solutionを指定するだけです。
## Travis CI Integrationlanguage:csharpsolution:hogehoge.slnMiniMeggagePack もこちらの設定を使うようにしてみました。
nunitを使ってテストする場合は結局sudo apt-get install nunit-consoleする必要があるみたいですが、 複数バージョンのmonoでテストできたりしていい感じです。 ただ、ドキュメントにはmono2.10.8もサポートしているとあるのにmonoのインストールが404で失敗したり、 他のバージョンでも時たまmonoのインストールにコケたり、 3.8.0でnunitのテストが上手く動かなかったり、不安定な感じがしてます。 徐々に改善していくといいなー。
参考  Building a C#, F#, or Visual Basic Project  </description>
    </item>
    
    <item>
      <title>git diffでcsvの差分を見やすく表示する</title>
      <link>https://shogo82148.github.io/blog/2015/03/24/git-diff-csv/</link>
      <pubDate>Tue, 24 Mar 2015 23:08:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/03/24/git-diff-csv/</guid>
      <description>ExcelやGoogle Spreadsheetを使って作ったデータをプログラムに取り込むのにcsv形式が便利でよく使っているんですが、 gitで履歴管理をしてもdiffが見づらい・・・。 gitのdiffがかなり自由にカスタマイズできることを知ったので、いろいろいじってみたメモ。
例として、以下のようなcsvファイルを編集することを考えます。
id,name,param_a,param_b,param_c,param_d,param_e 101,hoge,314,159,265,358,979 102,fuga,271,828,182,845,904 一行目は列の見出しになっていて、プログラムからは列番号ではなくparam_dの様に指定する、 という作りになってます。 id: 101の行のparam_dの数値に変更が入った場合、普通のgitだと以下のようになります。
diff --git a/hogehoge.csv b/hogehoge.csv index c8dbd17..37f4ff5 100644 --- a/hogehoge.csv +++ b/hogehoge.csv @@ -1,3 +1,3 @@ id,name,param_a,param_b,param_c,param_d,param_e -101,hoge,314,159,265,358,979 +101,hoge,314,159,265,359,979  102,fuga,271,828,182,845,904 二行目に何か変更があったことはわかりますが、 param_d だとはすぐにはわかりませんね・・・
YAMLに変換して比較する バイナリファイルであっても差分が確認できるよう、 git-diffを実行する前に変換ツールを実行する機能があります。 拡張子がcsvのファイルに対してこの機能が働くように.gitattributesに以下の行を足します。
*.csv diff=csv .git/config に変換ツールの設定を追加します。 key: valueの形式になっていると見やすそうなので、変換先の形式にはyamlを選びました。
[diff &amp;#34;csv&amp;#34;] textconv = csv2yaml ここで指定しているcsv2yamlは自前で用意する必要があります。 インターネット上をさまよえば同名のツールはいくらでもありそうですが、今回は自分でgoを使って書きました。 csv2yaml.goをコンパイルしてパスの通る場所においておきましょう。 csv2yamlは自分のよく使うcsvのフォーマットにあわせて以下のようなカスタマイズをしてあります。
 idという名前のキーを必ず最初にする それ以外のキーはアルファベット順にソートする  この状態でgit diffを実行すると以下のようになります。
diff --git a/hogehoge.csv b/hogehoge.csv index c8dbd17..37f4ff5 100644 --- a/hogehoge.csv +++ b/hogehoge.</description>
    </item>
    
    <item>
      <title>git で管理しているリポジトリの各ブランチの中身をそれぞれ個別のディレクトリにエクスポートする(git-archive版)</title>
      <link>https://shogo82148.github.io/blog/2015/03/20/git-pack-branch/</link>
      <pubDate>Fri, 20 Mar 2015 18:38:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/03/20/git-pack-branch/</guid>
      <description>git で管理しているリポジトリの各ブランチの中身をそれぞれ個別のディレクトリにエクスポートする を読んで、 git-archive を使うともう少しシンプルに書けるんじゃないかと思ってやってみた。
git branch | sed -e &amp;#39;s/^[\* ]*//g&amp;#39; | xargs -n1 -I% sh -c &amp;#39;git archive --prefix=%/ % | tar x&amp;#39; .gitconfig とかでエイリアスを設定しておくといいんじゃないでしょうか
以上</description>
    </item>
    
    <item>
      <title>map[string]Hoge or map[string]*Hoge ?</title>
      <link>https://shogo82148.github.io/blog/2015/02/22/should-i-use-a-pointer-in-go/</link>
      <pubDate>Sun, 22 Feb 2015 02:14:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/02/22/should-i-use-a-pointer-in-go/</guid>
      <description>Go言語でポインタを使うべきか使わないべきか問題。 「ケース・バイ・ケースなので、状況に応じて使い分けましょう！」という結論が出るのは目に見えているので、 具体例について検証してみた結果を書いておきます。
背景 他の人のコードレビューを見ていたら、 レビュアーが「コピーをしないで済むのでstructの受け渡しにはポインタ使ったほうがいいと思います！」とコメントしていて、 そうなのか？と思ったのですがあんまり自信がなかったので検証してみました。 コメントがついていたのは以下のようなコード。
package hoge import ( &amp;#34;strconv&amp;#34; ) type Hoge struct { A int B int C int } func NewHogeMapStruct() map[string]Hoge { m := make(map[string]Hoge) for i := 0; i &amp;lt; 10000; i++ { m[strconv.Itoa(i)] = Hoge{i, i, i} } return m } ポイントは以下の点です。
 受け渡すstructはintが3つ程度の小さなもの mapに入れて返す  benchmarkを使って検証する ポインタを使わない版と使う版を両方作ってベンチマークをとってみます。
package hoge import ( &amp;#34;strconv&amp;#34; ) type Hoge struct { A int B int C int } // ポインタ使わない版 func NewHogeMapStruct() map[string]Hoge { m := make(map[string]Hoge) for i := 0; i &amp;lt; 10000; i++ { m[strconv.</description>
    </item>
    
    <item>
      <title>GithubのIRCフックがgollumをサポートしました</title>
      <link>https://shogo82148.github.io/blog/2014/11/15/github-irc-hook-supports-gollum/</link>
      <pubDate>Sat, 15 Nov 2014 22:24:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2014/11/15/github-irc-hook-supports-gollum/</guid>
      <description>GithubのIRCフックがgollum(Wikiページの変更通知)をサポートしました。
最近ぴーちんさんがWikiの編集業に精を出していて、編集の度にIRCに「変更しました！」とポストしてました。 「自動で通知してくれるとうれしいよねー」と話していたら、ある秘密を教えてもらいました。
acidlemon: githubのwiki編集のIRC通知、ここに秘密が隠されています https://github.com/github/github-services/blob/master/lib/services/irc.rb acidlemon: Blameおして黄色い変なアイコンを調べれば何をすれば良いかわかるはず おや・・・何処かで見た黄色いアイコンが・・・
真似してgithub-servicesにプルリクエストをだしてマージしてもらった。 で、さっき対応イベント一覧見てたらgollum増えてる！ マージのときのコメントで「a few days」と言われたので2,3日かかるのかな？と思ってたけど、24時間経たないうちに反映されたよ！ 早い！！
さっそくGithub::Hooks::Managerを使って設定しておきました。 「[project-name] shogo82148 edited wiki page hogehoge」みたいに編集されたページが通知されます。
便利！！！
SEE ALSO  github-services github の irc hook に幾つかの event type が追加されました - @soh335 memo GithubのHookについてのまとめとソリューション - おそらくはそれさえも平凡な日々  </description>
    </item>
    
    <item>
      <title>Gitで作業ディレクトリの変更を破棄したのに差分が出続けて困った話その2</title>
      <link>https://shogo82148.github.io/blog/2014/10/21/git-case-sensitivity/</link>
      <pubDate>Tue, 21 Oct 2014 00:56:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2014/10/21/git-case-sensitivity/</guid>
      <description>先日「Gitで作業ディレクトリの変更を破棄したのに差分が出続けて困った話」と いうのを書きましたが、より強力な敵が現われました。 このときは文字コードが原因で git checkout -- &amp;lt;file&amp;gt; しても差分が残り続けるというもので、git add してコミットし直すことで回避出来ました。 しかし、今度の敵は git checkout -- &amp;lt;file&amp;gt; しても git add &amp;lt;file&amp;gt;しても差分が残り続けます。
なんだ・・・このボスを倒したら新たなラスボスが現れた感・・・
acidlemon先生の手助けにより事無きを得たのですが、 ちょっと不明な点もあったので、その点もあわせてメモを残しておきます。
症状 git checkout -- &amp;lt;file&amp;gt; しても、git add &amp;lt;file&amp;gt; しても、git reset --hard HEAD しても、 何をしても差分が出続ける・・・なんだこいつ・・・
$ git checkout -- AwesomeFeature $ git add . $ git status On branch master Changes not staged for commit: (use &amp;#34;git add &amp;lt;file&amp;gt;...&amp;#34; to update what will be committed) (use &amp;#34;git checkout -- &amp;lt;file&amp;gt;.</description>
    </item>
    
    <item>
      <title>Redis::Fast 0.13をリリースしました</title>
      <link>https://shogo82148.github.io/blog/2014/10/16/redis-fast-0-dot-13-released/</link>
      <pubDate>Thu, 16 Oct 2014 23:51:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2014/10/16/redis-fast-0-dot-13-released/</guid>
      <description>Redis::Fast 0.13をリリースしました。 主な変更点は以下のとおりです。
 passwordオプションの対応 maxclientsに達した場合に、deep recursion することがある問題の修正 トランザクション内で再接続処理が行われる問題の修正  passwordオプションの対応 今更感のある機能ですね。昔は対応してたんです。 対応してたんですが、Sentinel対応のために接続開始周りをごそっと入れ替えて、そのときに間違ってパスワード認証機能を削除しちゃってたっぽいです(・ω&amp;lt;) なんというかごめんなさい。
実際実装してテストしてみると、認証失敗したときにdouble freeで落ちてちょっとハマりました。 hiredisを使う場合はredisAsyncSetConnectCallbackに指定する関数内で、コネクションを切断するような処理(password認証とか)はしないようにしましょう。
maxclientsに達した場合に、deep recursion することがある問題の修正 Redis::Fastでは、接続処理の中で、コネクションに名前をつけたり、パスワード認証したり、その他独自の処理を実行しています。 この処理の途中でも再接続処理が走ってしまい、 再接続処理の中で再接続処理が実行されて、その再接続処理の中で再接続が&amp;hellip; というような無限ループに突入する場合があります。 maxclientsに達した場合、一度コネクションの確立に成功したあとに接続が切られるので、この無限ループに入ってしまうようです。
接続処理中は再接続処理を行わないようにすることで対応しました。
トランザクション内で再接続処理が行われる問題の修正 Redis::Fast 0.07以降、MULTI-EXECコマンドを遣ったトランザクションの中にいるときは再接続処理が行わないようになっています。 その仕組みを作るにあたって、トランザクションの中にいるか外にいるかを表すフラグをコマンド送信前に更新していました。
 再接続を禁止する MULTI コマンドを送る 結果を受け取る 必要なコマンド発行を行う 再接続を許可する EXECコマンドを実行する 結果を受け取る  しかしこれだと 5 と 6 の間で再接続が起こってしまいます。 EXECコマンドがまだ実行されていないので、ここはまだトランザクションの中ですね。
Redis::Fast 0.13ではフラグの更新はコマンドが成功したときに変更してあります。
 MULTIコマンドを送る 結果を受け取る 再接続を禁止する 必要なコマンド発行を行う EXECコマンドを実行する 結果を受け取る 再接続を許可する  これでトランザクション中に再接続処理が走ることは無いはずです。</description>
    </item>
    
    <item>
      <title>gitで作業ディレクトリの変更を破棄したのに差分が出続けて困った話</title>
      <link>https://shogo82148.github.io/blog/2014/10/04/gitattribute-eol-equals-crlf/</link>
      <pubDate>Sat, 04 Oct 2014 15:05:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2014/10/04/gitattribute-eol-equals-crlf/</guid>
      <description>gitで変更した覚えの無いファイルに差分が出ていたので、 作業ディレクトリの変更を破棄したのに、 git statusで差分が出続けて困ったのでメモ。
症状 gitではgit checkout -- &amp;lt;file&amp;gt; ってコマンドを叩くと、 作業ディレクトリの変更を破棄できます。
$ git checkout -- hoge.txt $ git status On branch master Changes not staged for commit: (use &amp;#34;git add &amp;lt;file&amp;gt;...&amp;#34; to update what will be committed) (use &amp;#34;git checkout -- &amp;lt;file&amp;gt;...&amp;#34; to discard changes in working directory) modified: hoge.txt しかし、差分が出続ける&amp;hellip; git checkout -- &amp;lt;file&amp;gt; ならさっきやったよ！
git reset --hard HEAD して全変更を破棄してもダメでした。
原因 .gitattributesに改行コードの指定があったからでした。
*.txt text=auto eol=crlf これが指定されていると、CRLFなファイルをコミットしようとしても、 レポジトリには改行コードがLFで保存されるようになる。
$ cat .</description>
    </item>
    
    <item>
      <title>ISUCON4にチームぽわわで参加しました</title>
      <link>https://shogo82148.github.io/blog/2014/10/03/isucon-powawa-4/</link>
      <pubDate>Fri, 03 Oct 2014 19:55:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2014/10/03/isucon-powawa-4/</guid>
      <description>遅くなりましたが、ISUCON4のレポートです。 まこぴーとchroneさんとともにチームぽわわで参加し、惨敗してきました。
2014-10-06 追記: 競技中に使ったレポジトリを公開しました。
事前準備  メンバー三人で集まって、去年のnopasteアプリで練習  chroneさんは初参戦なので雰囲気を掴んでもらう   Ansibleを使っていこうっていう話になったので、プレイブックを書いて遊んでみる githubにprivate repositoryを予め建てる  PayPalに対応してるっぽいので、ログインを試みるも何故か失敗 諦めてクレカ情報を直接入力 どうなってるんですかgithubさん！！！    競技 10時くらいまで  お題確認 サーバのセットアップはchroneさんにお願いしスムーズにできた サーバは人数分準備  僕がコミット＆実行確認をこまめに繰り返すタイプなので、書いたコードはすぐにデプロイしてテストに回したい！！ サーバ一台だとインフラの調整とアプリの確認がかぶって面倒 かといってローカルで同じ環境用意するのも面倒 AMIがあるならそれを使っちゃえ！(って記事を去年見た気がしたので)   密かにUkigumoで自動デプロイする仕組みを作っておいた  書いたコードはすぐにデプロイしてテストに回したい！！ あらかじめukigumo-agentを起動 github-hookを設定してコミットしたら実行 Github::Hooks::Receiverいじってたのはこれやるためだったんだけど、Ukigumoさんで十分でした。便利ですね！！ 去年はサーバに入って作業する人(まこぴー)がかなり忙しそうだったので、なんとか解消したかった    お昼くらいまで  nginxで静的ファイル配信とかMySQLのクエリ分析とか いっちーさんは早速Redis::Fastに手を付ける  みんなもRedis::Fast使ってね！！   あとUkigumoさんのおもり  UkigumoとAnsibleのお陰で僕が何もしなくても、まこぴー氏が「nginxで静的ファイル配信したよ！」って言って数分後には確認できる状態になっていて便利 これのおかげでページが真っ白になっているのに気がつく 普通に設定を書き換えるとMIMEの設定がなくなるらしい Ukigumo++    14時くらいまで  chroneさんにMySQLのクエリ改善  COUNT() している部分を一行SELECTだけにする修正とか   一部Redis::Fastに書き換えた版も一応スコアでる アプリが単純すぎてMySQLでもRedisでも大差ないスコア 自分の環境でmy.</description>
    </item>
    
    <item>
      <title>Github::Hooks::ReceiverがX-Hub-Signatureをサポートしました</title>
      <link>https://shogo82148.github.io/blog/2014/09/23/github-hooks-receiver-supports-x-hub-signature/</link>
      <pubDate>Tue, 23 Sep 2014 00:25:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2014/09/23/github-hooks-receiver-supports-x-hub-signature/</guid>
      <description>Github::Hooks::ReceiverにX-Hub-SignatureをサポートするPull Requestを送ったら、 速攻取り込まれ、さらにGithubのコミット権とPAUSEのco-maintパーミッションをもらったというお話。
X-Hub-Signature GithubのWebhookは大変便利なんですが、特に対策をしないままだと 他の人にcurlとかで叩かれてしまう可能性があります。 本来であればIPアドレスで制限をかけるべきなんですが、 iptablesの設定とかよくわからないし・・・と思ってGithubのドキュメントを読んでいたら、 もっとお手軽な方法発見。
 Securing your webhooks  GithubからのリクエストにはX-Hub-Signatureというのがついていて、 これを使うとPayloadの検証ができるらしい。 Github::Hooks::Receiverは このヘッダを全くみていないようだったのでPull Requestを送ってみた。
Github::Hooks::Receiver 0.02以降で、以下のようにsecretの指定ができるようになります。
use Github::Hooks::Receiver::Declare; my $receiver = receiver { secret &amp;#39;secret1234&amp;#39;; # Webhookの設定画面のsecretの項目と同じものを入力 on push =&amp;gt; sub { # レポジトリにPushされた時の処理とかをゴニョゴニョ書く }; }; my $psgi = $receiver-&amp;gt;to_app; $receiver-&amp;gt;run; これでsecretを知らない人がリクエストを偽装できなくなるので安心です。 secretはエントロピーが高いほうがいいので ruby -rsecurerandom -e &#39;puts SecureRandom.hex(20)&#39; みたいなコマンド使うといいらしいですよ。
String::Compare::ConstantTime Signatureの比較にはRubyのsecure_compareのような関数を 使ったほうがいいらしい。 Github::Hooks::Receiverでは、そのPerl版のString::Compare::ConstantTimeを使ってみた。 ちょっと引数のチェックに甘いところがあって、segmentation fault場合があったので、こちらにもPull Requestを送っておきました。 Github::Hooks::Receiverは使う前にチェックを入れてあるので、現行バージョンでも問題なく動くはず。
String::Compare::ConstantTimeはXSで書かれたモジュールなんですが、 この手のバグが入り込みやすいのでXS難しいですね。
まとめ  XS怖い Github::Hooks::Receiverにsecretを指定できるようになったので、IP制限がかけられない場合でも安心 でも、可能であればIP制限もしましょうね XS怖い  追記 IP制限について Songmu先生よりコメントをいただきました。</description>
    </item>
    
    <item>
      <title>Githubさんにpack exceeds maximum allowed sizeって言われた</title>
      <link>https://shogo82148.github.io/blog/2014/09/13/github-remote-push-pack-size-exceeded/</link>
      <pubDate>Sat, 13 Sep 2014 10:51:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2014/09/13/github-remote-push-pack-size-exceeded/</guid>
      <description>Githubに手元のレポジトリをpushしようとしたら、 「Pushできないよ！！」って言われたときのメモ。
コミット数が17kほどあって、画像とかサイズが比較的大きいファイルがたくさんあるレポジトリを、 一度に全部pushしようとしたら「制限を超えてます」って言われてダメだった。
$ git push origin master Counting objects: 280874, done. Delta compression using up to 4 threads. Compressing objects: 100% (60497/60497), done. remote: fatal: pack exceeds maximum allowed size error: pack-objects died of signal 13 error: failed to push some refs to &amp;#39;git@github.com:***/****.git&amp;#39; ググってみると、おんなじような症状が見つかった。
 Github remote push pack size exceeded  リモートへのPushはオブジェクトを全部一つにPackしてしまうので、 一度に大量のコミットをPushしようとすると制限に引っかかるらしい。 (そして、サイズを制限する方法はないみたい)
解決策は「2回以上に分けてPushしてね」とのこと
git push remoteB &amp;lt;some previous commit on master&amp;gt;:master ... git push remoteB &amp;lt;some previous commit after the last one&amp;gt;:master git push remoteB master 頑張ってコミットログを遡ってコミットハッシュを調べるのはつらかったので、 打ってあったタグからコミットハッシュを調べてPushした。</description>
    </item>
    
    <item>
      <title>秘密鍵から公開鍵をつくる</title>
      <link>https://shogo82148.github.io/blog/2014/09/03/get-public-key/</link>
      <pubDate>Wed, 03 Sep 2014 13:40:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2014/09/03/get-public-key/</guid>
      <description>githubに公開鍵を登録しようと思ったけど、 手元に秘密鍵しかなくて困った時のメモ。
ssh-keygenを使うとできます。
# 秘密鍵を読み込んで公開鍵を出力する ssh-keygen -y -f ~/.ssh/id_rsa この公開鍵って登録したっけ？ ってときには以下のコマンドでフィンガープリントを確認できます。
# 公開鍵のフィンガープリントを取得する ssh-keygen -l -f ~/.ssh/id_rsa.pub </description>
    </item>
    
    <item>
      <title>YAPC::Asia 2014 に行ってきた #yapcasia</title>
      <link>https://shogo82148.github.io/blog/2014/08/31/yapcasia/</link>
      <pubDate>Sun, 31 Aug 2014 16:02:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2014/08/31/yapcasia/</guid>
      <description>YAPC::Asia 2014 に参加してきました。 「ブログに書くまでがYAPC」らしいので、メモ書き。
見たトーク   Perl meets Real World 〜ハードウェアと恋に落ちるPerlの使い方〜
 デモ中のURLが「localhost」になってたんであれ？って思ったんですが、WebサーバはPC上にあったんですね。RaspberryPi上でPerl動くんじゃなかったんですか！ ネギ振りミククラウド化するって言ってたんで期待してます    Go For Perl Mongers
  お待たせしました。Perl で BDD を簡単に実践する最高にクールなフレームワークができました
  DBIx::Class - what is it and what is it good for?
 HashRefInflatorの存在を初めて知りました 今関わってるプロジェクトでDBICのRowObject生成コストが問題になってるんで、後で試してみたいです    Scala In Perl Company : Hatena
  WHERE狙いのキー、ORDER BY狙いのキー
  Get a kick out of CPAN
  初心者が Web エンジニアのコミュニティに触れてみて感じたこと - ゆとりエンジニアの成長戦略</description>
    </item>
    
    <item>
      <title>PerlのXS中に起きたシグナルの扱い</title>
      <link>https://shogo82148.github.io/blog/2014/07/05/signal-in-xs/</link>
      <pubDate>Sat, 05 Jul 2014 11:56:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2014/07/05/signal-in-xs/</guid>
      <description>Redis::Fast にIssueが来ていたので、 それに関して調査したお話です。
 接続タイムアウトすると double free check に引っかかる brpop みたいな長時間ブロックするコマンド中にシグナルが入ると、最初の1回が無視される  前者はC言語つらいって話で頑張って double free になる条件を探せばいいんですが、 後者はシグナル時のPerlやPOSIX APIの挙動を知らなくと解決できなそう。 そういうわけで、主に後者について調べた結果をまとめておきます。
PERL_ASYNC_CHECKってXS中から呼んでもいいの？ 言いたいことは最初に書いとけって偉い人に言われたので、最初にこの記事の結論を。 「よしななタイミングでPERL_ASYNC_CHECKを呼べばいいっぽい」みたいです。 でも、 ** 「PERL_ASYNC_CHECKってXS中から呼んでもいいの？」 ** という点に確証が持ててないので、 識者のご意見を募集してます！
selectの挙動を調べる Redis::FastはRedisからのレスポンスを待つのにLinuxのselect apiを叩いてます。 ファイルとかが読み書き可能になるまで処理をブロックしてくれるいいやつです。 しかし、select が処理をブロックしている間にシグナルを受信すると、うまく処理ができてないらしい。 そこで割り込み発生時の挙動を確認してみます。
困った時のmanページ(select) をちゃんと読めば書いてありますね。
 エラーならば -1 を返し、 errno にエラーを示す値が設定される;
EINTR シグナルを受信した。
 Redis::Fastはerrnoを特に確認せず、とにかくエラーが発生したらリトライになってたのでダメだったみたいです。 通信にエラーが起きたわけではないので、再接続処理とかみたいな複雑なリトライ処理は必要なく、 単にもう一度selectしなおせば良さそうです。
Perlさんのシグナル処理のタイミング 「割り込みかかったら再度select」っていうふうに修正してみたんですが、 今度はPerlのシグナルハンドラがなかなか呼び出されない！！
use Redis::Fast; $SIG{TERM}= sub { warn &amp;#34;TERM handler called&amp;#34;; }; my $c =-&amp;gt;new(reconnect=&amp;gt;2, every =&amp;gt; 100, server =&amp;gt; &amp;#34;localhost:6379&amp;#34;); $c-&amp;gt;brpop(&amp;#34;a&amp;#34;, 100); # 100秒経ったら諦めて戻ってくる このコードを実行中にSIGTERMを送ると、送った瞬間に&amp;quot;TERM handler called&amp;quot;と表示されて欲しいのですが、 brpopコマンドが終わるまで実行されない……</description>
    </item>
    
    <item>
      <title>IRCに癒やしボットを入れてみた</title>
      <link>https://shogo82148.github.io/blog/2014/06/04/irc-healing-bot/</link>
      <pubDate>Wed, 04 Jun 2014 07:37:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2014/06/04/irc-healing-bot/</guid>
      <description>別チームがIRCに癒やしボットを入れてたので、自分のチームのチャンネルにも入れてみた。
Instagramに登録する InstagramのDeveloperサイトに開発者として登録します。 Authentication のページを見ながら、Server-side (Explicit) Flow を参考にアクセストークンを取得します。
Instagram APIを叩く https://api.instagram.com/v1/tags/$TAGNAME/media/recent?access_token=YOUR_ACCESS_TOKENを叩くと TAGNAMEに関連する画像の情報がJSONで帰ってくるので、 Perlからこのエンドポイントを叩きます。 IRCとのやりとりにはUnazuSanを使いました。
!/usr/bin/env perl use 5.014; use warnings; use strict; use utf8; use Encode qw/encode_utf8/; use Furl; use JSON; use UnazuSan; sub neko { state $data = undef; state $time = 0; if( !$data || time - $time &amp;gt; 60 * 60) { $time = time; my $furl = Furl-&amp;gt;new; my $res = $furl-&amp;gt;get(&amp;#39;https://api.instagram.com/v1/tags/%E7%8C%AB/media/recent?access_token=YOUR_ACCESS_TOKEN&amp;#39;); my $hash = JSON::decode_json($res-&amp;gt;content); $data = $hash-&amp;gt;{data}; } my $media = $data-&amp;gt;[rand(scalar @$data)]; return $media-&amp;gt;{images}{standard_resolution}{url}; } my $unazu_san; my $NICKNAME = &amp;#39;iyashi&amp;#39;; $unazu_san = UnazuSan-&amp;gt;new( host =&amp;gt; &amp;#39;127.</description>
    </item>
    
    <item>
      <title>キレイになったコトバとハートを元に戻すツール作った</title>
      <link>https://shogo82148.github.io/blog/2014/06/01/anti-sizukatter/</link>
      <pubDate>Sun, 01 Jun 2014 00:24:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2014/06/01/anti-sizukatter/</guid>
      <description>現実世界にご満足の方消えてなくなってほしいの！！！
しずかったーを使うと個性あふれるコトバを使ってもキレイにしてくれるので とっても便利ですね！ でも、本当は何を言っているのか真意を知りたい・・・。
そんな人のために、キレイになったコトバとハートを元に戻す アンチしずかったー を作りました。
仕組み しずかったーは単純な文字列置換で動いているみたいなので、 対応表を頑張って作りました。 それをMeCab用の辞書に変換し、 Igoを使ってバイナリ辞書に変換、 igo-javascriptでブラ失礼しちゃう上で解析できるようにしました。
既知の問題点 しずかったー前後の文脈関係なく変換しちゃうので、 同音異義語は元に戻らないことがあります。 特にひらがな・カタカナは失敗することが多いです。(「（お昼寝したい）ふわふわ」だとか「ブラ失礼しちゃう」だとか)
あと、マシュマロ的な内緒の言葉はさすがのしずかちゃんでも代替表現が思いつかなかったらしく、 全部ハートになってしまいます。 元に戻せと言う方が頑張ればなんとかできそうなので期待しないでく時代が変わればかっこいい。
まとめ またおもしろいものを作ってしまいましたが、 igo-javascriptのバグを発見できたりしたので、いいのです。
自宅警備員でお時間ある方の皆様、天才だと思ったらぜひおしゃべり広場や「いいね！」広場で共有をお願いします。</description>
    </item>
    
    <item>
      <title>C#のconditional Attributeのコンパイル結果を見てみる</title>
      <link>https://shogo82148.github.io/blog/2014/05/29/conditional-attribute/</link>
      <pubDate>Thu, 29 May 2014 19:20:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2014/05/29/conditional-attribute/</guid>
      <description>C#で「ある環境では関数の定義ごと消したい」みたいな要件があって、 そういう用途にconditinal attributeが使えるのかなーと話題のあがったので、実際に確認してみました。
結論から言えばできないのですが、せっかく調べたのでメモとして残しておきます。
conditional attribute 「デバッグ時のみにしか実行して欲しくない関数」みたいなものを定義するための機能です。
using System; using System.IO; using System.Diagnostics; namespace ConditionalAttributeTest { class MainClass { public static void Main (string[] args) { Log(&amp;#34;fugu&amp;#34;); } [ConditionalAttribute(&amp;#34;DEBUG&amp;#34;)] public static void Log(string message) { Console.WriteLine(message); } } } こんなふうに書いておくと DEBUG シンボルが定義されている時にだけLogの呼び出しが行われます。
&amp;gt; mcs -d:DEBUG ConditionalAttributeTest.cs &amp;gt; mono ConditionalAttributeTest fugu &amp;gt; mcs ConditionalAttributeTest.cs &amp;gt; mono ConditionalAttributeTest 逆アセンブルしてみる DEBUG付きでコンパイルした結果を逆アセンブルしてみます。
// ...前略 // method line 2 .method public static hidebysig default void Main (string[] args) cil managed { // Method begins at RVA 0x2058 .</description>
    </item>
    
    <item>
      <title>初期化なしのusing文ってOK？</title>
      <link>https://shogo82148.github.io/blog/2014/05/27/using-statement-without-instantiating/</link>
      <pubDate>Tue, 27 May 2014 13:48:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2014/05/27/using-statement-without-instantiating/</guid>
      <description>C# の using ステートメント、普通は変数の初期化とか new とかをまとめてやるものだと思ってたんですが、 某プロジェクトでusing文をこんな感じで使っているのを見かけました。
var hoge = new Hoge(); using(hoge) { // using( var hoge = new Hoge() ) { ならよく見る  ... } 見慣れない書き方だったので、本当にリソース解放が行われているのか不安・・・。 リソース解放が行われているのか調べてみました。
まずは結論  リソース解放自体は行われているので、ちゃんと書いてあれば問題なし しかしエラーをコンパイル時に見つけられない場合があるので非推奨  逆アセンブルして調べてみた コンパイル結果見ればちゃんとリソース解放されているかわかるよね！ ってことでバイナリを逆アセンブルして調べてみました。
サンプルコード 検証に使ったのはこんなコード。
using System; using System.IO; namespace UsingTest { class MainClass { public static void Main (string[] args) { var sr = new StreamReader (&amp;#34;hoge.txt&amp;#34;); Console.WriteLine (&amp;#34;Hoge: {0}&amp;#34;, sr.ReadLine ()); } } } 僕はMac使いに転向したので、Monoを使います。 mcsを使ってコンパイル、monodis ってのを使うとILを見れるらしいです。 Windowsだったら .</description>
    </item>
    
    <item>
      <title>C# でお手軽にMessagePack解析！</title>
      <link>https://shogo82148.github.io/blog/2014/05/25/mini-message-pack/</link>
      <pubDate>Sun, 25 May 2014 01:38:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2014/05/25/mini-message-pack/</guid>
      <description>MiniMessagePack.csってのを作った。 C#のプロジェクトにファイルひとつ導入するだけで、お手軽にMessagePackの解析ができます。
なんで作ったの？ MiniJSON の置き換えが目的です。 とあるUnityプロジェクトでMB単位のJSONをパースする箇所があってですね・・・ パースにはMiniJSONを使っているのですが、さすがに対象がでかすぎて重たい。 そこでMessagePackへの置き換えを検討してみたわけです。
もちろん C# で動く MessagePack のパーサはすでにあって、 messagepack-cliとかmessagepack-unityとか見つけました。 しかし、Unityのちょっと古いMonoで動かすためにちょっとゴニョゴニョしないといけなかったり、 MiniJSON との互換性を取るためにもゴニョゴニョしないといけなかったり(実際やってみたらキャストが大量に失敗して辛かった・・・)、 今回の用途にはちょっと高機能かなーと思ったので作っちゃいました！
つかいかた デコードする byteの配列を渡すとパースして返してくれます。 配列はList&amp;lt;object&amp;gt;で、マップはDictionary&amp;lt;string, object&amp;gt;になります。
using MiniMessagePack; // it means {&amp;#34;compact&amp;#34;:true,&amp;#34;schema&amp;#34;:0} in JSON var msgpack = new byte[] { 0x82, 0xa7, 0x63, 0x6f, 0x6d, 0x70, 0x61, 0x63, 0x74, 0xc3, 0xa6, 0x73, 0x63, 0x68, 0x65, 0x6d, 0x61, 0x00 }; var packer = new MiniMessagePacker (); object unpacked_data = packer.Unpack (msgpack); /* unpacked_data = new Dictionary&amp;lt;string, object&amp;gt; { { &amp;#34;compact&amp;#34;, true }, { &amp;#34;schema&amp;#34;, 0}, }; */ エンコードする オブジェクトを渡すと MessagePack にエンコードして返してくれます。</description>
    </item>
    
    <item>
      <title>travis-ciでC&#43;&#43;11のテストをする</title>
      <link>https://shogo82148.github.io/blog/2014/05/22/use-cpp11-in-travis/</link>
      <pubDate>Thu, 22 May 2014 23:34:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2014/05/22/use-cpp11-in-travis/</guid>
      <description>今 C++ を書くなら C++11 だよね！と言うわけでC++11の新機能を使ってコードを書いたので、 travis-cliでテストしたらFAIL。
$ g++ -std=gnu++0x hogehoge.cpp sorry, unimplemented: non-static data member initializers unimplemented・・・だと・・・。
頑張って動かしてみたのでメモ。
autoconf の設定をする autotoolsを使っていたので、 C++11 に対応しているかのチェックを追加しておきます。
ax_cxx_compile_stdcxx_11.m4をダウンロードし、 configure.ac でm4ファイルをダウンロードするようにしておきます。
m4_include([m4/ax_cxx_compile_stdcxx_11.m4]) AX_CXX_COMPILE_STDCXX_11 AC_LANG([C++]) travis.yaml を設定する ぐぐったらstackoverflowでやり方を見つけました。 標準でテストに使われるコンパイラは古いようなので、新しいバージョンのものをインストールするように設定します。
language: cpp compiler: - clang - gcc before_install: # g++4.8.1 - if [ &amp;#34;$CXX&amp;#34; == &amp;#34;g++&amp;#34; ]; then sudo add-apt-repository -y ppa:ubuntu-toolchain-r/test; fi # clang 3.4 - if [ &amp;#34;$CXX&amp;#34; == &amp;#34;clang++&amp;#34; ]; then sudo add-apt-repository -y ppa:h-rayflood/llvm; fi - sudo apt-get update -qq install: # g++4.</description>
    </item>
    
    <item>
      <title>Google Test を使ってC&#43;&#43;のテストしてみた</title>
      <link>https://shogo82148.github.io/blog/2014/05/18/test-with-google-test/</link>
      <pubDate>Sun, 18 May 2014 21:24:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2014/05/18/test-with-google-test/</guid>
      <description>C++ なライブラリを書こうと思い、C++のテストってどうやるんだろうと調べたメモ。 テストフレームワークとして Google C++ Testing Framework を使用、 コンパイルにはautotoolを使ってtravis-ciでテストするところまでやってみました。
やってみた結果→ cpp-test
Testを書く Google Test の入門ガイドに書いてあったテストをコピペしてきました。
#include &amp;#34;gtest/gtest.h&amp;#34; int Factorial(int n); TEST(FractionTest, hoge) { EXPECT_EQ(1, Factorial(1)); EXPECT_EQ(2, Factorial(2)); EXPECT_EQ(6, Factorial(3)); EXPECT_EQ(40320, Factorial(8)); } テストの対象となる関数はこちら。
// calculate 1 * 2 * 3 * ... * n int Factorial(int n) { if(n == 0) return 1; return n * Factorial(n - 1); } テスト用実行ファイルのビルドをする せっかくならしっかりしたものをつくろうと、Autotoolsを使ってビルドしてみました。 新しめの Autotools (Autoconf&amp;amp;Automake) を使ってみよう を参考に Makefileのひな形を書いていきます。
Google Test と Travice CI で、C言語で書いたライブラリの継続的インテグレーションをしてみた結果 ではGoogle Testをシステムにインストールしていますが、 システムへのインストールは推奨されていないのと、手元で動かすのが面倒だったので Fused Source File を作ってGoogle Testを自分のプロジェクトに同梱しちゃいました。</description>
    </item>
    
    <item>
      <title>Redis::Fast 0.07 をリリースしました！</title>
      <link>https://shogo82148.github.io/blog/2014/05/17/redis-fast-0-dot-07-released/</link>
      <pubDate>Sat, 17 May 2014 16:27:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2014/05/17/redis-fast-0-dot-07-released/</guid>
      <description>Redis::Fast 0.07 をリリースしました。 現時点での最新バージョンである Redis.pm 1.974 とコンパチブルになります。
主な修正点は以下の通りです
 Redis Sentinel 対応 トランザクション内での再接続禁止 再接続にDB選択し直し  Redis Sentinel 対応 Redis Sentinel というのは自動フェールオーバーの仕組みらしいです。 (ソースはコピペしたきただけで仕組みはあまり理解していない) どんなものかは本家ドキュメントや実際に検証してみた人の記事をご参照ください。
 Redis Sentinel Documentation Redis 2.8 の Sentinel の動きを検証してみた Redis Sentinelを動かしてみた  前から移植作業は進めてたのですが、本家 Redis.pm でもテストがコケたりしてちょっと不安だったのでリリースを見送ってました。 今日 Redis.pm の安定版がリリースされたのでこっちも追従しますよ！！
コネクションを作るときに sentinels を渡すと Redis Sentinel から接続情報を取ってきてくれます。 一緒に reconnect を設定しておいてあげると、Masterに何かあった時に接続情報を再取得→ 自動的に Slave へフェールオーバーしてくれます。
use Redis::Fast; my $redis = Redis::Fast-&amp;gt;new( sentinels =&amp;gt; [ &amp;#39;127.0.0.1:26379&amp;#39; ], service =&amp;gt; &amp;#39;mymaster&amp;#39;, reconnect =&amp;gt; 1, ); トランザクション内での再接続禁止 Redisにも簡単なトランザクション機能があって、 複数の命令を同時に実行することができます。 トランザクション中に再接続が発生するとトランザクションがリセットされてしまうので、 接続前の命令を再投入する必要があるのですが、Redis.</description>
    </item>
    
    <item>
      <title>Androidのバイナリファイルを解析するgoのライブラリ</title>
      <link>https://shogo82148.github.io/blog/2014/05/07/androidbinary/</link>
      <pubDate>Wed, 07 May 2014 13:29:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2014/05/07/androidbinary/</guid>
      <description>Androidのアプリの実態はzipファイルなのでunzipすれば簡単に中身を見ることができるわけですが、 開いてもバイナリファイルが入っているだけでよくわかりません。 AndroidSDKに付属しているaaptというツールを使えば読めるんだけどインストールが大変で苦しんでいる人がいたので、 お手軽に解析できるgolangのライブラリを書いてみました。
使い方 go getしてくる githubのレポジトリ からダウンロードしてきます。
go get github.com/shogo82148/androidbinary AndroidManifest.xmlを解析する io.ReaderAtインターフェースを満たすオブジェクトをandroidbinary.NewXMLFileに渡すと解析してくれます。
f, _ := os.Open(&amp;#34;AndroidManifest.xml&amp;#34;) xmlFile, _ := androidbinary.NewXMLFile(f) reader := xmlFile.Reader() // reader を読むと普通のXMLファイルとして読める resources.arscを解析する アプリ名などの設定はAndroidManifest.xmlには直接書かれておらず、 リソースファイルに書いてあることがほとんどです(開発者がよほどものぐさでなければ)。 リソースの情報はapk内のresources.arscに書かれているので、 このファイルを読む機能もついてます。
f, _ := os.Open(&amp;#34;resources.arsc&amp;#34;) tableFile, _ := androidbinary.NewTableFile(f) // ID 0x7F040000 に対応するリソースを読む config := &amp;amp;androidbinary.ResTableConfig{} val, _ := tableFile.GetResource(androidbinary.ResId(0x7f040000), config) アプリ名はロケールによって変わったりするので、 configで設定できます。 例えば日本語の名前を取得したい場合はこんな感じ。
// ID 0x7F040000 に対応するリソース(日本語)を読む config := &amp;amp;androidbinary.ResTableConfig{} config.Language[0] = &amp;#39;j&amp;#39; config.Language[1] = &amp;#39;a&amp;#39; val, _ := tableFile.</description>
    </item>
    
    <item>
      <title>Tweepyの2.3.0が出ました</title>
      <link>https://shogo82148.github.io/blog/2014/04/27/tweepy-2-dot-3-0-released/</link>
      <pubDate>Sun, 27 Apr 2014 21:51:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2014/04/27/tweepy-2-dot-3-0-released/</guid>
      <description>Tweepyの2.3.0が出ました。 「Tweepy が Application-only Authentication に対応します」僕のprも取り込まれていて、 Application-only Authentication が標準で使えるようになりました。 というわけで、早速遊んでみます。
Application-only Authenticationで遊ぶ 使い方は「tweepyでApplication-only Authenticationしてみた」のときとほぼ同じ。 Tweepy本体に取り込んでもらったので、名前空間がちょこっと変わったくらいです。 Consumer Key と Consumer Secretだけ設定すればいいので、簡単に使えます。
#!/usr/bin/env python # -*- coding: utf-8 -*- import tweepy import codecs import sys sys.stdin = codecs.getreader(&amp;#39;utf-8&amp;#39;)(sys.stdin) sys.stdout = codecs.getwriter(&amp;#39;utf-8&amp;#39;)(sys.stdout) CONSUMER_KEY = &amp;#39;YOUR CONSUMER KEY&amp;#39; CONSUMER_SECRET = &amp;#39;YOUR CONSUMER SECRET&amp;#39; def main(): user_id = &amp;#34;JO_RI&amp;#34; auth = tweepy.AppAuthHandler(CONSUMER_KEY, CONSUMER_SECRET) api = tweepy.API(auth) arg = {&amp;#39;id&amp;#39;: user_id, &amp;#39;include_rts&amp;#39;: 1} user_statuses = tweepy.Cursor(api.user_timeline, **arg).</description>
    </item>
    
    <item>
      <title>Tweepy が Application-only authentication に対応します</title>
      <link>https://shogo82148.github.io/blog/2014/04/18/tweepy-will-application-only-auth/</link>
      <pubDate>Fri, 18 Apr 2014 06:37:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2014/04/18/tweepy-will-application-only-auth/</guid>
      <description>以前 「tweepyでApplication-only Authenticationしてみた」で 書いたTweepyのAuthHandlerを本体に取り込んでもらいました。 リリースタイミングとかよくわかってないですが、次のリリースとかでApplication-only Authenticationを簡単に使えるようになります、たぶん。
(2014-04-27追記) このprを取り込んだTweepy 2.3.0がリリースされました。早速遊んでみたのでこちらもどうぞ&amp;gt;Tweepyの2.3.0が出ました
取り込まれるまでの経緯  「Application-only Authentication 対応しないの？」って質問は去年からあった(tweepy#318) 先日「ここに動くコード載ってるよ」と僕の記事が紹介される 昨日の夕方「コントリビュートしてみない？」とブログやgithub経由で頼まれる やるしか無い！と思って昨日のうちにpr作成 朝起きたら取り込まれてた  日本語なんてマイナーな言語で記事が書いてあっても、読んでくれる人は読んでくれるんですね。 Tweepy は僕も何度か使ったことがあるので Issue とかみて開発状況をチェックしていたんですが、 見覚えのある名前が見えたときはびっくりしました。
ちょっとしたコードでも公開しておくといいことがあるよ、というお話でした。 最近ここも全然更新してないので、もっとアウトプットしていかないと・・・。</description>
    </item>
    
    <item>
      <title>スパコンで約2時間36分かかったという、5×5の魔方陣の全解列挙を、おねえさんのコンピュータで試す</title>
      <link>https://shogo82148.github.io/blog/2014/03/19/letscount-magic-square/</link>
      <pubDate>Wed, 19 Mar 2014 18:26:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2014/03/19/letscount-magic-square/</guid>
      <description>高校生がスパコンを使って5x5の魔方陣の全解を求めたというニュースをきっかけに、 魔方陣の全解列挙が流行っているようです。
 高校生がスーパーコンピュータを使って5×5魔方陣の全解を求めることに成功(筑波大プレスリリース) スパコンで約2時間36分かかったという、5×5の魔方陣の全解列挙を、パソコンで試す（C++）  「全解列挙」「数え上げ」「組み合わせ爆発」・・・そして整然とならんだこのマス目・・・ あのおねえさんを思い出しますね。
と、いうわけで、「おねえさんのコンピュータ」の魔方陣版を作ってみました。
 おねえさんのコンピュータ(魔方陣編)  「全解列挙をパソコンで試す」の記事と同じような感じで、頭の悪いコードをずらずらと書いてあります。 以下の様な特徴があります。
 マスを埋める順番はスパコンで求めたものをベース  ただし、対称な位置にあるマスを優先(反転・回転の検索を早い段階で打ち切るため)   asm.js による最適化！  firefoxで特に高速に動作します わかってはいたけど、asm.jsは人間の書くものではない   WebWorkerを使った並列計算  実はまだ5x5の計算結果を見てないのですが、 途中までの計算スピードから推測すると十数時間程度で計算が終わるかと・・・。 (Mac Book Air Mid 2012, 4並列)
コンパイルの手間が無いのでお手軽に試せます。 もっと速いマシンでやればすぐに結果がでてくると思うので、みなさんのレポートお待ちしています。</description>
    </item>
    
    <item>
      <title>githubのタブサイズを変えるChrome拡張を作った</title>
      <link>https://shogo82148.github.io/blog/2014/02/10/github-tab-change/</link>
      <pubDate>Mon, 10 Feb 2014 08:01:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2014/02/10/github-tab-change/</guid>
      <description>にゃんぱすー。 最近 C# のコードを見ることが多くなってきました。 開発はVSやMonoDevelop等のIDEを使っているのですが、 diffの確認程度ならgithub上で行っています。 しかし、github上の表示は崩れて非常に読みづらい・・・。
githubのコードプレビューはタブストップが8文字幅で表示されます。 しかし、有名ドコロのIDEはデフォルトがタブインデント、4文字幅で設定されているので、 どうしても表示が狂ってしまいます。 タブインデントではなくスペースインデントを使えば解決☆ なのですが、スペースインデントの中にタブインデントを混入する場合が多々あるので、僕は疲れました・・・。 混在したときのコードなんて、読めたものじゃないですよ。
そこで、githubのタブサイズを変更する Chrome拡張を作ってみました。 ユーザスタイルシートでもできるんですが、まあ、勉強を兼ねて。
 GithubTabChange  インストール後、github上のレポジトリを開くと≡みたいなマークがURLの横に表示されます。 それをクリックでタブサイズの設定変更が可能です。 githubのプレビューの一斉設定だけでなく、 レポジトリ単位でタブサイズを切り替えることができます。
アイコンとか設定画面のデザインとかちゃんとしたものを作る気力はなかったので、 皆さんのprをお待ちしております。
 GithubTabChange on github  (これ作ってるときに、githubのHTMLソースの中にtab-size-8というクラスを見つけたのですが、実はどこかに隠し機能としてあるんですかね？)</description>
    </item>
    
    <item>
      <title>Redis::Fast 0.06 released</title>
      <link>https://shogo82148.github.io/blog/2014/02/01/redis-fast-0-dot-06-released/</link>
      <pubDate>Sat, 01 Feb 2014 21:36:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2014/02/01/redis-fast-0-dot-06-released/</guid>
      <description>こんにちは、もうすぐ17才と100ヶ月を迎えるいっちーです。 今朝、Redis::Fast 0.06をリリースしました。 主な変更点はメモリーリークの修正と、エラー発生時にSegmentation Faltで落ちる問題の修正です。
メモリーリーク Redis::Fastをサブスクライバーモードで動作させると、メモリを無限に食い続ける問題をついに！ついに！修正しました。 原因は、一言で言ってしまえば、Perlのリファレンスカウントの扱いの勉強不足です・・・。
XSの中でPerlのオブジェクトを作るとき、プログラマが手動でリファレンスカウントを制御する必要があります。 とはいうものの、全てのオブジェクトのリファレンスカウントを制御するのは大変なので、 XSには「揮発性」という考え方があります。 sv_2motralを使って変数を揮発性に設定しておけば、よしななタイミングでオブジェクトを解放してくれます。 gfx先生のブログにもあるように、 オブジェクト作成したら原則sv_2motralをつけるようにすれば、 メモリーリークはほとんどなくなるはずです。
SV * s = newSVpv(&amp;#34;Hello World&amp;#34;,0); // Perl の文字列オブジェクト sv_2motral(s) // 揮発性にすることで、使われなくなったら自動的に解放してくれる この「よしななタイミング」をよく理解していなかったのでリークしてました・・・。 XSからオブジェクトへアクセスできなくなったときでないとオブジェクトを解放できないので、 揮発性のオブジェクトが実際に解放されるのは「XSで書かれた関数が終了してPerlに戻るとき」です。 メッセージを待ち続けるwait_for_messages関数は (タイムアウトをしない限り)ずっと終了しないので、 揮発性のオブジェクトを解放するタイミングが一切なかったのです。
不要になったら解放されるよう、揮発性オブジェクトの有効範囲を明示的に指定しました。
sv_2motral(s); ENTER; SAVETMPS; sv_2motral(v); FREETMPS; LEAVE; // v はココで解放される // s は生き残ってる perlcallとかちゃんとドキュメントを読みましょう &amp;gt; 自分
Segmentation Falt 同期的にコマンドを実行してる最中にSIGNAL等で実行が中断されると、 Segmentation Faltが起こる問題を修正しました。 Redis::Fastは同期モードでコマンドを発行したときでも、 hiredisの非同期モードの機能を使って通信しています。 コマンド実行中にエラーが発生すると、 コールバック関数の呼び出しタイミングが変わってしまい、 メモリの確保・解放のタイミングが狂ってしまっていました。
このバグ、試した環境の中ではUbuntu+Perl5.14でしか再現しませんでした。 他の環境ではたまたま解放後もアクセスできてしまって、 正常に動作してしまっていたようです。 嫌なバグだ・・・。
まとめ C言語でメモリ管理するコードは書くべきでない。</description>
    </item>
    
    <item>
      <title>Unity Test Tools を使ってみる</title>
      <link>https://shogo82148.github.io/blog/2013/12/21/unity-test-tools/</link>
      <pubDate>Sat, 21 Dec 2013 21:02:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2013/12/21/unity-test-tools/</guid>
      <description>みなさんこんにちは、 最近つらいことばかりで元気のないいっちーです。 少しでもつらいことを解消できないかと Unity Test Tools ってので遊んでみました。
背景 最近あったつらいことのひとつに「Unityで作ってるプロジェクトで、機能拡張したときに間違えて一行消しちゃった！！！」 ってのがあります。
もちろん僕が消したわけじゃないですよ！！！ 僕サーバサイドエンジニアですから、Unityはいじりません。 でも、一応修正コミットは見ていたはずなので、気がつけなかったのは残念です・・・。
どんなにコード書く人が頑張っても、レビューする人が頑張っても、 人間誰だってミスします。 じゃあ、機械にやらせよう！テストコードだ！って話なんですが、 コードカバレッジが低く、今回のつらい事例でもテストがありませんでした。 一部書いてあるテストも、担当者が代わってからなんか怪しい・・・。
あと、自分も手元でテスト動かしてみたのですが、今のテスト面倒・・・。
 Unityのコンソールにドバッと流れる  テストが全部通ったのか、失敗したのかよくわからない   ユニットテストを1項目だけやりたいとかどうやるんだろう  「テストの実行」が「シーンの再生」なので1項目とかどうすんの？    Unity Test Tools つらいので解決方法を探るべくインターネットの海をさまよっていたら Unity Test Tools なるものを発見。
 Unity Test Tools Released  これを書いてる時点で、3日前のリリースです！ タイムリーだ！！
英語でよくわかんないけど、スクリーンショットはわかりやすくてかっこいいぞ！ 遊んでみよう！
事前準備 まず、Unity Testing Tools をダウンロードしてこよう！ Aseet Store に並んでるので、ダウンロードボタンを押してしばらく待ってれば Unity が勝手に使える状態にしてくれます。
簡単なユニットテストを書いてみる 以前れもんさんが書いた「#24 「Unityでコルーチンも単体テストしよう」 tech.kayac.com Advent Calendar 2012」を Unity Testing Tools でやってみました。</description>
    </item>
    
    <item>
      <title>Ark-View-DataTable グラフや表やCSVを簡単に表示したい</title>
      <link>https://shogo82148.github.io/blog/2013/12/07/ark-view-datatable/</link>
      <pubDate>Sat, 07 Dec 2013 20:11:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2013/12/07/ark-view-datatable/</guid>
      <description>こんにちは、最近ログの解析をして遊んでいるいっちーです。 解析の結果は最終的にグラフに出すわけなのですが、 先輩方がよく使っているのもあって Google Charts を使ってます。
で、このグラフを他の人に見せると「その元データCSVでちょうだい！」と言われるんです&amp;hellip;。
もちろんcsvを作るなんてこと簡単にできるんですが、 今のプログラムにはグラフ用のテンプレートとHTMLで表出力するためのテンプレートとCSV用のテンプレートがあって、 グラフが追加されるたびにコピペして微妙に書き直し、 という不毛な作業が発生してしまうのです。つらい。
Ark::View::DataTable 使い回しの効かないテンプレートとかなんのためのテンプレートなのか。 データだけ用意してあとはそれぞれのテンプレートに入れるだけとなるのが理想的だよねー、と思い続けて早数ヶ月。 ようやく重い腰を上げて Ark::View::DataTableってのを書きました。
使い方 Data::Google::Visualization::DataTable をレンダリングするための ArkのViewです。
use Ark::View::DataTable; use Data::Google::Visualization::DataTable; sub gvis :Local { my ($self, $c) = @_; my $datatable = Data::Google::Visualization::DataTable-&amp;gt;new(); $datatable-&amp;gt;add_columns( { id =&amp;gt; &amp;#39;x&amp;#39;, label =&amp;gt; &amp;#34;X&amp;#34;, type =&amp;gt; &amp;#39;number&amp;#39; }, { id =&amp;gt; &amp;#39;y&amp;#39;, label =&amp;gt; &amp;#34;Y&amp;#34;, type =&amp;gt; &amp;#39;number&amp;#39; }, ); # 〜〜〜〜正弦波を描きましょう〜〜〜〜 $datatable-&amp;gt;add_rows( map { [$_, sin(2*3.1415926535*$_/500)] } 1..1000, ); $c-&amp;gt;stash-&amp;gt;{table} = $datatable; $c-&amp;gt;forward( $c-&amp;gt;view( &amp;#39;DataTable&amp;#39; ) ); } Controllerに感じでかくと使えます。 「/gvis?</description>
    </item>
    
    <item>
      <title>ISUCON3の本戦に参加してきた</title>
      <link>https://shogo82148.github.io/blog/2013/11/09/isucon3/</link>
      <pubDate>Sat, 09 Nov 2013 23:58:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2013/11/09/isucon3/</guid>
      <description>ISUCON3の予選を何とか通過し、 本戦へと参戦してきました。
大会中の方針とか考えたこととかメモ。
お題  Tw○tter&amp;ndash;likeな画像投稿サービス  ユーザをフォローできる フォローしたユーザが画像を投稿すると、タイムラインに画像が流れる 公開範囲を全員に公開・フォロワーのみに公開・自分だけに公開から選べる   タイムラインはロングポーリングを使ってリアルタイム反映  JSON-APIが用意されていて、Javascriptから叩く   使用できるサーバは5台  画像を扱うお題と聞いて、会場がざわめきました。
MySQLのクエリを見てみる 開始直後、鍵を用意したり、gitのレポジトリを立てたりなんだりした後、 一回目の計測。
topコマンドで走っているプロセスを見ていると、大量のconvertが！！ プロセス名とお題から考えるに、こいつら確実にImage Magickだ・・・。 CPUのほとんどが画像の変換にくわれていたので、 まずは「どこかでキャッシュする」作戦をとることに。 キャッシュするならフロントに近いほうがいいだろうということで、 フロントのnginxでキャッシュする作戦をとることにしました (アクセス制限があるimageは難しいかもしれないけど、全部publicなiconならすぐできるだろうとこのときは思ってました)。
僕はnginxがconvertを駆逐してくれると信じて、MySQLに投げているクエリを中心にPerlのコードを見てました。 役割分担はこんな感じ。
 サーバの設定とか(@mackee_wさん) nginxでキャッシュする設定(@9reさん) コード読む、主にMySQLに投げてるクエリとか(@shogo82148)  毎回、ひどいクエリが仕込まれているようなイメージがあったけど、 今回はそこまでひどくない。 クエリチューニング全然効果なさそうと判断して、次の作戦を考えることにしました。
No Image Magick, use Imager! やっぱり一番のボトルネックは画像変換。 nginxでキャッシュするとはいえ軽いほうがいいよね、ということで、 外部プロセスで実行している画像変換をImagerを使ってPerlと同じプロセスでやる作戦。
Imagerに置き換え後ベンチにかけたら、若干スコアが・・・上がった・・・ような・・・？ しかし、画像が変化していると怒られて、スコアは無効。 画像エラーを修正するコストと、スコアの上がり具合を見て、Image Magickのままにすることにしました。
予選でも同じように外部プロセス起動している部分をPerlのライブラリにしたけど、 その時はあっさり動いた。 あれは外部プロセス起動をやめたらスコア上がると思い込ませるための布石だったんだ・・・。 (今回の場合、プロセスの起動より画像の変換のほうが重いので、スコアが上がらないのは当たり前)
いろいろ諦めてPerl側でファイルキャッシュ Imagerはテストを通らず、nginxの設定キャッシュ設定も上手く動作しなかったので、 Perlでファイルキャッシュする方針に変更。 convertの結果にmvで適当な場所にコピーして保存。 これだけでスコアが5倍くらいに跳ね上がり、一気に上位に浮上！ 最初からやっておくべきだった・・・。 もうちょっと早ければ特別賞もらえたかもしれないのに。
rsync! rsync! ファイルキャッシュの作業をやっている間に、@mackee_wさんがnfsの設定をやってくれたので、 アップロードされたファイルやキャッシュファイルの保存先をnfsに変更。
あとは物量作戦でいくしかないだろうということで、rsyncで他のサーバにコピーして調整を繰り返してた。 (並行してnginxのキャッシュ設定にも再チャレンジしてたけど、nginx力が足りなかった)</description>
    </item>
    
    <item>
      <title>第10回６さいカンファレンス「C言語のポインタ復習」</title>
      <link>https://shogo82148.github.io/blog/2013/10/30/6saiconf-10/</link>
      <pubDate>Wed, 30 Oct 2013 23:42:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2013/10/30/6saiconf-10/</guid>
      <description>気づかぬ間に第10回６さいカンファレンスが開催されていました。
 第10回６さいカンファレンス「C言語のポインタ復習」  くいなちゃんSNS上で行われ、ログも残っているのでそちらを参照。 「６さいカンファレンス」のカテゴリから辿れるように記事にしておきます。</description>
    </item>
    
    <item>
      <title>Redis::NamespaceとRedis::Keyをリリースしました</title>
      <link>https://shogo82148.github.io/blog/2013/10/18/redis-namespace-and-redis-key/</link>
      <pubDate>Fri, 18 Oct 2013 23:21:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2013/10/18/redis-namespace-and-redis-key/</guid>
      <description>こんばんは、最近シングルトン恐怖症になっているいっちーです。 Redis::Namespaceと Redis::Keyをリリースしました。
Redis::Namespace 「Redis::NamespaceのPerl版書いた」 で紹介したモジュールをCPANizeしました。 コマンドのキー名に当たる部分に、自動にプレフィックスをつけてくれる賢い奴です。
use Redis; use Redis::Namespace; my $redis = Redis-&amp;gt;new; my $ns = Redis::Namespace-&amp;gt;new(redis =&amp;gt; $redis, namespace =&amp;gt; &amp;#39;fugu&amp;#39;); $ns-&amp;gt;set(&amp;#39;foo&amp;#39;, &amp;#39;bar&amp;#39;); # $redis-&amp;gt;set(&amp;#39;fugu:foo&amp;#39;, &amp;#39;bar&amp;#39;); my $foo = $ns-&amp;gt;get(&amp;#39;foo&amp;#39;); # my $foo = $redis-&amp;gt;get(&amp;#39;fugu:foo&amp;#39;); RedisにはKey-Value Storeなんてかっこいい名前が付いているけど、 結局はシステム全体で使えるグローバル変数なわけです。 グローバル変数は駆逐するべきです。 いちいちプレフィックスつけて名前の衝突を回避するなんて人間のやることとは思えません。
せめてモジュールローカルとか、クラスローカルとかある程度スコープを制限したいですよね。 Redis::Namespaceを使えば簡単に実現できます。
Redis::Key Redis::Key は Redisのキーの簡単なラッパークラスです。 毎回毎回「接続先のRedisサーバ」と「キーの名前」を指定するのは面倒です。 この2つをセットにして、一つのオブジェクトとして扱うことができます。
use Redis; use Redis::Key; my $redis = Redis-&amp;gt;new; my $key = Redis::Key-&amp;gt;new(redis =&amp;gt; $redis, key =&amp;gt; &amp;#39;hoge&amp;#39;); $key-&amp;gt;set(&amp;#39;fugu&amp;#39;); # $redis-&amp;gt;set(&amp;#39;hoge&amp;#39;, &amp;#39;fuga&amp;#39;); $key-&amp;gt;get; # $redis-&amp;gt;get(&amp;#39;hoge&amp;#39;); 普通に使っている限りは他のキーにアクセスすることができなくなるので、 Redis::Keyのオブジェクトを他のクラスに渡す、とかしても安心です。</description>
    </item>
    
    <item>
      <title>Redis::Fastをcpanize＆アップデートしました</title>
      <link>https://shogo82148.github.io/blog/2013/10/13/cpanize-redis-fast/</link>
      <pubDate>Sun, 13 Oct 2013 22:39:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2013/10/13/cpanize-redis-fast/</guid>
      <description>Redis::Fastをcpanizeしました！
さらに！早速不具合が見つかったので0.01から0.02にアップデートしました！
CPANに上げてから24時間も経たないうちにpull requestがやってきてCPAN怖いところです。
最初のバージョンである0.01ではタイムアウト処理をちゃんと書いていなかったので、 タイムアウト時に無限ループに陥る不具合がありました。 LinuxとMacとでコネクションを張るのに失敗したときの挙動が違うらしく、 Linuxでは問題なくテストが通るのに、Mac上でのテストでは再現するという面倒バグでした。 さらに面倒なことにRedisの起動のタイミングによって、 Macでもテストが通ったり通らなかったりするという・・・。
主に開発はLinux上でやって、Linux上でしかテスト動かしてなかったので全く気がついていませんでした。 CPANデビューのモジュールがネットワーク関連でXSで少しハードルを上げ過ぎた感じがします。 環境依存な部分が多くてつらいです。
pull requestを送ってくださったsyohexさん、実際にインストールを試みてテストが通らないことを教えてくださったみなさん、ありがとうございました。 アップデートした0.02では、タイムアウト時の処理を少し書きなおして、pull requestも取り込みました。 Mac上でも問題なくテストが通ってインストールできるはずです(きっとね)。</description>
    </item>
    
    <item>
      <title>ISUCON3の予選に参加してきた</title>
      <link>https://shogo82148.github.io/blog/2013/10/07/isucon3-qualify/</link>
      <pubDate>Mon, 07 Oct 2013 13:03:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2013/10/07/isucon3-qualify/</guid>
      <description>こんにちは、いつの間にかチームぽわわ2のメンバーになっていたいっちーです。
@9reさんと @mackee_wさんとでISUCON3の予選に参加してきました。 主にアプリの書き換えを担当していたので、やったことを残しておきます。 チーム全体の方針とか役割分担とかはまこぴー先生の#isucon 予選でとりあえず10位だったを参照。
お題 gistみたいなWebアプリ。 社内ISUCONのときと似たようなお題ですね。 違いは&amp;hellip;
 スターは無い Recent Postsのサイドバーが無い代わりに、ページングしてたどっていけるページがある privateな投稿ができる Markdown形式で投稿できて、表示はHTMLでレンダリングされる  詳しくは、れもんさんの#isucon 2013年予選問題の解説などを参照。
やったこと 一言で言えば、Redisにキャッシュするようにしました。
RecentをRedisのリストで管理 Recentの表示で日付順ソートしているのが重たそうだったので、 公開メモのソート結果をあらかじめRedisのリストに入れておく作戦。
RedisのSORTコマンドが高機能で面白いなーって思ってたので使ってみました。 リストにはメモのIDだけ入れておいて、メモの実体は別のキーを参照する、なんてことができます。 このコマンド、SORTって名前なのに「ソートしない」ってオプションあるところがいいですよね！
MySQLがボトルネックになっているのはこれで解消できました。
bin/markdownを使わない＆レンダリング結果をキャッシュ Markdownのレンダリングを外部コマンド叩いてやっていたので、 Text::Markdown::Discountを使ってレンダリングするように変更。 qx{hoge}って記法はじめて見ました。Perlってやつはいろんな書き方があってよくわからないです。
Markdownの文法って亜種が結構あるので、レンダラをかえるのはちょっと怖かったんですが、全く問題なし。 スコアも3000くらい上がってかなり効果がありました。
さらにレンダリング結果をRedisに入れてキャッシュで+1000くらい。
Recentのレンダリング結果をキャッシュ RecentをRedisでさばくようにしたけど、そもそも100要素もあるHTMLのレンダリングそうとう重いはず。 と、いうわけでここもRedisにキャッシュするようにしました。 公開メモが投稿されたらRecent/:pageのキャッシュを全部削除。 Postのたびにキャッシュクリアされるのであんまり効果ないかなーと思っていたけど、わりと効果あったみたい？ (正確なスコアよく見てなかった)
Redis::Fast!! 残り時間も少なくなり時間内にできることも限られれきたので、最後の最後でRedis::Fastを投入。 これで+1000くらい上がったらしい。(正確なスコアよく見てなかった)
s/Redis/Redis::Fast/ するだけの簡単なお仕事の予定が、githubからのインストールに一番手間取った。 cpanfileにgitのレポジトリを書くと(非公式だけど)インストールできるよ！ってどこかで見た気がするけどなかなかうまく行かず、 自分でgit cloneしてそのディレクトリを指定してインストール(したってまこぴー先生が言ってた)。 (hiredis.hが無い！って叫んでいたから、cartonがsubmoduleをうまく処理できていなかったと予想。 非公式の機能に頼るの良くないね。)
できなかったこと  my.cnf？なにそれ美味しいの？ SQLクエリをいじる余裕がなかった  Newer/Olderのクエリが残念なのはわかってたけど、結局いじってない   Nginxでキャッシュしたい 必要なモジュールは事前にCPANにあげておこう。  まとめ 結果は13192.1点で10位でした。 特に問題がなければこのまま予選突破できるはず・・・！
ところで、魔王軍が学生枠を制圧していて恐ろしいですね。 てか、僕らのチームとの差、500点程度しか無いじゃないですか。怖！！！ これ以上の侵攻はなんとしてでも食い止めなければ。</description>
    </item>
    
    <item>
      <title>Redis::Fastってモジュールを書いた</title>
      <link>https://shogo82148.github.io/blog/2013/09/28/redis-fast/</link>
      <pubDate>Sat, 28 Sep 2013 00:18:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2013/09/28/redis-fast/</guid>
      <description>hiredisをPerlから扱うためのライブラリとして Redis::hiredisってのがあるけど、 なんだか微妙だって聞いたので自分でPerlのhiredisバインディング書いてみたよ。
 https://github.com/shogo82148/Redis-Fast  (READMEからRedis.pmをそのまま持ってきたことがまるわかりですね。なんとかしよう。)
使い方 Redis.pmと全く同じインターフェースなので、 そのまま置換できる、はず。
use Redis::Fast; my $redis = Redis::Fast-&amp;gt;new; ### synchronize mode $redis-&amp;gt;set(&amp;#39;hoge&amp;#39;, &amp;#39;piyo&amp;#39;); print $redis-&amp;gt;get(&amp;#39;hoge&amp;#39;); # piyo ### asynchronize mode $redis-&amp;gt;get(&amp;#39;hoge&amp;#39;, sub { my ($result, $error) = @_; print $result; # piyo }); $redis-&amp;gt;wait_all_responses; ### pubsub $redis-&amp;gt;publish(&amp;#39;fugu&amp;#39;, &amp;#39;fuga&amp;#39;); $redis-&amp;gt;subscribe(&amp;#39;fugu&amp;#39;, sub { my ($message, $topic, $subscribed_topic) = @_; }); my $timeout = 10; $redis-&amp;gt;wait_for_messages($timeout) while 1; 以前作った、Redis::Namespaceにもそのまま使えます。
use Redis::Fast; use Redis::Namespace; my $redis = Redis::Fast-&amp;gt;new; my $ns = Redis::Namespace(redis =&amp;gt; $redis, namespace =&amp;gt; &amp;#39;fugu&amp;#39;); $ns-&amp;gt;set(&amp;#39;foo&amp;#39;, &amp;#39;bar&amp;#39;); # $redis-&amp;gt;set(&amp;#39;fugu:foo&amp;#39;, &amp;#39;bar&amp;#39;); my $foo = $ns-&amp;gt;get(&amp;#39;foo&amp;#39;); # my $foo = $redis-&amp;gt;get(&amp;#39;fugu:foo&amp;#39;); ベンチマーク Redis.</description>
    </item>
    
    <item>
      <title>YAPCへ行ってきた(二日目)</title>
      <link>https://shogo82148.github.io/blog/2013/09/24/yapc-second-day/</link>
      <pubDate>Tue, 24 Sep 2013 07:52:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2013/09/24/yapc-second-day/</guid>
      <description>前回のポストにつづいてYAPC二日目。 聞いたトークの内容を簡単にメモ。
Perl で書く結合テスト 前半はSWET(Software Engineer in Test), TE(Test Engineer)といった業種の話。 後半はテスト手法の分類(誰がする？テストの対象は？方法は？目的は？)について。
スライドはこちら→[Perlで書く結合テスト(]http://ikasama.hateblo.jp/entry/2013/09/22/234521)
これからのPerlプロダクトのかたち 世界一高速な処理系を目指して開発中のgperlと、 その過程でできたツールの紹介。 PerlをLLVMにコンパイルすることがで、高速動作するらしい。 恐ろしい・・・。
Perlは文脈によってトークンの意味が変わってしまうから、トークナイザーを作るのに苦労したとのこと。 (例えば、hoge * fuga とあったときに、*が掛け算なのかブロブなのかわからない) コンパイルの高速化のために文法を工夫しているKuinを見習って欲しいですね。
Emacs実践入門 Perl編 typester先生によるEmacs入門。 PerlCompletion とか helm とか便利そう。 あんまりEmacsカスタマイズできていないので、今度いろいろ入れて遊んでみよう。
Perlでレコメンデーション 登壇者はJubatusのPerlモジュールを書いたりしているらしい。 Jubatus に触ってみようと考え始めてからどれだけの月日が経っただろう・・・ そのうち触ってみます。そのうち。
中規模チャットサービスの運用事例 handlename先生のLobi運用のお話。 今日もcronのメールが迷惑メールフィルタによって闇に葬りさられる悲しいことがあったので、 cronの結果をIRCに飛ばすのとか参考にして何とかしたい。
PhantomJSによる多岐にわたる広告枠の確実な表示テスト 最近の広告はJavascriptを使った遅延読み込みをするので、 ちゃんと表示されるかを静的に判断することができない。 そこで PhantomJS を使ってテストするお話。
フルテストも50msで終わらせたい 〜 FreakOutの取り組み 〜 さすがにフルテストは50msで終わりません。 Ukigumoを使って複数台のサーバでテストを分散実行する取り組みを紹介。
スライド→http://yapcasia.org/2013/talk/show/767463b0-d8fd-11e2-971a-72936aeab6a4
LT 前日にアイデアだけLTで紹介したHTTP::Body::Builderが、別の人の手によって実現されていたのには驚いた。 YAPC恐ろしいところだ・・・。
HUB 懇親会参加しない組だったので、 @sasaplus1 さん, @kazuph さん, @aokcub とHUBで飲み会。 なぜ学内にHUBがあるんだ・・・？
NDS勢やNiigata.pm勢、あと何故かスタッフになっていた @jewel_x12 とも会えて楽しかったです！</description>
    </item>
    
    <item>
      <title>YAPCへ行ってきた(一日目)</title>
      <link>https://shogo82148.github.io/blog/2013/09/20/yapc-first-day/</link>
      <pubDate>Fri, 20 Sep 2013 21:48:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2013/09/20/yapc-first-day/</guid>
      <description>YAPCの一日目に行ってきたよ。
いまどきのカジュアルなデータベース関連開発 Songmu先生のセッション。
DBIx::Schema::DSL とか GitDDL::Migrator とかの説明や、 DBのスキーマ設計、Redisの紹介なんかがありました。 自分もMySQLやRedisを触る機会が増えて、DB周りでつらい思いをしたことが何度かあるので (外部キー制約でデッドロック起こしたり、無駄なインデックスを必死に削除したり・・・) 大いに参考に参考にさせていただきます。
スライドはこちらから→いまどきのカジュアルなデータベース関連開発
学術分野におけるPerlの活用例 Perlを使ったアンケートの結果と、PerCUDAの紹介。 GPGPUをPerlのコードで実現しようとのお話。
大規模Perl初心者研修を支える技術 :DeNAさんが行った研修の紹介です。 顔覚えられない、 研修生の状況把握が大変、 信頼関係を作るのが大変 といった問題をどうやって解決したかについてのお話がありました。
トークの中で紹介された本何冊か持っているけど、全然読んでない・・・。 というか研修生みんなこれ読んだんですか。
スライドはこちらから→大規模Perl初心者研修を支える技術
mod_perlの展望とApacheの超絶技巧 最近僕の周辺ではあまり Apache の話題を聞かなくなってしまいましたね。 しかし、その知名度の高さからか、他のオープンソースのプロダクトはダメでも、 Apache はOKという案件があるらしい。 「Apache使いました！」っていうために、mod_perl で代替品を作ろう、というお話。 おそろしい・・・。
スライドはこちらから→mod_perlの展望とApacheの超絶技巧
0から学んだポストモダンPerl ルーティングとかORMはWAFにはいらない。 blessで十分！これぞ、ポスト・モダンPerl！とのことでした。
僕もフルスタックのフレームワークより、 各機能が別になっているほうが好きですね。 (でもblessよりはクラスを扱うためのライブラリ使ったほうがよいと思う) まあ、あんまり大規模なWebアプリ作ったこと無いので、 実際に作ってみると意見が変わるかもしれませんが。
スライドはこちらから→0から学んだポストモダンPerl
Dist::Zilla 英語のトークに紛れ込んでしまい、正直良くわからなかった。 英語能力全く向上していない。
モジュールを作成、テスト、アップロード等の管理をするためのプログラムらしい。 Redis::Namespace でつらい思いをしたので、 次モジュールを作りたくなったら試してみよう。
perl な web application のためのテスト情報 スライドの順番が正しいか、今使っているのは本当にマイクなのかのテストが必要ですね！ 335さん自らテストの必要性を教えてくれました。 「なぜテストが必要か」言葉では語らず行動で示す335さんかっこいい。
Test::Deep は Redis::Namespace のテストでも一部使っていますが、これ便利ですね。 Test::More の is_deeply はちょっと不便だと思っていたので、今後も使っていこうと思います。</description>
    </item>
    
    <item>
      <title>Redis::NamespaceのPerl版書いた</title>
      <link>https://shogo82148.github.io/blog/2013/09/14/redis-namespace-perl/</link>
      <pubDate>Sat, 14 Sep 2013 18:36:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2013/09/14/redis-namespace-perl/</guid>
      <description>Redis のキーにプリフィックスつけるの面倒だなー自動的につけてくれないかなーと思い、 調べてみると Ruby に Redis-Namespace というものがあるらしい。 だけども、Perl では探しても見つからなかったので書いてみた。
レポジトリはこちら→Redis::Namespace
使い方 インターフェースは Perl Redis と一緒。 コマンドのキー名に当たる部分に、自動的にプレフィックスをつけてくれる。
use Redis; use Redis::Namespace; my $redis = Redis-&amp;gt;new; my $ns = Redis::Namespace(redis =&amp;gt; $redis, namespace =&amp;gt; &amp;#39;fugu&amp;#39;); $ns-&amp;gt;set(&amp;#39;foo&amp;#39;, &amp;#39;bar&amp;#39;); # $redis-&amp;gt;set(&amp;#39;fugu:foo&amp;#39;, &amp;#39;bar&amp;#39;); my $foo = $ns-&amp;gt;get(&amp;#39;foo&amp;#39;); # my $foo = $redis-&amp;gt;get(&amp;#39;fugu:foo&amp;#39;); 大体のコマンドには対応したつもり。 別のプレフィックスがついたキーには基本的にアクセスできなくなるので、 キー名の管理が少し楽になると思います。
でも、flushdb とか flushall すると全部消えるので気をつけてね！</description>
    </item>
    
    <item>
      <title>Perl の Redis ライブラリを調べた</title>
      <link>https://shogo82148.github.io/blog/2013/08/24/perl-redis-libraries/</link>
      <pubDate>Sat, 24 Aug 2013 17:51:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2013/08/24/perl-redis-libraries/</guid>
      <description>最近Redis を使ったコードを書くようになったのですが、 キー名を毎回指定するのがだるいです。 Ruby には redis-objects というのがあって、 Redisのキーをオブジェクトとして扱うことができるようです。 きっと、Perl にも似たようなのあるだろ、って思って調べてみました。
ほしいもの 低レベルなRedisのライブラリはたいていメソッドとRedisのコマンドが一対一対応していて、 次のようなコードになると思います。
$redis-&amp;gt;set(&amp;#39;key-name&amp;#39;, &amp;#39;piyopiyo&amp;#39;); $redis-&amp;gt;get(&amp;#39;key_name&amp;#39;); でも、Redisに何か操作をしたいわけじゃなくて、 Redisのキーに対して操作をしたいので、 次のように書けるべきだと思うんです。
my $key = key($redis, &amp;#39;key-name&amp;#39;); $key-&amp;gt;set(&amp;#39;piyopiyo&amp;#39;); $key-&amp;gt;get(); Redis::Hash, Redis::List Redis::Hashと Redis::Listは Perlのハッシュや配列と同じ操作で Redis にアクセスできるようにするライブラリ。
use utf8; use warnings; use strict; use 5.014; use Redis::Hash; tie my %my_hash, &amp;#39;Redis::Hash&amp;#39;, &amp;#39;hash_prefix&amp;#39;, (server =&amp;gt; &amp;#39;localhost:6379&amp;#39;); # set hash_prefix:hogehoge piyopiyo # set hash_prefix:fugafuga fugufugu $my_hash{hogehoge} = &amp;#39;piyopiyo&amp;#39;; $my_hash{fugafuga} = &amp;#39;fugufugu&amp;#39;; # get hash_prefix:hogehoge piyopiyo say $my_hash{hogehoge}; # piyopiyo # keys hash_prefix:* say join &amp;#39;,&amp;#39;, keys %my_hash; #fugafuga,hogehoge # keys hash_prefix:* # get hash_prefix:fugafuga # get hash_prefix:hogehoge say join &amp;#39;,&amp;#39;, values %my_hash; #fugufugu,piyopiyo # del hash_prefix:hogehoge delete $my_hash{hogehoge}; tie とかよくわかない。 Perl の黒魔術を見た気がしました。</description>
    </item>
    
    <item>
      <title>ランダム抽出アルゴリズムについて考える</title>
      <link>https://shogo82148.github.io/blog/2013/07/13/random-sample/</link>
      <pubDate>Sat, 13 Jul 2013 22:13:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2013/07/13/random-sample/</guid>
      <description>数日前に社内IRCで「スマートな非復元抽出の方法はないか」と話題になったので、 ランダムサンプリングのアルゴリズムについて調べたり考えたりしてみた。
復元抽出 非復元抽出の手法って調べてもなかなか出てこない・・・。 ひとまず、復元抽出についてまとめてみましょう。
線形検索 一番簡単な実装方法。 どの区間に入るかを線形検索して求める。 選択肢の個数nとすると計算量はO(n)。
use strict; use warnings; use List::Util qw(sum); sub linear_search_method { my $weights = shift; my $num = shift; my $sum = sum @$weights; my $length = @$weights; my @a; for (1..$num) { my $r = rand($sum); for my $i(0..$length-1) { $r -= $weights-&amp;gt;[$i]; if($r &amp;lt; 0) { push @a, $i; last; } } } return \@a; } print join &amp;#39;, &amp;#39;, @{linear_search_method [1,2,3], 100}; バイナリサーチ あらかじめ累積分布表を作っておき、どの区間に入るかをバイナリサーチ。 準備にO(n)、選択に O(log n)かかる。</description>
    </item>
    
    <item>
      <title>Google Cloud Messaging for Chrome を試してみた</title>
      <link>https://shogo82148.github.io/blog/2013/05/15/google-cloud-messaging-for-chrome/</link>
      <pubDate>Wed, 15 May 2013 11:26:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2013/05/15/google-cloud-messaging-for-chrome/</guid>
      <description>少し前にGoogle Cloud Messaging for Chrome が発表されました。 Android向けに提供されていた Push 通信の仕組みである GCM の Chrome 版です。 ちょうど GCM for Android に触っていたところだったので、 for Chrome のほうも試してみることにしました。
拡張機能の登録 公式ページの説明にしたがって、 APIを使えるようにします。 GCMはOAuth2.0で認証を行うので、
 クライアントIDを作る Refresh Token を作る  という2ステップが必要。
クライアントIDを作る まず、新しい OAuth2.0 のアプリを作成。 拡張機能をアップロードする予定のGoogleアカウントで以下の作業して Client IDを作ります。
 Google APIs Console にログインする ** Create&amp;hellip; ** メニューから新しいプロジェクトを作成 &amp;ldquo;Services&amp;rdquo; を開いて ** Google Cloud Messaging for Chrome API ** を有効化 &amp;ldquo;API Access&amp;rdquo; を開いて ** Create an OAuth 2.0 cliend ID&amp;hellip; ** というボタンをクリック branding information を適当に入力 &amp;ldquo;Application Type&amp;rdquo; という項目の &amp;ldquo;Web application&amp;rdquo; を選択 &amp;ldquo;Create client ID&amp;rdquo;！！  Client ID と Client Secret が表示されるのでメモしておきましょう。</description>
    </item>
    
    <item>
      <title>RaspberryPiからメールを送る</title>
      <link>https://shogo82148.github.io/blog/2013/05/12/mail-from-raspberrypi/</link>
      <pubDate>Sun, 12 May 2013 21:50:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2013/05/12/mail-from-raspberrypi/</guid>
      <description>RaspberryPi に cron を仕込んで定期実行をやってみようと考えました。 cron の設定自体は crontab -e コマンドを実行すれば簡単にできます。 ただ、これだけだとちゃんと動いているか少し心配なので、 エラーが起きた時に何か通知して欲しい。 普通なら設定ファイルに MAILTO=hogehoge@example.com と書いておくと メールが送られるはずなのですが、 メールサーバが動いてないのでうまくいかない・・・。
そういうわけで、RaspberryPiからメールを送るための設定をしたのでメモ。
MTAをインストールする Raspberry Pi には標準でMTA(Message Transfer Agent)が入ってないようなのでインストール。 今回はPostfixを採用
sudo apt-get install postfix 最初、Sendmailも試してみたんだけど、送信者マスカレードがなぜかうまく行かなったので断念。 後述するように、この設定がないとスパムフィルタに引っかかってしまうのです。
プロバイダのSMTPにリレーしてもらう 実際にメールを送りには以下の条件を満たす必要があるようです。
 送信元のドメインを引ける 固定IPからのアクセス  固定IPなんて自前で持ってないし、 cron からのメールは送信元が pi@raspberrypi になってしまいドメインを引けません。 そのためそのままではスパムメールとして扱われてしまい、メールが届きません。
そこで、プロバイダが提供しているSMTPサーバにメールをリレーしてもらいます。 /etc/postfix/main.cfに以下の行を追加します。
sender_canonical_maps = regexp:/etc/postfix/canonical relayhost = [smtp.example.com]:587 smtp_sasl_auth_enable = yes smtp_sasl_password_maps = hash:/etc/postfix/relay_password smtp_sasl_security_options = noanonymous プロバイダにリレーしてもらうには SMTP-Auth で認証する必要があるので、 ユーザ名とパスワードを設定しておきます。
smtp.example.com hogehoge:your-password postmapコマンドを使って、Postfixから扱える形式に変換します。
$ postmap hash:/etc/postfix/relay_password さらに、エンベロープのFromがプロバイダから提供されたメールアドレスでないと メールをリレーしてくれないので、 すべてのメールのFromをすべて書き換えるよう設定します。</description>
    </item>
    
    <item>
      <title>RaspberryPiでhttps通信が失敗するのを何とかする</title>
      <link>https://shogo82148.github.io/blog/2013/05/12/raspberry-pi-https-connection/</link>
      <pubDate>Sun, 12 May 2013 16:48:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2013/05/12/raspberry-pi-https-connection/</guid>
      <description>RaspberryPiをネットつないでみたので、PythonからいろんなURLを叩いて遊んでいたんだけど、 一部のhttps通信が Connection Timed Out で失敗しちゃう。 プログラムの問題かと思ったけど、curlで叩いてもやっぱりタイムアウト。 Macで全く同じ事をするとうまくいく・・・。 いろいろ調べて、何とかしてみたお話。
原因 接続先がTLSv1にしか対応していないのにSSLv3でアクセスしようとしていたことが問題だったらしい。 明示的にTLSv1を使うように指定して curl を叩いてみるとうまくいった。
$ curl --tlsv3 https://hogehoge なぜRaspberryPiではダメで Macでは成功するのか、という根本的な原因はよくわからなかった。 SSLv3に対応していないなら自動的にフォールバックしてくれてもよさそうなものだけど、 なぜうまく行かないんだろう・・・？
Pythonでの対処 PythonでもTLSv3を使えばうまくいくはずなんだけど、 暗号化方式を指定するオプションは見当たらない(2.7での話)。 どうやら標準ライブラリのファイルを直接書き換えるか、 実行時に中身を入れ替えるかしないとできないみたいだ。 この問題普通のUbuntuでも起こるらしく、 そのフォーラムで置き換えコードを見つけた。
import httplib from httplib import HTTPConnection, HTTPS_PORT import ssl class HTTPSConnection(HTTPConnection): &amp;#34;This class allows communication via SSL.&amp;#34; default_port = HTTPS_PORT def __init__(self, host, port=None, key_file=None, cert_file=None, strict=None, timeout=socket._GLOBAL_DEFAULT_TIMEOUT, source_address=None): HTTPConnection.__init__(self, host, port, strict, timeout, source_address) self.key_file = key_file self.cert_file = cert_file def connect(self): &amp;#34;Connect to a host on a given (SSL) port.</description>
    </item>
    
    <item>
      <title>tweepyでApplication-only authenticationしてみた</title>
      <link>https://shogo82148.github.io/blog/2013/05/09/application-only-authentication-with-tweepy/</link>
      <pubDate>Thu, 09 May 2013 23:29:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2013/05/09/application-only-authentication-with-tweepy/</guid>
      <description>Twitter の API リファレンスを久しぶりに見たら、 Application-only authenticationとかいうのを発見。 特定のユーザと関連付けられない代わりに、普通に認証するより制限が緩いみたい。 3月に追加されてたらしい。
知らなかった・・・。 最近API叩いてなかったからな・・・。
便利そうなので、Python用のTwitterライブラリであるTweepyから使ってみた。
AuthHandler Tweepy用のAuthHandler。 認証部分は TwitterのApplication-only authenticationを試してみた のページからほぼコピペ。
import tweepy import urllib import urllib2 import base64 import json class AppAuthHandler(tweepy.auth.AuthHandler): TOKEN_URL = &amp;#39;https://api.twitter.com/oauth2/token&amp;#39; def __init__(self, consumer_key, consumer_secret): token_credential = urllib.quote(consumer_key) + &amp;#39;:&amp;#39; + urllib.quote(consumer_secret) credential = base64.b64encode(token_credential) value = {&amp;#39;grant_type&amp;#39;: &amp;#39;client_credentials&amp;#39;} data = urllib.urlencode(value) req = urllib2.Request(self.TOKEN_URL) req.add_header(&amp;#39;Authorization&amp;#39;, &amp;#39;Basic &amp;#39; + credential) req.add_header(&amp;#39;Content-Type&amp;#39;, &amp;#39;application/x-www-form-urlencoded;charset=UTF-8&amp;#39;) response = urllib2.urlopen(req, data) json_response = json.loads(response.read()) self.</description>
    </item>
    
    <item>
      <title>社内ISUCONに参加した</title>
      <link>https://shogo82148.github.io/blog/2013/04/13/isucon/</link>
      <pubDate>Sat, 13 Apr 2013 17:17:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2013/04/13/isucon/</guid>
      <description>先日、社内 ISUCON(良い感じにスピードアップコンテスト) に参加してきました。 Livedoorで開催されたISUCONのミニ版で、 Webアプリをひたすら高速化するコンテストです。
高速化の対象はNoPaste。 テキストを共有するWebアプリです。 テキストの投稿・投稿の閲覧・投稿にスターをつける の3つの動作ができる簡単なアプリです。
新卒 vs 先輩ということで、それぞれ4チームが参戦。 チームは二人一組で僕は @Maco_Tasu くんと一緒でした。 @Maco_Tasuくんのブログも参照。
Recent Posts 生成クエリの高速化 高速化前のアプリのベンチマークの結果、スコアは77(≒1分あたりの捌いたリクエスト数)。 何も考えずにデータベースの全行を舐めるクエリを書いていたので、まあ、妥当なスコアですね。
重いのはサイドバーに表示される Recent Posts。 Recent Posts は表示回数が多く、 複数の行、複数のテーブルへのアクセスが発生するため、 きっとここがボトルネックになるだろうと予測してました。 そこで最初にこの部分を解決することにしました。
 とりあえずインデックスを張る クエリを修正してアクセスする行を最小化 スターのカウントした結果をテーブルに格納  オリジナルのデータベース構成では、スターした回数だけ行が増えてました 必要なのは投稿ごとのスター数なので、独立したテーブルに この時点で早くも重大なバグを組み込んでしまったことに、この時はまだ気がついていなかった・・・    nginxによる静的ファイル配信 僕がクエリをいじっている間、@Maco_Tasuくんには サーバの設定をお願いしました。
ログの様子を眺めてみると、cssとかjsとかの静的ファイルが結構な量ありました。 最初のスクリプトでは静的ファイルの配信もアプリでやってたので、 これをnginxを使って配信するように変更。 その他のリクエストはリバースプロキシを設定してアプリに投げます。
Starlet と Server::Starter リバースプロキシを設定する際にアプリの起動スクリプトを編集する必要があったので、 ついでに起動時の設定を色々変更。 PSGI実行のStarletというのが速いと聞いてこれを採用。 Starlet使い方調べてたら、Server::Starterを使った例が出てきたので一緒にインストール。 ワーカーの数の数は適当に10個にしました。
ここで2回目のベンチマークを実行。 スコア1300程度で、その時点のトップ！
SSIを使ったサイドバーの埋め込み お昼を挟んで、さらなる高速化を目指します。
topコマンドを眺めているとPerlで作ったアプリの負荷が大きい。 ほとんどテンプレートエンジンを呼び出しているだけの単純なコードなので、 ここを高速化するのは面倒くさい。 そこで、前段のnginxでキャッシュする作戦を採用することにしました。
もっともキャッシュが有効なのはサイドバーだろうと予想。 クエリの最適化をしたとは言え、サイドバーには100件程度の投稿が表示されるので、 クエリ実行にもレンダリングにも時間がかかるはず。 さらにすべてのページでサイドバーは共有できるので、大幅な高速化が期待できるはずです。
過去のISUCONの記事にSSI(Server Side Include)を使った例があったのを思い出し、 これを使ってサイドバーのみキャッシュ、nginx内でサイドバーを埋め込むように。</description>
    </item>
    
    <item>
      <title>出、出〜〜〜〜wwww emacsをふたつ以上実行奴〜〜〜〜www(emacsclient編)</title>
      <link>https://shogo82148.github.io/blog/2013/03/05/emacsclient/</link>
      <pubDate>Tue, 05 Mar 2013 12:35:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2013/03/05/emacsclient/</guid>
      <description>emacsを使って編集している最中にシェル操作をしたくなって， C-z を押してバックグラウンドにしてシェル操作． その後，emacsに戻ってくるには fg コマンドを打つ必要があるんだけど， 間違えてもう一回 emacs を新しく立ち上げるというミスを何度もやってしまう・・・．
これに対し，猫型さんが複数起動しようとすると警告を出してくれるようにしてくれました． (出、出〜〜〜〜wwww emacsをふたつ以上実行奴〜〜〜〜www)
警告してくれるのはありがたいんだけど， これだとシェル操作中に別のファイルの編集をしたいと思っても，警告が返ってくるだけ． emacs をフォアグラウンドに出して，ファイルの指定をやり直さなきゃいけない． 僕はファイルの編集をしたいんだ！！ わかったから早く編集させろ！！！
emacsclient 単なる警告じゃなくて， 「裏で動いていたemacsを復帰させ，新しいバッファを開く」 ところまで自動的にやってくれると嬉しいですね．
まず，emacs をデーモンモードで起動しておきます．
emacs --daemon emacsclient コマンドでファイルを開くと， emacs デーモンさんが新しいバッファで開いてくれます． オプションに -nw を指定しておくと現在の端末で閲覧編集することができます．
emacsclient -nw hoge.txt 終了するにはC-x 5 0． C-x C-cでも終了できるけど， デーモンにバッファが残ってしまうみたい．
aオプションでemacs デーモンが起動してないときに 編集に使うエディタを指定できる． 空っぽにしておくと，emacs をデーモンモードで起動してくれる．
emacsclient -nw -a &amp;#39;&amp;#39; hoge.txt emacs デーモンを終了させるのは以下のコマンド．
emacsclient -e &amp;#39;(kill-emacs)&amp;#39; emacsclient に対して alias を作っておけば， 複数起動かどうか意識せずに使えますね．
alias emacs=&amp;#39;emacsclient -nw -a &amp;#34;&amp;#34;&amp;#39; 参考  emacsclientを使おう emacsclient の使い方の種類と、便利な使い方 emacsclientを終了する方法  </description>
    </item>
    
    <item>
      <title>LaTeX2EPUBで電子書籍を作ってみる</title>
      <link>https://shogo82148.github.io/blog/2013/03/02/latex2epub/</link>
      <pubDate>Sat, 02 Mar 2013 16:20:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2013/03/02/latex2epub/</guid>
      <description>LaTeXで書いた文章を電子書籍にしたくなったので， LaTeX2EPUBを使ってみました．
LaTeX2EPUBはLaTeXMLとReVIEWに依存しているようなので， それぞれインストールしていきます． あと，数式の変換とかにLaTeXを使っているので別途用意する必要あり． いろんなディストリビューションがあるけど， ここでは TeX Live 2012 を使いました．
LaTeXML のインストール LaTeXMLはLaTeXの文章をXML形式に変換するソフト． そこからさらにXSLTを使ってXHTMLへ変換できる． ドキュメントに従って 依存するライブラリをインストール．
perl -MCPAN -e shell cpan&amp;gt; install DB_File, Parse::RecDescent, File::Which cpan&amp;gt; install XML::LibXML, XML::LibXSLT ドキュメントが少し古いらしく，これだけでは不十分だった． 追加でParse::RecDescentとImage::Magickもインストールしておく．
cpan&amp;gt; install Parse::RecDescent cpan&amp;gt; quit yum install ImageMagick-perl 後はソースを取ってきてmakeするだけ． 現時点での最新版0.7.0をインストールした．
wget http://dlmf.nist.gov/LaTeXML/releases/LaTeXML-0.7.0.tar.gz tar zxvf LaTeXML-0.7.0.tar.gz cd LaTeXML-0.7.0 perl Makefile.PL make make test make install ReVIEW のインストール ReVIEWは簡単なマークアップ言語で書かれたテキストから PDFやEPUBを作成するためのスクリプトです． このなかのEPUB作成機能に依存しているようなのでインストールしておきます． ReVIEWはgemで簡単インストール．
gem install review LaTeX2EPUB のインストール LaTeX2EPUB本体をインストール． 本家の日本語化対応が少し不十分だったので 改造版を上げといた． これをダウンロードしてパスの通ったところに置けばインストール完了．</description>
    </item>
    
    <item>
      <title>AWSをはじめてみた</title>
      <link>https://shogo82148.github.io/blog/2013/02/21/starting-aws/</link>
      <pubDate>Thu, 21 Feb 2013 01:01:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2013/02/21/starting-aws/</guid>
      <description>Amazon Web Services(AWS)でEC2でも使ってみようかと， 登録を試みました．
が，しかし，電話認証の段階で何度やってもシステムエラー・・・．
 An Error Has Occured システムエラー 電話確認要求を処理できません。後でもう一度お試しください。
 こういう時は，とりあえずエラーメッセージでググってみましょう． なんだかそれっぽい記事が見つかりました．
 AWSアカウント開設で”電話確認要求を処理できません。後でもう一度お試しください。”と怒られ続けた Amazon Developer Forums: 電話による身元確認でエラー発生  どうやら，登録時に入力した「支払い方法」と「アドレス情報」が正しく反映されていないことが原因のようです．
アカウントの管理 画面から，「支払い方法」を選び，クレジットカードや請求先を記入します． アドレス情報は「登録内容の変更」から変更可能です．
AWSをはじめてみたというエントリだけど， 実はじょりぼっとの「買うべき？」機能を実装するために， AWSのProduct Advertising APIを前々から使っていたのでした． このAPI使うだけなら支払い方法などの入力は不要だったので， 必要最低限の情報しか入力していませんでした． 住所とかの入力もしなかったのですが， 自分が確認したときはアドレス情報の国設定が何故かアメリカになってました． これのせいですかね？
詳しい原因はよくわかりませんが，とりあえず，「支払い方法」と「登録内容の変更」の全項目を正しく入力したら認証が出来ました． 1年は無料でいろいろ遊べるらしいので，何か動かして遊んでみましょう．</description>
    </item>
    
    <item>
      <title>じょりぼっとが起動して一年がたちました</title>
      <link>https://shogo82148.github.io/blog/2013/01/22/jo-ri-bot-1st-anniversary/</link>
      <pubDate>Tue, 22 Jan 2013 13:57:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2013/01/22/jo-ri-bot-1st-anniversary/</guid>
      <description>じょりぼっとが初めてつぶやいてから 今日でちょうど一年となりました．
突然の凍結，74回にも及ぶバルスなどなどを乗り越え， 今日まで生き延びられたことを嬉しく思います．
ちなみに一番最初のツイートはこんなのでした．
自分の教科にしましたというわけで終わりー。どっちも一部の断面図
&amp;mdash; 狼とボット (@JO_RI_bot) 2012年1月22日  学食メニュー じょりぼっとが一周年を迎えるということは， 起動当初から続けてきた学食メニュー表示機能も一周年ということです． 一年分のメニューはこちらにストックしてあります． どんなメニューが出されることが多いのか，簡単な統計を取って見ました．
1食昼食A定  回鍋肉 13 鶏肉と味噌漬け焼き 9 チキン唐揚げ 8 豚肉キムチ炒め 7 ちきんカツ 7 チキン唐揚げ&amp;lt;スパイシーカレー&amp;gt; 7 豚肉朝鮮焼き 7 焼肉とピーマン肉詰めフライ 7 チキンソテーさわやかソース 7 チキンマスタード焼き 7 鶏肉キムチ焼き 7 チキンピザソース焼 7  1食夕食A定  チキンピザソース焼 13 酢豚 11 豚カツ 9 チキンソテーさわやかソース 9 グリルドチキンイタリア風 9 鶏肉と味噌漬け焼き 8 エッグ焼肉 8 Bigメンチ 8 焼肉と春巻き 8 チキンステーキタルタルソース 8  1食昼食B定  筑前煮 16 いりどり 13 八宝菜 12 白身魚フライの卵とじ 11 白身魚のピリピリ漬け 10 鯖の生姜焼き 9 白身魚フライチーズ焼き 9 うずら卵と野菜の五目煮 8 鶏肉の酢豚風 8 シューマイの中華風旨煮 8 チキンブラウンソース煮 8 サーモンシチュー 8 アジフライとツナサラダ 8 白身魚の磯辺揚げ 8  1食夕食B定  すき焼き風旨煮 19 うずら卵と野菜の五目煮 13 スペイン風オムレツとコロッケ 13 ピザ卵とコロッケ 12 鶏肉と野菜の七味炒め 12 鮭の野菜あんかけ 11 鶏肉とヤングコーンの豆板醤炒め 10 アジフライとツナサラダ 9 チキンブラウンソース煮 9 白身魚のピリピリ漬け 9  1食昼食セット  オムライス 16 五目あんかけ焼きそば 13 鮭チャーハン 12 ねぎトロ丼 12 鶏肉ときのこのチャーハン 11 トルコライス 11 三色丼 9 鶏の照り焼き丼 9 ビビンバ丼 9 親子丼 9 麻婆丼 9  1食夕食セット  キーマカレー 13 ビビンバ丼 10 肉たれうどんとぶっ玉丼 10 海の幸うどん 9 すき焼き丼 8 肉うどんとカレーライス 8 ねぎトロ丼 8 イタリア風チキンカツ丼 8 鶏の照り焼き丼 6 とろろそばとミニカツ丼 6 鮭茶漬け 6  1食昼食単品  鶏肉とブロッコリー炒め 16 さつま汁 15 揚ギョーザ 13 のっぺ 13 イカ野菜カツ 13 揚げ豆腐の旨煮 13 かぼちゃのそぼろあんかけ 12 ハムチーズサンドフライ 12 エビ風味グラタンコロッケ 12 鶏肉とタケノコの旨煮 12 ブロッコリーとカリフラワーの炒め 12 茄子の中華風旨煮 12 豚肉と野菜の煮込み 12 卵と玉ねぎのソテー 12  1食夕食単品  鶏肉とチーズ焼き 17 レバニラ炒め 15 豆腐きのこあんかけ 13 ゆで卵 13 ちくわの二色揚げ 12 鶏肉と里芋の煮物 11 蒸シューマイ 11 けんちん汁 11 五目金平 11 五目肉じゃが 10 シューマイのカレー揚げ 10 ブロッコリーとカリフラワーの炒め 10  2食お昼ごはん定食  ピーマン肉詰めフライ 13 ちきんチーズ焼き 13 ハッシュドビーフ 12 鶏肉のピリカラ味噌焼き 10 カレーコロッケ 8 春巻き 7 野菜コロッケ 7 鰹の刺し丼 7 ちきんカツ 7 豚玉丼 7 レッドホットチキン 7 きじ焼き丼 7 ちきん南蛮漬け 7 ハンバーグ 7 海老グラタンコロッケ 7  2食晩御飯定食  545円定食 34 545円丼 16 フライアンドフライ 13 ちきん南蛮 11 新潟タレカツどん 11 中華角煮丼 10 ねぎトロ丼 9 スパイシードライカレー 9 レッドほっとマヨ 9 545丼 8  2食に関しては，集計か3月からなのでまだ一年たっていません． それにしても圧倒的な545円定食の出現頻度． 結局何が食べられるのか全くわからないのですが・・・．</description>
    </item>
    
    <item>
      <title>UDPのパケットをSSHを通してトンネルする</title>
      <link>https://shogo82148.github.io/blog/2012/12/28/tunneling-udp-via-ssh/</link>
      <pubDate>Fri, 28 Dec 2012 16:38:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/12/28/tunneling-udp-via-ssh/</guid>
      <description>SSHには標準でTCPのトンネリング機能は付いているのですが， UDPはトンネリングしてくれません． なんとかできないものかと試行錯誤してみました．
TCP をトンネル TCPのトンネリングの復習から． 以下のコマンドでクライアントの8080番ポートを，リモートの80番ポートに転送することができます．
ssh -L 8080:localhost:80 remote SOCKS proxyとして動作させることも出来ます． ブラウザのプロキシとして設定すれば，リモートのサーバがすべての通信を中継してくれます．
ssh -D 8080 remote UDP をトンネル NetCatを使うと TCP/UDP の通信内容と標準入出力をつなげることが出来るらしいです． これを使って，クライアント側で UDP サーバを立て，その通信内容をSSH経由でリモートの UDP クライアントに送ってあげます． 最後にリモートからクライアント側へのパケットを名前付きパイプで転送してあげればトンネル完成です．
mkfifo tunnel nc -ul 8080 &amp;lt; tunnel | ssh remote nc -u localhost 8080 &amp;gt; tunnel Mosh をトンネル なんでこんなことをしようと思ったかというと，Moshをファイヤーウォール越しに使いたかったから． MoshはUDPで通信しているので，SSHしか通らない環境では使えません． そこでUDPをSSHでトンネリングしてできないかとやって見ました． セッションの確立にSSHも使っているので，以下のようにして Mosh用のUDPトンネルと SSH用のTCPトンネルを作ります．
mkfifo tunnel nc -ul 60000 &amp;lt; tunnel | ssh -L 10000:localhost:22 remote nc -u localhost 60000 &amp;gt; tunnel &amp;amp; mosh -p 60000 --ssh=&amp;#34;ssh -p 10000&amp;#34; localhost 外部からのSSH通信が遅かったので，Moshのローカルエコーでなんとかならないかと挑戦してみました． 実際の効果は未確認．またあとで試してみます．</description>
    </item>
    
    <item>
      <title>JavaScript版WaveZutaZuta作ってみた</title>
      <link>https://shogo82148.github.io/blog/2012/12/24/wavezutazutajs/</link>
      <pubDate>Mon, 24 Dec 2012 13:51:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/12/24/wavezutazutajs/</guid>
      <description>「WaveZutaZutaというおもちゃを書いている話」 という記事を見ていたら，誰かがツイッターで 「いっちーがJavaScriptに移植してくれる」と発言．
あ，はい．やってみましょう．
どんな感じのものなの？ 音声ファイルをテキトーに切り貼りできるライブラリです． WaveZutaZutaJSにブラウザで実行出来るサンプルを置いたので 実際試してみるのが一番わかりやすいと思います． 適当な音声ファイルをドラッグ＆ドロップして，playボタンを押すと音が流れるので，いろいろ遊んでみてください．
テキストボックスには楽譜が書かれています． 楽譜の書き方は「WaveZutaZutaというおもちゃを書いている話」 と同じです．
 ちなみに、楽譜ファイルの読み方、書き方ですが、aからzまでの文字それぞれにずたずたにされたwaveファイルの&amp;quot;破片&amp;quot;がアサインされていて、-は音をのばす(タイ)を意味し、0は休符を意味します。*を指定すると、a-zのうちどれかをランダムで鳴らします。1文字が64分音符ひとつ分の長さです。空白文字は無視されます。
 使い方 リポジトリの WaveZutaZutaJS.js がライブラリの本体です． 次のように使います．
var data = new ArrayBuffer(); // ずたずたにしたい音声データを入れておく var context = new AudioContext(); var zuta = new WaveZutaZuta(context); zuta.onSuccess = function(self, source) { // 元の音声の先頭5秒から3秒間流す  zuta.setNote(&amp;#39;a&amp;#39;, 5); var node = zuta.getAudioNode([{sound: &amp;#39;a&amp;#39;: length: 3}]); node.connect(context.destination); }; zuta.loadAudio(data); data には入力音声のバイナリデータを入れておきます． 形式はブラウザが対応していれば何でもOKです． Chromeなら wav, mp3, mp4 など，メジャーな形式はたいてい読めると思います．
getAudioNodeで返ってくるのは AudioNode なので，WaveZutzZutaJS の出力にさらにエフェクトをかけることができます． 例えば，次のコードで周波数フィルタを通すことができます．</description>
    </item>
    
    <item>
      <title>TinySegmenterをLaTeXに移植してみた</title>
      <link>https://shogo82148.github.io/blog/2012/12/16/tinysegmenter-for-tex/</link>
      <pubDate>Sun, 16 Dec 2012 13:11:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/12/16/tinysegmenter-for-tex/</guid>
      <description>この記事はTeX &amp;amp; LaTeX Advent Calendarの傘下記事です． 15日はk16.shikanoさんの「TeX がむかついたので実装したけど挫折してる話」, 17日は@egtraさんの「LCDF TypetoolsでOpenTypeフォントを使う(DVIPDFMXで)」です．
neruko3114が参加しているのを見てなんだか楽しそうだったで参加してみました． とはいってもネタも思いつかなったので，過去に作ったものをTeXに移植してみました． ターゲットはTinySegmenter． 以前作ったTinySegmenterMakerでLaTeXを出力できるようになったよ！
使ってみる TinySegmenterMakerのレポジトリをダウンロードするなりgit cloneするなりして 落としてきます． レポジトリに入っているのはモデルファイルとスクリプトだけです． これらを使ってTeXのスタイルファイルを作ります．
$ cd /path/to/TinySegmenterMaker/ $ ./maker tex &amp;lt; RWCP.model カレントディレクトリにtinysegmenter.styができます． TeX から見えるところにおいておきましょう． これを使うソースコードは次のようになります．
\documentclass{jarticle} \usepackage{tinysegmenter} \begin{document} \TinySegmenter{-}{私の名前は中野です} \end{document} platexで処理するとこんな感じに表示されるはず．
私-の-名前-は-中野-です 仕組み TinySegmeneterは元の文章の一部を切り取ってハッシュに入れる動作をしている． でも，LaTeXにはハッシュみたいなデータ構造がないのでコントロールシーケンスで代用． \@ifundefinedで有無を確認し，\csname\endcsnameで置き換え． コントロールシーケンスの一部に日本語を使わないといけないので，日本語LaTeX環境でしか動かない． ただ，一部句点などの扱いが違う？よくわからない．
あとは，文字種の取得が必要なんだけど，ここでも同じことをしてます． すべてのアルファベット・ひらがな・カタカナ・数字について，その文字種をベタ書き． それ以外は全部漢字扱い． そのため，それ以外の文字を使うとオリジナルとは違う結果になるかも．
最後は足し算．これはカウンタを使えば簡単ですね．
応用編 TinySegmenterMakerでは自由にモデルを差し替えることができます． 以前JavaScript版のTinySegmenterを使って， 聞こえますか…自動生成…してみた…よ… ということをしてみました． LaTeXだってできるはず．
聞こえますか… に心に呼びかけるためのモデルファイルが含まれています． これをダウンロードして読み込ませます．
$ ./maker tex &amp;lt; model これを自分のドキュメントに読み込ませてみます．
\documentclass{jarticle} \usepackage{tinysegmenter} \begin{document} (…\TinySegmenter{…}{聞こえますか聞こえますかあなたの心に直接語りかけています}…) \end{document} 私の声が聞こえましたか・・・？</description>
    </item>
    
    <item>
      <title>MeCabをPythonから使う注意点とか</title>
      <link>https://shogo82148.github.io/blog/2012/12/15/mecab-python/</link>
      <pubDate>Sat, 15 Dec 2012 17:38:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/12/15/mecab-python/</guid>
      <description>日本語の文章をコンピュータで色々いじるときに， 必ずと言っていいほどよく使うのが形態素解析器． スペースなどの明示的な区切りの無い日本語を単語に分割してくれるツールです． 中でもMeCabが非常に有名で，さまざまなところで使われています．
MeCabはいろいろな言語から呼び出すことができます． 自然言語処理の分野ではPythonが人気のようですね．僕も使っています． しかし，MeCabをPythonから使う場合，注意する点がいくつかあります． そこにハマっている後輩を見かけたので，文章として残しておくことにします． Python2系が対象です(3系はよくわからない)． 注意するのは以下の二点です．
 MeCabに渡す文字列はencode，戻ってきた文字列はdecodeする MeCabに渡した文字列は必ず変数に入れておく  EncodeとDecode Python2系の文字列には，バイト列として扱われる文字列(str)と，Unicodeで表現された文字列(unicode)があります． 日本語を扱う場合，strだといろいろ問題があるので，特に理由がなければunicodeを使うべきです． しかし，MeCabはstrしか受け付けません． そこでMeCabに渡す直前・直後でencode・decodeするようにします．
import MeCab tagger = MeCab.tagger(&amp;#39;-Owakati&amp;#39;) text = u&amp;#39;MeCabで遊んでみよう！&amp;#39; result = tagger.parse(text) # エラー！ encoded_text = text.encode(&amp;#39;utf-8&amp;#39;) # encodeが必要 encoded_result = tagger.parse(text) result = result.decode(&amp;#39;utf-8&amp;#39;) # 必ずdecode &#39;utf-8&#39;の部分は辞書の文字コードに合わせて適宜書き換えてください． デフォルトはeuc-jpですが，utf-8の方が幸せになれると思います．
必ず変数に入れる 次にMeCabの作ったノードに直接アクセスして，品詞情報などを取ってくることを考えます． 適当に書いてみるとこんな感じでしょうか．
import MeCab tagger = MeCab.tagger(&amp;#39;&amp;#39;) text = u&amp;#39;MeCabで遊んでみよう！&amp;#39; node = tagger.parseToNode(text.encode(&amp;#39;utf-8&amp;#39;)) while node: #printはstrを渡す必要があるのでdecodeは不要 print node.surface + &amp;#39;\t&amp;#39; + node.feature node = node.</description>
    </item>
    
    <item>
      <title>聞こえますか…自動生成…してみた…よ…</title>
      <link>https://shogo82148.github.io/blog/2012/12/05/kikoemasuka/</link>
      <pubDate>Wed, 05 Dec 2012 23:07:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/12/05/kikoemasuka/</guid>
      <description>聞こえますか…あなたの心に直接…で始まるこのテンプレート． 誰かが「文章入力したら…を自動で入れてくれるのないかな」って呟いてたのでつくってみた．
サクッと作成 TinySegmenterで単語分割， ランダムに…を単語の間に挿入して出力してみた．
 聞こえますか…  この程度なら数十分あれば作れますね．
挿入位置を学習してみる さて，実際やってみるとちょっと挿入位置が不自然な気がします． 世の中に出回っているツイートでは単語間ではなく文節の間に挿入しているのが多いように見えます．
しかし，TinySegmenterは品詞情報をつけてはくれないので文節の判定は少し面倒ですね．
・・・待てよ・・・このテンプレートを使ったツイートなんて大量に手に入る・・・これから学習すればいいんじゃね？
はい，やってみましょう．
ツイートを集める Twitter APIを使ってテンプレートを使っているようなツイートを拾ってきます． ** 「聞こえますか OR きこえますか -RT」** で検索してみました．
普段Twitter APIを叩くときはTweepyを使っているのですが，これで検索するとあまり古いツイートは取れません． API 1.1 を使うと古いツイートも取ってこれるらしいので，強引にTweepyを書き換えて1.1対応． ** 72,529ツイートの取得に成功しました． ** プログラムについてはTweepyの書き換えでゴチャゴチャしているのでまた今度．
TinySegmenterMakerに放り込む カッコで囲まれている部分を抽出，点々を空白に置換，パクリツイッタラー消去などの処理をした後， TinySegmentermakerに放り込みます． 実際に学習に使ったツイートは49,573ツイートです． 10000回の繰り返しで，学習結果は以下のようになりました．
Result: Accuracy: 94.794% (3466578/3656961) Precision: 90.9504% (526277/578642) Recall: 79.2234% (526277/664295) System/Answer p/p p/n n/p n/n: 526277 52365 138018 2940301 約95%の精度という非常に高い性能を示してくれましたが， 区切るところ(p)よりも区切らないところ(n)のほうが多いためですね． Recallが8割しかありませんが，人によるばらつきが大きそうなので，まあこんなもんでしょう．
学習が終わったら最後にオリジナルのTinySegmenterを学習後のもので置き換えるだけ． チェックボックスで単語分割とツイートの学習結果，どちらを使うか選択できます． なんだかそれっぽくなりましたかね・・・？
元ネタについて ところでこのテンプレートの元ネタについて調査している方がいらっしゃるようです．
 「聞こえますか…心に直接…」のオリジナル検証  ゲームが元ネタだ，っていう人を時々見かけたけど， 検証してみると微妙に内容が違うらしい． もちろん影響は受けているんだろうけどね． マンガとかゲームで始めて心に直接語りかけたのって何なんだろう？</description>
    </item>
    
    <item>
      <title>OAuthの認証にWebViewを使うのはやめよう</title>
      <link>https://shogo82148.github.io/blog/2012/11/24/no-more-webview/</link>
      <pubDate>Sat, 24 Nov 2012 23:06:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/11/24/no-more-webview/</guid>
      <description>AndroidからTwitterへアクセスするためのライブラリとして，Twitter4Jが有名です． これを使ってみようと，「Android Twitter4J」と検索すると 認証にWebViewを使った例がたくさん出てきます．
・・・いや，ちょっとまて． それはちょっとまずいだろう．
そういうわけでもうちょっと賢い方法を探してみました．
何がまずいのさ 「Android Twitter4J」と検索すると，上位にこんなページが出てきます．
 Twitter4jを使ってOAuth認証をアプリ内で行う方法 Twitter4j-2.2.xを使ったOAuth認証のコーディング例 twitter4jでツイートする Android+Twitter4JでOAuthするためのソースコード  上のサイトでは次の様は方法をとっています．
 アプリ内にWebViewを貼り付け WebViewでTwitterの認証画面を表示 onPageStarted や onPageFinished をオーバーライドして callback URL へのアクセスを検出 URL に入っている認証コードで認証  アプリ内でWebViewを使うとURLが表示されません． つまり ** 本当にツイッターにアクセスしているかわからない ** のです． もし，表示されるのが偽の認証画面だったら，アプリから簡単にパスワードがわかってしまいます．
じゃあ，URL を表示させればいいかというとそういうわけでもありません． 画面上のURL表示なんて簡単に偽装できてしまいます． どんな工夫をしても ** アプリがパスワードの要求をしていることには変わりありません ** ． アプリはパスワードを簡単に取得できます．
アプリのユーザはTwitterに限らずSNSへのログイン時にブラウザを開かないアプリは信用しないようにしましょう． どこかでパスワードの抜かれている可能性があります． (ただし，公式アプリは除く．公式アプリが信用できないならそもそもサービスを利用できないもんね．)
じゃあどうするのさ じゃあ，開発者はどうするのかって話ですが，もう少し詳しく検索してみましょう． 他の方法を使っているページもでてきます．
 PINコードを利用  TwitterでPIN番号認証を行う   Intent Fileterを利用しコールバック  twitter4jを使用したAndroid Twitterアプリケーション作成 Twitter4Jを使ってAndroidアプリでStreamingAPIのUserTimelineを取得する TwitterでOAuth認証を行う  Twitterへのアプリケーション登録 Twitterの認証ページをブラウザで開く Access Tokenを取得する      PIN コードを利用 一つ目の方法はPC版クライアントでよく使われる方法． 認証後にPINコードと呼ばれる数字が表示されるので，それをアプリに入力します． twiccaなんかでも使われてますね． Twitter へのアプリケーション登録のときにコールバックURLを入力しないとこの認証方式になります．</description>
    </item>
    
    <item>
      <title>TinySegmenterの学習ツールを作ってみた</title>
      <link>https://shogo82148.github.io/blog/2012/11/23/tinysegmentermaker/</link>
      <pubDate>Fri, 23 Nov 2012 14:37:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/11/23/tinysegmentermaker/</guid>
      <description>TinySegmenterは工藤さん作のJavaScriptだけで書かれたコンパクトな分かち書きソフトウェアです． わずか20kバイト程度のサイズしかなく，お手軽に使える分かち書きソフトウェアですが， 当たり前のことながら学習データに使った新聞記事以外の文章の精度はイマイチ． 改善しようにも学習用のプログラムが公開されていないのでモデルの修正が大変です．
ないなら作ってしまいましょう！
ダウンロード ソースはgithubで公開しています．cloneするなりzipファイルを落としてくるなりしてください．
 TinySegmenterMaker  学習方法 スペースで分かち書きしたコーパスをあらかじめ準備しておきます． コーパスから分かち書きの情報と素性を取り出します．
$ ./extract &amp;lt; corpus.txt &amp;gt; features.txt AdaBoostを用いて学習します． 新しい弱分類器の分類精度が0.001以下，繰り返し回数が10000回以上となったら学習を終了します．
$ g++ -O3 -o train train.cpp # コンパイル $ ./train -t 0.001 -n 10000 features.txt model # 学習 きちんと分割できるが実際に試してみます．
$ ./segment model 私の名前は中野です 私 の 名前 は 中野 です ライブラリの作成 TinySegmenterは実装が簡単なためいろいろな言語へ移植されています． モデルの更新のたびにそれらへの言語の移植バージョンを作るのは大変です． というわけで，makerコマンドで各種言語用のライブラリを作れます． 学習結果のモデルはライブラリのなかに組み込まれ，ファイル単体で簡単に使用することができます． allを指定することで，対応しているすべての言語向けのライブラリを出力します．
$ ./maker javascript &amp;lt; model $ ./maker perl &amp;lt; model $ ./maker ruby &amp;lt; medel $ .</description>
    </item>
    
    <item>
      <title>6さいカンファレンス 第9回「マスタリングの技法 ～音圧を上げよう～」まとめ</title>
      <link>https://shogo82148.github.io/blog/2012/11/09/6saiconf-9/</link>
      <pubDate>Fri, 09 Nov 2012 00:13:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/11/09/6saiconf-9/</guid>
      <description>2012/11/8にくいなちゃんさん主催で開催された6さいカンファレンスのまとめ。 第9回は「マスタリングの技法 ～音圧を上げよう～」です。
勝手にまとめてしまったので、何か問題があれば@shogo82148まで。
よるほー くいなちゃん: みなさん、自分が作った曲が、市販のCDの曲にくらべ、 音量が小さい (最大まで波形を上げたにも関わらず)と悩んだことはありませんか？
くいなちゃん: しかし、心配はいりません。 今回のことを実践していただくと、 みなさんの曲も、市販の楽曲並みに、音圧をあげることができるですん！ では次の波形をご覧ください。
くいなちゃん: http://kuina.tes.so/6saiconf_9/img0.png はい、さっき作った曲です。 いい曲ですね！ しかし、なんだか音量が小さいですね… それでは、波形に注目してください。 この図では、波形が-1.0～1.0 の範囲で 示されていますが、この範囲に比べ、明らかに波形が小さいです。 余白が空きすぎです！
くいなちゃん: え、mp3ファイルがどこにあるかって？ ｷﾆｼﾅｲ! では、とりあえず、この波形を -1.0～1.0 まで拡大してみましょう。 http://kuina.tes.so/6saiconf_9/img1.png はい、赤い矢印で示されたところが、確かに-1.0～1.0 の範囲に到達していますね。 素人さんは、この状態で完成、と思うでしょう。 しかし、それではダメダメですん☆
くいなちゃん: なぜなら、緑の2本線で示された範囲がメインの波形であって、 そこから飛び出た いわゆる魚の骨は、音量を上げる邪魔をするものだからです。 この魚の骨さえなければ、もっと音量が上がるのに…そう考えてください。
くいなちゃん: 市販のCD の音楽なんかは、こんな波形をしています。 http://kuina.tes.so/6saiconf_9/img2.png これは、全体が波形で埋まった、いわゆる海苔みたいなことになっているので、 業界でもしばしば 海苔 と言われます。 ここまで来ると、相当 音量が大きく聞こえます。 波形のピークは、魚の骨と同じなんですけどね。
くいなちゃん: で、素人さんは、この状態にしようと、魚の骨を無視して、 波形のレベルを上げるわけです。 しかし、これには問題があるのです。
くいなちゃん: http://kuina.tes.so/6saiconf_9/img3.png この図を見ればわかるのですが、青のラインが -1.0 ～ 1.0 の範囲をしめしています。 で、無理やり波形を拡大すると、青のラインを超えた部分が潰されて、 右の波形のようなことになってしまいます。これは、元の波形から変わっているので、 当然音も変わります。大抵、ノイズが入った汚い音になってしまいますですー
くいなちゃん: じゃあ、どうするのか。 それは、波形を潰すことなく、波形のピークを下げて -1.0 ～ 1.</description>
    </item>
    
    <item>
      <title>VirtualBoxでHadoop環境を作ってみる</title>
      <link>https://shogo82148.github.io/blog/2012/11/06/hadoop/</link>
      <pubDate>Tue, 06 Nov 2012 23:20:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/11/06/hadoop/</guid>
      <description>隣の人がHadoopいじって遊んでたので，自分もちょっとやっておこうかなと思い少し触ってみました． 実際にマシンを借りて大規模な計算をするのは大変なので， 仮想マシンを作って遊んでみました．
仮想Hadoop環境の構築 巷ではVMWareが人気だったりしますが，今回はVirtualBoxを使ってみたいと思います． なぜかというとVirtualBoxをコンソールから扱えるVagrantで遊んでいたので， ちょうどパソコンにインストールされていたから． 以下，VirtualBoxは既にインストールされているものとして話を進めます．
Cloudera&amp;rsquo;s Hadoop Demo VM for CDH4に VMWare, KVM, VirtualBox用の各種イメージが置いてあるので， VirtualBox用のものをダウンロードしてきます． tar.gzで圧縮されているので解凍しましょう． 中にcloudera-demo-vm.vmdkというファイルが入ってます．
VirtualBoxを起動してHadoop用のマシンを新規作成します． 設定は以下のとおりに
 デモイメージはCentOSベースらしいのでOSタイプとして RedHat**(64bit版)** を選択 メモリは3Gバイト以上 ハードディスクは後で設定するので，「起動ディスク」のチェックを外し割り当てしない  新規作成したら設定を少しいじります．
 IO APICが有効化されていることを確認 ストレージにcloudera-demo-vm.vmdkを追加．この時 IDEコントローラ の下にいれること． ネットワークアダプタをホストオンリーアダプタに設定  これで実行できるようになります．
遊んでみる せっかくなので少し遊んでみる事にします． イメージの置いてあったページにあるHadoop Tutorialをやってみましょう． Hadoopの例として必ず最初に出てくるであろう，Word Countです．
まずソースコードを入力します．
package org.myorg; import java.io.IOException; import java.util.*; import org.apache.hadoop.fs.Path; import org.apache.hadoop.conf.*; import org.apache.hadoop.io.*; import org.apache.hadoop.mapred.*; import org.apache.hadoop.util.*; public class WordCount { public static class Map extends MapReduceBase implements Mapper&amp;lt;LongWritable, Text, Text, IntWritable&amp;gt; { private final static IntWritable one = new IntWritable(1); private Text word = new Text(); public void map(LongWritable key, Text value, OutputCollector&amp;lt;Text, IntWritable&amp;gt; output, Reporter reporter) throws IOException { String line = value.</description>
    </item>
    
    <item>
      <title>PythonでCaboChaを美味しくいただく</title>
      <link>https://shogo82148.github.io/blog/2012/11/01/cabocha/</link>
      <pubDate>Thu, 01 Nov 2012 23:02:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/11/01/cabocha/</guid>
      <description>日本語構文解析器CaboChaをPythonから使ってみたメモ．
インストール CaboCha自体のインストールは公式のドキュメントを参照． ググれば他の人のレポートも出てくるはず．
CaboChaのソースコードを展開したディレクトリの中の pythonディレクトリにPython-bindingが入ってます． そこに移動した後，管理者権限で以下のコマンドを実行すればインストール完了．
python setup.py install 食べ方 解析結果を文字列出力 python/test.py に書いてあるとおり．
#!/usr/bin/python # -*- coding: utf-8 -*- import CaboCha # c = CaboCha.Parser(&amp;#34;&amp;#34;); c = CaboCha.Parser() sentence = &amp;#34;太郎はこの本を二郎を見た女性に渡した。&amp;#34; print c.parseToString(sentence) tree = c.parse(sentence) print tree.toString(CaboCha.FORMAT_TREE) print tree.toString(CaboCha.FORMAT_LATTICE) 以下のような結果が得られれば成功．
&amp;lt;PERSON&amp;gt;太郎&amp;lt;/PERSON&amp;gt;は-----------D この-D | 本を---D | 二郎を-D | 見た-D | 女性に-D 渡した。 EOS &amp;lt;PERSON&amp;gt;太郎&amp;lt;/PERSON&amp;gt;は-----------D この-D | 本を---D | 二郎を-D | 見た-D | 女性に-D 渡した。 EOS * 0 6D 0/1 2.</description>
    </item>
    
    <item>
      <title>Togetterの編集作業便利にしたい</title>
      <link>https://shogo82148.github.io/blog/2012/10/28/togetter-helper/</link>
      <pubDate>Sun, 28 Oct 2012 01:11:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/10/28/togetter-helper/</guid>
      <description>TogetterはTwitterの投稿をまとめられる非常に便利なサイトですが， 編集画面が異様に使いにくいです． そんなわけで前回は 自動的に検索ボタンを押してくれるブックマークレットを書いてみました．
それをユーザスクリプトにして， ついでに編集画面の不便なところを修正してみました．
編集を便利にするユーザスクリプト スクリプトはGistにあげておきました．
 https://gist.github.com/3953476 インストールはこちら  Chrome拡張Tampermonkey で動作を確認しました． この拡張，ユーザスクリプトの管理ができてオススメです．
変更内容 ユーザスクリプトは編集画面に対して次のような変更をします．
 画面レイアウトの変更 自動検索機能 重複削除・ソートの高速化 選択動作の変更 元に戻す機能 ショートカットキーの追加  画面レイアウトの変更 Togetterの編集画面のレイアウト，非常に使いにくいです． ツイート一覧をスクロールしようとしたら画面全体がスクロールしてしまって， 編集用のボタンが隠れてしまう，ということが編集中に何度もあってイライラします．
** 余計なものでごちゃごちゃし過ぎなんだ！ **
** 僕は編集に集中したいんだ！ **
編集と関係の無いヘッダやナビゲーションは要らないので消えてもらうことにしました． ツイートの一覧が画面いっぱいに表示され， 編集用のボタンは常常に画面上に表示されます．
自動検索機能 前回ブックマークレットで実現した機能です． 検索キーワードと一回あたりの読み込み回数を設定し， 「自動検索開始」ボタンを押しましょう． すると，繰り返し間隔を聞いてくるので秒単位で時間を指定しましょう． カウントダウンが始まり，周期的に検索・ソート・重複削除が行われます．
重複削除．ソートの高速化 Togetterのソートのスピードはびっくりするほど遅いです． 例えば，「劇的ビフォーアフター佐世保高専ラグビー部部室をリフォーム」には 1190個のツイートが含まれています． これを時間順にソートしてみたところ， 三回の平均で9.978秒(それぞれの結果は10.118秒, 9.925秒, 9.892秒)かかりました． 1000ツイート程度のソートに約10秒です．遅い！
ソート自体は数ミリ秒で終わるのになんでこんなに遅いというと，結果を画面に反映するのにjQueryのセレクタを大量に呼び出しているから． ソートのときに一回読み込んだものをキャッシュしておけばもっと速くなるはず．
ってことで自前で実装してボタンを置き換えました． 結果0.171秒(0.174, 0.177, 0.161)まで短縮することができました． 約58倍の高速化！
高速化とは直接関係ないけど， 「選択したところだけソート」にしました． ツイートを内容ごとに分類してるときとかに， 一部分だけソートできます(例:ロボコン死亡かるた)． 何も選択されてないときは何もしません． 全体をソートしたい時は明示的に全選択する必要があります．
重複削除とかも実装しなおしました． 約200ミリ秒かかってたのが約20ミリ秒に高速化！
選択動作の変更 もともとの編集画面では，ツイートをクリックするとクリックしたツイートの選択状態が切り替わります． 他に選択しているツイートがある場合，そのツイートは選択されたままです． Excelとかではセルをクリックすると他のセルは非選択状態になるので， それに慣れているとなんだか違和感があるんですよね． そういうわけで，ツイートをクリックしたときはクリックしたツイートのみ選択されるようにしました． 複数選択ができないのも困るので， Ctrlキーと同時クリックでクリックしたツイートを全部選択， Shiftキーと同時クリックで範囲内のツイートを全部選択にしました． Excelとかと一緒ですね．</description>
    </item>
    
    <item>
      <title>6さいカンファレンス 第7回「Windowsのアプリをクラックしよう！(再)」まとめ</title>
      <link>https://shogo82148.github.io/blog/2012/10/27/6saiconf-7/</link>
      <pubDate>Sat, 27 Oct 2012 18:21:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/10/27/6saiconf-7/</guid>
      <description>2012/10/25にくいなちゃんさん主催で開催された6さいカンファレンスのまとめ。 第7回は「Windowsのアプリをクラックしよう！(再)」です。
第4回「Windowsのアプリをクラックしよう！」はどこへいってしまったのでしょう？ 頑張って探したけどこれしか情報が無い・・・？
昨日の ６さいカンファレンスは盛り上がりましたね (第４回 「Windowsのアプリをクラックしよう！」)　来週は、作曲講座をしようと思っています。　お楽しみに☆　#6saiconf
&amp;mdash; くいなちゃんさん (@kuina_tesso) 9月 28, 2012  厳しい緘口令が敷かれているのか，参加者がくいなちゃんさんしか居なかったのか，そもそもそんなのなかったのか・・・．
勝手にまとめてしまったので、何か問題があれば@shogo82148まで。 (カンファレンスの内容にはくいなちゃんライセンスが適用されるらしいです．怖！)
&amp;mdash;&amp;ndash;ｷﾘﾄﾘｾﾝ&amp;mdash;&amp;ndash; くいなちゃん: 10/25(木) 21:00 から、第７回 ６さいカンファレンスを開催します。 テーマは、「Windowsのアプリをクラックしよう！(再)」 です。 ** (再) と付いていますが、前回やった記憶はございません。 ** 参加されない方は、今のうちにご退場お願いします。 ROMでの参加も歓迎ですん☆ それでは、もうしばらくお待ちください。
くいなちゃん: それでは、第７回　６さいカンファレンスを開催します。 テーマは、「Windowsのアプリをクラックしよう！(再)」　ですん☆ しかし、これを開始する前に、いくつかの免責事項をお伝えしなければなりません。 (６さい的な事情)
くいなちゃん: まず、実際に既存の Windowsアプリをクラックする、という流れで 話を進めていきますが、実際にクラックを行っているわけではなく、 また画像も合成です。 実際に既存のアプリに対してクラックする行為は、 場合によっては犯罪となりますので、** 決してマネしないでください **。 本講座は、犯罪を助長する意図があるわけではなく、 むしろ攻撃側を知ることで、防衛スキルを身に着けようというものです！
マインスイーパ！ くいなちゃん: はい、よろしいでしょうか。 では、本日クラックするアプリはこちらです！ http://kuina.tes.so/6saiconf_7/img0.png
くいなちゃん: みなさん大好きな、マインスイーパですん☆ くいなちゃんは、マインスイーパが得意ではないので、上級をクリアする頃には、 時間が999になってしまいます。 そこで、この時間が経過しないよう、改造することを今日の目標としましょう。
くいなちゃん: まず、ollydbg というフリーソフトを起動します。 これは、主に アプリをクラックするのに使われるソフトです[要出典] http://kuina.tes.so/6saiconf_7/img1.png 画像は、ollydbg 上でマインスイーパを起動したところです。</description>
    </item>
    
    <item>
      <title>Twitter公式クライアントのコンシューマキー流出について考える</title>
      <link>https://shogo82148.github.io/blog/2012/10/22/twitter-key/</link>
      <pubDate>Mon, 22 Oct 2012 20:46:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/10/22/twitter-key/</guid>
      <description>コンシューマキー流出？ 朝のTLにTwitter公式クライアントのコンシューマキーなるものが流れてきたので， なにか面白いことに使えないか セキュリティ的に何か問題になるのか 考えてみました．
コンシューマキーとは コンシューマキーとはクライアントの身分証眼書のようなものです． Twitterはコンシューマキーを使用してクライアントを識別します．
このコンシューマキーがどのように使われるのかを知るために， Twitterの認証方式であるOAuthについて簡単なスライドを描いてみました．
 OAuthの認証は大きく分けて次の6ステップからなります．
 認証開始  Twitterの使用を開始するためにユーザはクライアントに認証の開始を指示します   鍵の使用申請書の要求  開始指示を受けたクライアントは，コンシューマキーを利用して身分証明を行います 証明できたクライアントに対してTwitterは鍵の使用申請書を渡します   ユーザの使用許可をもらう  クライアントはユーザに使用申請書を渡し使用許可を求めます 使用申請書はウェブページのアドレスの形で渡されるので，多くの場合ここで自動的にブラウザが立ち上がります   Twitter認証  ユーザはTwitterにパスワードを渡し，クライアントに使用許可することを伝えます   ハンコを受け取る  使用許可の証としてPINコード(ハンコ)を受け取ります PINコードをクライアントに渡します   申請書を鍵を交換  クライアントは使用申請書とTwitterに渡し，鍵をもらいます 次回以降，クライアントは鍵を利用してTwitterにアクセスすることができます    コンシューマキーが流出したということは， ステップ2のクライアントの身分証明の際に「自分は公式クライアントだ！」と名乗ることができてしまうという事です．
一般ユーザに対する影響 さて，これによる一般ユーザへの影響について考えてみましょう．
認証画面の偽装 ステップ4のTwitter認証の際，画面にはクライアント名が表示されます． 公式クライアントのコンシューマキーを使えばここに「Twitter for iPhone」「Twitter for Android」等， 公式クライアントの名前を表示することができてしまいます． これは間違えて認証してしまいそうですね！
・・・でも，ちょっと待ってください． ステップ4にたどり着くには，ユーザ自身が「ステップ1.認証開始」をする必要があります． これをするには，ユーザ自身がソフトをダウンロードして，解凍して，実行する必要があります． ** まともな ** な情報リテラシーを持ったユーザであれば，怪しいソフトは実行すらしませんよね？
偽装Webアプリ Webサイトであれば，アクセスしただけで「ステップ1.認証開始」をしたことにするのは技術的に難しくありません． ステップ1をクリアしてしまえば，流出したクライアントキーを使ってステップ4まで進むことができてしまいます． この時表示されるクライアント名は公式クライアントのものなので，悪意のあるサイトなのか本物なのか見分けが付きません．</description>
    </item>
    
    <item>
      <title>半自動トゥギャりスクリプトを書いてみた</title>
      <link>https://shogo82148.github.io/blog/2012/10/13/semiauto-togetter/</link>
      <pubDate>Sat, 13 Oct 2012 17:35:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/10/13/semiauto-togetter/</guid>
      <description>togetterでたくさんツイートをまとめたい Twitterは手軽に情報収集ができ他人とのコミニュケーションができる楽しいSNSですが、 古いツイートはしばらく経つとタイムラインや検索結果からはたどれなくなってしまいます。 過去のイベントに関するつぶやきを後から見たい、といった場合に不便です。
そこで登場するのがtogetterというサービス。 Twitterのツイートを引用して、「まとめ」を作ることができます。 Twitter上での議論やイベントに対するみんなの反応がわかりやすく見れるので便利です。 僕もJO_RI_botのツイートをまとめたりといろいろとお世話になってます。
簡単なまとめを作るのには非常に便利なtogetter。 しかし、ツイート数が多くなると少し大変です。 例えば何かのイベントのハッシュタグのついたツイートをまとめたい場合、 検索に現れるツイートの数には上限があるので、 漏れ無くツイートを集めるにはイベントの最中にまとめを作る必要があります。 togetterには自動更新機能がないので、数分毎に「検索」ボタンを押さなければなりません。 これは面倒だ・・・
ブックマークレットを書いてみたよ 面倒なので、自動的に検索ボタンを押すブックマークレットを書いてみた。
** ユーザスクリプトで書き直してみたよ！ **
 // 直接書くとなぜかうまくいかない・・・ document.write(&#34;&amp;quot;).insertAfter(a);var%20c=$(&#39;&#39;).appendTo(b);var%20d=$(&#39;&#39;).appendTo(b);var%20e;d.click(function(){if(e){clearInterval(e);d.attr(&amp;quot;value&amp;quot;,&amp;quot;開始&amp;quot;)}else{e=setInterval(g,c.val()*1e3);d.attr(&amp;quot;value&amp;quot;,&amp;quot;停止&amp;quot;);g()}});var%20f={}})()\&#34;半自動トゥギャりスクリプト(このリンクをブックマーク！)&#34;);  上のリンクをブックマークに登録しておき、togetterのまとめ作成ページを開くと、 検索ボックスのしたにテキストボックスとボタンが追加されます。 テキストボックスに検索ボタンを押す間隔(秒単位)を入れ、開始ボタンを押すと、 自動的に検索・移動・重複ツイートの削除・ソートをしてくれます。
スクリプト 元のスクリプトをgistにあげておきます。
{% gist 3883841 %}
ブラウザ拡張のほうが便利だろうけどブックマークレットとして実装しているのは、togetterのスクリプトやjQueryを自前のスクリプトから呼びたかったから。 ブラウザ拡張でも実現する方法はあるんだろうけど、調べるの面倒だからやってない。 DOMの操作だけでもなんとかなりそうだから、余力があれば書きなおすかも。
これ作るにあたって、togetterのソース見てたけど、重複削除やソートアルゴリズムがなんだか残念な感じ。 ツイート数に比例した回数だけjQueryのセレクタを呼び出している。 jQueryのセレクタって結構重い処理だし、オーダーが O( n^2 ) になるわけで・・・。 単なるソートにしては重すぎだろ、とは思ってはいたんだ。まさかこんな中身だとは。</description>
    </item>
    
    <item>
      <title>6さいカンファレンス 第6回「幼女を描いてみよう！　～原画から彩色まで～」まとめ</title>
      <link>https://shogo82148.github.io/blog/2012/10/12/6saiconf-6/</link>
      <pubDate>Fri, 12 Oct 2012 00:28:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/10/12/6saiconf-6/</guid>
      <description>2012/10/11にくいなちゃんさん主催で開催された6さいカンファレンスのまとめ。 第6回は「幼女を描いてみよう！　～原画から彩色まで～」です。
勝手にまとめてしまったので、何か問題があれば@shogo82148まで。 (カンファレンスの内容にはくいなちゃんライセンスが適用されるらしいです．怖！)
ゆるふわ☆タイム くいなちゃん: 今日も、前回と引き続き、プログラミングのプの字も出てこない、ゆるふわ講義ですん☆
くいなちゃん: テーマは 「幼女を描いてみよう！　～原画から彩色まで～」 ということなので、今回描いてみた絵を、いきなり完成形からご覧いただくことにします。 ３時間で描いたです。 http://kuina.tes.so/6saiconf_6/img0.jpg
構図を描いてみるです！ くいなちゃん: では、順を追って、描いていくことにしましょう。 最初はもちろん、カンヴァスは白紙です。 そこに、まずは構図をﾃｷﾄｰに描いてみるです： http://kuina.tes.so/6saiconf_6/img1.jpg はい、ここまではみなさん描けますね。 まるで６さいが描いたようなﾃｷﾄｰな落書きです。
くいなちゃん: ここでのポイントは、脳内に立体をイメージすることです。 構図をイメージしやすいように、背景に線を引いていますが、無くてもイメージできるなら描く必要はありません。 注意してほしいのは、2D絵を描くからといって、2Dで捉えないことです。 アニメ絵でも同様ですん
くいなちゃん: はい、キャラに、顔と髪を追加してみました。 http://kuina.tes.so/6saiconf_6/img2.jpg えっ、完成形と絵が違う？ キニシナイ！ あと、独りでは寂しいので、小鳥も追加しました。
色を塗っていくです！ くいなちゃん: アニメ調の絵を描く場合は、ここからアニメ塗りをしていただけば完成しそうなんですが、せっかくなので、油彩画っぽく塗っていくことにします。
くいなちゃん: まずは、べた塗りです。 http://kuina.tes.so/6saiconf_6/img3.jpg
くいなちゃん: なんてことはありません。 太いブラシで、ﾃｷﾄｰに塗っただけです。 はみ出しまくってますね。　しかし、ブラシが太いので、細かな部分はそもそも塗れません。 このくらいﾃｷﾄｰでもキニシナイでok
くいなちゃん: 人物に影が、若干付けられていますが、原画を描くときに立体を意識したならば、光源を意識すればある程度付けられると思います。 物理学的に考えるのです！
細部を塗っていくです！ くいなちゃん: はい、次は、もう少し細いブラシで、細部を塗っていきます。http://kuina.tes.so/6saiconf_6/img4.jpg 基本的には、最初に太いブラシで大まかに塗り、徐々にブラシを細くしていき、細部を描きこんでいく流れですね。 ブラシの目安は、半々にしていくと良さそうです
くいなちゃん: この時点で、服に謎の模様が描かれていますが、ﾃｷﾄｰです。 その太さのブラシで表現できる粒度のものを塗ってください。
くいなちゃん: で、更に細いブラシで塗っていきます(3段階目)　そして、このあたりまで塗ったら、試しに線画(原画)を外してみましょう。 http://kuina.tes.so/6saiconf_6/img5.jpg おや、線画が無くても 綺麗に見えますね！
くいなちゃん: 目を描きこんでいなかったのは、意図的です。 最初のアニメ調の絵で完成させたい場合は、目も塗ってあげてください。
顔を描くです！ くいなちゃん: はい、それでは、もう線画が無くても輪郭が解りますので、線画は非表示にしたまま塗っていきましょう。 更に細いブラシで塗ります。</description>
    </item>
    
    <item>
      <title>6さいカンファレンス 第5回「６さいからの作曲講座」まとめ</title>
      <link>https://shogo82148.github.io/blog/2012/10/11/6saiconf-5/</link>
      <pubDate>Thu, 11 Oct 2012 12:37:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/10/11/6saiconf-5/</guid>
      <description>2012/10/04にくいなちゃんさん主催で開催された6さいカンファレンスのまとめ。 第5回は「６さいからの作曲講座」です。
勝手にまとめてしまったので、何か問題があれば@shogo82148まで。 (カンファレンスの内容にはくいなちゃんライセンスが適用されるらしいです．怖！)
THE END くいなちゃん: みなさん、楽譜は読めますね！(ﾁﾗｯ
くいなちゃん: 今回は、作曲理論などの難しい講義というよりも、実際にどうすれば綺麗な曲が作れるのか、という実践的な内容になっています。 くいなちゃんの独自理論ですん
くいなちゃん: では、さっそく、曲を作ってみましょうー
コード くいなちゃん: はい、まず曲に必要なのは、　&amp;ldquo;コード&amp;rdquo;　です。　「えっ、メロディじゃ？」 と言った あなたは素人です。 コードをしっかり押さえない曲は、聴くに堪えない感じになってしまいます。 くいなちゃんは、コードもメロディも全部同時に浮かぶことのできる天才肌ですが、とりあえず今回はコードを中心に創っていきましょう！
くいなちゃん: コードのルール： ** 「あるコードには、移りやすい次のコードが ある程度決まっている」 ** です！ たとえば、C(ド・ミ・ソ) のコードからは、G(ソ・シ・レ) や F(略) や Am(略) に移りやすいです。　逆に、G や F から、 C にも移りやすいです。
くいなちゃん: ということなので、C → G → C → G　は移りやすいコードのルールで作ったので、自然なコードということになりますね。　このコードで曲を作っていきましょ！
くいなちゃん: はい、この楽譜をご覧ください。　C(ドミソ) と G(ソシレ) が交互に来ているのが解るかと思います。　わからない人は、じっくり読んでね。 http://kuina.tes.so/6saiconf_5/img0.png(魚拓)
くいなちゃん: はい、コード完成です！ せっかくなので、これを鳴らしてみましょう。 http://kuina.tes.so/6saiconf_5/snd0.mp3
くいなちゃん: 自然ですね！
メロディをのせる くいなちゃん: では、コードが完成したので、メロディを乗せて行きましょう。 メロディのルール： ** 「拍子の部分には、コードの音を使う」 ** です！ さっきの、音が鳴っているタイミングの部分に、コードの音を使って、メロディを配置してみましょう。</description>
    </item>
    
    <item>
      <title>6さいカンファレンス 第3回「アルゴリズムを自力で生み出すプログラムを作ろう！」まとめ</title>
      <link>https://shogo82148.github.io/blog/2012/10/04/6saiconf-3/</link>
      <pubDate>Thu, 04 Oct 2012 16:58:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/10/04/6saiconf-3/</guid>
      <description>2012/09/06にくいなちゃんさん主催で開催された6さいカンファレンスのまとめ。 第3回は「アルゴリズムを自力で生み出すプログラムを作ろう！」です。
勝手にまとめてしまったので、何か問題があれば@shogo82148まで。
 function Tree() { this.value = &#39;&#39;; this.children = []; } Tree.prototype.dump = function() { var result = this.value; var i; for(i = 0; i = 5 ? 6 : (Math.random()*7|0)) { case 0: result.value = &#39;+&#39;; numchildren = 2; break; case 1: result.value = &#39;-&#39;; numchildren = 2; break; case 2: result.value = &#39;*&#39;; numchildren = 2; break; case 3: result.value = &#39;/&#39;; numchildren = 2; break; case 4: result.</description>
    </item>
    
    <item>
      <title>リアルタイムにテンションを上げてみた</title>
      <link>https://shogo82148.github.io/blog/2012/10/03/tension-upper/</link>
      <pubDate>Wed, 03 Oct 2012 11:42:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/10/03/tension-upper/</guid>
      <description>昨日，Twitterで猫型さんのアイコンのテンションが上がっている話をしていたら， こんな無茶ぶりをされたんですよ．
明日には、いっちーがWebRTCでリアルタイムテンション上がってきたサービス作ってくれるだろうし、猫型さんがアプリの申請出してるだろう
&amp;mdash; Takashi Sasakiさん (@civic) 10月 2, 2012  いいだろう，その挑戦受けてやる！
WebRTCって？ WebRTCというのはブラウザ上で Real Time Communication を行うAPI群のことことです．
 ローカルデバイス(Webカメラとかマイクとか)へのアクセス ブラウザ同士が(サーバを介さずに)直接通信  なんてことができるようになるらしいです． つまり WebRTCを使えば Skype っぽいものをプラグインのインストールなしにブラウザ上で実現できるってわけですね． Chrome の最新安定版で、ウェブの最先端に触れてみようから いろいろなWebRTCを使ったデモを見ることができます． 僕も似顔絵描いてもらったりしてみました．
getUserMedia API を使ってみる まだまだ仕様策定中で対応ブラウザがほとんどない状況ですが， 2012年10月現在，最新版の Chrome 21 で前者のローカルデバイスへアクセスするAPIである getUserMedia API が使えるようです． 早速遊んでみましょう．
navigator.getUserMedia( {video: true}, // constrains: 接続先のデバイス  function successCallback(stream) { // アクセス成功  // stream に LocalMediaStream オブジェクトが入ってる  // &amp;lt;video id=&amp;#34;video&amp;#34;&amp;gt;&amp;lt;/video&amp;gt; 要素を取ってくる  var video = document.</description>
    </item>
    
    <item>
      <title>6さいカンファレンス 第2回「数学の定理を自動で発見するAI を Haskellで作ろう！」まとめ</title>
      <link>https://shogo82148.github.io/blog/2012/10/02/6saiconf-2/</link>
      <pubDate>Tue, 02 Oct 2012 13:07:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/10/02/6saiconf-2/</guid>
      <description>2012/09/13にくいなちゃんさん主催で開催された6さいカンファレンスのまとめ。 第2回は「数学の定理を自動で発見するAI を Haskellで作ろう！」です。
勝手にまとめてしまったので、何か問題があれば@shogo82148まで。
WELCOME TO HELL!! くいなちゃん: それでは、まず、数学の「定理」とは何か、について説明したいと思います。 みなさん、日常的に「定理」という言葉を使っていると思いますが、「定理」とは何か、説明できますか
くいなちゃん: 「教科書に載っている公式が、定理だ！」と思うかもしれませんね。 確かに、教科書にも定理は載っています。
くいなちゃん: では、曖昧な理解の方のために、厳密かつ ゆるふわに説明しましょう。
くいなちゃん: 定理とは、次のように定義できます。
 公理であるならば、定理である。 定理を推論規則によって推論したものは、定理である。  以上。
くいなちゃん: はい、みなさんこれで定理が何かを理解したと思いますので、数学の定理を自動で発見するAIを作ろうと思います。
くいなちゃん: Haskellで。
Haskell! くいなちゃん: そもそも、Haskellって何？ という方もおられるかと思いますので、まずは Haskell について簡単に説明しておきたいと思います。
くいなちゃん: Haskell は、関数型言語です。 宣言的プログラミングによって、プログラムしていくプログラミング言語です。「○○は××である！」というのを繰り返してプログラミングする感じですね。　「まずは○○して、次に××しろ！」という C言語(手続き型言語)とはかなり異なります。
くいなちゃん: では具体的に、今回定理を発見するための数学の体系を説明しながら、同時に Haskell で実装してみることにしましょう。
くいなちゃん: 最終的には 大規模な数学体系の定理を発見するとしても、まずは試しに小さな体系で定理を発見してみることを考えます。 今回は、命題論理を対象としてみます。
定義 くいなちゃん: では、今回対象とする命題論理を、厳密に定義していきましょう。 まず、この体系で用いられる記号は、P　Q　R　￢　⇒　の5種類です。 この5種類をうまく並べると、この数学体系でのあらゆる式や命題が記述できます。
くいなちゃん: まあ、たとえば、　P⇒P　(PならばPである)　といった感じですん。 わかりますね。
くいなちゃん: ￢　は数学における否定によく使われる記号ですが、いまのところ、単なる記号にすぎず、意味は定義されていません
くいなちゃん: ちなみに、くいなちゃんはポーランド記法が好きなので、　P⇒P　を、　⇒PP　と書くことにしましょう</description>
    </item>
    
    <item>
      <title>6さいカンファレンス 第1回「C言語で作る、はじめてのDAW制作」まとめ</title>
      <link>https://shogo82148.github.io/blog/2012/09/30/6saiconf-1/</link>
      <pubDate>Sun, 30 Sep 2012 20:33:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/09/30/6saiconf-1/</guid>
      <description>だいぶ時間がたってしまったけど、2012/09/06にくいなちゃんさん主催で開催された6さいカンファレンスのまとめ。 第1回は「C言語で作る、はじめてのDAWソフト制作」です。
勝手にまとめてしまったので、何か問題があれば@shogo82148まで。
 (function(global) { global.executeC = executeC; function base64(input) { var i, length = input.length; var val; var s = &#39;&#39;; var table = &#39;ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/&#39;; for(i = 0; i 18)&amp;0x3F) + table.charAt((val12)&amp;0x3F) + (i + 1 6) &amp; 0x3F) : &#39;=&#39;) + (i + 2 8) &amp; 0xFF); break; case 4: fp.push(val &amp; 0xFF); fp.push((val8) &amp; 0xFF); fp.push((val16) &amp; 0xFF); fp.push((val24) &amp; 0xFF); break; default: throw &#39;fwrite: invalid size&#39;; } } else { switch(size) { case 1: for(i=0;i8) &amp; 0xFF); } break; case 4: for(i=0;i8) &amp; 0xFF); fp.</description>
    </item>
    
    <item>
      <title>NDS28に参加してきた #nds28</title>
      <link>https://shogo82148.github.io/blog/2012/09/24/nds28/</link>
      <pubDate>Mon, 24 Sep 2012 14:29:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/09/24/nds28/</guid>
      <description>先週土曜日は第28回NDS(長岡技術者勉強会)でした。
スーツ vs ギーク Togetterのまとめを見ながら、内容を頑張って思い出してみる。 (せっかくローカルでブログ書ける環境作ったんだから、ちゃんとメモっとくべきですね・・・と思いつつ毎回できない)
 プログラマは誰でもいい？  人に依存しないことはいいこと でも、本当にそれでいいの？ 能力があれば誰もいいのかも 社長の方が誰でもいい   (自称)ギークなスーツ  「これからはHadoopらしいよ」   ギークにもユーザの対応して欲しい  「技術的な制限で無理」なことを説明するときとか 浅い知識だけでは矛盾点を突かれて、Yesと言わざる負えない時も 「ときどき行く→ギーク行くといいじゃんってなる→ときどきが毎回になる」と困るよね   判断を全部ギークに丸投げしないで！  例えば、初期コストを取るか、拡張性を取るか、とか 技術的な利点・欠点は説明するけど、実際どっち使うかの判断はスーツな人にお願いしたい   スーツを手玉に取るコミュ力  コミュ力の低いギークは技術力を生かせなくてもったいない！ ギークもコミュ力を身につけるべき   名選手と名監督は両立しない  技術者からの叩き上げでマネージメントする側になった人は他人を上手く使えない マネージメント系は手足のように他人を使えなければならない    社会は怖いところです。
通常セッション  マッチョ見積もり by @hiro55bsさん  「つまり、見積りは予想ではなく、帳尻をあわせるものなんだよ！」 見積もりはリスク管理、プロジェクト初期だけでなく随時やっていくもの プロジェクト初期では見積もりに幅があって当然 もる いろんな統計データからざっくり見積もれるんですね。勉強になります。   ワンライナーでノイズミュージック by @neko_gata_sさん  Experimental music from very short C programsに触発されたというお話 RIFFヘッダつけるとこは Perl でやってます！ 波といえば正弦波の組み合わせで・・・と思っていたので、ビット演算で音を出してみるというのはおもしろいです。ぜひやってみたいです。    LT  SIの現場から感じた未来 by @nemuzukaさん  現在の契約形態に対する問題提起 皆さんで考えて行きましょう   RubyMotionでiOSゲームを作るっきゃない by @jewel_x12さん  Pythonが主人公のゲーム Android版はまだですか？   Echigo Network Operators&#39; Group について by @yyasuyukiさん  コイントスで決めよう    お姉さんのコンピュータを高速化したお話 補足とか スライド上げようと思ったんですけど、よく考えたら半分他人さまの画像使ってるのであまりよろしくないですね。 検索アルゴリズムの紹介などは「おねえさんのコンピュータを作ってみた」を ご覧ください。</description>
    </item>
    
    <item>
      <title>おねえさんのコンピュータを作ってみた</title>
      <link>https://shogo82148.github.io/blog/2012/09/22/letscount/</link>
      <pubDate>Sat, 22 Sep 2012 11:08:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/09/22/letscount/</guid>
      <description>まだやってたのか、と言われてしまいそうですが、おねえさんが計算にかけた時間と比べればまだまだです。
『フカシギの数え方』 おねえさんといっしょ！ みんなで数えてみよう！
 この動画で出てくるおねえさんのコンピュータを作ってみた、というお話。
おねえさんのコンピュータからアクセスできます。
検索アルゴリズム HTML+CSSでコンピュータの画面を再現してみました。Javascriptを組むより、そっちの方に時間がかかった気がする。 経路の描画にはCanvasを使ってます。
この問題は自己回避歩行(Self-avoiding walk)と呼ばれるものらしいです。 単にグラフ上を移動するだけなので、小さいなサイズなら単純な深さ優先検索(DFS)で解けます(大きなサイズで何が起こるのか・・・それは動画で)。 実装では、DFSによる検索プログラムをWeb Workerを使って走らせ、スタートとゴールを結ぶ経路を見つけたらメッセージを飛ばしてます。
さすがに全部は表示できないので、実際に表示するのは50ms秒程度の間隔。 4×4以下ではそれだと速すぎて何が何だかわからないので、待ち時間を入れてある。
さあ、君も10×10にチャレンジだ！！
おねえさんに教えて上げよう！ しかしながらDFSだけだとなんだか負けた気がして悔しいので、高速化したアルゴリズムも試してみた。 「おねえさんに教えてあげる」のチェックボックスにチェックを入れると高速化したアルゴリズムで問題を解きます。
ゼロサプレス型二分決定グラフ 自分が色々試行錯誤している間に他の人が解いてしまった(「フカシギの数え方」の問題を解いてみた) ので、それを参考に実装してみた。
今回の問題は「グラフ上の経路問題」ですが、どの枝を通ってどの枝を通らないかという「枝の選択問題」として考えることができます。 その組み合わせを効率良く表すための方法が、ゼロサプレス型二分決定グラフ(ZDD; Zero-Suppressed Binary Decision Diagram)。 ZDDは数学の組み合わせでよく使う樹形図の一種で、 同じ結果になる枝を集めることで樹形図を効率良く表したものです。 概要はBDD/ZDDを基盤とする離散構造と処理演算系の最近の展望 を参照。 もっと詳しい説明はThe Art of Computer Programmingに書いてあるらしい(まだ読んでない)。
ZDDを考えた湊先生は最初の動画の企画・監修も努めている方なので、 動画中の数値もZDDを使って求めたものと思われます。
Simpath ZDDは単なる組み合わせの表現方法なので、別途グラフからZDDを求める手法が必要になります。 これに関する簡単な解説がZDDを用いたパスの列挙と索引生成 から見られます。
上のセミナー資料ではZDDの基本演算を使った列挙の方法が紹介されているけど、 今回はクヌース先生のSimpathを採用。 Simpathでは(既約でない)ZDDを作ることができます。 経路の両端にのみ着目し、この情報をmateという配列で管理。 frontierと呼ばれる頂点のmateを用いてZDD上のノードを共有することで簡略化を行います。
実際使ったアルゴリズム セミナー資料では幅優先でノードを作ってみるように見えるけど、今回の実装では深さ優先で経路数だけカウント。 ZDDのノードを作るのが面倒だったんです。 しかし、覚えなければならないmateが大量になってしまいメモリがああああ！！ すべて覚えるのは諦め、一部のmateだけ覚えるようにしました。
「おねえさんに教えてあげる」のチェックを入れると、適当実装のSimpathで計算します。 計算中一部の枝が灰色になるのは、ZDD上でノードの共有化が行われたため、実際には枝が処理されなかったためです。 格子上の点に丸がついているのはfrontier。 この点の継続情報を用いて共有化を行います。
まとめ おねえさんのコンピュータの実装と高速化を行いました。 高速化の結果、処理に数分かかっていた6×6の計算が200msで終わるようになりました。 10×10も1分程度で終わります。
ただ、表示のためのオーバーヘッドがあるとはいえ、他の人と比べると少し遅いような。 なにか実装間違っているかも。 The Art of Computer Programmingを読んで勉強しないとかな。</description>
    </item>
    
    <item>
      <title>VeeWeeでVagrantのboxを作ってみた</title>
      <link>https://shogo82148.github.io/blog/2012/09/01/veewee/</link>
      <pubDate>Sat, 01 Sep 2012 15:26:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/09/01/veewee/</guid>
      <description>Vagrant VagrantはコマンドラインからVirtualBoxを扱えるようにするツール。 仮想マシンの起動・再起動をコマンドライン上から行えるのはもちろん、Chefや Puppet と連携することで必要なソフトウェアのインストールを行なってくれます。
Vagrantを使うには仮想マシンのひな形であるBase Boxが必要です。 Vagrantbox.esにいろんなOSのBoxがあるけど、 インストールされているOSのバージョンが古かったり、タイムゾーンがUTCになっていたりして 不具合発生。 そこでBoxを自分で作ってみようと思い立ち、やってみたのでそのメモ。
作ったBoxは GitHub にあげておいたので使いたい方はどうぞ。 Ubuntu 12.04.2 Server + VirtualBox 4.2.10 で作ってあります。
vagrant box add myubuntu http://shogo82148.github.com/boxes/ubuntu-12.04.2-amd64.box VeeWee VeeWeeはBoxの作成を自動化してくれるツール。 OSのインストール、不要なパッケージの削除、Box化なんかを自動でやってくれるらしい。
VagrantとVeeWeeのインストール Rubyの実行環境とVirtualBoxのインストールを済ませたら、 gemを使ってVagrantとVeeWeeをインストール。
gem install vagrant gem install veewee 使ってみる vagrant basebox templates と打つとテンプレートの一覧が出てくる。 現時点でのUbuntu最新版であるUbuntu 12.04をテンプレートとして使ってみる。
vagrant basebox define myubuntu ubuntu-12.04-server-amd64 これでdefinitions/myubuntuの中に設定ファイルができる。
そのままだとisoのダウンロードで404が帰ってくるので設定ファイルを書き換え。 加えて日本語が使えるようにLocaleをja_JPに、タイムゾーンをAsia/Tokyoにしておく。
--- templates/ubuntu-12.04-server-amd64/definition.rb 2012-08-31 18:23:28.000000000 +0900 +++ definitions/myubuntu/definition.rb 2012-08-31 21:17:52.000000000 +0900 @@ -6,8 +6,8 @@  :hostiocache =&amp;gt; &amp;#39;off&amp;#39;, :os_type_id =&amp;gt; &amp;#39;Ubuntu_64&amp;#39;, :iso_file =&amp;gt; &amp;#34;ubuntu-12.</description>
    </item>
    
    <item>
      <title>Octopress用OEmbedプラグインを作ってみた</title>
      <link>https://shogo82148.github.io/blog/2012/08/09/oembed/</link>
      <pubDate>Thu, 09 Aug 2012 18:43:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/08/09/oembed/</guid>
      <description>Octopressでツイートを引用しようと思ったけど 使えそうなプラグインがなかったので作ってみた。 ツイートに限らずいろんなものを挿入できるよ！
OEmbed 調べてみるとツイートの表示はOEmbedというのを使うとできるらしい。 これはURLを埋め込み適した形に変換してくれるプロトコル。 ツイートのURLから引用のためのHTMLを作ったり、YouTubeのURLから動画再生用のHTMLを作ることができる。
せっかくだからOEmbedに対応してしまえばいろんなものを埋め込めて便利だよね！ってことでやってみた。
インストール ruby-oembedをインストール。
gem install ruby-oembed ruby-oembedは名前から想像できる通り、RubyでOEmbedプロトコルを扱うためのライブラリ。 Provider(OEmbedの提供者)を自分で追加したり、Discovery(HTMLドキュメントにProviderの情報を入れる)にも対応している。 しかし、プロキシ環境下で動かなかったり、文字コードのエラーを吐いて死んだりしたので、 フォークして改造版ruby-oembedを作った。 もしオリジナルで不具合が出るようなら、こちらもどうぞ。
oembed_tagからoembed_tag.rbをダウンロードして、pluginsフォルダに置く。
Gemfileを適当なテキストエディタで開き、「gem &amp;lsquo;ruby-oembed&amp;rsquo;」の行を追加
source &amp;#34;http://rubygems.org&amp;#34; group :development do gem &amp;#39;rake&amp;#39; gem &amp;#39;rack&amp;#39; gem &amp;#39;jekyll&amp;#39; gem &amp;#39;rdiscount&amp;#39; gem &amp;#39;pygments.rb&amp;#39; gem &amp;#39;RedCloth&amp;#39; gem &amp;#39;haml&amp;#39;, &amp;#39;&amp;gt;= 3.1&amp;#39; gem &amp;#39;compass&amp;#39;, &amp;#39;&amp;gt;= 0.11&amp;#39; gem &amp;#39;rubypants&amp;#39; gem &amp;#39;rb-fsevent&amp;#39; gem &amp;#39;stringex&amp;#39; gem &amp;#39;liquid&amp;#39;, &amp;#39;2.2.2&amp;#39; gem &amp;#39;ruby-oembed&amp;#39; #追加 end gem &amp;#39;sinatra&amp;#39;, &amp;#39;1.2.6&amp;#39; これでとりあえずは動くはず。 以上の作業に加えて、キャッシュファイルがリポジトリに含まれないよう.gitignoreに.oembed-cacheを追加しておく。
使い方 以下の様に書くと、適切な埋め込み方法をWebから取得して変換してくれる。
&amp;amp;#123;% oembed URL %&amp;amp;#125; 例 Twitter &amp;amp;#123;% oembed https://twitter.</description>
    </item>
    
    <item>
      <title>OMakeの使い方復習</title>
      <link>https://shogo82148.github.io/blog/2012/08/09/omake/</link>
      <pubDate>Thu, 09 Aug 2012 11:13:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/08/09/omake/</guid>
      <description>久しぶりにOMakeを使おうと思ったら、使い方を忘れてしまったので復習。
基本的な流れ 初期化 OMakeのインストールはaptitudeやyumやDownload OMakeあたりで頑張る。 OMakeがインストールできたら、まずは初期化のおまじない。
omake --install カレントディレクトリにOmakefileとOmakerootが作られる。 自分のプロジェクト内容に合わせてOmakefileを編集。 具体的な例は後述。
ビルドする 単に「omake」と打つとビルド
omake 継続監視ビルド 「-P」オプションで継続監視ビルド
omake -P 関連するファイルを監視して、変更があれば自動的にビルドしてくれる。
キャッシュの削除 OMakeでビルドすると環境依存なパスの設定とかを書き込んだファイルが作成される。 Dropboxなどの同期ソフトはこれらの設定ファイルも同期してしまうので、 別環境で作業しようとするとエラーを吐いて止まってしまう。
次のコマンドでキャッシュファイルを無視すれば大丈夫。
omake --flush-includes Omakefileの例 TeXの文章をビルドするOMakefileの例。 LinuxとWindowsでデフォルトの文字コードが違って面倒なので、文字コードはutf-8に統一。 PDF出力はA3サイズ。
{% gist 3300749 OMakefile %}
prosperを使ってプレゼン資料を作った時のOMakefile。 dvipdfmでは処理できない場合があるので、一度PostScriptにしてからPDFに変換するようにルールを上書き。 数式を多用するようなプレゼン資料だと便利。
{% gist 3300749 OMakefile-slide %}
参考  OMake つかったらC言語でプログラム書く手間がバカみたいに減った OMake つかって LaTeX コンパイルしたら簡単すぎて身長が5cm伸びた OMake マニュアル日本語訳 omakeが動かない &amp;hellip;. 動いた [卒論] LaTeXのビルドにOMakeを使ってみた  おまけ Dropboxと連携するとこんなことも。
Dropboxで同期しているフォルダで、「omake -P」を実行して自動コンパイルする設定のまま放置してきちゃった。別のPCでソース書き換えると、Dropboxが同期→リモートのomakeが自動コンパイル→Dropbox経由でコンパイル結果が帰ってきた。
&amp;mdash; Ichinose Shogoさん (@shogo82148) 9月 27, 2011  </description>
    </item>
    
    <item>
      <title>夏だ！花火だ！Androidで遊ぼう！</title>
      <link>https://shogo82148.github.io/blog/2012/08/02/fireworks/</link>
      <pubDate>Thu, 02 Aug 2012 14:43:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/08/02/fireworks/</guid>
      <description>さあ、皆さん！今年も長岡の大花火大会の季節がやって参りました！
花火大会といえば、 光と音の速度差を体感できる絶好の機会です。 というわけで、去年もこんなアプリを作って遊んでました。 このアプリを頑張って改良したので、改めて紹介したいと思います。
アプリをダウンロード
使い方 起動すると、こんな画面が表示されます。
花火が開いたら画面をタップ！ そして、花火が画面中央に来るよう素早く端末を動かします。 (※画像ははめ込み合成です)
花火の音がしたら、目標をセンターに入れてタップ！
タップの間隔から花火までの距離を計算し表示してくれます。 さらに、加速度センサの値から端末の仰角を読み取り、花火の高さや水平距離などを算出してくれるという機能もついてます。
去年からの変更点 と、ここまでは、去年と一緒。 今年はさらにパワーアップしました。
地図へのマッピング スマートフォンには磁気センサがついており、方位が分かります。 加えて、GPSもついているので、スマートフォンの現在位置も分かります。 これだけの情報が揃えば、地図にプロットできるはず！
結果表示の画面で「地図を表示」を選ぶとマッピングしてくれます。 この画面でメニューキーを押すと、TwitterやGoogle+などで、花火の位置をみんなに知らせることもできます。
GPS測位ができない場合は、デフォルトの位置を使用します。 この位置は設定画面で変更できます。
自動花火検出 去年からの課題であった、花火の自動検出も試みてみました。 初期画面でメニューキーを押すと設定画面へ飛べます。
ここで「花火を自動的に検出する」「花火の音を検出する」を選択すると、自動検出してくれるはずです(※理論値)。
花火が開いたことは、画面が明るくなったことで検出します。 明るさの検出は初期画面中央の四角の中が使われます。 設定画面でこの四角の大きさを変えることができます。 明るさの変化が閾値を超えたら測定開始です。
音は音量で検出します。 音声にDFTをかけて、周波数フィルタリングをかけてあります。 これで人ごみにまぎれても花火の音が検出できる・・・はず。 周波数0Hzにすると、周波数フィルタを通さずに振幅のみで判定します。
検出した値は、画面の右上に表示しているので、設定の時の参考にしてください。
ダウンロード アプリをダウンロード
野良アプリなので、「設定→アプリケーション→提供元不明のアプリ」をチェックする必要があります。 スマートフォンの機能をフル活用するので権限をたくさん要求してきますが、きっとだいじょうぶ。 そろそろマーケットでの公開も試してみたいですね。
** Google Play にリリースしました！ ** Google Play からアプリをダウンロード まとめ それでは、大幅に機能UPしたアプリと一緒に、長岡の大花火大会をお楽しみください。
打ち上げはこのあたりらしいです。 ちゃんとマッピングできますかね？</description>
    </item>
    
    <item>
      <title>Gitでプロキシを使う</title>
      <link>https://shogo82148.github.io/blog/2012/07/30/git-proxy/</link>
      <pubDate>Mon, 30 Jul 2012 21:10:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/07/30/git-proxy/</guid>
      <description>背景・目的 なぜだか研究室のWiFi経由でSSHが通らないので、 GithubがBitbucketに繋がらない＞＜。 有線LAN経由なら通るので、ネットワークの問題だと思うのですが、 よくわからないのでとりあえずHTTPS経由で頑張ることにしました。
うちの学校ではHTTPSで外部に出るにはプロキシの設定が必要です。 そういうわけで、Gitでプロキシを使う方法を調べて見ました。
方法 .ssh/config に以下の設定をしました。
Host github.com User git Port 22 # or 443 Hostname github.com # or ssh.github.com IdentityFile /path/to/ssh.key TCPKeepAlive yes IdentitiesOnly yes ProxyCommand nc -X connect -x proxy.example.com:8080 %h %p  参考文献  git pull/push to github.com in proxy environment http proxy 越えの ssh SSHでプロキシ経由でアクセス  </description>
    </item>
    
    <item>
      <title>NDS27に参加してきた</title>
      <link>https://shogo82148.github.io/blog/2012/07/29/nds27/</link>
      <pubDate>Sun, 29 Jul 2012 23:45:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/07/29/nds27/</guid>
      <description>第27回NDS(長岡技術者勉強会)に参加してきました。
Gitハンズオン 今回はNiigata.scmとのコラボで GitハンズオンといつものLTの二本立てでした。
@masaru_b_clさんのGitの歴史や利点についての解説の後、 @dictavさんによる解説・演習。
 addしてcommitする logやreflogでログ確認 reset &amp;ndash;hard で元に戻す merge rebaseでコミットログを一本道に  あたりをやりました。
一つのファイルの同じ行を20人でいじるという怖いこともしました。 凄まじいコンフリクト発生頻度と、すごい勢いで分岐していくログ。 実際の現場であったら恐ろしいですね。 gitはプラグインが使えるので、いろんなプラグインが出てます。 今回紹介があったのはgit-nowとgit-master。名前だけは聞いたことあるんだけど、使ってみますかね。
 git-now masuru_b_clさんバージョン git-master  あと、コミットログ英文の書き方とか
  Changelogのための英文テンプレート集
  ust Gitの説明
  ust 午前の演習その1
  ust 午前の演習その2
  ust 午後の部 push戦争
  いつものLT  電子国土と地形図(その後) (@yu_hori)[http://twitter.com/yu_hori]さん  NDS23での電子国土地図の発表の続き。 利用者にとって価値ある使いやすい電子国土基本図を目指して(中間提言) 電子国土ポータル   長岡にギークハウスを @geek_niigataさん やったーPICで作曲できたよー＼(�o�)／ @aokcub  うおおおおおおおおおお！！！！ 期待の21世紀枠最後の昭和枠 NDS27に参加してきたよ！よ！   git-svn @masaru_c_blさん  svnのリポジトリをgitにしてしまう奴。   ソフトウェアメトリクス調査2012を読み解く @hiro55bsさん  ソフトウェアメトリックス調査2012 COBOL&amp;hellip; 品質が低いと顧客満足度も低いけど、逆に品質が高すぎても顧客満足度は低い お客さんの要望に十分に答えられないのが原因？   やったーPerlでにゃん読化ツールできたよー＼(�o�)／ @neko_gata_sさん  Niigata.</description>
    </item>
    
    <item>
      <title>CやC&#43;&#43;でのincludeの優先順位</title>
      <link>https://shogo82148.github.io/blog/2012/06/26/c-include/</link>
      <pubDate>Tue, 26 Jun 2012 11:13:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/06/26/c-include/</guid>
      <description>こんにちは、gccのオプションを十個も言えない、非人のshogoです。
工藤氏作のTinySVMで遊ぼうとしていたところ、 ヘッダファイルの読み込み順序ではまったのでメモ。
2つのinclude文 皆さんご存知の通り、Cプリプロセッサの#include文ではファイルの指定方法が2種類あります。
 include &amp;lt;somefile&amp;gt; // システムにインストールされたライブラリを使う場合 include &amp;quot;somefile&amp;quot; // 自作のヘッダファイルなどを読み込む場合  大抵はコメントで書いたような使い分けをするんじゃないかと思います。 両者の違いはファイルの検索対象となるディレクトリの違いにあります。 前者はコンパイラが知っているディレクトリのみを検索するのに対して、 後者はカレントディレクトリを検索したのち、&amp;lt;&amp;gt;と同じディレクトリを検索します。
コンパイラが知っているディレクトリは具体的に書くと次のようになっています。
 -I オプションで指定されたディレクトリ 環境変数 C�INCLUDE�PATH や CPLUS�INCLUDE�PATH で指定されたディレクトリ システムによって予め決められたディレクトリ(/usr/local/includeとか)  上にあるものほど優先順位高く、同名のファイルがあった場合、優先順位の高いディレクトリにあるものが読み込まれます。
標準のヘッダを使いたい 次のようなCのプログラムを考えてみます。
/* sample.c */ #include &amp;lt;stdio.h&amp;gt; // 標準ヘッダのstdio.hを取り込んでほしい！#include &amp;#34;stdio.h&amp;#34; // ../userheaderディレクトリ内のstdio.hを取り込んでほしい！最初のincludeではシステムに用意された標準ヘッダのstdio.hを、 2つ目のincludeでは自前で用意したstdio.hを読み込もうとしています。 しかし、自前で用意したstdio.hはuserheaderという別ディレクトリにあるので このままでは参照できません。
別ディレクトリにあるヘッダファイルを参照する場合、一般的には-Iオプションを使って次のようにコンパイルすると思います。
gcc -I../userheader sample.c しかしこの例の場合はこの方法は上手く行きません。 &amp;lt;&amp;gt;で囲った場合も&amp;quot;&amp;ldquo;で囲った場合も、カレントディレクトリにはstdio.hは見つからないので、 先の優先順位に従って次のような順番で検索を行います。
 userheader 標準ヘッダstdio.hが入ったディレクトリ  どちらの書き方でもuserheader内のstdio.hを先に発見してしまうので、 標準ヘッダのstdio.hにはどう頑張ってもアクセスすることができません。
解決策 iquoteオプションを使うと、&amp;quot;&amp;quot;で囲った場合のみuserheaderを見に行くようになります。
gcc -iquote../userheader sample.c TinySVMの場合 TinySVM0.09(現時点での最新版)は一部環境でgetoptの違うというエラーが発生するようです。 これは-Iオプションを使ってしまったため、標準ヘッダのgetopt.hと、自前で用意したgetopt.hの使い分けができていないのが原因です。
TinySVMに同梱されたgetopt関数の引数を書き換えることで対処している例がほとんど (himorogiの日記, RとLinuxと&amp;hellip;,etc) ですが、大抵の環境にgetoptはあると思うのでgetopt.</description>
    </item>
    
    <item>
      <title>第1回 意味知識勉強会</title>
      <link>https://shogo82148.github.io/blog/2012/04/20/semantic-knowledge/</link>
      <pubDate>Fri, 20 Apr 2012 15:12:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/04/20/semantic-knowledge/</guid>
      <description>なんだか誘われたので、行ってきた。 メモメモ。
紹介された論文とか、スライドは自然言語処理研究室の意味知識勉強会のページからどうぞ。
関連学会  ACL AAAI IJCNLP Coling JIST 人工知能学会誌 自然言語処理(学会誌)  背景  人工知能の目指すところ 常識知識(common-sense knowledge)が必要  知識表現  オントロジー(ontology) 上位オントロジー 具体的な事象を対象としないオントロジー  常識オントロジー(Common-Sence Ontology)  OpenCyc   語彙オントロジー(e.g. WordNet) 形式オントロジー    OpenCyc  常識知識をデータベース化するCyc Project の一部。 専門家の手によって、手作業で構築されているオントロジー。  Open Mind Common Sense(OMCS)  機械的な常識知識獲得プロジェクト。 獲得した知識は ConceptNet というデータベースに取り込まれる。 GithubにデータベースアクセスのためのAPIが上がってるよ。  Recognizing Textual Entailment(RTE)  テキスト含意関係認識 テキスト(Text)に対する仮定(Hypothesis)が含意している・矛盾している・Uknownであるかを判定するタスク RTEの初期のデータセットは無料で公開されている  論文紹介:Types of Common-Sense Knowledge Needed for Recognizing Texual Entailment  RTE-5データセットから常識知識がなければ解けないものを「人手」で選択  単語の単純な言い換えなどで解決できないもの 600あるデータセットから108個見つけた   仮説が含意していると判定されるために必要な根拠を考える 分類して整理したよ！  必要とされる回数が多いカテゴリは重要だよね！(ホント？元のデータセットに偏りない？) 言語処理でよく使うpart-of, is-a の様な関係が使われるのは、全体の40%でしかない 分類が正しさを表す指標としてκ値(Fleiss&amp;rsquo;s κ)を使って評価    20のカテゴリは大きく3つ分けられる</description>
    </item>
    
    <item>
      <title>Linuxでプロキシの除外設定</title>
      <link>https://shogo82148.github.io/blog/2012/04/09/no-proxy/</link>
      <pubDate>Mon, 09 Apr 2012 13:40:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/04/09/no-proxy/</guid>
      <description>僕の学校では、学校のネットワークから外へ出ていくためにはプロキシと通す必要があります。 しかし、学内にあるサーバへは直接接続しなければなりません。
これを行うには no_proxy という環境変数を設定すればよいようです。
# Proxy 設定 export http_proxy=http://example.com:port/ export ftp_proxy=http://example.com:port/ export HTTP_PROXY=http://example.com:port/ export FTP_PROXY=http://example.com:port/ # 除外したいドメイン export no_proxy=localhost,.example.com no_proxyにカンマ区切りで除外したいホストを列挙します。 この設定を .bash_profile などに書いておけば、起動時に反映されるようになります。
全く・・・プロキシ面倒・・・。</description>
    </item>
    
    <item>
      <title>NDS25に参加してきた</title>
      <link>https://shogo82148.github.io/blog/2012/04/02/nds25/</link>
      <pubDate>Mon, 02 Apr 2012 00:44:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/04/02/nds25/</guid>
      <description>第25回NDS(長岡技術者勉強会)に参加してきました。 どこかの誰かが、ブログを書くまでが勉強会だ、と言っていた気がするので簡単に書いてみます。
Togetterまとめ
  負荷テストことはじめ(JMeterハック) (@nemuzuka)
 JMeterはサーバにたくさんリクエストを送って、その時の挙動を見るためのJava製ツール サーバ-クライアント間の通信を読み取ってそのまま再現したり、CSVからデータを吸いだしてリクエストに埋め込んだり、レスポンスからデータを吸い出したり、JavaScriptで挙動をカスタマイズできたりするらしい slideshare「負荷テストことはじめ」 ust「負荷テストことはじめ」    雪のシミュレーション(一部ハッキングが入ります) (@piras4)
 気象庁が提供しているアメダスのデータなどから、雪の状態(温度とか密度)を計算するお話 熱伝導方程式とか微分とか忘れました ust「雪のシミュレーション」    Remember the MilkでGTD（RTMハック） (@masaru_b_cl) LT
 Remember the Milk は ToDo 管理のための Web サービス Webフォームからはもちろん、メールやTwitterからもToDoを作成できる slideshare「GTD on RTM」 ust「Remember the MilkでGTD」    JavaerがiPhoneアプリ開発入門してミタ（Objective-Cハック）　(@makomegane)
 Keynote はアイコンを作るためのツール App Store のアプリのスクリーンショットは、自分の子供の可愛さを伝える場 Java と Objective-C の比較(メモリ管理の仕方とか) [ust「JavaerがiPhoneアプリ開発入門してミタ」]http://www.ustream.tv/recorded/21483875    「やったーGAでDTMできたよー＼(^o^)／」 (@neko_gata_s)
 遺伝的アルゴリズムで簡単な作曲をやってみようというお話 メロディを機械的にどう評価するかが難しい 評価関数が解析的に簡単に解けてしまって面白くないな・・・今後の検討課題ですね スライド ust「やったーGAでDTMできたよー＼(^o^)／」 ブログ    CSharperがWindows Phoneアプリ開発入門してミタ（C#ハック） (@ailight)</description>
    </item>
    
    <item>
      <title>JavascriptでIME</title>
      <link>https://shogo82148.github.io/blog/2012/03/28/igoime/</link>
      <pubDate>Wed, 28 Mar 2012 22:00:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/03/28/igoime/</guid>
      <description>この前いじったChrome17対応版AjaxIMEは 実際の変換を行うのに本家AjaxIMEが提供している変換サーバをそのまま使用しています。 そのため、すべての入力内容は本家サーバに送信されてしまいます。 どんな入力をしたのか作者さんにバレバレです。 この送信内容、暗号化すらされていないので、作者以外の人に見られる可能性もあります。 自分の書いた文章が勝手にインターネットに送信されているっていうのはあんまり嬉しくないですね。 ローカルのみで完結するのが理想です。
本家サーバはどうやらmecab-skkservと同じエンジンを使っているようです。 このバックエンドで動いているのは実はMeCab。 ということは、MeCabと互換性のあるigo-javascriptでも同じことができるはず・・・！ これはならブラウザ上ですべてが完結する！
はい、そういうことで作ってみました。
 IgoIME  使い方は本家と一緒です。Alt-o (Ctrl-9)でモード切替。 ローマ字で日本語を入力することができます。
日本語入力をするためには変換候補をいくつか出力する必要がありますが、 本来Igoにはその機能はありません。 そのため、複数候補を出す部分だけ独自実装してあります。 しかし、まだなんか変換候補が怪しいですね・・・。 長い文章を入力したのに一文字しか結果が帰ってこないことがあります。 なんでだろう・・・・
まだまだ改良が必要なようです。</description>
    </item>
    
    <item>
      <title>Javascriptでの関数宣言</title>
      <link>https://shogo82148.github.io/blog/2012/03/23/javascript-function/</link>
      <pubDate>Fri, 23 Mar 2012 18:22:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/03/23/javascript-function/</guid>
      <description>Chrome17対応版AjaxIME Ajaxを使ってIMEを実現したAjaxIMEがFireFoxでは動くのに最新版のChromeで動かない。 動くように少しいじってみた。
 Chrome17対応版AjaxIME  原因 Chromeで動かなかった原因はここ。
if(typeof getComputedStyle == &amp;#39;undefined&amp;#39;) { function getComputedStyle() { //中身は省略  } } FireFoxやChromeには getComputedStyle という関数が定義されているけど、 IEには定義されていない。 if文で有無を判定して、無い場合は動作をエミュレートする関数を定義している。
実行の様子をデバッガで追って見ると、Chromeではエミュレートする必要が無いのになぜか自前で定義した関数が呼び出されていた。 どうやら、Chromeでは 自作 getComputedStyle 関数が if文の中にあったとしてもコード読み込み時に作成されてしまうみたい。 FireFox だと if文の中が実行されない場合には作成されない。
結果だけ書くと、次のように書きなおしたら動いた。
if(typeof getComputedStyle == &amp;#39;undefined&amp;#39;) { getComputedStyle = function() { //中身は省略  } } あと Chrome だと、Input要素にフォーカスがあたった時に余計な装飾がついてしまうので、CSS上書きして抑制。 IE8でTextRangeが使えない問題は「IE8でのTextRange.moveToPoint()」を参考にして解決。 IE7のエミュレートモードにしているだけで、根本的な解決にはなってないけど、まあIEだしいいでしょ。
どっちが正しいの？ とりあえず問題は解決したんだけど、FireFoxとChromeで動作が違うけど、どちらの動作が正しいの？ 気になったので調べてみた。
「mixi Engineers&#39; Blog &amp;raquo; 詳細 ECMA-262-3 第5章 関数」に関数の定義法についてわかりやすい解説が載っていた。 結論からいうと、一番初めの書き方は「誤り」で実際の動作は実装依存、つまり FireFox の動作も Chrome の動作も正しいとのこと。
関数定義と関数式 関数の定義法は大きく分けて、次のような関数定義と関数式に分かれている。 関数式は更に名前なしと名前付きがある。</description>
    </item>
    
    <item>
      <title>GitHubにブログを設置してみたよ</title>
      <link>https://shogo82148.github.io/blog/2012/03/21/test/</link>
      <pubDate>Wed, 21 Mar 2012 19:29:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/03/21/test/</guid>
      <description>TLにGitHubでブログのホスティングしている人がいたので、 「githubとjekyllとoctopressで作る簡単でモダンなブログ」 を参考に作ってみましたよ。
RVM のインストール 自分の環境には Ruby 1.9.2.2 が入っているんだけど、Ocropressでは Ruby 1.9.2 が必要らしい。 そのままでもいけるかと思ったけど、怒られた。 rake コマンドを全部 bundle exec rake に置き換えると一応実行はできるけど、なんだか警告がでる。
こういう時は複数のバージョンの Ruby を切り替えて管理できる、 rvm というのを使うといいらしい。 公式サイトの「Installing RVM」通りにコマンドを打てばOK。
bash -s stable &amp;lt; &amp;lt;(curl -s https://raw.github.com/wayneeseguin/rvm/master/binscripts/rvm-installer) echo &amp;#39;[[ -s &amp;#34;$HOME/.rvm/scripts/rvm&amp;#34; ]] &amp;amp;&amp;amp; . &amp;#34;$HOME/.rvm/scripts/rvm&amp;#34; # Load RVM function&amp;#39; &amp;gt;&amp;gt; ~/.bash_profile source ~/.bash_profile rvm install 1.9.2 &amp;amp;&amp;amp; rvm use 1.9.2 rvm rubygems latest Octopress のインストール あとはgitでクローンして、インストールコマンドを叩くだけ。
git clone git://github.com/imathis/octopress.git octopress cd octopress gem install bundler bundle install rake install rake setup_github_pages 最後のコマンドは GitHub Pages に公開するためのもの。公開用のレポジトリを聞いてくるので予め登録しておこう。</description>
    </item>
    
  </channel>
</rss>
