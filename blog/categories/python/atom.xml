<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Python | Shogo's Blog]]></title>
  <link href="http://shogo82148.github.io/blog/categories/python/atom.xml" rel="self"/>
  <link href="http://shogo82148.github.io/"/>
  <updated>2013-11-10T01:32:27+09:00</updated>
  <id>http://shogo82148.github.io/</id>
  <author>
    <name><![CDATA[Shogo Ichinose]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[RaspberryPiでhttps通信が失敗するのを何とかする]]></title>
    <link href="http://shogo82148.github.io/blog/2013/05/12/raspberry-pi-https-connection/"/>
    <updated>2013-05-12T16:48:00+09:00</updated>
    <id>http://shogo82148.github.io/blog/2013/05/12/raspberry-pi-https-connection</id>
    <content type="html"><![CDATA[<p>RaspberryPiをネットつないでみたので、PythonからいろんなURLを叩いて遊んでいたんだけど、
一部のhttps通信が Connection Timed Out で失敗しちゃう。
プログラムの問題かと思ったけど、curlで叩いてもやっぱりタイムアウト。
Macで全く同じ事をするとうまくいく・・・。
いろいろ調べて、何とかしてみたお話。</p>

<!-- More -->


<h2>原因</h2>

<p>接続先がTLSv1にしか対応していないのにSSLv3でアクセスしようとしていたことが問題だったらしい。
明示的にTLSv1を使うように指定して curl を叩いてみるとうまくいった。</p>

<p><code>bash
$ curl --tlsv3 https://hogehoge
</code></p>

<p>なぜRaspberryPiではダメで
Macでは成功するのか、という根本的な原因はよくわからなかった。
SSLv3に対応していないなら自動的にフォールバックしてくれてもよさそうなものだけど、
なぜうまく行かないんだろう・・・？</p>

<h2>Pythonでの対処</h2>

<p>PythonでもTLSv3を使えばうまくいくはずなんだけど、
暗号化方式を指定するオプションは見当たらない(2.7での話)。
どうやら標準ライブラリのファイルを直接書き換えるか、
実行時に中身を入れ替えるかしないとできないみたいだ。
この問題普通のUbuntuでも起こるらしく、
そのフォーラムで置き換えコードを見つけた。</p>

<p>``` python
import httplib
from httplib import HTTPConnection, HTTPS_PORT
import ssl</p>

<p>class HTTPSConnection(HTTPConnection):</p>

<pre><code>"This class allows communication via SSL."
default_port = HTTPS_PORT

def __init__(self, host, port=None, key_file=None, cert_file=None,
        strict=None, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,
        source_address=None):
    HTTPConnection.__init__(self, host, port, strict, timeout,
            source_address)
    self.key_file = key_file
    self.cert_file = cert_file

def connect(self):
    "Connect to a host on a given (SSL) port."
    sock = socket.create_connection((self.host, self.port),
            self.timeout, self.source_address)
    if self._tunnel_host:
        self.sock = sock
        self._tunnel()
    # this is the only line we modified from the httplib.py file
    # we added the ssl_version variable
    self.sock = ssl.wrap_socket(sock, self.key_file, self.cert_file, ssl_version=ssl.PROTOCOL_TLSv1)
</code></pre>

<h1>now we override the one in httplib</h1>

<p>httplib.HTTPSConnection = HTTPSConnection</p>

<h1>ssl_version corrections are done</h1>

<p>```</p>

<p>これを通信開始前に読みこめば、あとは<code>urllib</code>で読み込めるようになるはず。</p>

<h2>参考</h2>

<ul>
<li><a href="http://www.abe3.net/2012/12/ruby-https-error/">RubyでHTTPS通信に失敗したのでcURLで対処した</a></li>
<li><a href="http://askubuntu.com/questions/116020/python-https-requests-urllib2-to-some-sites-fail-on-ubuntu-12-04-without-proxy">Python HTTPS requests (urllib2) to some sites fail on Ubuntu 12.04 without proxy</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[tweepyでApplication-only authenticationしてみた]]></title>
    <link href="http://shogo82148.github.io/blog/2013/05/09/application-only-authentication-with-tweepy/"/>
    <updated>2013-05-09T23:29:00+09:00</updated>
    <id>http://shogo82148.github.io/blog/2013/05/09/application-only-authentication-with-tweepy</id>
    <content type="html"><![CDATA[<p>Twitter の API リファレンスを久しぶりに見たら、
<a href="https://dev.twitter.com/docs/auth/application-only-auth">Application-only authentication</a>とかいうのを発見。
特定のユーザと関連付けられない代わりに、普通に認証するより制限が緩いみたい。
3月に追加されてたらしい。</p>

<p>知らなかった・・・。
最近API叩いてなかったからな・・・。</p>

<p>便利そうなので、Python用のTwitterライブラリである<a href="https://github.com/tweepy/tweepy">Tweepy</a>から使ってみた。</p>

<!-- More -->


<h2>AuthHandler</h2>

<p>Tweepy用のAuthHandler。
認証部分は
<a href="http://ktkrhr.hatenablog.com/entry/2013/03/27/002447">TwitterのApplication-only authenticationを試してみた</a>
のページからほぼコピペ。</p>

<p>``` python AppAuthHandler.py
import tweepy
import urllib
import urllib2
import base64
import json</p>

<p>class AppAuthHandler(tweepy.auth.AuthHandler):</p>

<pre><code>TOKEN_URL = 'https://api.twitter.com/oauth2/token'

def __init__(self, consumer_key, consumer_secret):
    token_credential = urllib.quote(consumer_key) + ':' + urllib.quote(consumer_secret)
    credential = base64.b64encode(token_credential)

    value = {'grant_type': 'client_credentials'}
    data = urllib.urlencode(value)
    req = urllib2.Request(self.TOKEN_URL)
    req.add_header('Authorization', 'Basic ' + credential)
    req.add_header('Content-Type', 'application/x-www-form-urlencoded;charset=UTF-8')

    response = urllib2.urlopen(req, data)
    json_response = json.loads(response.read())
    self._access_token = json_response['access_token']

def apply_auth(self, url, method, headers, parameters):
    headers['Authorization'] = 'Bearer ' + self._access_token
</code></pre>

<p>```</p>

<h2>使ってみる</h2>

<p>今まではOAuthHandlerを使っていたのを、上のAppAuthHandlerに置き換えるだけ。
あとは今までどおりAPIを叩ける。
以下は特定のユーザのツイートを取れるだけ取ってくる例。</p>

<p>``` python crawl.py</p>

<h1>!/usr/bin/env python</h1>

<h1>-<em>- coding: utf-8 -</em>-</h1>

<p>import tweepy
import codecs
import sys
import AppAuthHandler</p>

<p>sys.stdin = codecs.getreader('utf-8')(sys.stdin)
sys.stdout = codecs.getwriter('utf-8')(sys.stdout)</p>

<p>CONSUMER_KEY = 'hogehoge'
CONSUMER_SECRET = 'hogehoge'</p>

<p>def main():</p>

<pre><code>user_id = "JO_RI"

auth = AppAuthHandler.AppAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)
api = tweepy.API(auth)

arg = {'id': user_id, 'include_rts': 1}
user_statuses = tweepy.Cursor(api.user_timeline, **arg).items(3200)
for user_status in user_statuses:
    print user_status.text
</code></pre>

<p>if <strong>name</strong> == "<strong>main</strong>":
  main()
```</p>

<h2>参考</h2>

<ul>
<li><a href="https://dev.twitter.com/docs/auth/application-only-auth">Application-only authentication</a></li>
<li><a href="http://blog.k52.org/0162">TwitterAPIがApplication-only authenticationを公開。これを使うと検索API等の一部回数制限が大幅に緩和される。</a></li>
<li><a href="http://www.macminiosx.com/2013/03/twitterapplication-only_authen.html">TwitterのApplication-only authenticationをperlで試す。</a></li>
<li><a href="http://ktkrhr.hatenablog.com/entry/2013/03/27/002447">TwitterのApplication-only authenticationを試してみた</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MeCabをPythonから使う注意点とか]]></title>
    <link href="http://shogo82148.github.io/blog/2012/12/15/mecab-python/"/>
    <updated>2012-12-15T17:38:00+09:00</updated>
    <id>http://shogo82148.github.io/blog/2012/12/15/mecab-python</id>
    <content type="html"><![CDATA[<p>日本語の文章をコンピュータで色々いじるときに，
必ずと言っていいほどよく使うのが形態素解析器．
スペースなどの明示的な区切りの無い日本語を単語に分割してくれるツールです．
中でもMeCabが非常に有名で，さまざまなところで使われています．</p>

<p>MeCabはいろいろな言語から呼び出すことができます．
自然言語処理の分野ではPythonが人気のようですね．僕も使っています．
しかし，MeCabをPythonから使う場合，注意する点がいくつかあります．
そこにハマっている後輩を見かけたので，文章として残しておくことにします．
Python2系が対象です(3系はよくわからない)．
注意するのは以下の二点です．</p>

<ul>
<li>MeCabに渡す文字列はencode，戻ってきた文字列はdecodeする</li>
<li>MeCabに渡した文字列は必ず変数に入れておく</li>
</ul>


<!-- More -->


<h2>EncodeとDecode</h2>

<p>Python2系の文字列には，バイト列として扱われる文字列(str)と，Unicodeで表現された文字列(unicode)があります．
日本語を扱う場合，strだといろいろ問題があるので，特に理由がなければunicodeを使うべきです．
しかし，MeCabはstrしか受け付けません．
そこでMeCabに渡す直前・直後でencode・decodeするようにします．</p>

<p>```python
import MeCab
tagger = MeCab.tagger('-Owakati')
text = u'MeCabで遊んでみよう！'</p>

<p>result = tagger.parse(text) # エラー！</p>

<p>encoded_text = text.encode('utf-8') # encodeが必要
encoded_result = tagger.parse(text)
result = result.decode('utf-8') # 必ずdecode
```</p>

<p><code>'utf-8'</code>の部分は辞書の文字コードに合わせて適宜書き換えてください．
デフォルトはeuc-jpですが，utf-8の方が幸せになれると思います．</p>

<h2>必ず変数に入れる</h2>

<p>次にMeCabの作ったノードに直接アクセスして，品詞情報などを取ってくることを考えます．
適当に書いてみるとこんな感じでしょうか．</p>

<p>```python
import MeCab
tagger = MeCab.tagger('')
text = u'MeCabで遊んでみよう！'</p>

<p>node = tagger.parseToNode(text.encode('utf-8'))
while node:</p>

<pre><code>#printはstrを渡す必要があるのでdecodeは不要
print node.surface + '\t' + node.feature
node = node.next
</code></pre>

<p>```</p>

<p>MeCabに渡す直前にencodeもしているので上手く動きそうです．
(decodeしてないのはprintに渡すためなので気にしなくておｋ)
しかし，このコードの出力は下のような悲惨なものとなるのです
(ブラウザさんに配慮して一部修正，環境によっても違うと思います)</p>

<p>``` plain</p>

<pre><code>    BOS/EOS,*,*,*,*,*,*,*,*
</code></pre>

<p>MeCab   名詞,一般,<em>,</em>,<em>,</em>,*</p>

<pre><code>    ??   助詞,格助詞,一般,*,*,*,で,デ,デ
</code></pre>

<p>?詞,?   動詞,自立,<em>,</em>,五段・バ行,連用タ接続,遊ぶ,アソン,アソン
???     助詞,接続助詞,<em>,</em>,<em>,</em>,で,デ,デ
??,<em>,</em>       動詞,非自立,<em>,</em>,一段,未然ウ接続,みる,ミヨ,ミヨ
,<em>,     助動詞,</em>,<em>,</em>,不変化型,基本形,う,ウ,ウ
<em>,</em>     記号,一般,<em>,</em>,<em>,</em>,！,！,！</p>

<pre><code>    BOS/EOS,*,*,*,*,*,*,*,*
</code></pre>

<p>```</p>

<p>なぜこのようなことが起きてしまったのでしょう？
答えは<code>text.encode('utf-8')</code>の戻り値の寿命と，MeCabノードの構造にあります．</p>

<p>みんなさんが普段お使いのPythonは，C言語で実装されたCPythonだと思います．
「CPythonでは、ガベージコレクションの方式として参照カウント方式とマーク・アンド・スイープ方式を併用」しています
(<a href="http://ja.wikipedia.org/wiki/Python#.E3.83.87.E3.83.BC.E3.82.BF.E5.9E.8B">Python - Wikipedia</a>)．
参照カウント方式おかげでCPythonは不要になったオブジェクトを不要になった瞬間に検出し，そのオブジェクトを解放することができます．
つまり実際には5行目を少し細かく見ると，Pythonは以下の処理をします．</p>

<ol>
<li><code>text.encode('utf-8')</code>を呼び出し，"エンコード済みtext"を作成</li>
<li><code>tagger.parseToNode</code>を呼び出し，結果を<code>node</code>に代入</li>
<li>不要になった<strong> "エンコード済みtext"を破棄 </strong></li>
</ol>


<p>ポイントは3番ですね．6行目を実行する前に，"エンコード済みtext"は破棄されてしまいます．</p>

<p>さて，次にMeCabがどのようにノードの情報を扱っているか見てみましょう．
MeCabの言語バインディングのページには，ノードのsurfaceは文字列型であるような定義が書いてありますが，あれは嘘です．
<a href="http://code.google.com/p/mecab/source/browse/trunk/mecab/src/mecab.h">ソース</a>を見ればわかりますが，みんな大好きポインタとして定義されています．
実はこのポインタ，<strong> "エンコード済みtext"上の開始点を指し示しています </strong>．</p>

<p>つまり，どういうことかというと，</p>

<ul>
<li>MeCabはsurfaceを作るのに毎回"エンコード済みtext"からコピペしてた</li>
<li>しかし，MeCabはPythonにそのことを伝えていなかった</li>
<li>不要と判断したPythonによって"エンコード済みtext"はすでに破棄されており，そこには何もなかった</li>
</ul>


<p>これを解決するにはPythonに"エンコード済みtext"が使用中であることを伝え，破棄されないようにする必要があります．
一番簡単な方法は変数に保存しておくことです．変数のスコープにいる間は"エンコード済みtext"が破棄される心配はありません．</p>

<p>```python
import MeCab
tagger = MeCab.tagger('')
text = u'MeCabで遊んでみよう！'</p>

<p>encoded_text = text.encode('utf-8')
node = tagger.parseToNode(encoded_text) # 変数に入れる！
while node:</p>

<pre><code>print node.surface + '\t' + node.feature
node = node.next
</code></pre>

<p>```</p>

<p>これで上手く行きます．</p>

<p>encode_textとnodeの寿命が一致している必要があります．
nodeの結果を何度も利用する場合は一度nodeの内容をすべてPythonのリストか何かに格納しましょう．
一度変換してしまえば，ガーベージコレクションは正しく動きます．</p>

<h2>まとめ</h2>

<ul>
<li>MeCabに渡す文字列はencode，戻ってきた文字列はdecodeする</li>
<li>MeCabに渡した文字列は必ず変数に入れておく</li>
</ul>


<p>面倒なのでラッパーを書くかといいかもしれませんね．
もしくは自前で実装とか．</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[PythonでCaboChaを美味しくいただく]]></title>
    <link href="http://shogo82148.github.io/blog/2012/11/01/cabocha/"/>
    <updated>2012-11-01T23:02:00+09:00</updated>
    <id>http://shogo82148.github.io/blog/2012/11/01/cabocha</id>
    <content type="html"><![CDATA[<p>日本語構文解析器<a href="http://code.google.com/p/cabocha/">CaboCha</a>をPythonから使ってみたメモ．</p>

<!-- More -->


<h2>インストール</h2>

<p><a href="http://code.google.com/p/cabocha/">CaboCha</a>自体のインストールは公式のドキュメントを参照．
ググれば他の人のレポートも出てくるはず．</p>

<p><a href="http://code.google.com/p/cabocha/">CaboCha</a>のソースコードを展開したディレクトリの中の
pythonディレクトリにPython-bindingが入ってます．
そこに移動した後，管理者権限で以下のコマンドを実行すればインストール完了．</p>

<p><code>bash
python setup.py install
</code></p>

<h2>食べ方</h2>

<h3>解析結果を文字列出力</h3>

<p>python/test.py に書いてあるとおり．</p>

<p>``` python test.py http://code.google.com/p/cabocha/source/browse/trunk/python/test.py</p>

<h1>!/usr/bin/python</h1>

<h1>-<em>- coding: utf-8 -</em>-</h1>

<p>import CaboCha</p>

<h1>c = CaboCha.Parser("");</h1>

<p>c = CaboCha.Parser()</p>

<p>sentence = "太郎はこの本を二郎を見た女性に渡した。"</p>

<p>print c.parseToString(sentence)</p>

<p>tree =  c.parse(sentence)</p>

<p>print tree.toString(CaboCha.FORMAT_TREE)
print tree.toString(CaboCha.FORMAT_LATTICE)
```</p>

<p>以下のような結果が得られれば成功．</p>

<p>``` plain
<PERSON>太郎</PERSON>は-----------D</p>

<pre><code>                 この-D       |
                   本を---D   |
                   二郎を-D   |
                       見た-D |
                       女性に-D
                       渡した。
</code></pre>

<p>EOS</p>

<p><PERSON>太郎</PERSON>は-----------D</p>

<pre><code>                 この-D       |
                   本を---D   |
                   二郎を-D   |
                       見た-D |
                       女性に-D
                       渡した。
</code></pre>

<p>EOS</p>

<ul>
<li>0 6D 0/1 2.909358
太郎  名詞,固有名詞,人名,名,<em>,</em>,太郎,タロウ,タロー   B-PERSON
は 助詞,係助詞,<em>,</em>,<em>,</em>,は,ハ,ワ    O</li>
<li>1 2D 0/0 1.257926
この  連体詞,<em>,</em>,<em>,</em>,*,この,コノ,コノ    O</li>
<li>2 4D 0/1 0.638994
本 名詞,一般,<em>,</em>,<em>,</em>,本,ホン,ホン O
を 助詞,格助詞,一般,<em>,</em>,*,を,ヲ,ヲ   O</li>
<li>3 4D 1/2 1.696047
二 名詞,数,<em>,</em>,<em>,</em>,二,ニ,ニ  O
郎 名詞,一般,<em>,</em>,<em>,</em>,郎,ロウ,ロー O
を 助詞,格助詞,一般,<em>,</em>,*,を,ヲ,ヲ   O</li>
<li>4 5D 0/1 0.000000
見 動詞,自立,<em>,</em>,一段,連用形,見る,ミ,ミ   O
た 助動詞,<em>,</em>,*,特殊・タ,基本形,た,タ,タ  O</li>
<li>5 6D 0/1 0.000000
女性  名詞,一般,<em>,</em>,<em>,</em>,女性,ジョセイ,ジョセイ  O
に 助詞,格助詞,一般,<em>,</em>,*,に,ニ,ニ   O</li>
<li>6 -1D 0/1 0.000000
渡し  動詞,自立,<em>,</em>,五段・サ行,連用形,渡す,ワタシ,ワタシ  O
た 助動詞,<em>,</em>,<em>,特殊・タ,基本形,た,タ,タ  O
。 記号,句点,</em>,<em>,</em>,*,。,。,。   O
EOS
```</li>
</ul>


<p><code>tree.toString(CaboCha.FORMAT_XML)</code>でXML形式の出力も可能です．</p>

<p><code>xml
&lt;sentence&gt;
 &lt;chunk id="0" link="6" rel="D" score="2.909358" head="0" func="1"&gt;
  &lt;tok id="0" feature="名詞,固有名詞,人名,名,*,*,太郎,タロウ,タロー" ne="B-PERSON"&gt;太郎&lt;/tok&gt;
  &lt;tok id="1" feature="助詞,係助詞,*,*,*,*,は,ハ,ワ" ne="O"&gt;は&lt;/tok&gt;
 &lt;/chunk&gt;
 &lt;chunk id="1" link="2" rel="D" score="1.257926" head="2" func="2"&gt;
  &lt;tok id="2" feature="連体詞,*,*,*,*,*,この,コノ,コノ" ne="O"&gt;この&lt;/tok&gt;
 &lt;/chunk&gt;
 &lt;chunk id="2" link="4" rel="D" score="0.638994" head="3" func="4"&gt;
  &lt;tok id="3" feature="名詞,一般,*,*,*,*,本,ホン,ホン" ne="O"&gt;本&lt;/tok&gt;
  &lt;tok id="4" feature="助詞,格助詞,一般,*,*,*,を,ヲ,ヲ" ne="O"&gt;を&lt;/tok&gt;
 &lt;/chunk&gt;
 &lt;chunk id="3" link="4" rel="D" score="1.696047" head="6" func="7"&gt;
  &lt;tok id="5" feature="名詞,数,*,*,*,*,二,ニ,ニ" ne="O"&gt;二&lt;/tok&gt;
  &lt;tok id="6" feature="名詞,一般,*,*,*,*,郎,ロウ,ロー" ne="O"&gt;郎&lt;/tok&gt;
  &lt;tok id="7" feature="助詞,格助詞,一般,*,*,*,を,ヲ,ヲ" ne="O"&gt;を&lt;/tok&gt;
 &lt;/chunk&gt;
 &lt;chunk id="4" link="5" rel="D" score="0.000000" head="8" func="9"&gt;
  &lt;tok id="8" feature="動詞,自立,*,*,一段,連用形,見る,ミ,ミ" ne="O"&gt;見&lt;/tok&gt;
  &lt;tok id="9" feature="助動詞,*,*,*,特殊・タ,基本形,た,タ,タ" ne="O"&gt;た&lt;/tok&gt;
 &lt;/chunk&gt;
 &lt;chunk id="5" link="6" rel="D" score="0.000000" head="10" func="11"&gt;
  &lt;tok id="10" feature="名詞,一般,*,*,*,*,女性,ジョセイ,ジョセイ" ne="O"&gt;女性&lt;/tok&gt;
  &lt;tok id="11" feature="助詞,格助詞,一般,*,*,*,に,ニ,ニ" ne="O"&gt;に&lt;/tok&gt;
 &lt;/chunk&gt;
 &lt;chunk id="6" link="-1" rel="D" score="0.000000" head="12" func="13"&gt;
  &lt;tok id="12" feature="動詞,自立,*,*,五段・サ行,連用形,渡す,ワタシ,ワタシ" ne="O"&gt;渡し&lt;/tok&gt;
  &lt;tok id="13" feature="助動詞,*,*,*,特殊・タ,基本形,た,タ,タ" ne="O"&gt;た&lt;/tok&gt;
  &lt;tok id="14" feature="記号,句点,*,*,*,*,。,。,。" ne="O"&gt;。&lt;/tok&gt;
 &lt;/chunk&gt;
&lt;/sentence&gt;
</code></p>

<p>しかし，このXML形式，<code>&amp;</code>や<code>"</code>，<code>&lt;</code>, <code>&gt;</code>などの特殊記号を置換してくれないので，
この結果をXMLのパーサに通す場合などは注意が必要．</p>

<p>そもそも標準の辞書ではこれらの文字を上手く扱えないので前処理を行ったほうがいいのかもしれない．
半角の<code>&amp;</code>は辞書に登録されていおらず，全角の＆にする必要がある．</p>

<h3>Treeの中身をいじってみる</h3>

<p>一度文字列に変換してしまうと色々面倒なことが起こりそうなので，Treeの中身を直接いじってみる．
ドキュメントが無いので<a href="http://code.google.com/p/cabocha/source/browse/trunk/src/cabocha.h">cabocha.h</a>
の中身を見ながら試してみました．</p>

<p>``` python</p>

<h1>!/usr/bin/python</h1>

<h1>-<em>- coding: utf-8 -</em>-</h1>

<p>import CaboCha
c = CaboCha.Parser()</p>

<p>sentence = "太郎はこの本を渡した。"</p>

<p>tree =  c.parse(sentence)</p>

<p>for i in range(tree.chunk_size()):</p>

<pre><code>chunk = tree.chunk(i)
print 'Chunk:', i
print ' Score:', chunk.score
print ' Link:', chunk.link
print ' Size:', chunk.token_size
print ' Pos:', chunk.token_pos
print ' Head:', chunk.head_pos # 主辞
print ' Func:', chunk.func_pos # 機能語
print ' Features:',
for j in range(chunk.feature_list_size):
    print chunk.feature_list(j),
print
print
</code></pre>

<p>for i in range(tree.token_size()):</p>

<pre><code>token = tree.token(i)
print 'Surface:', token.surface
print ' Normalized:', token.normalized_surface
print ' Feature:', token.feature
print ' NE:', token.ne # 固有表現
print ' Info:', token.additional_info
print ' Chunk:', token.chunk
print
</code></pre>

<p>```</p>
]]></content>
  </entry>
  
</feed>
