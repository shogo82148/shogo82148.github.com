<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: golang | Shogo's Blog]]></title>
  <link href="https://shogo82148.github.io/blog/categories/golang/atom.xml" rel="self"/>
  <link href="https://shogo82148.github.io/"/>
  <updated>2017-04-13T09:14:41+09:00</updated>
  <id>https://shogo82148.github.io/</id>
  <author>
    <name><![CDATA[Shogo Ichinose]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Go言語のヒープに確保するデータの初期化コストについて調べてみた(Go1.8.1版)]]></title>
    <link href="https://shogo82148.github.io/blog/2017/04/13/go1-8-allocation/"/>
    <updated>2017-04-13T08:23:08+09:00</updated>
    <id>https://shogo82148.github.io/blog/2017/04/13/go1-8-allocation</id>
    <content type="html"><![CDATA[<p><a href="https://twitter.com/kaoriya/status/851983856966283265">https://twitter.com/kaoriya/status/851983856966283265</a>">https://twitter.com/kaoriya/status/851983856966283265">https://twitter.com/kaoriya/status/851983856966283265</a></a></p>

<p>こちらのツイートに対して、以下のベンチ結果が紹介されていました。</p>

<ul>
<li><a href="http://ryochack.hatenablog.com/entry/2014/06/08/225606">Go言語のヒープに確保するデータの初期化コストについて調べてみた</a></li>
</ul>


<p>しかし<a href="https://twitter.com/hnakamur2">hnakamur2</a>さんも言及しているように、
これはGo1.2.2時の結果。
その後、GoのコンパイラがGo実装になったり、SSAが導入されたりと、
今のコンパイラの実装は当時とは全く違うものになっています。</p>

<p>というわけで、現時点での最新のバージョン(Go1.8.1)で、同様の検証をおこなってみました。</p>

<!-- More -->


<h2>検証コード</h2>

<p>検証に使用したコードはGo1.2.2のときと全く同じものです。</p>

<pre><code class="go">// alloc_overhead.go

package main

type container struct {
    v [64]byte
}

func MakeContainer() *container {
    c := container{}
    return &amp;c
}

func MakeContainerOneLine() *container {
    return &amp;container{}
}

func MakeContainerNew() *container {
    return new(container)
}

func main() {
    _ = MakeContainer()
    _ = MakeContainerOneLine()
    _ = MakeContainerNew()
}
</code></pre>

<pre><code class="go">// alloc_overhead_test.go

package main

import (
    "testing"
)

func BenchmarkMakeContainer(b *testing.B) {
    for i := 0; i &lt; b.N; i++ {
        _ = MakeContainer()
    }
}

func BenchmarkMakeContainerOneLine(b *testing.B) {
    for i := 0; i &lt; b.N; i++ {
        _ = MakeContainerOneLine()
    }
}

func BenchmarkMakeContainerNew(b *testing.B) {
    for i := 0; i &lt; b.N; i++ {
        _ = MakeContainerNew()
    }
}
</code></pre>

<h2>ベンチマーク結果</h2>

<p>Go1.8.1でベンチマークを実行した結果がこちら。</p>

<pre><code class="plain">$ go test -bench . -benchmem
BenchmarkMakeContainer-4            1000000000           2.79 ns/op        0 B/op          0 allocs/op
BenchmarkMakeContainerOneLine-4     1000000000           2.84 ns/op        0 B/op          0 allocs/op
BenchmarkMakeContainerNew-4         1000000000           2.83 ns/op        0 B/op          0 allocs/op
PASS
ok      _/Users/shogo/workspace/tmp/2017-04-13-alloc    9.345s
</code></pre>

<p>ベンチマークの結果、ほとんど速度の差はありませんでした。</p>

<p>しかし、「ヒープに置かれるデータの初期化」を検証したかったのに、アロケーションが0なのはおかしいですね？
どうやら最適化の結果、スタックに置かれるようになってしまったようです。</p>

<h2>再検証</h2>

<p>Go1.7から追加された<a href="https://golang.org/pkg/runtime/#KeepAlive">runtime.KeepAlive</a>を使ってベンチマークを修正しました。
<code>runtime.KeepAlive</code>が呼ばれるまで確保した領域は解放されることが無いので、
データがヒープに乗ってくれるはずです(たぶん)。</p>

<pre><code class="go">// alloc_overhead_test.go

package main

import (
    "runtime"
    "testing"
)

func BenchmarkMakeContainer(b *testing.B) {
    for i := 0; i &lt; b.N; i++ {
        runtime.KeepAlive(MakeContainer())
    }
}

func BenchmarkMakeContainerOneLine(b *testing.B) {
    for i := 0; i &lt; b.N; i++ {
        runtime.KeepAlive(MakeContainerOneLine())
    }
}

func BenchmarkMakeContainerNew(b *testing.B) {
    for i := 0; i &lt; b.N; i++ {
        runtime.KeepAlive(MakeContainerNew())
    }
}
</code></pre>

<p>修正版のベンチマークはこちら。</p>

<pre><code class="plain">$ go test -bench . -benchmem
BenchmarkMakeContainer-4            50000000            34.7 ns/op        64 B/op          1 allocs/op
BenchmarkMakeContainerOneLine-4     30000000            34.4 ns/op        64 B/op          1 allocs/op
BenchmarkMakeContainerNew-4         50000000            35.9 ns/op        64 B/op          1 allocs/op
PASS
ok      _/Users/shogo/workspace/tmp/2017-04-13-alloc    4.690s
</code></pre>

<p>意図したとおりアロケーションが発生しています。
速度差もほとんどありません。</p>

<h2>最適化の結果を見てみる</h2>

<p><a href="http://shinpei.github.io/blog/2016/08/13/what-ssa-brings-to-go-17/">Go1.7からSSAが導入された</a>ことにより、
以下のようなコマンドで最適化の様子を簡単に知ることができるようになりました。</p>

<pre><code class="bash">GOSSAFUNC=MakeContainer go build alloc_overhead.go
</code></pre>

<p>この機能を使って、各関数が最終的にどのように最適化されたのかを確認してみます。</p>

<p>以下は<code>MakeContainer</code>の結果(<a href="/files/2017-04-13-go1-8-allocation/MakeContainer.html">ssa.html</a>)。</p>

<pre><code class="plain">v1 = InitMem &lt;mem&gt;
v2 = SP &lt;uintptr&gt; : SP
v3 = SB &lt;uintptr&gt; : SB
v10 = LEAQ &lt;*uint8&gt; {type."".container} v3 : AX
v8 = MOVQstore &lt;mem&gt; v2 v10 v1
v9 = CALLstatic &lt;mem&gt; {runtime.newobject} [16] v8
v11 = MOVQload &lt;*container&gt; [8] v2 v9 : AX
v13 = VarDef &lt;mem&gt; {~r0} v9
v14 = MOVQstore &lt;mem&gt; {~r0} v2 v11 v13
</code></pre>

<p><code>MakeContainerOneLine</code>の結果(<a href="/files/2017-04-13-go1-8-allocation/MakeContainerOneLine.html">ssa.html</a>)。</p>

<pre><code class="plain">v1 = InitMem &lt;mem&gt;
v2 = SP &lt;uintptr&gt; : SP
v3 = SB &lt;uintptr&gt; : SB
v10 = LEAQ &lt;*uint8&gt; {type."".container} v3 : AX
v8 = MOVQstore &lt;mem&gt; v2 v10 v1
v9 = CALLstatic &lt;mem&gt; {runtime.newobject} [16] v8
v11 = MOVQload &lt;*container&gt; [8] v2 v9 : AX
v14 = VarDef &lt;mem&gt; {~r0} v9
v15 = MOVQstore &lt;mem&gt; {~r0} v2 v11 v14
</code></pre>

<p><code>MakeContainerNew</code>の結果(<a href="/files/2017-04-13-go1-8-allocation/MakeContainerNew.html">ssa.html</a>)。</p>

<pre><code class="plain">v1 = InitMem &lt;mem&gt;
v2 = SP &lt;uintptr&gt; : SP
v3 = SB &lt;uintptr&gt; : SB
v10 = LEAQ &lt;*uint8&gt; {type."".container} v3 : AX
v8 = MOVQstore &lt;mem&gt; v2 v10 v1
v9 = CALLstatic &lt;mem&gt; {runtime.newobject} [16] v8
v11 = MOVQload &lt;*container&gt; [8] v2 v9 : AX
v12 = VarDef &lt;mem&gt; {~r0} v9
v13 = MOVQstore &lt;mem&gt; {~r0} v2 v11 v12
</code></pre>

<p>変数名の割り当てが異なるだけで実質同じ内容ですね。</p>

<h2>まとめ</h2>

<ul>
<li>Go1.8.1の最適化強い</li>
<li>Go1.8.1では<code>new(Type)</code>と<code>&amp;Type{}</code>の差はない(少なくとも性能面では)</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Go言語のchanはいったいいくつ付けられるのか試してみた]]></title>
    <link href="https://shogo82148.github.io/blog/2017/03/17/how-many-chan-can-i-write-in-golang/"/>
    <updated>2017-03-17T21:10:25+09:00</updated>
    <id>https://shogo82148.github.io/blog/2017/03/17/how-many-chan-can-i-write-in-golang</id>
    <content type="html"><![CDATA[<p>pecoに入った修正をみて、果たして<code>chan</code>はいくつまで付けられるのか気になったので、
雑に試してみました。
先に断っておきますが、全く有用ではないですよ。</p>

<!-- More -->


<h2>背景</h2>

<p>pecoに入った修正はこちら(一部抜粋)。</p>

<ul>
<li><a href="https://github.com/peco/peco/pull/411">Make Resume a blocking operation #411</a></li>
</ul>


<pre><code class="diff">diff --git a/interface.go b/interface.go
index 3d4472f..fff446c 100644
--- a/interface.go
+++ b/interface.go
@@ -162,8 +162,8 @@ type Screen interface {
 // Termbox just hands out the processing to the termbox library
 type Termbox struct {
    mutex     sync.Mutex
-   resumeCh  chan (struct{})
-   suspendCh chan (struct{})
+   resumeCh  chan chan struct{}
+   suspendCh chan struct{}
 }

 // View handles the drawing/updating the screen
diff --git a/screen.go b/screen.go
index edbce87..f6dd71e 100644
--- a/screen.go
+++ b/screen.go
@@ -21,7 +21,7 @@ func (t *Termbox) Init() error {
 func NewTermbox() *Termbox {
    return &amp;Termbox{
        suspendCh: make(chan struct{}),
-       resumeCh:  make(chan struct{}),
+       resumeCh:  make(chan chan struct{}),
    }
 }
</code></pre>

<p>channelを使ってchannelをやり取りすることができるので、
<code>chan struct{}</code>をやり取りする<code>chan chan struct{}</code>という型が使えます。
同じ要領で、channelをやり取りするchannelをやり取りするchannelをやり取り&hellip;するchannelが
無限に作れるはずです(少なくとも構文上は)。
ということで、実際にやってみました。</p>

<h2>実験</h2>

<p>雑なPerlスクリプトを準備して、大量の<code>chan</code>を付けたGoのコードを自動生成します。</p>

<pre><code class="perl">print &lt;&lt;EOF;
package main

import (
    "fmt"
)

type Foo @{['chan ' x 4096]} struct{}

func main() {
    fmt.Printf("Hello, %#v\\n", make(Foo))
}
EOF
</code></pre>

<p><code>chan</code>の個数を変えて何度かビルドを繰り返します。</p>

<pre><code class="bash">time go build -o main main.go
</code></pre>

<h2>結果</h2>

<p>chanの個数とビルドにかかった時間をまとめてみました。</p>

<table>
    <tr><th>chanの個数</th><th>ビルド時間</th></tr>
    <tr><td>1</td><td>0.236s</td></tr>
    <tr><td>2</td><td>0.240s</td></tr>
    <tr><td>4</td><td>0.226s</td></tr>
    <tr><td>8</td><td>0.234s</td></tr>
    <tr><td>16</td><td>0.240s</td></tr>
    <tr><td>32</td><td>0.250s</td></tr>
    <tr><td>64</td><td>0.281s</td></tr>
    <tr><td>128</td><td>0.258s</td></tr>
    <tr><td>256</td><td>0.360s</td></tr>
    <tr><td>512</td><td>0.775s</td></tr>
    <tr><td>1024</td><td>3.228s</td></tr>
    <tr><td>2048</td><td>18.605s</td></tr>
    <tr><td>4096</td><td>1m53.614s</td></tr>
    <tr><td>8192</td><td>13m46.018s(ビルド失敗したので参考記録)</td></tr>
</table>


<p>8192個付けたら以下のようなエラーを吐いてビルドが失敗してしまったので、
8192個の時の記録は参考記録です。</p>

<pre><code class="plain"># command-line-arguments
too much data in section SDWARFINFO (over 2000000000 bytes)
</code></pre>

<p>何かビルドの設定をいじればもっと行けるかもしれませんが、
デフォルトの設定では4096から8192の間に限界があるようです。
4096個<code>chan</code>を付けたときのソースコードは20KB程度なのにバイナリサイズは524MBまで膨らんでいました。</p>

<p>256個当たりからビルド時間に影響が出ているので、
ビルド時間を考える256個以下に抑えるのがよさそうです。
それ以上だと <script type="math/tex">O(n^{2.6})</script> 程度のオーダーでビルド時間が延びます。
とはいえ、256個も<code>chan</code>を付いたコードを人間が読めるとは思えないので、
2個が限度でしょうね・・・。
3個以上必要になるケースは余りないと思います。</p>

<h2>型定義を再帰的にして無限chanを実現する</h2>

<p>そもそも、<code>chan</code>を大量に並べなくとも、
型定義を再帰的に行えば無限の<code>chan</code>を付けたときと同等のことができます。
例えば以下のコードで"Goroutine 1"と"Goroutine 2"を交互に表示することが可能です。</p>

<pre><code class="go">package main

import (
    "fmt"
)

type Foo chan Foo

func main() {
    ch := make(Foo)
    go func() {
        ch := ch
        for {
            done := &lt;-ch
            fmt.Println("Goroutine 2")
            done &lt;- ch
        }
    }()

    for i := 0; i &lt; 100; i++ {
        fmt.Println("Goroutine 1")
        done := make(Foo)
        ch &lt;- done
        ch = &lt;-done
    }
    fmt.Println("Hello, playground")
}
</code></pre>

<p>channelでのやり取りが複雑になるので実用性があるかは不明ですが・・・。
例えば先程の例だと、普通にループを書いたほうが圧倒的にシンプルです。</p>

<pre><code class="go">package main

import (
    "fmt"
)

func main() {
    for i := 0; i &lt; 100; i++ {
        fmt.Println("Goroutine 1")
        fmt.Println("Goroutine 2")
    }
    fmt.Println("Hello, playground")
}
</code></pre>

<p>無限<code>chan</code>が必要になる多くのケースは、このような書き換えができるような気がします。
(そもそも必要になったことがない)</p>

<h2>まとめ</h2>

<ul>
<li><code>chan</code>の個数の上限は4096から8192の間のどこか</li>
<li>256個あたりからビルド時間に影響が出始める

<ul>
<li>プログラムを読む人の精神力に多大な影響を与えるので、実際は2個までに留めるべきだと思う</li>
</ul>
</li>
<li>再帰的に型を定義することで、無限に<code>chan</code>を付けた時と同等のことが可能</li>
</ul>


<p><code>chan</code>を大量に付けたいケースには今までに僕自身は遭遇したことがないです。
有用な例を見つけた人は教えてください。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HTTP/WebSocketで時刻同期するWebNTPを書いた]]></title>
    <link href="https://shogo82148.github.io/blog/2017/03/11/go-webntp/"/>
    <updated>2017-03-11T18:48:09+09:00</updated>
    <id>https://shogo82148.github.io/blog/2017/03/11/go-webntp</id>
    <content type="html"><![CDATA[<p>Go1.8から<a href="https://golang.org/pkg/net/http/httptrace/">http/httpgtrace</a>が追加され、
HTTP通信にフックを差し込めるようになりました。
以前触った時は<a href="https://shogo82148.github.io/blog/2017/01/14/re-golang-dns-cache/">パフォーマンス測定に利用</a>しましたが、
他に面白い活用法はないかとWebNTPというのを作ってみました。</p>

<ul>
<li><a href="https://github.com/shogo82148/go-webntp">webntp</a></li>
</ul>


<p>HTTP/HTTPS/Websocket上でNTP(Network Time Protocol)っぽいことをするプログラムです。</p>

<!-- More -->


<h2>HTTP/HTTPSで時刻同期</h2>

<p>日本標準時はNICTの管理する原子時計が基準になっており、
NICTでは原子時計に直結したNTPサーバー(ntp.nict.jp)の提供を行っています。
それに加えて、<a href="http://www.nict.go.jp/JST/http.html">https/httpサービス</a>も提供しており、
ブラウザを使って現在時刻を取得できます。</p>

<p>APIは簡単でミリ秒単位のtimestampを返してくれるだけです。
その情報からサーバーとクライアント間の時間のズレを算出するわけですが、
HTTP通信では、DNSの名前解決、TCPハンドシェイク、TLSハンドシェイク等々の時間が入ってしまうため、
正確なズレを求めることは困難です。</p>

<p>そこでhttp/httpgtraceを使って、ハンドシェイクを除いたリクエストの送信時刻、レスポンスを最初に受信した時刻から、
より正確なズレを知ることができるのではと作ったのがWebNTPです。
NICTの<a href="https://ntp-a1.nict.go.jp/cgi-bin/json">JSON形式のAPI</a>に対応しており、
以下のように時刻を取得できます。</p>

<pre><code class="plain">$ go get github.com/shogo82148/go-webntp/cmd/webntp
$ webntp https://ntp-a1.nict.go.jp/cgi-bin/json
server https://ntp-a1.nict.go.jp/cgi-bin/json, offset -0.006376, delay 0.024411
2017-03-11 16:08:06.150393313 +0900 JST, server https://ntp-a1.nict.go.jp/cgi-bin/json, offset -0.006376
</code></pre>

<p>WebNTPはNICTのAPIと同様の内容を返すサーバーにもなれます。
本家のフォーマットにしたがい、しっかりとうるう秒の情報も返すようになっているので、
ntpdのSLEWモードを切った状態でお試しください。</p>

<pre><code class="plain">$ webntp -serve :8080

$ curl -s http://localhost:8080/ | jq .
{
  "id": "localhost:8080",
  "it": 0,
  "st": 1489217288.328757,
  "time": 1489217288.328757,
  "leap": 36,
  "next": 1483228800, // 今年の1/1にあったうるう秒の情報
  "step": 1
}
</code></pre>

<p>ところで、URLにcgi-binが入っているのは、過去との互換性を保つためにそうなっているのか、
今もCGIで動いているのか、気になる・・・
(少なくとも初期実装はPerlのCGIだったみたいですね)。</p>

<h2>Websocketで時刻同期</h2>

<p>HTTPで取れるのは便利ですが、これではブラウザ等や他のクライアントで正確な時間を知るのが難しいです。
今ならWebSocketが使えるのでは？と、WebSocketにも対応してみました。
時刻取得時にws/wssスキーマを指定するとWebSocketモードになります。</p>

<pre><code class="plain">$ webntp ws://localhost:8080/
server ws://localhost:8080/, offset 0.000031, delay 0.000671
2017-03-11 16:19:29.850452219 +0900 JST, server ws://localhost:8080/, offset 0.000031
</code></pre>

<p>ブラウザからもJavaScriptを使ってアクセスできるというのが大きな利点ですね。
TCP上での通信のためNTPに比べればもちろん精度は落ちますが、
スプラトゥーンができる程度のネットワーク環境であれば±十数ミリ秒程度の誤差に収まるのではないでしょうか。</p>

<h2>ntpdの参照クロックとして使う</h2>

<p>実装している最中にいろいろと調べてみたところ、
ntpdはNTPでネットワークから時刻を取得する以外に、コンピュータに直結したデバイスからも時刻情報を取得できることがわかりました。
たとえばGPSモジュールを繋いで、GPSに積まれている原子時計と同期をとることができるらしいです。</p>

<p>同期方法はたくさんあるのですが、Shared Memory <a href="http://doc.ntp.org/4.2.8/drivers/driver28.html">driver28</a>というのが
比較的ポピュラーなようです。
Python+SWIGの実装(<a href="https://github.com/mjuenema/python-ntpdshm">python-ntpdshm</a>)があったので、
それを参考にGoに移植しました。</p>

<p><code>ntpd.conf</code>にShared Memoryと同期する設定を追加します。
アドレス部分に<code>127.127.28.x</code>を指定するとShared Memoryになるそうです。</p>

<pre><code class="plain">server 127.127.28.2 noselect
fudge 127.127.28.2 refid PYTH stratum 10
</code></pre>

<p><code>-shm x</code>をオプションにつけると、ntpdとの同期モードになり、
HTTP等で取得した時刻情報をntpdに送信します。
デフォルトだと4回連続でAPIを叩いて怒られそうなので、<code>-p 1</code>も一緒につけています。</p>

<pre><code class="plain">$ webntp -p 1 -shm 2 https://ntp-a1.nict.go.jp/cgi-bin/json https://ntp-b1.nict.go.jp/cgi-bin/json
server https://ntp-a1.nict.go.jp/cgi-bin/json, offset -0.003258, delay 0.018910
server https://ntp-b1.nict.go.jp/cgi-bin/json, offset -0.003570, delay 0.021652
</code></pre>

<p>しばらくしてから、ntpdのステータスを確認すると、
remote:SHM(2)にoffset情報が表示されるはずです。</p>

<pre><code class="plain">$ ntpq -p
     remote           refid      st t when poll reach   delay   offset  jitter
==============================================================================
 SHM(2)          .PYTH.          10 l    2   64   17    0.000   -3.331   0.384
*ntp-a2.nict.go. .NICT.           1 u   58   64   37   10.280    1.494   2.028
</code></pre>

<h2>その他類似プロジェクト</h2>

<p>HTTPで時刻同期というアイデア自体はすでにあったようで、
<a href="http://www.htptime.org/index.html">htptime</a>というものがありました。
WebNTPはhtptimeのサーバーとも同期できます。
AWS Lambdaで動いているhtptimeサーバーも公開されているのですが、Internal Server Errorしか帰ってこない・・・。</p>

<p><a href="http://www.vervest.org/htp/">htp</a>はhtptimeの元ネタらしいです。
HTTPのDateヘッダーで時刻合わせするので、秒単位でしか同期できません。
WebNTPでは未対応です。</p>

<h2>まとめ</h2>

<ul>
<li>http/httpgtraceの活用法としてWebNTPというのを作ってみた</li>
<li>HTTP/HTTPS/WebSocketでの同期が可能(UDP通信を禁止されている環境でも大丈夫！)</li>
<li>取得した時刻をntpdに反映することも可能</li>
</ul>


<p>UDP/123が禁止されている環境って今はどの程度あるんですかね？</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[go-JSONStoreの高速化と機能追加]]></title>
    <link href="https://shogo82148.github.io/blog/2017/03/05/tune-up-go-jsonstore/"/>
    <updated>2017-03-05T16:19:25+09:00</updated>
    <id>https://shogo82148.github.io/blog/2017/03/05/tune-up-go-jsonstore</id>
    <content type="html"><![CDATA[<p>以前mattnさんが紹介していた<a href="https://github.com/schollz/jsonstore">schollz/jsonstore</a>。
時間が経ってしまいましたが「ここは高速化できそうだなー」といじってみたので、
やってみたことをメモ。</p>

<p>本来は上流にフィードバックしたほうがよいのですが、
本家のほうも修正が入ってコンフリクトして面倒になったので、
フォーク版をそのまま置いておきます。</p>

<ul>
<li><a href="https://github.com/shogo82148/jsonstore">shogo82148/jsonstore</a></li>
</ul>


<!-- More -->


<h2>高速化</h2>

<p>まだまだ高速化できそうなところがあったので、いじってみた部分です。</p>

<h3>ロックの範囲を最小にする</h3>

<p>ロックの範囲を小さくすることで、並列処理時の性能が上がります。
例えば、jsonstoreに値を入れる<code>Set</code>メソッドは、
以下のように<code>Set</code>全体がロックの対象になっていました。</p>

<pre><code class="go">func (s *JSONStore) Set(key string, value interface{}) error {
    // Set の中全体がロックの対象になっている
    s.Lock()
    defer s.Unlock()

    b, err := json.Marshal(value)
    if err != nil {
        return err
    }

    if s.data == nil {
        s.data = make(map[string]*json.RawMessage)
    }
    s.data[key] = (*json.RawMessage)(&amp;b)
    return nil
}
</code></pre>

<p>jsonのエンコード処理はjsonstoreの中身を触らないので並列実行可能です。
次のように <code>s.data</code> だけをロックの対象にすれば十分です。</p>

<pre><code class="go">func (s *JSONStore) Set(key string, value interface{}) error {
    // json.Marshal は並列実行可能
    b, err := json.Marshal(value)
    if err != nil {
        return err
    }

    // s.data を触る直前でロック
    s.Lock()
    defer s.Unlock()

    if s.data == nil {
        s.data = make(map[string]*json.RawMessage)
    }
    s.data[key] = (*json.RawMessage)(&amp;b)
    return nil
}
</code></pre>

<p>デコード処理も同様に並列化が可能なので、<code>Get</code>にも同じ修正をいれました。
修正前後でベンチを取ってみたところ以下のようになりました。</p>

<pre><code class="plain">Before:
BenchmarkGet-4               1000000          1923 ns/op         272 B/op          5 allocs/op
BenchmarkParaGet-4           1000000          1000 ns/op         272 B/op          5 allocs/op
BenchmarkSet-4               1000000          1159 ns/op         216 B/op          3 allocs/op
BenchmarkParaSet-4           1000000          1974 ns/op         216 B/op          3 allocs/op

After:
BenchmarkGet-4               1000000          1793 ns/op         256 B/op          4 allocs/op
BenchmarkParaGet-4           2000000           845 ns/op         256 B/op          4 allocs/op
BenchmarkSet-4               1000000          1212 ns/op         248 B/op          4 allocs/op
BenchmarkParaSet-4           2000000           686 ns/op         248 B/op          4 allocs/op
</code></pre>

<p>Paraが付いているのが並列実行したとき、付いていないのが単一のgorotineで実行したときの結果です。
単一gorotineでは修正前後で余り大きな性能差はありませんが、
並列実行の性能が向上していることがわかりますね。</p>

<p>(他にも細々とした修正を入れたので、全部がロックの効果ではないと思いますが)</p>

<h3>ストリーミングAPIを利用する</h3>

<p>ファイル保存時にjsonのエンコーディングをしているのですが、
修正前のコードでは<code>json.MarshalIndent</code>を使用していました。
<code>json.MarshalIndent</code>は結果をメモリ上に出力するので、
メモリの消費量が増え、そのメモリをアロケーションする分だけ性能が劣化します。</p>

<p><code>io.Writer</code>に書き込むだけなら、以下のように<code>json.NewEncoder</code>を利用するのが効率的です。</p>

<pre><code class="go">enc := json.NewEncoder(w)
return enc.Encode(data)
</code></pre>

<h3>不要な再エンコードを避ける</h3>

<p>元のコードでは一度jsonに変換した値を、ファイル保存時に<code>string</code>にキャストしていました。
そのため、出力されたjsonは以下のように文字列の中にjsonが入っている形になります。
この形式だと<code>"</code>のエスケープが必要になるので、
処理性能的にも、ファイル容量的にも不利です。</p>

<pre><code class="go">package main

import (
    "encoding/json"
    "os"
)

func main() {
    b := []byte(`{"Name":"Dante","Height":5.4}`)
    data := map[string]string{
        "human:1": string(b), // ここでキャストしている
    }
    enc := json.NewEncoder(os.Stdout)
    enc.Encode(data)
}
</code></pre>

<pre><code class="json">{"human:1": "{\"Name\":\"Dante\",\"Height\":5.4}"}
</code></pre>

<p>値は既にjsonエンコード済みなので、ファイル出力時に手を加える必要はありません。
以下のように<code>*json.RawMessage</code>型に変換することで、
余計な再エンコードを避けることができます。</p>

<pre><code class="go">package main

import (
    "encoding/json"
    "os"
)

func main() {
    b := []byte(`{"Name":"Dante","Height":5.4}`)
    data := map[string]*json.RawMessage{
        "human:1": (*json.RawMessage)(&amp;b),
    }
    enc := json.NewEncoder(os.Stdout)
    enc.Encode(data)
}
</code></pre>

<pre><code class="json">{"human:1":{"Name":"Dante","Height":5.4}}
</code></pre>

<p><code>json.RawMessage</code>でなく<code>*json.RawMessage</code>とポインタを使っているのがポイントです。
<code>json.RawMessage</code>だと<code>[]byte</code>とみなされてbase64エンコーディングされてしまうのです・・・。</p>

<pre><code class="go">package main

import (
    "encoding/json"
    "os"
)

func main() {
    b := []byte(`{"Name":"Dante","Height":5.4}`)
    data := map[string]json.RawMessage{
        "human:1": json.RawMessage(b),
    }
    enc := json.NewEncoder(os.Stdout)
    enc.Encode(data)
}
</code></pre>

<pre><code class="json">// Go1.7以下で実行時
{"human:1":"eyJOYW1lIjoiRGFudGUiLCJIZWlnaHQiOjUuNH0="}

// Go1.8で実行時
{"human:1":{"Name":"Dante","Height":5.4}}
</code></pre>

<p>ちなみにこの挙動、1.8で<code>json.RawMessage</code>も<code>*json.RawMessage</code>と同じ結果になる修正されたようです(この記事を書いていて気がついた)。
1.7以下を切り捨てるなら<code>json.RawMessage</code>の方が良さそうですね。</p>

<p>「ストリーミングAPIを利用する」「不要な再エンコードを避ける」をやった結果は以下のとおりです。</p>

<pre><code class="plain">Before:
BenchmarkSave-4                  500       3324647 ns/op     1418718 B/op       3121 allocs/op

After:
BenchmarkSave-4                  500       2455853 ns/op     1127372 B/op       3094 allocs/op
</code></pre>

<h3>浅いコピーで並列処理性能を上げる</h3>

<p>一度<code>Set</code>で<code>json.RawMessage</code>に変換されたデータは書き換えられることがないので、
浅いコピーをするだけでスナップショットが簡単にとれます。</p>

<pre><code class="go">func (s *JSONStore) Snapshot() *JSONStore {
    s.RLock()
    defer s.RUnlock()
    results := make(map[string]*json.RawMessage)
    for k, v := range s.data {
        results[k] = v
    }
    return &amp;JSONStore{
        data:     results,
    }
}
</code></pre>

<p>一度スナップショットを取ってしまえば、ファイルへの書き込み時にはロックが不要になります。
ファイルの書き込みはI/Oを伴うとても重い処理なので、
この部分をロックの外側に出せるのは非常に効果大です。</p>

<pre><code class="go">func (s *JSONStore) Save() {
    snapshot := s.Snapshot()

    // snapshotを取ったあとはLock不要
    enc := json.NewEncoder(w)
    return enc.Encode(snapshot.data)
}
</code></pre>

<p>別gorotineでひたすらSaveを繰り返しながらSetのベンチを取ってみた結果です。
修正前はSaveがほとんどの時間ロックを獲得していまうので、Saveと同程度の性能しか出ません。
修正後はSaveとSetを並列実行できるようになるので、大幅に性能が改善します。</p>

<pre><code class="plain">Before:
BenchmarkSaveSet-4               500       3260143 ns/op     1382516 B/op       3047 allocs/op

After:
BenchmarkSaveSet-4           1000000          1948 ns/op         914 B/op          5 allocs/op
</code></pre>

<h3>正規表現をなるべく避ける</h3>

<p>元のjsonstoreには正規表現でキーを指定して値を取ってくる機能があります。</p>

<pre><code class="go">func GetAll(re *regexp.Regexp) map[string]json.RawMessage
</code></pre>

<p>Gopherのみなさんなら御存知の通り、Goの正規表現はとても遅いです。
stringsパッケージなどを使えるよう、関数を受け取るインターフェースの方がよいでしょう。</p>

<pre><code class="go">func GetAll(matcher func(key string) bool) map[string]json.RawMessage
</code></pre>

<p>このインターフェースなら簡単なものであれば自分で関数をかけば良いし、
どうしても正規表現が必要な場合は<code>s.GetAll(re.MatchString)</code>とやればいいので大きな問題にはなりません。</p>

<p>以下ベンチマークの結果です。Afterの方は正規表現ではなくstringsパッケージを使用しています。</p>

<pre><code class="plain">Before:
BenchmarkRegex-4                3000        449209 ns/op      206954 B/op         67 allocs/op

After:
BenchmarkRegex-4                5000        251788 ns/op      124483 B/op         68 allocs/op
</code></pre>

<h2>機能追加</h2>

<p>実際使うなら最低限こんな機能も必要だよな・・・
といくつか機能追加も行いました。</p>

<h3>アトミックなデータ保存</h3>

<p>例えば<code>humans.json.gz</code>に保存されたデータを書き換えることを考えます。
単純に書くと以下のようになるでしょう。</p>

<pre><code class="go">ks, _ := jsonstore.Open("humans.json.gz")

// ksに何か操作を行う

go jsonstore.Save(ks, "humans.json.gz")

// もしpanicしたら・・・？
panic("error!!")
</code></pre>

<p>ここでもしSaveの最中にプログラムが強制終了してしまったらどうなるでしょう。
書きかけの<code>humans.json.gz</code>だけが残り、元のデータが失われてしまう可能性があります。</p>

<p>それを避けるために、一度テンポラリファイルに書き出し、Renameするのが安全です。
たとえ途中でクラッシュしてしまっても、最悪変更前のデータは残ります。</p>

<pre><code class="go">ks, _ := jsonstore.Open("humans.json.gz")

// ksに何か操作を行う

go func() {
    jsonstore.Save(ks, "humans.json.tmp.gz")
    os.Rename("humans.json.tmp.gz", "humans.json.gz")
}()

panic("error!!")
</code></pre>

<p>これを勝手にやってくれる<code>SaveAndRename</code>という関数を追加しました。</p>

<p>Linuxの場合、Renameはアトミックに行われるので、
サーバを起動したままデータベースのバックアップを取るのも安全にできます。
しかしWindowsの場合、アトミック性は保証されていない模様・・・？
本当は<code>SafeSave</code>とかにしたかったけど、Windowsの事情がよくわからなったので、
やってることをそのまま名前にしました。</p>

<h3>自動保存機能</h3>

<p>変更のたびに毎回ファイルに書き込んでいたら、極端に性能が劣化してしまうので、
適当なタイミングで自動保存してくれる機能を追加しました。
次のようにすることで、1000回変更があるたびに保存、
変更回数が1000回に満たなくても最低60秒毎に保存してくれます。</p>

<pre><code class="go">ks := new(jsonstore.JSONStore)
ks.StartAutoSave("db.json.gz", 60 * time.Second, 1000)
defer ks.StopAutoSave()
</code></pre>

<h2>まとめ</h2>

<p>以下の高速化を行いました。</p>

<ul>
<li>ロックの範囲を最小にする</li>
<li>ストリーミングAPIを利用する</li>
<li>不要な再エンコードを避ける</li>
<li>浅いコピーで並列処理性能を上げる</li>
<li>正規表現をなるべく避ける</li>
</ul>


<p>また、実際使う際に必要になるであろう、次の機能も追加しました。</p>

<ul>
<li>アトミックなデータ保存</li>
<li>自動保存機能</li>
</ul>


<p>これだけあれば、簡単なおもちゃを作るときのデータベースに使うくらいは出来るんじゃないですかね。</p>

<p>プロセス間でデータ共有できない問題はありますが・・・
まあ、そういうときは素直にRedisとかSQLiteとかboltdbとか使って下さい。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rust vs Go の終戦へ向けてPolyglotを作ってみた]]></title>
    <link href="https://shogo82148.github.io/blog/2017/02/25/rust-and-go-ploygolot/"/>
    <updated>2017-02-25T16:58:27+09:00</updated>
    <id>https://shogo82148.github.io/blog/2017/02/25/rust-and-go-ploygolot</id>
    <content type="html"><![CDATA[<p>「Golang Rust」とググると、関連項目は「Rust vs Go」のように
GolangとRustが対立しているような項目ばかりです。
まあまあ、もっと仲良くやろうじゃないですか、ということで、
どうしたら仲良くなれるかを考えました。
Polyglotにして同じソースコードの中に閉じ込めてやれば、
そのうち仲良くなるのではないかと考え、
RustとGoのPloyglotを作ってみました。</p>

<!-- More -->


<h2>結果</h2>

<pre><code class="rust polyglot.rs">/*/*/
package main

import "fmt"

func main() {
    fmt.Print("Hello Go!!")
    _ = `*/*/
fn main() {
    println!("Hello Rust!!");
//`
}
</code></pre>

<pre><code class="go polyglot.go">/*/*/
package main

import "fmt"

func main() {
    fmt.Print("Hello Go!!")
    _ = `*/*/
fn main() {
    println!("Hello Rust!!");
//`
}
</code></pre>

<h2>仕組み</h2>

<p>一番のポイントは最初の行の <code>/*/*/</code> です。
RustもGoも<code>/* */</code>形式の複数行コメントに対応していますが、
Rustはネストに対応しており、Goはネストはできないという違いがあります。
この違いにより、Rustは<code>/*/*/</code>を<code>/* /* /</code>のように「二重にネストしたコメントの開始部分」として扱いますが、
Goは<code>/* / */</code>のように「<code>/</code>をコメントアウトしたもの」と見なします。
これにより2行目<code>package main</code>以降はGoには普通のコードに見えますが、
Rustからは単なるコメントとして認識されます。</p>

<p>次はGoからRustへの切り替えです。
Goではバッククオートで複数行文字列を定義できるので、その中にRustのコードを書きます。
この中ではバッククオートさえ使わなければ自由にRustのコードを書くことが出来るので、
あとはGoのコードだけ上手くコメントアウトされるよう調整すれば完成です。</p>

<h2>せっかくなのでリンクしてみた</h2>

<p>GoからRustのコードを呼び出すサンプルコードを見つけたので、
せっかくなのでリンクしてみました。</p>

<ul>
<li><a href="https://github.com/medimatrix/rust-plus-golang">medimatrix/rust-plus-golang</a></li>
</ul>


<p><code>main.go</code>と<code>lib.go</code>を以下のように置き換えます。
内容は一緒なので、シンボリックリンクにすると編集が楽でいいかもしれませんね。</p>

<pre><code class="go main.go">/*golang code starts from here/*/
package main

/*
#cgo LDFLAGS: -L./lib -lhello
void hello(char *name);
*/
import "C"

func main() {
    C.hello(C.CString("John Smith"))

    _ = `rustlang code starts from here */*/
extern crate libc;
use std::ffi::CStr;

#[no_mangle]
pub extern "C" fn hello(name: *const libc::c_char) {
    let buf_name = unsafe { CStr::from_ptr(name).to_bytes() };
    let str_name = String::from_utf8(buf_name.to_vec()).unwrap();
    println!("Hello {}!", str_name);
//`
}
</code></pre>

<pre><code class="rust lib.rs">/*golang code starts from here/*/
package main

/*
#cgo LDFLAGS: -L./lib -lhello
void hello(char *name);
*/
import "C"

func main() {
    C.hello(C.CString("John Smith"))

    _ = `rustlang code starts from here */*/
extern crate libc;
use std::ffi::CStr;

#[no_mangle]
pub extern "C" fn hello(name: *const libc::c_char) {
    let buf_name = unsafe { CStr::from_ptr(name).to_bytes() };
    let str_name = String::from_utf8(buf_name.to_vec()).unwrap();
    println!("Hello {}!", str_name);
//`
}
</code></pre>

<p>呼び出し元と呼び出し先のコードが一度に確認できて便利(？)</p>

<h2>まとめ</h2>

<p>Goの最初に<code>package main</code>を書かなければいけない制限が意外と厳しいため、
Polyglotにする言語には相性があります。
つまりRustとGoは相性バツグンということですね！(？？？)
みなさんもRustとGoを仲良く使っていきましょう！！！！！</p>

<p>(※ジョークなので本気にしないでくださいね、念のため)</p>

<h2>参考</h2>

<ul>
<li><a href="https://doc.rust-lang.org/reference.html#comments">The Rust Reference#comment</a></li>
<li><a href="https://shogo82148.github.io/blog/2016/04/05/polyglot-of-perl-and-golang/">PerlとGolangで実行できるPolyglot書いてみた</a>

<ul>
<li>どうやらGoはPerlとも相性がいいようです</li>
</ul>
</li>
<li><a href="https://github.com/medimatrix/rust-plus-golang">medimatrix/rust-plus-golang</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
