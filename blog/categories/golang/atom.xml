<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: golang | Shogo's Blog]]></title>
  <link href="https://shogo82148.github.io/blog/categories/golang/atom.xml" rel="self"/>
  <link href="https://shogo82148.github.io/"/>
  <updated>2017-05-30T18:03:42+09:00</updated>
  <id>https://shogo82148.github.io/</id>
  <author>
    <name><![CDATA[Shogo Ichinose]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Re: GoとPythonとGrumpyの速度ベンチマーク]]></title>
    <link href="https://shogo82148.github.io/blog/2017/05/30/grumpy/"/>
    <updated>2017-05-30T17:53:32+09:00</updated>
    <id>https://shogo82148.github.io/blog/2017/05/30/grumpy</id>
    <content type="html"><![CDATA[<p><a href="http://qiita.com/kotauchisunsun/items/db28d14f7f13fb29e5f9">GoとPythonとGrumpyの速度ベンチマーク ～Googleのトランスパイラはどれくらい速い？～</a>という記事を拝読したのですが、
もう一歩踏み込んで検証して欲しい・・・。</p>

<blockquote><p>並列処理性能が優れているほか、PythonコードからGoのパッケージをPythonモジュールのように呼び出して利用することもできるという特徴がある。</p></blockquote>

<p>と<a href="http://news.mynavi.jp/news/2017/01/06/110/">Google、すごくスケールするPython実行環境をGoで開発</a>から引用しているのに、
この件に全く触れていないんですよね。
Twitterに呟いたってどうせ誰もやってくれない気がするので、自分で試してみました。</p>

<!-- More -->


<h2>環境</h2>

<p>この記事を書いている2017年5月30日現在の最新バージョンで検証しました。</p>

<ul>
<li>go version go1.8.3 darwin/amd64</li>
<li>CPython 2.7.13</li>
<li>Grumpy <a href="https://github.com/google/grumpy/tree/d8d01899f5eedf99602887567aaeb39a9154bf68">d8d01899f5</a></li>
</ul>


<p>Grumpyのインストール方法はREADMEにある通り。</p>

<pre><code class="bash">make
export GOPATH=$PWD/build
export PYTHONPATH=$PWD/build/lib/python2.7/site-packages
</code></pre>

<p>ただ個人的な環境問題としてPythonのバージョン管理に利用しているpyenvとの相性が悪いらしく、
pyenvが管理しているPythonへのパスを直接通す必要がありました。
(これがないとPythonスクリプトがなぜかbashに処理される。なんかこの問題最近Twitterで見たような・・・)</p>

<pre><code class="bash">export PATH=$HOME/.pyenv/versions/2.7.13/bin:$PATH
</code></pre>

<h2>モンテカルロ法を並列実行してみる</h2>

<p>まず、並列処理性能について検証してみましょう。
モンテカルロ法の各試行は独立しているので、並列実行にするのは容易です。
Python2のthreadingモジュールを使って並列実行してみましょう。</p>

<h3>コード</h3>

<pre><code class="python">#coding:utf-8
# モンテカルロ法 Pure Python 並列版
import threading
import random
import sys

class MyThread(threading.Thread):
    def __init__(self):
        super(MyThread, self).__init__()
        self.c = 0

    def run(self):
        r = random.Random()
        c = 0
        for _ in xrange(num):
            x = r.random()
            y = r.random()

            if x * x + y * y &lt;= 1.0:
                c += 1
        self.c = c


if __name__ == "__main__":
    num = int(sys.argv[1])
    para = int(sys.argv[2])

    threads = []
    for i in xrange(para):
        t = MyThread()
        t.start()
        threads.append(t)

    c = 0
    for t in threads:
        t.join()
        c += t.c

    print 4.0*c/(num*para)
</code></pre>

<p>並列度に比例した計算負荷がかかるようになってます。
理想的な並列処理が行えていれば、並列度に関わらず同じ実時間で実行されるはずです。</p>

<h3>CPythonでの結果</h3>

<p>CPythonでtimeを使って雑に測定した結果です。
並列度を4倍にしたら実行時間も4倍になっています。
また、実時間と実行時間が大体おなじで、まったく並列実行できていません。</p>

<pre><code class="plain"># 並列度1で実行した場合(CPython)
$ time python con_monte.py 300000 1
3.14529333333
real    0m0.358s
user    0m0.279s
sys 0m0.032s

# 並列度4で実行した場合(CPython)
$ time python con_monte.py 300000 4
3.14382666667
real    0m1.261s
user    0m1.124s
sys 0m0.441s
</code></pre>

<p>CPythonを利用しているひとにはおなじみの<a href="https://ja.wikipedia.org/wiki/%E3%82%B0%E3%83%AD%E3%83%BC%E3%83%90%E3%83%AB%E3%82%A4%E3%83%B3%E3%82%BF%E3%83%97%E3%83%AA%E3%82%BF%E3%83%AD%E3%83%83%E3%82%AF">グローバルインタプリタロック(GIL: Global Interpreter Lock)</a>の影響ですね。
CPythonのスレッドはI/Oの並列化には向いていますが、計算の並列化には向いていません。</p>

<h3>Grumpyでの結果</h3>

<p>次にGrumpyで測定した結果です。
並列度を4倍にしたところ、実行時間は2倍程度になりました。</p>

<pre><code class="plain"># 並列度1で実行した場合(Grumpy)
$ time ./con_monte_darwin_amd64 300000 1
3.1441733333333333
real    0m16.129s
user    0m16.787s
sys 0m0.125s

# 並列度4で実行した場合(Grumpy)
$ time ./con_monte_darwin_amd64 300000 4
3.1401766666666666
real    0m33.935s
user    1m45.979s
sys 0m0.654s
</code></pre>

<p>実時間4倍までは行かなかったので、理想的な並列計算には及ばないものの、
CPythonよりは並列化の効果が出ていそうです。
実のところ、Goも計算の並列化よりI/Oの並列化・並行処理のほうが得意なんですよね(GILよりはまし)。</p>

<p>手元の4コアのMBAで試した結果なので、コア数が多いとまた結果が変わってくるかもしれません。</p>

<h2>PythonからGoのライブラリを直接呼び出す</h2>

<p>次にGoのパッケージを呼び出す機能を試してみます。
Pythonのrandomパッケージではなく、Goのmath/randパッケージを使ってモンテカルロ法を実行してみます。</p>

<h3>コード</h3>

<pre><code class="python">#coding:utf-8
# モンテカルロ法 Python+Go 並列版
import threading
import random
import sys
from __go__.time import Now
from __go__.math.rand import New, NewSource


class MyThread(threading.Thread):
    def __init__(self):
        super(MyThread, self).__init__()
        self.c = 0

    def run(self):
        r = New(NewSource(Now().UnixNano()))
        c = 0
        for _ in xrange(num):
            x = r.Float64()
            y = r.Float64()

            if x * x + y * y &lt;= 1.0:
                c += 1
        self.c = c


if __name__ == "__main__":
    num = int(sys.argv[1])
    para = int(sys.argv[2])

    threads = []
    for i in xrange(para):
        t = MyThread()
        t.start()
        threads.append(t)

    c = 0
    for t in threads:
        t.join()
        c += t.c

    print 4.0*c/(num*para)
</code></pre>

<h3>Grumpyでの結果</h3>

<p>Grumpyでの実行結果です。
CPythonには遠く及ばないものの、もとのコードの8倍速くらいにはなりました。</p>

<pre><code class="plain"># 並列度1で実行した場合(Grumpy)
$ time ./con_monte_go_darwin_amd64 300000 1
3.1388133333333332
real    0m1.921s
user    0m2.006s
sys 0m0.029s

# 並列度4で実行した場合(Grumpy)
$ time ./con_monte_go_darwin_amd64 300000 4
3.143743333333333
real    0m4.115s
user    0m12.855s
sys 0m0.096s
</code></pre>

<h2>竹内関数を並列実行してみる</h2>

<p>竹内関数を並列実行した場合も試してみました。</p>

<h3>コード</h3>

<pre><code class="python">#coding:utf-8
# 竹内関数 Pure Python 並列版
import sys
import threading

def tak(x, y, z):
    if x &lt;= y:
        return y
    else:
        return tak(tak((x-1), y , z), tak((y-1), z , x), tak((z-1) , x, y))

class MyThread(threading.Thread):
    def __init__(self, a, b, c):
        super(MyThread, self).__init__()
        self.a = a
        self.b = b
        self.c = c
        self.result = 0

    def run(self):
        self.result = tak(self.a, self.b, self.c)

def main():
    a = int(sys.argv[1])
    b = int(sys.argv[2])
    c = int(sys.argv[3])
    para = int(sys.argv[4])

    threads = []
    for i in xrange(para):
        t = MyThread(a, b, c)
        t.start()
        threads.append(t)

    for t in threads:
        t.join()
        print t.result

if __name__=="__main__":
    main()
</code></pre>

<p>モンテカルロ法と同様に、理想的な並列処理が行えていれば、並列度に関わらず同じ実時間で実行されるはずです。</p>

<h3>CPythonでの結果</h3>

<p>CPythonでの結果です。
モンテカルロ法の場合と同様に、
並列度を4倍にしたら実行時間も4倍になっています。</p>

<pre><code class="plain"># 並列度1で実行した場合(CPython)
$ time python con_take.py 11 10 0 1
11
real    0m1.529s
user    0m1.498s
sys 0m0.028s

# 並列度4で実行した場合(CPython)
$ time python con_take.py 11 10 0 4
11
11
11
11
real    0m7.333s
user    0m6.620s
sys 0m2.565s
</code></pre>

<h3>Grumpyでの結果</h3>

<p>Grumpyでの結果です。</p>

<pre><code class="plain"># 並列度1で実行した場合(Grumpy)
$ time ./con_take_darwin_amd64 11 10 0 1
11
real    0m0.988s
user    0m0.988s
sys 0m0.018s

# 並列度4で実行した場合(Grumpy)
$ time ./con_take_darwin_amd64 11 10 0 4
11
11
11
11
real    0m2.031s
user    0m7.135s
sys 0m0.031s
</code></pre>

<p><strong>(なんかCPythonより早くなったぞ？？？？)</strong></p>

<p>最初に紹介した記事でも、
モンテカルロ法のベンチマークではCPythonがGrumpyの数十倍の速度で圧倒的勝利でしたが、
竹内関数のベンチマークではその差は縮まっています。
この程度であれば並列度を上げて物理で殴れば容易にGrumpyが逆転するでしょう。</p>

<p>(この検証で並列度1のときもGrumpy勝ったの謎だけど・・・)</p>

<h2>考察</h2>

<p>モンテカルロ法はCPythonのほうが圧倒的に速かったのに、
竹内関数ではGrumpyのほうが速かった(あるいは差が縮まった)という結果から、
「<strong>GrumpyからGoの関数を呼び出すオーバーヘッドが大きい</strong>」のではと推測しています。
モンテカルロ法のPure Python版でも圧倒的差が付いたのは、
<a href="https://github.com/google/grumpy/blob/d8d01899f5eedf99602887567aaeb39a9154bf68/lib/_random.py">Grumpyのrandomパッケージの実装が内部でGoのmath/randを呼んでいる</a>からです。</p>

<p>純粋なPure Pythonなコードであれば、Grumpyのシングルスレッド性能はCPythonより数倍遅い程度です。
最近のCPUコアたくさんなマシンであれば、GILのなくマルチスレッドを活かせるGrumpyが有利になると思います。
このことはグーグルのブログ記事「<a href="https://opensource.googleblog.com/2017/01/grumpy-go-running-python.html">Grumpy: Go running Python!</a>」でも触れられていますね。</p>

<h2>まとめ</h2>

<ul>
<li>Grumpyが非常に遅い<strong>のではなく</strong>、「GrumpyからGoの関数を呼び出すオーバーヘッドが大きい」(推測)</li>
<li>Grumpyのシングルスレッド性能はCPythonより数倍遅い程度</li>
<li>並列処理性能ではGrumpyが有利</li>
<li>そもそもGrumpyの目的は計算速度を上げることではないので、計算速度向上を求めている人は他の手法を模索しましょう</li>
</ul>


<p>今回の検証に使用したソースコード、Grumpyによるトランスパイルの結果、各種プラットフォームのバイナリをGithubにあげておきました。</p>

<ul>
<li><a href="https://github.com/shogo82148/grumpy-test">shogo82148/grumpy-test</a></li>
</ul>


<p>さらに検証を進めたい方は参考にどうぞ。</p>

<h2>参考</h2>

<ul>
<li><a href="https://opensource.googleblog.com/2017/01/grumpy-go-running-python.html">Grumpy: Go running Python!</a></li>
<li><a href="http://news.mynavi.jp/news/2017/01/06/110/">Google、すごくスケールするPython実行環境をGoで開発</a></li>
<li><a href="http://qiita.com/kmry2045/items/998250b3d430d82594c2">Grumpy(Go running Python)を試してみた。</a></li>
<li><a href="http://qiita.com/kotauchisunsun/items/db28d14f7f13fb29e5f9">GoとPythonとGrumpyの速度ベンチマーク ～Googleのトランスパイラはどれくらい速い？～</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[String::RandomのGo移植を書いてみた]]></title>
    <link href="https://shogo82148.github.io/blog/2017/05/04/go-rerand/"/>
    <updated>2017-05-04T10:57:37+09:00</updated>
    <id>https://shogo82148.github.io/blog/2017/05/04/go-rerand</id>
    <content type="html"><![CDATA[<p>golangkyotoで<a href="http://blog.yux3.net/entry/2017/05/01/014200">String::RandomのGo移植についての発表</a>があったと聞き、
これに対抗して以前途中まで書いていたString::RandomのGo移植をちょっといじって公開しました。</p>

<ul>
<li><a href="https://github.com/shogo82148/go-rerand">shogo82148/go-rerand</a></li>
</ul>


<!-- More -->


<h2>背景</h2>

<h3>ナイーブな実装の問題点</h3>

<p>実はgolangkyoto以前にもGoの正規表現エンジンを使ってランダムな文字列を生成する試みはあって、
たしかにこれは面白そうだと記事を読んでいました。</p>

<ul>
<li>「<a href="http://ymotongpoo.hatenablog.com/entry/2014/12/21/192304">Goの正規表現エンジンを使ってファジング用ツールを書いてみる</a>」</li>
</ul>


<p>しかし、gocha同様、この実装では文字列の長さが幾何分布に従うため、短い文字が多めにでてしまいます。</p>

<pre><code class="plain">% gocha -n 100000 'a*' | sort | uniq -c
50054
24894 a
12633 aa
6278 aaa
2994 aaaa
1517 aaaaa
 809 aaaaaa
 400 aaaaaaa
 206 aaaaaaaa
 109 aaaaaaaaa
  54 aaaaaaaaaa
  22 aaaaaaaaaaa
  15 aaaaaaaaaaaa
   7 aaaaaaaaaaaaa
   4 aaaaaaaaaaaaaa
   3 aaaaaaaaaaaaaaa
   1 aaaaaaaaaaaaaaaa
</code></pre>

<h3>正規表現のパターンを数え上げとその問題点</h3>

<p>この問題を解決するために
「この先何パターンあるかを調べておけば、正規表現が表す文字列の集合からランダムに文字列を取り出せるのでは？」
と考え、golangkyoto以前からちょこちょこ実装を進め、不完全ながらも一応動作するところまでは書いていたのです。
有向グラフの経路数えあげ問題なので、メモ化再帰を使って頑張れば解けます。
少々面倒ですが、<a href="https://www.youtube.com/watch?v=Q4gTV4r0zRs">おねえさんの問題</a>と比べれば簡単です。</p>

<p>パターンを数え上げる都合上、組み合わせが無限にある <code>a*</code> ような正規表現は扱えません。
<code>a{1,10}</code> のように明示的に範囲を指定する必要があります。
たとえば <code>a{1,10}</code> は10パターン組み合わせがあるので、20万個ランダムに生成すると、それぞれのパターンがおおよそ2万個ずつ生成されます。
(<code>-d</code> オプションについては後述)</p>

<pre><code class="plain">$ rerand -d -n 200000 'a{1,10}' | sort | uniq -c
20153 a
19863 aa
19899 aaa
19908 aaaa
19975 aaaaa
20000 aaaaaa
20081 aaaaaaa
20021 aaaaaaaa
20072 aaaaaaaaa
20028 aaaaaaaaaa
</code></pre>

<p><code>[ab]{1,3}</code>のような正規表現でも、それぞれのパターンがおおよそ同じ数だけ生成されます。</p>

<pre><code class="plain">$ rerand -d -n 200000 '[ab]{1,3}' | sort | uniq -c
14299 a
14249 aa
14215 aaa
14257 aab
14192 ab
14340 aba
14317 abb
14209 b
14213 ba
14332 baa
14228 bab
14355 bb
14634 bba
14160 bbb
</code></pre>

<p>これはこれで意図した挙動なのですが、
1文字のパターン数に比べて、3文字のパターン数が非常に多いため、相対的に短い文字列が出現しにくくなってしまいます。
「これは本当にユーザーが望んだものなのだろうか・・・？」と疑問に思ってしまい、
うまい解決策が思いつかないままずっと放置していました。</p>

<h2>文字グループの同一視</h2>

<p>ここまで実装では正規表現の定義に厳密に従い「<code>[ab]</code>は<code>a</code>と<code>b</code>にマッチするので2パターン」と解釈していましたが、
「<code>[ab]</code>のような1文字にマッチするパターンは全部1パターン」と緩い解釈にするようにしました。
<code>-d</code>オプションはこの挙動を制御するためのオプションです。</p>

<p>デフォルトの挙動は「1文字にマッチするパターンは全部1パターン」です。
さきほどと同じ<code>[ab]{1,3}</code>で、<code>-d</code>オプションを外しデフォルトの設定で文字列生成すると以下のようになります。</p>

<pre><code class="plain">$ rerand -n 200000 '[ab]{1,3}' | sort | uniq -c
33463 a
16432 aa
8392 aaa
8206 aab
16806 ab
8334 aba
8403 abb
33242 b
16549 ba
8393 baa
8372 bab
16644 bb
8376 bba
8388 bbb
</code></pre>

<p><code>a</code>や<code>b</code>が多めに出ているような気がしますが、
文字列長別に集計するとおおよそ同じ回数だけ出現していることが確認できます。</p>

<pre><code class="plain">$ rerand -n 200000 '[ab]{1,3}' | perl -nE 'chomp; say length' | sort -n | uniq -c
66769 1
67036 2
66195 3
</code></pre>

<p>これで少しはユーザーフレンドリーになったはず(？)</p>

<h2>ベンチマーク</h2>

<p>ベンチマークの結果も貼っておきます。
coffeescriptは <a href="https://cho45.stfuawsc.com/String_random.js/demo.html#%5B%E3%82%AB%E3%82%B3%E3%83%B5%E3%81%8B%5D%5B%E3%83%83%E3%83%BC%5D%7B1%2C3%7D%3F%5B%E3%83%95%E3%83%92%E3%81%B5%E3%81%B2%5D%7B1%2C3%7D%5B%E3%82%A3%E3%82%A7%E3%83%BC%5D%7B1%2C3%7D%5B%E3%82%BA%E3%82%B9%5D%5B%E3%83%89%E3%82%AF%E3%82%B0%E3%83%A5%5D%5B%E3%83%AA%E3%82%A4%5D%5B%E3%83%97%E3%83%96%E3%81%B7%E3%81%B6%5D%7B1%2C3%7D%5B%E3%83%88%E3%83%89%E3%82%A9%5D%7B1%2C2%7D">コーフィースクリップトの発音を生成する</a>ベンチマーク、
telephoneは<code>\d{2,3}-\d{3,4}-\d{3,4}</code>で電話番号っぽい文字列を生成するベンチです。</p>

<pre><code class="plain">$ go test -run none -bench . -benchmem ./...
BenchmarkGenerator/coffeescript-4            1000000          1737 ns/op          81 B/op          2 allocs/op
BenchmarkGenerator/[あ-お]{10}-4               2000000           845 ns/op          80 B/op          2 allocs/op
BenchmarkGenerator/[[:alpha:]]-4             5000000           274 ns/op          36 B/op          2 allocs/op
BenchmarkGenerator/\S-4                      5000000           292 ns/op          40 B/op          2 allocs/op
BenchmarkGenerator/\S{10}-4                  1000000          1568 ns/op          80 B/op          2 allocs/op
BenchmarkGenerator/\pN-4                     5000000           304 ns/op          39 B/op          2 allocs/op
BenchmarkGenerator/\p{Greek}-4               5000000           299 ns/op          39 B/op          2 allocs/op
BenchmarkGenerator/telephone-4               2000000           886 ns/op          48 B/op          2 allocs/op
BenchmarkRuneGenerator/[a]-4                300000000            4.24 ns/op        0 B/op          0 allocs/op
BenchmarkRuneGenerator/[a-z]-4              30000000            42.7 ns/op         0 B/op          0 allocs/op
BenchmarkRuneGenerator/[a-zA-Z0-9]-4        10000000           118 ns/op           0 B/op          0 allocs/op
PASS
ok      github.com/shogo82148/go-rerand 20.013s
?       github.com/shogo82148/go-rerand/cmd/rerand  [no test files]
BenchmarkGocha/coffeescript-4             300000          3967 ns/op        1090 B/op         34 allocs/op
BenchmarkGocha/[あ-お]{10}-4               1000000          1951 ns/op         328 B/op         15 allocs/op
BenchmarkGocha/[[:alpha:]]-4             5000000           323 ns/op          64 B/op          4 allocs/op
BenchmarkGocha/\S-4                      5000000           394 ns/op         128 B/op          5 allocs/op
BenchmarkGocha/\S{10}-4                   500000          3353 ns/op        1288 B/op         35 allocs/op
BenchmarkGocha/\pN-4                     1000000          1988 ns/op        4096 B/op         10 allocs/op
BenchmarkGocha/\p{Greek}-4               1000000          1122 ns/op        2048 B/op          9 allocs/op
BenchmarkGocha/telephone-4               1000000          1998 ns/op         288 B/op         14 allocs/op
PASS
ok      github.com/shogo82148/go-rerand/gocha_test  14.405s
BenchmarkStrRand/coffeescript-4              1000000          1828 ns/op         262 B/op         11 allocs/op
BenchmarkStrRand/[あ-お]{10}-4                 1000000          1189 ns/op         208 B/op          9 allocs/op
BenchmarkStrRand/\S-4                       20000000            72.9 ns/op         0 B/op          0 allocs/op
BenchmarkStrRand/\S{10}-4                    1000000          1097 ns/op          64 B/op          9 allocs/op
BenchmarkStrRand/telephone-4                 1000000          1409 ns/op          58 B/op         10 allocs/op
PASS
ok      github.com/shogo82148/go-rerand/strrand_test    7.136s
</code></pre>

<p>テストケースにもよりますが、Songmuさんのstrrandと同等かちょっと速い程度の性能です(シンプルな正規表現ではstrrandが速いこともある)。
Twitterには「Gocha速い！」みたいなことが流れてましたが、僕の手元での検証ではstrrandの方が高速でした。
どうも<a href="https://github.com/t-mrt/gocha/pull/3">ベンチマークの使い方間違っていた</a>っぽいですね・・・。</p>

<p>ちなみにこのベンチマークには正規表現をパースする処理は入っていません。
(どう考えてもstrrandに負けるのは目に見えている)
たいていのケースで初期化一回なので気にしない気にしない。</p>

<h2>グローバルなmath/rand関数の扱い</h2>

<p>go-rerandを作る際、他の実装も参考にしたのですが、
Seedの初期化のタイミングがまちまちで、少し気になりました。</p>

<ul>
<li>fuzzingo: <code>rand.Intn</code>を使う直前(！)</li>
<li>strrand: init関数内</li>
<li>gocha: Newの中</li>
</ul>


<p>Seedの初期化は本来一回だけでいいので、「<code>rand.Intn</code>を使う直前」や「Newの中」で行うのは無駄です。
init関数内でやる方法がベターですが、<code>math/rand</code>を使うライブラリを複数importしている場合、
結局何度もSeedの初期化が行われてしまいます。
ライブラリ利用者の手間は増えますが、ライブラリの中ではなく<code>main.go</code>の中でやってほしい！というのが僕の意見です。</p>

<pre><code class="go">// main.goの中でやってほしい！
func init() {
    rand.Seed(time.Now().UnixNano())
}
</code></pre>

<p>ベストなのは <strong>ライブラリではグローバルなmath/rand関数を使わない！</strong> ことです。
rerandでは以下のように<code>rand.New</code>を使って、グローバルな関数は使っていません。</p>

<pre><code class="go">r = rand.New(rand.NewSource(time.Now().UnixNano()))
</code></pre>

<p>goroutine-unsafeになってしまうので、同期処理を自前で書く必要があるのが難点です。
その代わり、ロックの粒度が細かく調整できるので、並列処理の効率は上がるはずです(たぶん)。</p>

<p>また、テストの際にSeedを固定できるので便利です。</p>

<pre><code class="go">r = rand.New(rand.NewSource(1))
</code></pre>

<h2>gocha互換オプション</h2>

<p><code>-prob 0.5</code>でGochaと同じ挙動になるはずです。
<code>a*</code>のような無限長の正規表現も扱えます。
数値をいじることで文字列の長さの分布を調整可能です。</p>

<h2>まとめ</h2>

<ul>
<li>Go版String::Randomを作った</li>
<li><strong>ライブラリではグローバルなmath/rand関数をなるべく使わないでほしい！</strong></li>
</ul>


<h2>参考</h2>

<ul>
<li><a href="http://ymotongpoo.hatenablog.com/entry/2014/12/21/192304">Goの正規表現エンジンを使ってファジング用ツールを書いてみる</a></li>
<li><a href="https://github.com/ymotongpoo/fuzzingo">ymotongpoo/fuzzingo</a></li>
<li><a href="http://www.songmu.jp/riji/entry/2015-03-28-strrand.html">String::Randomのgolang移植書いた</a></li>
<li><a href="https://github.com/Songmu/strrand">Songmu/strrand</a></li>
<li><a href="http://blog.yux3.net/entry/2017/05/01/014200">golangkyoto 「そうだ、 Go 京都」で「Go に String::Random を移植した話」というタイトルで発表した</a></li>
<li><a href="https://github.com/t-mrt/gocha">t-mrt/gocha</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Go言語のヒープに確保するデータの初期化コストについて調べてみた(Go1.8.1版)]]></title>
    <link href="https://shogo82148.github.io/blog/2017/04/13/go1-8-allocation/"/>
    <updated>2017-04-13T08:23:08+09:00</updated>
    <id>https://shogo82148.github.io/blog/2017/04/13/go1-8-allocation</id>
    <content type="html"><![CDATA[<p><a href="https://twitter.com/kaoriya/status/851983856966283265">https://twitter.com/kaoriya/status/851983856966283265</a>">https://twitter.com/kaoriya/status/851983856966283265">https://twitter.com/kaoriya/status/851983856966283265</a></a></p>

<p>こちらのツイートに対して、以下のベンチ結果が紹介されていました。</p>

<ul>
<li><a href="http://ryochack.hatenablog.com/entry/2014/06/08/225606">Go言語のヒープに確保するデータの初期化コストについて調べてみた</a></li>
</ul>


<p>しかし<a href="https://twitter.com/hnakamur2">hnakamur2</a>さんも言及しているように、
これはGo1.2.2時の結果。
その後、GoのコンパイラがGo実装になったり、SSAが導入されたりと、
今のコンパイラの実装は当時とは全く違うものになっています。</p>

<p>というわけで、現時点での最新のバージョン(Go1.8.1)で、同様の検証をおこなってみました。</p>

<!-- More -->


<h2>検証コード</h2>

<p>検証に使用したコードはGo1.2.2のときと全く同じものです。</p>

<pre><code class="go">// alloc_overhead.go

package main

type container struct {
    v [64]byte
}

func MakeContainer() *container {
    c := container{}
    return &amp;c
}

func MakeContainerOneLine() *container {
    return &amp;container{}
}

func MakeContainerNew() *container {
    return new(container)
}

func main() {
    _ = MakeContainer()
    _ = MakeContainerOneLine()
    _ = MakeContainerNew()
}
</code></pre>

<pre><code class="go">// alloc_overhead_test.go

package main

import (
    "testing"
)

func BenchmarkMakeContainer(b *testing.B) {
    for i := 0; i &lt; b.N; i++ {
        _ = MakeContainer()
    }
}

func BenchmarkMakeContainerOneLine(b *testing.B) {
    for i := 0; i &lt; b.N; i++ {
        _ = MakeContainerOneLine()
    }
}

func BenchmarkMakeContainerNew(b *testing.B) {
    for i := 0; i &lt; b.N; i++ {
        _ = MakeContainerNew()
    }
}
</code></pre>

<h2>ベンチマーク結果</h2>

<p>Go1.8.1でベンチマークを実行した結果がこちら。</p>

<pre><code class="plain">$ go test -bench . -benchmem
BenchmarkMakeContainer-4            1000000000           2.79 ns/op        0 B/op          0 allocs/op
BenchmarkMakeContainerOneLine-4     1000000000           2.84 ns/op        0 B/op          0 allocs/op
BenchmarkMakeContainerNew-4         1000000000           2.83 ns/op        0 B/op          0 allocs/op
PASS
ok      _/Users/shogo/workspace/tmp/2017-04-13-alloc    9.345s
</code></pre>

<p>ベンチマークの結果、ほとんど速度の差はありませんでした。</p>

<p>しかし、「ヒープに置かれるデータの初期化」を検証したかったのに、アロケーションが0なのはおかしいですね？
どうやら最適化の結果、スタックに置かれるようになってしまったようです。</p>

<h2>再検証</h2>

<p>Go1.7から追加された<a href="https://golang.org/pkg/runtime/#KeepAlive">runtime.KeepAlive</a>を使ってベンチマークを修正しました。
<code>runtime.KeepAlive</code>が呼ばれるまで確保した領域は解放されることが無いので、
データがヒープに乗ってくれるはずです(たぶん)。</p>

<pre><code class="go">// alloc_overhead_test.go

package main

import (
    "runtime"
    "testing"
)

func BenchmarkMakeContainer(b *testing.B) {
    for i := 0; i &lt; b.N; i++ {
        runtime.KeepAlive(MakeContainer())
    }
}

func BenchmarkMakeContainerOneLine(b *testing.B) {
    for i := 0; i &lt; b.N; i++ {
        runtime.KeepAlive(MakeContainerOneLine())
    }
}

func BenchmarkMakeContainerNew(b *testing.B) {
    for i := 0; i &lt; b.N; i++ {
        runtime.KeepAlive(MakeContainerNew())
    }
}
</code></pre>

<p>修正版のベンチマークはこちら。</p>

<pre><code class="plain">$ go test -bench . -benchmem
BenchmarkMakeContainer-4            50000000            34.7 ns/op        64 B/op          1 allocs/op
BenchmarkMakeContainerOneLine-4     30000000            34.4 ns/op        64 B/op          1 allocs/op
BenchmarkMakeContainerNew-4         50000000            35.9 ns/op        64 B/op          1 allocs/op
PASS
ok      _/Users/shogo/workspace/tmp/2017-04-13-alloc    4.690s
</code></pre>

<p>意図したとおりアロケーションが発生しています。
速度差もほとんどありません。</p>

<h2>最適化の結果を見てみる</h2>

<p><a href="http://shinpei.github.io/blog/2016/08/13/what-ssa-brings-to-go-17/">Go1.7からSSAが導入された</a>ことにより、
以下のようなコマンドで最適化の様子を簡単に知ることができるようになりました。</p>

<pre><code class="bash">GOSSAFUNC=MakeContainer go build alloc_overhead.go
</code></pre>

<p>この機能を使って、各関数が最終的にどのように最適化されたのかを確認してみます。</p>

<p>以下は<code>MakeContainer</code>の結果(<a href="/files/2017-04-13-go1-8-allocation/MakeContainer.html">ssa.html</a>)。</p>

<pre><code class="plain">v1 = InitMem &lt;mem&gt;
v2 = SP &lt;uintptr&gt; : SP
v3 = SB &lt;uintptr&gt; : SB
v10 = LEAQ &lt;*uint8&gt; {type."".container} v3 : AX
v8 = MOVQstore &lt;mem&gt; v2 v10 v1
v9 = CALLstatic &lt;mem&gt; {runtime.newobject} [16] v8
v11 = MOVQload &lt;*container&gt; [8] v2 v9 : AX
v13 = VarDef &lt;mem&gt; {~r0} v9
v14 = MOVQstore &lt;mem&gt; {~r0} v2 v11 v13
</code></pre>

<p><code>MakeContainerOneLine</code>の結果(<a href="/files/2017-04-13-go1-8-allocation/MakeContainerOneLine.html">ssa.html</a>)。</p>

<pre><code class="plain">v1 = InitMem &lt;mem&gt;
v2 = SP &lt;uintptr&gt; : SP
v3 = SB &lt;uintptr&gt; : SB
v10 = LEAQ &lt;*uint8&gt; {type."".container} v3 : AX
v8 = MOVQstore &lt;mem&gt; v2 v10 v1
v9 = CALLstatic &lt;mem&gt; {runtime.newobject} [16] v8
v11 = MOVQload &lt;*container&gt; [8] v2 v9 : AX
v14 = VarDef &lt;mem&gt; {~r0} v9
v15 = MOVQstore &lt;mem&gt; {~r0} v2 v11 v14
</code></pre>

<p><code>MakeContainerNew</code>の結果(<a href="/files/2017-04-13-go1-8-allocation/MakeContainerNew.html">ssa.html</a>)。</p>

<pre><code class="plain">v1 = InitMem &lt;mem&gt;
v2 = SP &lt;uintptr&gt; : SP
v3 = SB &lt;uintptr&gt; : SB
v10 = LEAQ &lt;*uint8&gt; {type."".container} v3 : AX
v8 = MOVQstore &lt;mem&gt; v2 v10 v1
v9 = CALLstatic &lt;mem&gt; {runtime.newobject} [16] v8
v11 = MOVQload &lt;*container&gt; [8] v2 v9 : AX
v12 = VarDef &lt;mem&gt; {~r0} v9
v13 = MOVQstore &lt;mem&gt; {~r0} v2 v11 v12
</code></pre>

<p>変数名の割り当てが異なるだけで実質同じ内容ですね。</p>

<h2>まとめ</h2>

<ul>
<li>Go1.8.1の最適化強い</li>
<li>Go1.8.1では<code>new(Type)</code>と<code>&amp;Type{}</code>の差はない(少なくとも性能面では)</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Go言語のchanはいったいいくつ付けられるのか試してみた]]></title>
    <link href="https://shogo82148.github.io/blog/2017/03/17/how-many-chan-can-i-write-in-golang/"/>
    <updated>2017-03-17T21:10:25+09:00</updated>
    <id>https://shogo82148.github.io/blog/2017/03/17/how-many-chan-can-i-write-in-golang</id>
    <content type="html"><![CDATA[<p>pecoに入った修正をみて、果たして<code>chan</code>はいくつまで付けられるのか気になったので、
雑に試してみました。
先に断っておきますが、全く有用ではないですよ。</p>

<!-- More -->


<h2>背景</h2>

<p>pecoに入った修正はこちら(一部抜粋)。</p>

<ul>
<li><a href="https://github.com/peco/peco/pull/411">Make Resume a blocking operation #411</a></li>
</ul>


<pre><code class="diff">diff --git a/interface.go b/interface.go
index 3d4472f..fff446c 100644
--- a/interface.go
+++ b/interface.go
@@ -162,8 +162,8 @@ type Screen interface {
 // Termbox just hands out the processing to the termbox library
 type Termbox struct {
    mutex     sync.Mutex
-   resumeCh  chan (struct{})
-   suspendCh chan (struct{})
+   resumeCh  chan chan struct{}
+   suspendCh chan struct{}
 }

 // View handles the drawing/updating the screen
diff --git a/screen.go b/screen.go
index edbce87..f6dd71e 100644
--- a/screen.go
+++ b/screen.go
@@ -21,7 +21,7 @@ func (t *Termbox) Init() error {
 func NewTermbox() *Termbox {
    return &amp;Termbox{
        suspendCh: make(chan struct{}),
-       resumeCh:  make(chan struct{}),
+       resumeCh:  make(chan chan struct{}),
    }
 }
</code></pre>

<p>channelを使ってchannelをやり取りすることができるので、
<code>chan struct{}</code>をやり取りする<code>chan chan struct{}</code>という型が使えます。
同じ要領で、channelをやり取りするchannelをやり取りするchannelをやり取り&hellip;するchannelが
無限に作れるはずです(少なくとも構文上は)。
ということで、実際にやってみました。</p>

<h2>実験</h2>

<p>雑なPerlスクリプトを準備して、大量の<code>chan</code>を付けたGoのコードを自動生成します。</p>

<pre><code class="perl">print &lt;&lt;EOF;
package main

import (
    "fmt"
)

type Foo @{['chan ' x 4096]} struct{}

func main() {
    fmt.Printf("Hello, %#v\\n", make(Foo))
}
EOF
</code></pre>

<p><code>chan</code>の個数を変えて何度かビルドを繰り返します。</p>

<pre><code class="bash">time go build -o main main.go
</code></pre>

<h2>結果</h2>

<p>chanの個数とビルドにかかった時間をまとめてみました。</p>

<table>
    <tr><th>chanの個数</th><th>ビルド時間</th></tr>
    <tr><td>1</td><td>0.236s</td></tr>
    <tr><td>2</td><td>0.240s</td></tr>
    <tr><td>4</td><td>0.226s</td></tr>
    <tr><td>8</td><td>0.234s</td></tr>
    <tr><td>16</td><td>0.240s</td></tr>
    <tr><td>32</td><td>0.250s</td></tr>
    <tr><td>64</td><td>0.281s</td></tr>
    <tr><td>128</td><td>0.258s</td></tr>
    <tr><td>256</td><td>0.360s</td></tr>
    <tr><td>512</td><td>0.775s</td></tr>
    <tr><td>1024</td><td>3.228s</td></tr>
    <tr><td>2048</td><td>18.605s</td></tr>
    <tr><td>4096</td><td>1m53.614s</td></tr>
    <tr><td>8192</td><td>13m46.018s(ビルド失敗したので参考記録)</td></tr>
</table>


<p>8192個付けたら以下のようなエラーを吐いてビルドが失敗してしまったので、
8192個の時の記録は参考記録です。</p>

<pre><code class="plain"># command-line-arguments
too much data in section SDWARFINFO (over 2000000000 bytes)
</code></pre>

<p>何かビルドの設定をいじればもっと行けるかもしれませんが、
デフォルトの設定では4096から8192の間に限界があるようです。
4096個<code>chan</code>を付けたときのソースコードは20KB程度なのにバイナリサイズは524MBまで膨らんでいました。</p>

<p>256個当たりからビルド時間に影響が出ているので、
ビルド時間を考える256個以下に抑えるのがよさそうです。
それ以上だと <script type="math/tex">O(n^{2.6})</script> 程度のオーダーでビルド時間が延びます。
とはいえ、256個も<code>chan</code>を付いたコードを人間が読めるとは思えないので、
2個が限度でしょうね・・・。
3個以上必要になるケースは余りないと思います。</p>

<h2>型定義を再帰的にして無限chanを実現する</h2>

<p>そもそも、<code>chan</code>を大量に並べなくとも、
型定義を再帰的に行えば無限の<code>chan</code>を付けたときと同等のことができます。
例えば以下のコードで"Goroutine 1"と"Goroutine 2"を交互に表示することが可能です。</p>

<pre><code class="go">package main

import (
    "fmt"
)

type Foo chan Foo

func main() {
    ch := make(Foo)
    go func() {
        ch := ch
        for {
            done := &lt;-ch
            fmt.Println("Goroutine 2")
            done &lt;- ch
        }
    }()

    for i := 0; i &lt; 100; i++ {
        fmt.Println("Goroutine 1")
        done := make(Foo)
        ch &lt;- done
        ch = &lt;-done
    }
    fmt.Println("Hello, playground")
}
</code></pre>

<p>channelでのやり取りが複雑になるので実用性があるかは不明ですが・・・。
例えば先程の例だと、普通にループを書いたほうが圧倒的にシンプルです。</p>

<pre><code class="go">package main

import (
    "fmt"
)

func main() {
    for i := 0; i &lt; 100; i++ {
        fmt.Println("Goroutine 1")
        fmt.Println("Goroutine 2")
    }
    fmt.Println("Hello, playground")
}
</code></pre>

<p>無限<code>chan</code>が必要になる多くのケースは、このような書き換えができるような気がします。
(そもそも必要になったことがない)</p>

<h2>まとめ</h2>

<ul>
<li><code>chan</code>の個数の上限は4096から8192の間のどこか</li>
<li>256個あたりからビルド時間に影響が出始める

<ul>
<li>プログラムを読む人の精神力に多大な影響を与えるので、実際は2個までに留めるべきだと思う</li>
</ul>
</li>
<li>再帰的に型を定義することで、無限に<code>chan</code>を付けた時と同等のことが可能</li>
</ul>


<p><code>chan</code>を大量に付けたいケースには今までに僕自身は遭遇したことがないです。
有用な例を見つけた人は教えてください。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HTTP/WebSocketで時刻同期するWebNTPを書いた]]></title>
    <link href="https://shogo82148.github.io/blog/2017/03/11/go-webntp/"/>
    <updated>2017-03-11T18:48:09+09:00</updated>
    <id>https://shogo82148.github.io/blog/2017/03/11/go-webntp</id>
    <content type="html"><![CDATA[<p>Go1.8から<a href="https://golang.org/pkg/net/http/httptrace/">http/httpgtrace</a>が追加され、
HTTP通信にフックを差し込めるようになりました。
以前触った時は<a href="https://shogo82148.github.io/blog/2017/01/14/re-golang-dns-cache/">パフォーマンス測定に利用</a>しましたが、
他に面白い活用法はないかとWebNTPというのを作ってみました。</p>

<ul>
<li><a href="https://github.com/shogo82148/go-webntp">webntp</a></li>
</ul>


<p>HTTP/HTTPS/Websocket上でNTP(Network Time Protocol)っぽいことをするプログラムです。</p>

<!-- More -->


<h2>HTTP/HTTPSで時刻同期</h2>

<p>日本標準時はNICTの管理する原子時計が基準になっており、
NICTでは原子時計に直結したNTPサーバー(ntp.nict.jp)の提供を行っています。
それに加えて、<a href="http://www.nict.go.jp/JST/http.html">https/httpサービス</a>も提供しており、
ブラウザを使って現在時刻を取得できます。</p>

<p>APIは簡単でミリ秒単位のtimestampを返してくれるだけです。
その情報からサーバーとクライアント間の時間のズレを算出するわけですが、
HTTP通信では、DNSの名前解決、TCPハンドシェイク、TLSハンドシェイク等々の時間が入ってしまうため、
正確なズレを求めることは困難です。</p>

<p>そこでhttp/httpgtraceを使って、ハンドシェイクを除いたリクエストの送信時刻、レスポンスを最初に受信した時刻から、
より正確なズレを知ることができるのではと作ったのがWebNTPです。
NICTの<a href="https://ntp-a1.nict.go.jp/cgi-bin/json">JSON形式のAPI</a>に対応しており、
以下のように時刻を取得できます。</p>

<pre><code class="plain">$ go get github.com/shogo82148/go-webntp/cmd/webntp
$ webntp https://ntp-a1.nict.go.jp/cgi-bin/json
server https://ntp-a1.nict.go.jp/cgi-bin/json, offset -0.006376, delay 0.024411
2017-03-11 16:08:06.150393313 +0900 JST, server https://ntp-a1.nict.go.jp/cgi-bin/json, offset -0.006376
</code></pre>

<p>WebNTPはNICTのAPIと同様の内容を返すサーバーにもなれます。
本家のフォーマットにしたがい、しっかりとうるう秒の情報も返すようになっているので、
ntpdのSLEWモードを切った状態でお試しください。</p>

<pre><code class="plain">$ webntp -serve :8080

$ curl -s http://localhost:8080/ | jq .
{
  "id": "localhost:8080",
  "it": 0,
  "st": 1489217288.328757,
  "time": 1489217288.328757,
  "leap": 36,
  "next": 1483228800, // 今年の1/1にあったうるう秒の情報
  "step": 1
}
</code></pre>

<p>ところで、URLにcgi-binが入っているのは、過去との互換性を保つためにそうなっているのか、
今もCGIで動いているのか、気になる・・・
(少なくとも初期実装はPerlのCGIだったみたいですね)。</p>

<h2>Websocketで時刻同期</h2>

<p>HTTPで取れるのは便利ですが、これではブラウザ等や他のクライアントで正確な時間を知るのが難しいです。
今ならWebSocketが使えるのでは？と、WebSocketにも対応してみました。
時刻取得時にws/wssスキーマを指定するとWebSocketモードになります。</p>

<pre><code class="plain">$ webntp ws://localhost:8080/
server ws://localhost:8080/, offset 0.000031, delay 0.000671
2017-03-11 16:19:29.850452219 +0900 JST, server ws://localhost:8080/, offset 0.000031
</code></pre>

<p>ブラウザからもJavaScriptを使ってアクセスできるというのが大きな利点ですね。
TCP上での通信のためNTPに比べればもちろん精度は落ちますが、
スプラトゥーンができる程度のネットワーク環境であれば±十数ミリ秒程度の誤差に収まるのではないでしょうか。</p>

<h2>ntpdの参照クロックとして使う</h2>

<p>実装している最中にいろいろと調べてみたところ、
ntpdはNTPでネットワークから時刻を取得する以外に、コンピュータに直結したデバイスからも時刻情報を取得できることがわかりました。
たとえばGPSモジュールを繋いで、GPSに積まれている原子時計と同期をとることができるらしいです。</p>

<p>同期方法はたくさんあるのですが、Shared Memory <a href="http://doc.ntp.org/4.2.8/drivers/driver28.html">driver28</a>というのが
比較的ポピュラーなようです。
Python+SWIGの実装(<a href="https://github.com/mjuenema/python-ntpdshm">python-ntpdshm</a>)があったので、
それを参考にGoに移植しました。</p>

<p><code>ntpd.conf</code>にShared Memoryと同期する設定を追加します。
アドレス部分に<code>127.127.28.x</code>を指定するとShared Memoryになるそうです。</p>

<pre><code class="plain">server 127.127.28.2 noselect
fudge 127.127.28.2 refid PYTH stratum 10
</code></pre>

<p><code>-shm x</code>をオプションにつけると、ntpdとの同期モードになり、
HTTP等で取得した時刻情報をntpdに送信します。
デフォルトだと4回連続でAPIを叩いて怒られそうなので、<code>-p 1</code>も一緒につけています。</p>

<pre><code class="plain">$ webntp -p 1 -shm 2 https://ntp-a1.nict.go.jp/cgi-bin/json https://ntp-b1.nict.go.jp/cgi-bin/json
server https://ntp-a1.nict.go.jp/cgi-bin/json, offset -0.003258, delay 0.018910
server https://ntp-b1.nict.go.jp/cgi-bin/json, offset -0.003570, delay 0.021652
</code></pre>

<p>しばらくしてから、ntpdのステータスを確認すると、
remote:SHM(2)にoffset情報が表示されるはずです。</p>

<pre><code class="plain">$ ntpq -p
     remote           refid      st t when poll reach   delay   offset  jitter
==============================================================================
 SHM(2)          .PYTH.          10 l    2   64   17    0.000   -3.331   0.384
*ntp-a2.nict.go. .NICT.           1 u   58   64   37   10.280    1.494   2.028
</code></pre>

<h2>その他類似プロジェクト</h2>

<p>HTTPで時刻同期というアイデア自体はすでにあったようで、
<a href="http://www.htptime.org/index.html">htptime</a>というものがありました。
WebNTPはhtptimeのサーバーとも同期できます。
AWS Lambdaで動いているhtptimeサーバーも公開されているのですが、Internal Server Errorしか帰ってこない・・・。</p>

<p><a href="http://www.vervest.org/htp/">htp</a>はhtptimeの元ネタらしいです。
HTTPのDateヘッダーで時刻合わせするので、秒単位でしか同期できません。
WebNTPでは未対応です。</p>

<h2>まとめ</h2>

<ul>
<li>http/httpgtraceの活用法としてWebNTPというのを作ってみた</li>
<li>HTTP/HTTPS/WebSocketでの同期が可能(UDP通信を禁止されている環境でも大丈夫！)</li>
<li>取得した時刻をntpdに反映することも可能</li>
</ul>


<p>UDP/123が禁止されている環境って今はどの程度あるんですかね？</p>
]]></content>
  </entry>
  
</feed>
