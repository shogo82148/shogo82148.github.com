<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: golang | Shogo's Blog]]></title>
  <link href="https://shogo82148.github.io/blog/categories/golang/atom.xml" rel="self"/>
  <link href="https://shogo82148.github.io/"/>
  <updated>2017-06-16T07:13:31+09:00</updated>
  <id>https://shogo82148.github.io/</id>
  <author>
    <name><![CDATA[Shogo Ichinose]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[ぼくのかんがえたさいきょうのcontext対応版go-mysql-driverをマージしてもらった]]></title>
    <link href="https://shogo82148.github.io/blog/2017/06/16/mysql-driver-and-context/"/>
    <updated>2017-06-16T07:11:15+09:00</updated>
    <id>https://shogo82148.github.io/blog/2017/06/16/mysql-driver-and-context</id>
    <content type="html"><![CDATA[<p><a href="https://github.com/go-sql-driver/mysql">go-sql-driver</a>に<code>context.Context</code>対応するプルリクエスト
<a href="https://github.com/go-sql-driver/mysql/pull/608">go-sql-driver/mysql#608</a>
を送って取り込んでもらいました！！
現時点ではまだ正式リリースされていませんが、次のリリース(version 1.4)から使えるようにはずです。
masterブランチではすでに使えるようになっているので、引き続き人柱募集中です。</p>

<p>コネクションプーリングを実装していて、自分も「<code>context.Context</code>サポートしたい！」というかたのために、
実装の概要をメモとして残しておきます。</p>

<!-- More -->


<h2>おおまかな仕組み</h2>

<ul>
<li>「<strong>contextの監視のみを行うgoroutine</strong>(以下、watcher goroutine)」をあらかじめ起動しておく</li>
<li>「<strong>やりたい処理を実際に実行するgoroutine</strong>(以下、executor goritune)」とchannelを経由して<code>context.Context</code>をやり取りする</li>
</ul>


<p>watcher goroutineがこの実装で一番重要な部分です。</p>

<h3>watcher goroutine の実装</h3>

<p>一番重要な watcher goroutine の実装例から見てみましょう
(実際には細かい最適化などが入るため、マージされたコードとは異なります)。</p>

<pre><code class="go">func (mc *mysqlConn) startWatcher() {
    // executor goritune と `context.Context` のやり取りをするための channel
    watcher := make(chan context.Context, 1)
    mc.watcher = watcher

    // executor goritune で処理が完了したことを知るための channel
    finished := make(chan struct{})
    mc.finished = finished

    // コネクションがCloseされたことを知らせるための channel
    mc.closech = make(chan struct{})

    // ここから watcher goroutine 本体
    go func() {
        for {
            // executor goritune から `context.Context` を待ち受ける
            var ctx context.Context
            select {
            case ctx = &lt;-watcher:
            case &lt;-mc.closech:
                // コネクションが Close されたので watcher gorutine を終了する
                return
            }

            // `context.Context` を監視する
            select {
            case &lt;-ctx.Done():
                // executor goritune を強制終了する
                mc.cancel(ctx.Err())
            case &lt;-finished:
                // 正常に処理が終了したので何もしない
            case &lt;-mc.closech:
                // コネクションが Close されたので watcher gorutine を終了する
                return
            }
        }
    }()
}
</code></pre>

<p><code>watcher</code>, <code>finished</code>, <code>closech</code> の3つの channel を経由して
executor goroutine と通信を行います。</p>

<h3>executor goroutine の実装</h3>

<p>executor goritune の実装例は以下のようになります。</p>

<pre><code class="go">// 何かやる
func (mc *mysqlConn) DoSomething(ctx context.Context) error {
    // watcher gorutineにctxを渡して監視してもらう
    if err := mc.watchCancel(ctx); err != nil {
        return err
    }

    // doSomthing()が実際に行いたい処理
    if err := mc.doSomthing(); err != nil {
        // キャンセルされたのか、ネットワークエラーで切断されたのか、を確認する
        if cerr := mc.canceled(); cerr != nil {
            return cerr
        }
        return err
    }

    // watcher gorutineに処理が終了したことを通知する
    mc.finish()

    return nil
}
</code></pre>

<p><code>mc.doSomthing()</code> が実際に行いたい処理なのですが、これに <code>ctx</code> を渡していないのがポイントです。
watcher goroutine に <code>ctx</code> の監視を任せているので、executor goroutine 側では監視しなくてもいいのです。</p>

<h3>executor goritune と watcher goroutine 間の通信</h3>

<p>executor goritune と watcher goroutine 間の通信は主に
<code>watcher</code> channel と <code>finished</code> channel が担当します。</p>

<pre><code class="go">func (mc *mysqlConn) watchCancel(ctx context.Context) error {
    // 実際の処理が始まるまえに、 `ctx` が終了していないか確認
    select {
    default:
    case &lt;-ctx.Done():
        return ctx.Err()
    }

    // watcher goroutineに渡す
    mc.watcher &lt;- ctx

    return nil
}

func (mc *mysqlConn) finish() {
    select {
    case mc.finished &lt;- struct{}{}:
    case &lt;-mc.closech:
    }
}
</code></pre>

<h3>キャンセルの実装</h3>

<p><code>context.Context</code>がキャンセルされたときに、executor goroutineを強制終了する処理は、
コネクションを強制的に <code>Close</code> することで行っています。
ちょっと強引な気はしますが、キャンセルされるような状況に陥った時点で正常な通信なんて出来ていないので、
まあいいかと、このような実装になっています。
もっと賢いキャンセルの方法があるかもしれませんが、キャンセルされない場合のほうが圧倒的に多いので、
余計なオーバーヘッドは避けたいというのもあります。</p>

<pre><code class="go">// キャンセルを実行する
func (mc *mysqlConn) cancel(err error) {
    // **コネクションを実際にCloseする前** にエラー内容を記録する
    mc.mu.Lock()
    mc.canceledErr = err
    mc.mu.Unlock()

    // 強制切断
    mc.cleanup()
}

// キャンセルされたか確認用
func (mc *mysqlConn) canceled() error {
    mc.mu.Lock()
    defer mc.mu.Unlock()
    return mc.canceledErr
}

func (mc *mysqlConn) cleanup() {
    // closeが2回以上実行されないようガード
    if atomic.SwapInt32(&amp;mc.closed, 1) != 0 {
        return
    }

    // (executor|watcher) goroutineに終了を通知
    close(mc.closech)

    // コネクションを切断
    mc.netConn.Close()
}
</code></pre>

<p>これらの関数は (executor|watcher) 両方の goroutine から呼ばれる可能性があるため、
以下の二点が非常に重要です。</p>

<ul>
<li>cancelでは <strong>コネクションを実際にCloseする前</strong> にエラー内容を記録する

<ul>
<li>これが逆だと executor がキャンセルを見逃してしまう場合がある</li>
</ul>
</li>
<li>sync package や sync/atomic package を使って <strong>goroutine-safe に書く</strong></li>
</ul>


<h2>FAQ(よくあるであろう質問)</h2>

<p>こっちの実装の方がいいんじゃないの？と実装中に自問自答した内容を
FAQと称して残しておきます。</p>

<h3>close(watcher)していないのはなぜ？</h3>

<p>最初は watcher goroutine の実装は以下のようになっていて、
<code>close(watcher)</code> で watcher goroutine を終了させようかと考えてました。</p>

<pre><code class="go">for ctx := range watcher {
    // context.Context監視処理
}
</code></pre>

<p>しかしこの実装では <code>mc.watcher &lt;- ctx</code> のところで <code>close</code> されていないかを毎回確認する必要があり、
channelを使うメリットが薄れてしまうので廃案となりました。</p>

<h3>close(finished)していないのはなぜ？</h3>

<p>監視の終了に <code>close(finished)</code> を使うという案も考えました。
しかしこの実装が廃案になったのには大きく二つの理由があります。</p>

<p>一つ目は「監視の終了は同期していなければならない」からです。
<code>close(finished)</code> を使った方法では executor goroutine が監視の終了を通知しても、
watcher goroutine が実際に監視を終了するタイミングは goroutine スケジューラの気分次第で遅れてしまう可能性があります。
すると watcher goroutine がクエリキャンセルしたときには、 executor goroutine では既に次のクエリが実行さており、
間違ったクエリをキャンセルしてしまうという事故が起こりえます。</p>

<p><code>finished &lt;- struct{}{}</code> を使った方法ならこれは起こりません。
executor goroutine が監視の終了を通知するのと、
watcher goroutine が実際に監視を終了するのとが同期しているので、
確実にキャンセルしたいクエリだけをキャンセルできます。</p>

<p>実際、PostgreSQLのGo driver実装は、最初 <code>close(finished)</code> で実装されていたものが、
<code>finished &lt;- struct{}{}</code> に置き換えられています(実装時には知らなくて、この記事を書いているときに知った)。</p>

<ul>
<li><a href="https://github.com/lib/pq/pull/535">Add context methods lib/pq#535</a></li>
<li><a href="https://github.com/lib/pq/pull/578">Fix race condition in query cancellation lib/pq#578</a></li>
</ul>


<p>二つ目は「channelの再利用ができない」という理由です。
一度 <code>close</code> した channel は <code>open</code> することはできないので、新規に channel を作る必要があります。
これにはメモリ確保が必要になるので、パフォーマンス面で不利になります。</p>

<h3>QueryContextの中でfinishを直接呼んでいないのはなぜ？</h3>

<p>QueryContext の実装をよく見てみると <code>rows.finish = mc.finish</code> しているだけで、
QueryContext の中では <code>finish</code> を呼んでいません。</p>

<ul>
<li><a href="https://github.com/go-sql-driver/mysql/blob/a825be04c652d01442384e9dcdf2cdc3f1eda67f/connection_go18.go#L87">QueryContext</a></li>
</ul>


<p>これはなぜかというと <code>QueryContext</code> の実行が終了した後、
rows の読み取り中に、<code>context.Context</code> がキャンセルされる場合があるからです。
たとえば以下のコードで、<code>rows.Err()</code> は <code>context.Canceled</code> になっているべきです。</p>

<pre><code class="go">ctx, cancel := context.WithCancel(context.Background())
rows, _ := dbt.db.QueryContext(ctx, "SELECT v FROM test")
rows.Next()
if err := rows.Scan(&amp;v); err != nil {
    panic(err)
}

cancel()
time.Sleep(100 * time.Millisecond)

rows.Next()
// rows.Err() は context.Canceled になっているべき
if err := rows.Err(); err != context.Canceled {
    panic(err)
}
</code></pre>

<p>この挙動は net/http を参考にしています。</p>

<pre><code class="go">package main

import (
    "context"
    "fmt"
    "io/ioutil"
    "log"
    "net/http"
    "net/http/httptest"
    "time"
)

func main() {
    log.SetFlags(log.LstdFlags | log.Lshortfile)

    // 1秒わざとレスポンスを返さないサーバー
    ts := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        w.Header().Set("Context-Type", "text/plain")
        w.WriteHeader(200)
        fmt.Fprint(w, "Hello, ")
        w.(http.Flusher).Flush()
        time.Sleep(time.Second)
        fmt.Fprint(w, "client\n")
    }))
    defer ts.Close()

    req, err := http.NewRequest("GET", ts.URL, nil)
    if err != nil {
        log.Fatal(err)
    }

    // 0.5秒後にキャンセル
    ctx, cancel := context.WithTimeout(context.Background(), 500*time.Millisecond)
    go func() {
        time.Sleep(500 * time.Millisecond)
        cancel()
    }()
    defer cancel()

    req = req.WithContext(ctx)
    res, err := http.DefaultClient.Do(req)
    if err != nil {
        log.Fatal(err)
    }

    // ioutil.ReadAll は "context canceled" か "context deadline exceeded" で失敗する
    greeting, err := ioutil.ReadAll(res.Body)
    res.Body.Close()
    if err != nil {
        log.Fatal(err)
    }

    fmt.Printf("%s", greeting)
}
</code></pre>

<h3>BeginTxの中ではfinishを直接呼んでいるのはなぜ？</h3>

<p><code>BeginTx</code> では <code>finish()</code> を呼んでいます。
<code>BeginTx</code>終了後にトランザクションがキャンセルされる場合を考えると、
<code>QueryContext</code> と同様に <code>tx.finish = mc.finish</code> となりそうですが、そうはなっていません。</p>

<p>これは database/sql が代わりに監視してくれていて、
<code>context.Context</code> がキャンセルされると自動的にRollbackしてくれるからです。</p>

<ul>
<li><a href="https://github.com/golang/go/blob/go1.8.3/src/database/sql/sql.go#L1435-L1447">Tx.awaitDone() (database/sql)</a></li>
</ul>


<p>実は rows にも同様の監視処理が入っているので勝手に <code>Close</code> してくれます。
しかし、packetの読み書きを <code>context.Context</code> 対応にする必要があり、
実装コスト・実行コストが大きそうだったので手を付けていません。</p>

<h2>まとめ</h2>

<p>executor goroutine と watcher goroutine を使った <code>context.Context</code> 対応の実装例を紹介しました。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Re: GoとPythonとGrumpyの速度ベンチマーク]]></title>
    <link href="https://shogo82148.github.io/blog/2017/05/30/grumpy/"/>
    <updated>2017-05-30T17:53:32+09:00</updated>
    <id>https://shogo82148.github.io/blog/2017/05/30/grumpy</id>
    <content type="html"><![CDATA[<p><a href="http://qiita.com/kotauchisunsun/items/db28d14f7f13fb29e5f9">GoとPythonとGrumpyの速度ベンチマーク ～Googleのトランスパイラはどれくらい速い？～</a>という記事を拝読したのですが、
もう一歩踏み込んで検証して欲しい・・・。</p>

<blockquote><p>並列処理性能が優れているほか、PythonコードからGoのパッケージをPythonモジュールのように呼び出して利用することもできるという特徴がある。</p></blockquote>

<p>と<a href="http://news.mynavi.jp/news/2017/01/06/110/">Google、すごくスケールするPython実行環境をGoで開発</a>から引用しているのに、
この件に全く触れていないんですよね。
Twitterに呟いたってどうせ誰もやってくれない気がするので、自分で試してみました。</p>

<!-- More -->


<h2>環境</h2>

<p>この記事を書いている2017年5月30日現在の最新バージョンで検証しました。</p>

<ul>
<li>go version go1.8.3 darwin/amd64</li>
<li>CPython 2.7.13</li>
<li>Grumpy <a href="https://github.com/google/grumpy/tree/d8d01899f5eedf99602887567aaeb39a9154bf68">d8d01899f5</a></li>
</ul>


<p>Grumpyのインストール方法はREADMEにある通り。</p>

<pre><code class="bash">make
export GOPATH=$PWD/build
export PYTHONPATH=$PWD/build/lib/python2.7/site-packages
</code></pre>

<p>ただ個人的な環境問題としてPythonのバージョン管理に利用しているpyenvとの相性が悪いらしく、
pyenvが管理しているPythonへのパスを直接通す必要がありました。
(これがないとPythonスクリプトがなぜかbashに処理される。なんかこの問題最近Twitterで見たような・・・)</p>

<pre><code class="bash">export PATH=$HOME/.pyenv/versions/2.7.13/bin:$PATH
</code></pre>

<h2>モンテカルロ法を並列実行してみる</h2>

<p>まず、並列処理性能について検証してみましょう。
モンテカルロ法の各試行は独立しているので、並列実行にするのは容易です。
Python2のthreadingモジュールを使って並列実行してみましょう。</p>

<h3>コード</h3>

<pre><code class="python">#coding:utf-8
# モンテカルロ法 Pure Python 並列版
import threading
import random
import sys

class MyThread(threading.Thread):
    def __init__(self):
        super(MyThread, self).__init__()
        self.c = 0

    def run(self):
        r = random.Random()
        c = 0
        for _ in xrange(num):
            x = r.random()
            y = r.random()

            if x * x + y * y &lt;= 1.0:
                c += 1
        self.c = c


if __name__ == "__main__":
    num = int(sys.argv[1])
    para = int(sys.argv[2])

    threads = []
    for i in xrange(para):
        t = MyThread()
        t.start()
        threads.append(t)

    c = 0
    for t in threads:
        t.join()
        c += t.c

    print 4.0*c/(num*para)
</code></pre>

<p>並列度に比例した計算負荷がかかるようになってます。
理想的な並列処理が行えていれば、並列度に関わらず同じ実時間で実行されるはずです。</p>

<h3>CPythonでの結果</h3>

<p>CPythonでtimeを使って雑に測定した結果です。
並列度を4倍にしたら実行時間も4倍になっています。
また、実時間と実行時間が大体おなじで、まったく並列実行できていません。</p>

<pre><code class="plain"># 並列度1で実行した場合(CPython)
$ time python con_monte.py 300000 1
3.14529333333
real    0m0.358s
user    0m0.279s
sys 0m0.032s

# 並列度4で実行した場合(CPython)
$ time python con_monte.py 300000 4
3.14382666667
real    0m1.261s
user    0m1.124s
sys 0m0.441s
</code></pre>

<p>CPythonを利用しているひとにはおなじみの<a href="https://ja.wikipedia.org/wiki/%E3%82%B0%E3%83%AD%E3%83%BC%E3%83%90%E3%83%AB%E3%82%A4%E3%83%B3%E3%82%BF%E3%83%97%E3%83%AA%E3%82%BF%E3%83%AD%E3%83%83%E3%82%AF">グローバルインタプリタロック(GIL: Global Interpreter Lock)</a>の影響ですね。
CPythonのスレッドはI/Oの並列化には向いていますが、計算の並列化には向いていません。</p>

<h3>Grumpyでの結果</h3>

<p>次にGrumpyで測定した結果です。
並列度を4倍にしたところ、実行時間は2倍程度になりました。</p>

<pre><code class="plain"># 並列度1で実行した場合(Grumpy)
$ time ./con_monte_darwin_amd64 300000 1
3.1441733333333333
real    0m16.129s
user    0m16.787s
sys 0m0.125s

# 並列度4で実行した場合(Grumpy)
$ time ./con_monte_darwin_amd64 300000 4
3.1401766666666666
real    0m33.935s
user    1m45.979s
sys 0m0.654s
</code></pre>

<p>実時間4倍までは行かなかったので、理想的な並列計算には及ばないものの、
CPythonよりは並列化の効果が出ていそうです。
実のところ、Goも計算の並列化よりI/Oの並列化・並行処理のほうが得意なんですよね(GILよりはまし)。</p>

<p>手元の4コアのMBAで試した結果なので、コア数が多いとまた結果が変わってくるかもしれません。</p>

<h2>PythonからGoのライブラリを直接呼び出す</h2>

<p>次にGoのパッケージを呼び出す機能を試してみます。
Pythonのrandomパッケージではなく、Goのmath/randパッケージを使ってモンテカルロ法を実行してみます。</p>

<h3>コード</h3>

<pre><code class="python">#coding:utf-8
# モンテカルロ法 Python+Go 並列版
import threading
import random
import sys
from __go__.time import Now
from __go__.math.rand import New, NewSource


class MyThread(threading.Thread):
    def __init__(self):
        super(MyThread, self).__init__()
        self.c = 0

    def run(self):
        r = New(NewSource(Now().UnixNano()))
        c = 0
        for _ in xrange(num):
            x = r.Float64()
            y = r.Float64()

            if x * x + y * y &lt;= 1.0:
                c += 1
        self.c = c


if __name__ == "__main__":
    num = int(sys.argv[1])
    para = int(sys.argv[2])

    threads = []
    for i in xrange(para):
        t = MyThread()
        t.start()
        threads.append(t)

    c = 0
    for t in threads:
        t.join()
        c += t.c

    print 4.0*c/(num*para)
</code></pre>

<h3>Grumpyでの結果</h3>

<p>Grumpyでの実行結果です。
CPythonには遠く及ばないものの、もとのコードの8倍速くらいにはなりました。</p>

<pre><code class="plain"># 並列度1で実行した場合(Grumpy)
$ time ./con_monte_go_darwin_amd64 300000 1
3.1388133333333332
real    0m1.921s
user    0m2.006s
sys 0m0.029s

# 並列度4で実行した場合(Grumpy)
$ time ./con_monte_go_darwin_amd64 300000 4
3.143743333333333
real    0m4.115s
user    0m12.855s
sys 0m0.096s
</code></pre>

<h2>竹内関数を並列実行してみる</h2>

<p>竹内関数を並列実行した場合も試してみました。</p>

<h3>コード</h3>

<pre><code class="python">#coding:utf-8
# 竹内関数 Pure Python 並列版
import sys
import threading

def tak(x, y, z):
    if x &lt;= y:
        return y
    else:
        return tak(tak((x-1), y , z), tak((y-1), z , x), tak((z-1) , x, y))

class MyThread(threading.Thread):
    def __init__(self, a, b, c):
        super(MyThread, self).__init__()
        self.a = a
        self.b = b
        self.c = c
        self.result = 0

    def run(self):
        self.result = tak(self.a, self.b, self.c)

def main():
    a = int(sys.argv[1])
    b = int(sys.argv[2])
    c = int(sys.argv[3])
    para = int(sys.argv[4])

    threads = []
    for i in xrange(para):
        t = MyThread(a, b, c)
        t.start()
        threads.append(t)

    for t in threads:
        t.join()
        print t.result

if __name__=="__main__":
    main()
</code></pre>

<p>モンテカルロ法と同様に、理想的な並列処理が行えていれば、並列度に関わらず同じ実時間で実行されるはずです。</p>

<h3>CPythonでの結果</h3>

<p>CPythonでの結果です。
モンテカルロ法の場合と同様に、
並列度を4倍にしたら実行時間も4倍になっています。</p>

<pre><code class="plain"># 並列度1で実行した場合(CPython)
$ time python con_take.py 11 10 0 1
11
real    0m1.529s
user    0m1.498s
sys 0m0.028s

# 並列度4で実行した場合(CPython)
$ time python con_take.py 11 10 0 4
11
11
11
11
real    0m7.333s
user    0m6.620s
sys 0m2.565s
</code></pre>

<h3>Grumpyでの結果</h3>

<p>Grumpyでの結果です。</p>

<pre><code class="plain"># 並列度1で実行した場合(Grumpy)
$ time ./con_take_darwin_amd64 11 10 0 1
11
real    0m0.988s
user    0m0.988s
sys 0m0.018s

# 並列度4で実行した場合(Grumpy)
$ time ./con_take_darwin_amd64 11 10 0 4
11
11
11
11
real    0m2.031s
user    0m7.135s
sys 0m0.031s
</code></pre>

<p><strong>(なんかCPythonより早くなったぞ？？？？)</strong></p>

<p>最初に紹介した記事でも、
モンテカルロ法のベンチマークではCPythonがGrumpyの数十倍の速度で圧倒的勝利でしたが、
竹内関数のベンチマークではその差は縮まっています。
この程度であれば並列度を上げて物理で殴れば容易にGrumpyが逆転するでしょう。</p>

<p>(この検証で並列度1のときもGrumpy勝ったの謎だけど・・・)</p>

<h2>考察</h2>

<p>モンテカルロ法はCPythonのほうが圧倒的に速かったのに、
竹内関数ではGrumpyのほうが速かった(あるいは差が縮まった)という結果から、
「<strong>GrumpyからGoの関数を呼び出すオーバーヘッドが大きい</strong>」のではと推測しています。
モンテカルロ法のPure Python版でも圧倒的差が付いたのは、
<a href="https://github.com/google/grumpy/blob/d8d01899f5eedf99602887567aaeb39a9154bf68/lib/_random.py">Grumpyのrandomパッケージの実装が内部でGoのmath/randを呼んでいる</a>からです。</p>

<p>純粋なPure Pythonなコードであれば、Grumpyのシングルスレッド性能はCPythonより数倍遅い程度です。
最近のCPUコアたくさんなマシンであれば、GILのなくマルチスレッドを活かせるGrumpyが有利になると思います。
このことはグーグルのブログ記事「<a href="https://opensource.googleblog.com/2017/01/grumpy-go-running-python.html">Grumpy: Go running Python!</a>」でも触れられていますね。</p>

<h2>まとめ</h2>

<ul>
<li>Grumpyが非常に遅い<strong>のではなく</strong>、「GrumpyからGoの関数を呼び出すオーバーヘッドが大きい」(推測)</li>
<li>Grumpyのシングルスレッド性能はCPythonより数倍遅い程度</li>
<li>並列処理性能ではGrumpyが有利</li>
<li>そもそもGrumpyの目的は計算速度を上げることではないので、計算速度向上を求めている人は他の手法を模索しましょう</li>
</ul>


<p>今回の検証に使用したソースコード、Grumpyによるトランスパイルの結果、各種プラットフォームのバイナリをGithubにあげておきました。</p>

<ul>
<li><a href="https://github.com/shogo82148/grumpy-test">shogo82148/grumpy-test</a></li>
</ul>


<p>さらに検証を進めたい方は参考にどうぞ。</p>

<h2>参考</h2>

<ul>
<li><a href="https://opensource.googleblog.com/2017/01/grumpy-go-running-python.html">Grumpy: Go running Python!</a></li>
<li><a href="http://news.mynavi.jp/news/2017/01/06/110/">Google、すごくスケールするPython実行環境をGoで開発</a></li>
<li><a href="http://qiita.com/kmry2045/items/998250b3d430d82594c2">Grumpy(Go running Python)を試してみた。</a></li>
<li><a href="http://qiita.com/kotauchisunsun/items/db28d14f7f13fb29e5f9">GoとPythonとGrumpyの速度ベンチマーク ～Googleのトランスパイラはどれくらい速い？～</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[String::RandomのGo移植を書いてみた]]></title>
    <link href="https://shogo82148.github.io/blog/2017/05/04/go-rerand/"/>
    <updated>2017-05-04T10:57:37+09:00</updated>
    <id>https://shogo82148.github.io/blog/2017/05/04/go-rerand</id>
    <content type="html"><![CDATA[<p>golangkyotoで<a href="http://blog.yux3.net/entry/2017/05/01/014200">String::RandomのGo移植についての発表</a>があったと聞き、
これに対抗して以前途中まで書いていたString::RandomのGo移植をちょっといじって公開しました。</p>

<ul>
<li><a href="https://github.com/shogo82148/go-rerand">shogo82148/go-rerand</a></li>
</ul>


<!-- More -->


<h2>背景</h2>

<h3>ナイーブな実装の問題点</h3>

<p>実はgolangkyoto以前にもGoの正規表現エンジンを使ってランダムな文字列を生成する試みはあって、
たしかにこれは面白そうだと記事を読んでいました。</p>

<ul>
<li>「<a href="http://ymotongpoo.hatenablog.com/entry/2014/12/21/192304">Goの正規表現エンジンを使ってファジング用ツールを書いてみる</a>」</li>
</ul>


<p>しかし、gocha同様、この実装では文字列の長さが幾何分布に従うため、短い文字が多めにでてしまいます。</p>

<pre><code class="plain">% gocha -n 100000 'a*' | sort | uniq -c
50054
24894 a
12633 aa
6278 aaa
2994 aaaa
1517 aaaaa
 809 aaaaaa
 400 aaaaaaa
 206 aaaaaaaa
 109 aaaaaaaaa
  54 aaaaaaaaaa
  22 aaaaaaaaaaa
  15 aaaaaaaaaaaa
   7 aaaaaaaaaaaaa
   4 aaaaaaaaaaaaaa
   3 aaaaaaaaaaaaaaa
   1 aaaaaaaaaaaaaaaa
</code></pre>

<h3>正規表現のパターンを数え上げとその問題点</h3>

<p>この問題を解決するために
「この先何パターンあるかを調べておけば、正規表現が表す文字列の集合からランダムに文字列を取り出せるのでは？」
と考え、golangkyoto以前からちょこちょこ実装を進め、不完全ながらも一応動作するところまでは書いていたのです。
有向グラフの経路数えあげ問題なので、メモ化再帰を使って頑張れば解けます。
少々面倒ですが、<a href="https://www.youtube.com/watch?v=Q4gTV4r0zRs">おねえさんの問題</a>と比べれば簡単です。</p>

<p>パターンを数え上げる都合上、組み合わせが無限にある <code>a*</code> ような正規表現は扱えません。
<code>a{1,10}</code> のように明示的に範囲を指定する必要があります。
たとえば <code>a{1,10}</code> は10パターン組み合わせがあるので、20万個ランダムに生成すると、それぞれのパターンがおおよそ2万個ずつ生成されます。
(<code>-d</code> オプションについては後述)</p>

<pre><code class="plain">$ rerand -d -n 200000 'a{1,10}' | sort | uniq -c
20153 a
19863 aa
19899 aaa
19908 aaaa
19975 aaaaa
20000 aaaaaa
20081 aaaaaaa
20021 aaaaaaaa
20072 aaaaaaaaa
20028 aaaaaaaaaa
</code></pre>

<p><code>[ab]{1,3}</code>のような正規表現でも、それぞれのパターンがおおよそ同じ数だけ生成されます。</p>

<pre><code class="plain">$ rerand -d -n 200000 '[ab]{1,3}' | sort | uniq -c
14299 a
14249 aa
14215 aaa
14257 aab
14192 ab
14340 aba
14317 abb
14209 b
14213 ba
14332 baa
14228 bab
14355 bb
14634 bba
14160 bbb
</code></pre>

<p>これはこれで意図した挙動なのですが、
1文字のパターン数に比べて、3文字のパターン数が非常に多いため、相対的に短い文字列が出現しにくくなってしまいます。
「これは本当にユーザーが望んだものなのだろうか・・・？」と疑問に思ってしまい、
うまい解決策が思いつかないままずっと放置していました。</p>

<h2>文字グループの同一視</h2>

<p>ここまで実装では正規表現の定義に厳密に従い「<code>[ab]</code>は<code>a</code>と<code>b</code>にマッチするので2パターン」と解釈していましたが、
「<code>[ab]</code>のような1文字にマッチするパターンは全部1パターン」と緩い解釈にするようにしました。
<code>-d</code>オプションはこの挙動を制御するためのオプションです。</p>

<p>デフォルトの挙動は「1文字にマッチするパターンは全部1パターン」です。
さきほどと同じ<code>[ab]{1,3}</code>で、<code>-d</code>オプションを外しデフォルトの設定で文字列生成すると以下のようになります。</p>

<pre><code class="plain">$ rerand -n 200000 '[ab]{1,3}' | sort | uniq -c
33463 a
16432 aa
8392 aaa
8206 aab
16806 ab
8334 aba
8403 abb
33242 b
16549 ba
8393 baa
8372 bab
16644 bb
8376 bba
8388 bbb
</code></pre>

<p><code>a</code>や<code>b</code>が多めに出ているような気がしますが、
文字列長別に集計するとおおよそ同じ回数だけ出現していることが確認できます。</p>

<pre><code class="plain">$ rerand -n 200000 '[ab]{1,3}' | perl -nE 'chomp; say length' | sort -n | uniq -c
66769 1
67036 2
66195 3
</code></pre>

<p>これで少しはユーザーフレンドリーになったはず(？)</p>

<h2>ベンチマーク</h2>

<p>ベンチマークの結果も貼っておきます。
coffeescriptは <a href="https://cho45.stfuawsc.com/String_random.js/demo.html#%5B%E3%82%AB%E3%82%B3%E3%83%B5%E3%81%8B%5D%5B%E3%83%83%E3%83%BC%5D%7B1%2C3%7D%3F%5B%E3%83%95%E3%83%92%E3%81%B5%E3%81%B2%5D%7B1%2C3%7D%5B%E3%82%A3%E3%82%A7%E3%83%BC%5D%7B1%2C3%7D%5B%E3%82%BA%E3%82%B9%5D%5B%E3%83%89%E3%82%AF%E3%82%B0%E3%83%A5%5D%5B%E3%83%AA%E3%82%A4%5D%5B%E3%83%97%E3%83%96%E3%81%B7%E3%81%B6%5D%7B1%2C3%7D%5B%E3%83%88%E3%83%89%E3%82%A9%5D%7B1%2C2%7D">コーフィースクリップトの発音を生成する</a>ベンチマーク、
telephoneは<code>\d{2,3}-\d{3,4}-\d{3,4}</code>で電話番号っぽい文字列を生成するベンチです。</p>

<pre><code class="plain">$ go test -run none -bench . -benchmem ./...
BenchmarkGenerator/coffeescript-4            1000000          1737 ns/op          81 B/op          2 allocs/op
BenchmarkGenerator/[あ-お]{10}-4               2000000           845 ns/op          80 B/op          2 allocs/op
BenchmarkGenerator/[[:alpha:]]-4             5000000           274 ns/op          36 B/op          2 allocs/op
BenchmarkGenerator/\S-4                      5000000           292 ns/op          40 B/op          2 allocs/op
BenchmarkGenerator/\S{10}-4                  1000000          1568 ns/op          80 B/op          2 allocs/op
BenchmarkGenerator/\pN-4                     5000000           304 ns/op          39 B/op          2 allocs/op
BenchmarkGenerator/\p{Greek}-4               5000000           299 ns/op          39 B/op          2 allocs/op
BenchmarkGenerator/telephone-4               2000000           886 ns/op          48 B/op          2 allocs/op
BenchmarkRuneGenerator/[a]-4                300000000            4.24 ns/op        0 B/op          0 allocs/op
BenchmarkRuneGenerator/[a-z]-4              30000000            42.7 ns/op         0 B/op          0 allocs/op
BenchmarkRuneGenerator/[a-zA-Z0-9]-4        10000000           118 ns/op           0 B/op          0 allocs/op
PASS
ok      github.com/shogo82148/go-rerand 20.013s
?       github.com/shogo82148/go-rerand/cmd/rerand  [no test files]
BenchmarkGocha/coffeescript-4             300000          3967 ns/op        1090 B/op         34 allocs/op
BenchmarkGocha/[あ-お]{10}-4               1000000          1951 ns/op         328 B/op         15 allocs/op
BenchmarkGocha/[[:alpha:]]-4             5000000           323 ns/op          64 B/op          4 allocs/op
BenchmarkGocha/\S-4                      5000000           394 ns/op         128 B/op          5 allocs/op
BenchmarkGocha/\S{10}-4                   500000          3353 ns/op        1288 B/op         35 allocs/op
BenchmarkGocha/\pN-4                     1000000          1988 ns/op        4096 B/op         10 allocs/op
BenchmarkGocha/\p{Greek}-4               1000000          1122 ns/op        2048 B/op          9 allocs/op
BenchmarkGocha/telephone-4               1000000          1998 ns/op         288 B/op         14 allocs/op
PASS
ok      github.com/shogo82148/go-rerand/gocha_test  14.405s
BenchmarkStrRand/coffeescript-4              1000000          1828 ns/op         262 B/op         11 allocs/op
BenchmarkStrRand/[あ-お]{10}-4                 1000000          1189 ns/op         208 B/op          9 allocs/op
BenchmarkStrRand/\S-4                       20000000            72.9 ns/op         0 B/op          0 allocs/op
BenchmarkStrRand/\S{10}-4                    1000000          1097 ns/op          64 B/op          9 allocs/op
BenchmarkStrRand/telephone-4                 1000000          1409 ns/op          58 B/op         10 allocs/op
PASS
ok      github.com/shogo82148/go-rerand/strrand_test    7.136s
</code></pre>

<p>テストケースにもよりますが、Songmuさんのstrrandと同等かちょっと速い程度の性能です(シンプルな正規表現ではstrrandが速いこともある)。
Twitterには「Gocha速い！」みたいなことが流れてましたが、僕の手元での検証ではstrrandの方が高速でした。
どうも<a href="https://github.com/t-mrt/gocha/pull/3">ベンチマークの使い方間違っていた</a>っぽいですね・・・。</p>

<p>ちなみにこのベンチマークには正規表現をパースする処理は入っていません。
(どう考えてもstrrandに負けるのは目に見えている)
たいていのケースで初期化一回なので気にしない気にしない。</p>

<h2>グローバルなmath/rand関数の扱い</h2>

<p>go-rerandを作る際、他の実装も参考にしたのですが、
Seedの初期化のタイミングがまちまちで、少し気になりました。</p>

<ul>
<li>fuzzingo: <code>rand.Intn</code>を使う直前(！)</li>
<li>strrand: init関数内</li>
<li>gocha: Newの中</li>
</ul>


<p>Seedの初期化は本来一回だけでいいので、「<code>rand.Intn</code>を使う直前」や「Newの中」で行うのは無駄です。
init関数内でやる方法がベターですが、<code>math/rand</code>を使うライブラリを複数importしている場合、
結局何度もSeedの初期化が行われてしまいます。
ライブラリ利用者の手間は増えますが、ライブラリの中ではなく<code>main.go</code>の中でやってほしい！というのが僕の意見です。</p>

<pre><code class="go">// main.goの中でやってほしい！
func init() {
    rand.Seed(time.Now().UnixNano())
}
</code></pre>

<p>ベストなのは <strong>ライブラリではグローバルなmath/rand関数を使わない！</strong> ことです。
rerandでは以下のように<code>rand.New</code>を使って、グローバルな関数は使っていません。</p>

<pre><code class="go">r = rand.New(rand.NewSource(time.Now().UnixNano()))
</code></pre>

<p>goroutine-unsafeになってしまうので、同期処理を自前で書く必要があるのが難点です。
その代わり、ロックの粒度が細かく調整できるので、並列処理の効率は上がるはずです(たぶん)。</p>

<p>また、テストの際にSeedを固定できるので便利です。</p>

<pre><code class="go">r = rand.New(rand.NewSource(1))
</code></pre>

<h2>gocha互換オプション</h2>

<p><code>-prob 0.5</code>でGochaと同じ挙動になるはずです。
<code>a*</code>のような無限長の正規表現も扱えます。
数値をいじることで文字列の長さの分布を調整可能です。</p>

<h2>まとめ</h2>

<ul>
<li>Go版String::Randomを作った</li>
<li><strong>ライブラリではグローバルなmath/rand関数をなるべく使わないでほしい！</strong></li>
</ul>


<h2>参考</h2>

<ul>
<li><a href="http://ymotongpoo.hatenablog.com/entry/2014/12/21/192304">Goの正規表現エンジンを使ってファジング用ツールを書いてみる</a></li>
<li><a href="https://github.com/ymotongpoo/fuzzingo">ymotongpoo/fuzzingo</a></li>
<li><a href="http://www.songmu.jp/riji/entry/2015-03-28-strrand.html">String::Randomのgolang移植書いた</a></li>
<li><a href="https://github.com/Songmu/strrand">Songmu/strrand</a></li>
<li><a href="http://blog.yux3.net/entry/2017/05/01/014200">golangkyoto 「そうだ、 Go 京都」で「Go に String::Random を移植した話」というタイトルで発表した</a></li>
<li><a href="https://github.com/t-mrt/gocha">t-mrt/gocha</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Go言語のヒープに確保するデータの初期化コストについて調べてみた(Go1.8.1版)]]></title>
    <link href="https://shogo82148.github.io/blog/2017/04/13/go1-8-allocation/"/>
    <updated>2017-04-13T08:23:08+09:00</updated>
    <id>https://shogo82148.github.io/blog/2017/04/13/go1-8-allocation</id>
    <content type="html"><![CDATA[<p><a href="https://twitter.com/kaoriya/status/851983856966283265">https://twitter.com/kaoriya/status/851983856966283265</a>">https://twitter.com/kaoriya/status/851983856966283265">https://twitter.com/kaoriya/status/851983856966283265</a></a></p>

<p>こちらのツイートに対して、以下のベンチ結果が紹介されていました。</p>

<ul>
<li><a href="http://ryochack.hatenablog.com/entry/2014/06/08/225606">Go言語のヒープに確保するデータの初期化コストについて調べてみた</a></li>
</ul>


<p>しかし<a href="https://twitter.com/hnakamur2">hnakamur2</a>さんも言及しているように、
これはGo1.2.2時の結果。
その後、GoのコンパイラがGo実装になったり、SSAが導入されたりと、
今のコンパイラの実装は当時とは全く違うものになっています。</p>

<p>というわけで、現時点での最新のバージョン(Go1.8.1)で、同様の検証をおこなってみました。</p>

<!-- More -->


<h2>検証コード</h2>

<p>検証に使用したコードはGo1.2.2のときと全く同じものです。</p>

<pre><code class="go">// alloc_overhead.go

package main

type container struct {
    v [64]byte
}

func MakeContainer() *container {
    c := container{}
    return &amp;c
}

func MakeContainerOneLine() *container {
    return &amp;container{}
}

func MakeContainerNew() *container {
    return new(container)
}

func main() {
    _ = MakeContainer()
    _ = MakeContainerOneLine()
    _ = MakeContainerNew()
}
</code></pre>

<pre><code class="go">// alloc_overhead_test.go

package main

import (
    "testing"
)

func BenchmarkMakeContainer(b *testing.B) {
    for i := 0; i &lt; b.N; i++ {
        _ = MakeContainer()
    }
}

func BenchmarkMakeContainerOneLine(b *testing.B) {
    for i := 0; i &lt; b.N; i++ {
        _ = MakeContainerOneLine()
    }
}

func BenchmarkMakeContainerNew(b *testing.B) {
    for i := 0; i &lt; b.N; i++ {
        _ = MakeContainerNew()
    }
}
</code></pre>

<h2>ベンチマーク結果</h2>

<p>Go1.8.1でベンチマークを実行した結果がこちら。</p>

<pre><code class="plain">$ go test -bench . -benchmem
BenchmarkMakeContainer-4            1000000000           2.79 ns/op        0 B/op          0 allocs/op
BenchmarkMakeContainerOneLine-4     1000000000           2.84 ns/op        0 B/op          0 allocs/op
BenchmarkMakeContainerNew-4         1000000000           2.83 ns/op        0 B/op          0 allocs/op
PASS
ok      _/Users/shogo/workspace/tmp/2017-04-13-alloc    9.345s
</code></pre>

<p>ベンチマークの結果、ほとんど速度の差はありませんでした。</p>

<p>しかし、「ヒープに置かれるデータの初期化」を検証したかったのに、アロケーションが0なのはおかしいですね？
どうやら最適化の結果、スタックに置かれるようになってしまったようです。</p>

<h2>再検証</h2>

<p>Go1.7から追加された<a href="https://golang.org/pkg/runtime/#KeepAlive">runtime.KeepAlive</a>を使ってベンチマークを修正しました。
<code>runtime.KeepAlive</code>が呼ばれるまで確保した領域は解放されることが無いので、
データがヒープに乗ってくれるはずです(たぶん)。</p>

<pre><code class="go">// alloc_overhead_test.go

package main

import (
    "runtime"
    "testing"
)

func BenchmarkMakeContainer(b *testing.B) {
    for i := 0; i &lt; b.N; i++ {
        runtime.KeepAlive(MakeContainer())
    }
}

func BenchmarkMakeContainerOneLine(b *testing.B) {
    for i := 0; i &lt; b.N; i++ {
        runtime.KeepAlive(MakeContainerOneLine())
    }
}

func BenchmarkMakeContainerNew(b *testing.B) {
    for i := 0; i &lt; b.N; i++ {
        runtime.KeepAlive(MakeContainerNew())
    }
}
</code></pre>

<p>修正版のベンチマークはこちら。</p>

<pre><code class="plain">$ go test -bench . -benchmem
BenchmarkMakeContainer-4            50000000            34.7 ns/op        64 B/op          1 allocs/op
BenchmarkMakeContainerOneLine-4     30000000            34.4 ns/op        64 B/op          1 allocs/op
BenchmarkMakeContainerNew-4         50000000            35.9 ns/op        64 B/op          1 allocs/op
PASS
ok      _/Users/shogo/workspace/tmp/2017-04-13-alloc    4.690s
</code></pre>

<p>意図したとおりアロケーションが発生しています。
速度差もほとんどありません。</p>

<h2>最適化の結果を見てみる</h2>

<p><a href="http://shinpei.github.io/blog/2016/08/13/what-ssa-brings-to-go-17/">Go1.7からSSAが導入された</a>ことにより、
以下のようなコマンドで最適化の様子を簡単に知ることができるようになりました。</p>

<pre><code class="bash">GOSSAFUNC=MakeContainer go build alloc_overhead.go
</code></pre>

<p>この機能を使って、各関数が最終的にどのように最適化されたのかを確認してみます。</p>

<p>以下は<code>MakeContainer</code>の結果(<a href="/files/2017-04-13-go1-8-allocation/MakeContainer.html">ssa.html</a>)。</p>

<pre><code class="plain">v1 = InitMem &lt;mem&gt;
v2 = SP &lt;uintptr&gt; : SP
v3 = SB &lt;uintptr&gt; : SB
v10 = LEAQ &lt;*uint8&gt; {type."".container} v3 : AX
v8 = MOVQstore &lt;mem&gt; v2 v10 v1
v9 = CALLstatic &lt;mem&gt; {runtime.newobject} [16] v8
v11 = MOVQload &lt;*container&gt; [8] v2 v9 : AX
v13 = VarDef &lt;mem&gt; {~r0} v9
v14 = MOVQstore &lt;mem&gt; {~r0} v2 v11 v13
</code></pre>

<p><code>MakeContainerOneLine</code>の結果(<a href="/files/2017-04-13-go1-8-allocation/MakeContainerOneLine.html">ssa.html</a>)。</p>

<pre><code class="plain">v1 = InitMem &lt;mem&gt;
v2 = SP &lt;uintptr&gt; : SP
v3 = SB &lt;uintptr&gt; : SB
v10 = LEAQ &lt;*uint8&gt; {type."".container} v3 : AX
v8 = MOVQstore &lt;mem&gt; v2 v10 v1
v9 = CALLstatic &lt;mem&gt; {runtime.newobject} [16] v8
v11 = MOVQload &lt;*container&gt; [8] v2 v9 : AX
v14 = VarDef &lt;mem&gt; {~r0} v9
v15 = MOVQstore &lt;mem&gt; {~r0} v2 v11 v14
</code></pre>

<p><code>MakeContainerNew</code>の結果(<a href="/files/2017-04-13-go1-8-allocation/MakeContainerNew.html">ssa.html</a>)。</p>

<pre><code class="plain">v1 = InitMem &lt;mem&gt;
v2 = SP &lt;uintptr&gt; : SP
v3 = SB &lt;uintptr&gt; : SB
v10 = LEAQ &lt;*uint8&gt; {type."".container} v3 : AX
v8 = MOVQstore &lt;mem&gt; v2 v10 v1
v9 = CALLstatic &lt;mem&gt; {runtime.newobject} [16] v8
v11 = MOVQload &lt;*container&gt; [8] v2 v9 : AX
v12 = VarDef &lt;mem&gt; {~r0} v9
v13 = MOVQstore &lt;mem&gt; {~r0} v2 v11 v12
</code></pre>

<p>変数名の割り当てが異なるだけで実質同じ内容ですね。</p>

<h2>まとめ</h2>

<ul>
<li>Go1.8.1の最適化強い</li>
<li>Go1.8.1では<code>new(Type)</code>と<code>&amp;Type{}</code>の差はない(少なくとも性能面では)</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Go言語のchanはいったいいくつ付けられるのか試してみた]]></title>
    <link href="https://shogo82148.github.io/blog/2017/03/17/how-many-chan-can-i-write-in-golang/"/>
    <updated>2017-03-17T21:10:25+09:00</updated>
    <id>https://shogo82148.github.io/blog/2017/03/17/how-many-chan-can-i-write-in-golang</id>
    <content type="html"><![CDATA[<p>pecoに入った修正をみて、果たして<code>chan</code>はいくつまで付けられるのか気になったので、
雑に試してみました。
先に断っておきますが、全く有用ではないですよ。</p>

<!-- More -->


<h2>背景</h2>

<p>pecoに入った修正はこちら(一部抜粋)。</p>

<ul>
<li><a href="https://github.com/peco/peco/pull/411">Make Resume a blocking operation #411</a></li>
</ul>


<pre><code class="diff">diff --git a/interface.go b/interface.go
index 3d4472f..fff446c 100644
--- a/interface.go
+++ b/interface.go
@@ -162,8 +162,8 @@ type Screen interface {
 // Termbox just hands out the processing to the termbox library
 type Termbox struct {
    mutex     sync.Mutex
-   resumeCh  chan (struct{})
-   suspendCh chan (struct{})
+   resumeCh  chan chan struct{}
+   suspendCh chan struct{}
 }

 // View handles the drawing/updating the screen
diff --git a/screen.go b/screen.go
index edbce87..f6dd71e 100644
--- a/screen.go
+++ b/screen.go
@@ -21,7 +21,7 @@ func (t *Termbox) Init() error {
 func NewTermbox() *Termbox {
    return &amp;Termbox{
        suspendCh: make(chan struct{}),
-       resumeCh:  make(chan struct{}),
+       resumeCh:  make(chan chan struct{}),
    }
 }
</code></pre>

<p>channelを使ってchannelをやり取りすることができるので、
<code>chan struct{}</code>をやり取りする<code>chan chan struct{}</code>という型が使えます。
同じ要領で、channelをやり取りするchannelをやり取りするchannelをやり取り&hellip;するchannelが
無限に作れるはずです(少なくとも構文上は)。
ということで、実際にやってみました。</p>

<h2>実験</h2>

<p>雑なPerlスクリプトを準備して、大量の<code>chan</code>を付けたGoのコードを自動生成します。</p>

<pre><code class="perl">print &lt;&lt;EOF;
package main

import (
    "fmt"
)

type Foo @{['chan ' x 4096]} struct{}

func main() {
    fmt.Printf("Hello, %#v\\n", make(Foo))
}
EOF
</code></pre>

<p><code>chan</code>の個数を変えて何度かビルドを繰り返します。</p>

<pre><code class="bash">time go build -o main main.go
</code></pre>

<h2>結果</h2>

<p>chanの個数とビルドにかかった時間をまとめてみました。</p>

<table>
    <tr><th>chanの個数</th><th>ビルド時間</th></tr>
    <tr><td>1</td><td>0.236s</td></tr>
    <tr><td>2</td><td>0.240s</td></tr>
    <tr><td>4</td><td>0.226s</td></tr>
    <tr><td>8</td><td>0.234s</td></tr>
    <tr><td>16</td><td>0.240s</td></tr>
    <tr><td>32</td><td>0.250s</td></tr>
    <tr><td>64</td><td>0.281s</td></tr>
    <tr><td>128</td><td>0.258s</td></tr>
    <tr><td>256</td><td>0.360s</td></tr>
    <tr><td>512</td><td>0.775s</td></tr>
    <tr><td>1024</td><td>3.228s</td></tr>
    <tr><td>2048</td><td>18.605s</td></tr>
    <tr><td>4096</td><td>1m53.614s</td></tr>
    <tr><td>8192</td><td>13m46.018s(ビルド失敗したので参考記録)</td></tr>
</table>


<p>8192個付けたら以下のようなエラーを吐いてビルドが失敗してしまったので、
8192個の時の記録は参考記録です。</p>

<pre><code class="plain"># command-line-arguments
too much data in section SDWARFINFO (over 2000000000 bytes)
</code></pre>

<p>何かビルドの設定をいじればもっと行けるかもしれませんが、
デフォルトの設定では4096から8192の間に限界があるようです。
4096個<code>chan</code>を付けたときのソースコードは20KB程度なのにバイナリサイズは524MBまで膨らんでいました。</p>

<p>256個当たりからビルド時間に影響が出ているので、
ビルド時間を考える256個以下に抑えるのがよさそうです。
それ以上だと <script type="math/tex">O(n^{2.6})</script> 程度のオーダーでビルド時間が延びます。
とはいえ、256個も<code>chan</code>を付いたコードを人間が読めるとは思えないので、
2個が限度でしょうね・・・。
3個以上必要になるケースは余りないと思います。</p>

<h2>型定義を再帰的にして無限chanを実現する</h2>

<p>そもそも、<code>chan</code>を大量に並べなくとも、
型定義を再帰的に行えば無限の<code>chan</code>を付けたときと同等のことができます。
例えば以下のコードで"Goroutine 1"と"Goroutine 2"を交互に表示することが可能です。</p>

<pre><code class="go">package main

import (
    "fmt"
)

type Foo chan Foo

func main() {
    ch := make(Foo)
    go func() {
        ch := ch
        for {
            done := &lt;-ch
            fmt.Println("Goroutine 2")
            done &lt;- ch
        }
    }()

    for i := 0; i &lt; 100; i++ {
        fmt.Println("Goroutine 1")
        done := make(Foo)
        ch &lt;- done
        ch = &lt;-done
    }
    fmt.Println("Hello, playground")
}
</code></pre>

<p>channelでのやり取りが複雑になるので実用性があるかは不明ですが・・・。
例えば先程の例だと、普通にループを書いたほうが圧倒的にシンプルです。</p>

<pre><code class="go">package main

import (
    "fmt"
)

func main() {
    for i := 0; i &lt; 100; i++ {
        fmt.Println("Goroutine 1")
        fmt.Println("Goroutine 2")
    }
    fmt.Println("Hello, playground")
}
</code></pre>

<p>無限<code>chan</code>が必要になる多くのケースは、このような書き換えができるような気がします。
(そもそも必要になったことがない)</p>

<h2>まとめ</h2>

<ul>
<li><code>chan</code>の個数の上限は4096から8192の間のどこか</li>
<li>256個あたりからビルド時間に影響が出始める

<ul>
<li>プログラムを読む人の精神力に多大な影響を与えるので、実際は2個までに留めるべきだと思う</li>
</ul>
</li>
<li>再帰的に型を定義することで、無限に<code>chan</code>を付けた時と同等のことが可能</li>
</ul>


<p><code>chan</code>を大量に付けたいケースには今までに僕自身は遭遇したことがないです。
有用な例を見つけた人は教えてください。</p>
]]></content>
  </entry>
  
</feed>
