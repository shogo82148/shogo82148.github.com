<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Perl on Shogo&#39;s Blog</title>
    <link>https://shogo82148.github.io/categories/perl/</link>
    <description>Recent content in Perl on Shogo&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <lastBuildDate>Fri, 25 Aug 2017 07:08:44 +0900</lastBuildDate>
    
	<atom:link href="https://shogo82148.github.io/categories/perl/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Perl 5.26 &amp; Unicode 9.0 で変わる書記素クラスタ(grapheme cluster)のお話</title>
      <link>https://shogo82148.github.io/blog/2017/08/25/2017-08-25-unicode9-grapheme-cluster/</link>
      <pubDate>Fri, 25 Aug 2017 07:08:44 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2017/08/25/2017-08-25-unicode9-grapheme-cluster/</guid>
      <description>WEB+DB PRESS Vol.100が発売されましたね。 記念すべき Vol.100 おめでとうございます！
WEB+DB PRESS の連載「Perl Hackers Hub」今回のテーマは「【第46回】Perl 5.26で変わること」です。 Perl 5.26 で追加になった機能、アップグレードの際に気をつけなければならないところ( 特に @INC 問題とか )などに触れられているので、 Perl Monger の方はぜひ読むとよいと思います。
追加された機能のひとつとして Unicode 9.0 サポートが挙げられているのですが、以下のような簡単な紹介に留まっています。
 Unicode 9.0にはオリンピックで活躍するであろう金銀 銅メダルの絵文字などが追加されました。
 Unicode 9.0 で変わるのはそれだけではありません！ Unicode 9.0 での 書記素クラスタ(grapheme cluster) の扱いを少し前に調査したので紹介します。
書記素クラスタ(grapheme cluster)とは 書記素クラスタ(grapheme cluster)とは、人間にとって自然な1文字を表すものです。
たとえば &amp;ldquo;é&amp;rdquo; という文字は一見1文字に見えますが、 length で文字数をカウントすると2文字としてカウントされます。
$ perl -Mutf8 -E &#39;say length &amp;quot;é&amp;quot;&#39; 2  これは length がUnicodeのコードポイント数を数えており、 &amp;ldquo;é&amp;rdquo;が&amp;rdquo;e&amp;rdquo;(U+0065) + アクセント記号(U+0301) の2つのコードポイントで構成されているためです。
他にも異字体セレクタというのがあったり、 絵文字シーケンスというのがあったりして、 コードポイントの数＝文字数とは限りません。
これらの文字たちを1文字として数えるための概念が書記素クラスタ(grapheme cluster)です。</description>
    </item>
    
    <item>
      <title>Perl&#43;List::Utilの64bit整数の罠にはまった話</title>
      <link>https://shogo82148.github.io/blog/2017/04/13/2017-04-13-perl-int64/</link>
      <pubDate>Thu, 13 Apr 2017 19:52:13 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2017/04/13/2017-04-13-perl-int64/</guid>
      <description>先日 Google Code Jam Qualification Round 2017 が開催されました (って何？というひとはAboutのページを確認。本題では無いので説明略)。
僕もこれに参加して、D以外の問題A,B,Cを解いて、無事Round1へ進むことができました。 しかしPerlで解いたC-largeだけ何故か間違いの判定。 原因を探ってみたところ、PerlおよびList::Utilの64bit整数の罠にはまっていたことに気が付いたので、その備忘録として残しておきます。
問題が発生したコード 問題が発生するのは以下の計算をするコードです。
 max: 250000000000000000と249999999999999999で大きい方を返す div: 249999999999999999を2で割った商を求める  この計算をそれぞれ二通りの計算方法で実装してみます。
use 5.24.0; use List::Util qw(max); say &amp;#34;max:&amp;#34;; say max(250000000000000000, 249999999999999999); say max(249999999999999999, 250000000000000000); say &amp;#34;div:&amp;#34;; say int(249999999999999999/2); say 249999999999999999 &amp;gt;&amp;gt; 1;  max: 順番を変えただけなので、同じ結果をになるはず div: 割り算と等価なビットシフトに置き換えたので、同じ結果になるはず  僕は「同じ結果になるはず」と期待していました。 しかし、これを実行してみると以下のようになります。
 [Wandbox]三へ( へ՞ਊ ՞)へ ﾊｯﾊｯ https://wandbox.org/permlink/5fUBzLmBCRKUo4xZ  max: 249999999999999999 250000000000000000 div: 125000000000000000 124999999999999999 原因 250000000000000000は大体2^57.8なので、64bitの整数で十分表現できます。 しかし倍精度浮動小数点数として扱われると、精度が53bit分しかないので正確に表現できないのです。
例えば以下のコードは&amp;rdquo;true&amp;rdquo;を出力します(ここだけ何故かGo)。
package main import ( &amp;#34;fmt&amp;#34; ) func main() { fmt.</description>
    </item>
    
    <item>
      <title>WEB&#43;DB PRESS Vol.97にPerlとRedisの記事を寄稿しました</title>
      <link>https://shogo82148.github.io/blog/2017/02/23/2017-02-23-perl-webdb-vol97/</link>
      <pubDate>Thu, 23 Feb 2017 18:27:53 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2017/02/23/2017-02-23-perl-webdb-vol97/</guid>
      <description>昨年末にSongmuさんからお話を頂き、 WEB+DB PRESS Vol.97内の連載「第43回Perl Hackers Hub」に 「PerlでのRedis活用法」というタイトルで寄稿しました。 発売日は2月24日です。
内容 簡単に内容を紹介しておきます。 Perl使いではじめてRedisを使う人向けに書いたつもりです。
Redisの簡単な説明 Redisのインストール方と、Perlからの接続方法、そしてRedisの型の説明です。 記事の中でも紹介していますが、Redisはその豊富な型が特長です。 読者はきっとPerl使いだろうということで、Perlの型(Perlにも型はあるんだよ！！)と 比較しながら簡単に紹介しています。
Redisの応用例とCPANモジュールの紹介 Redisを使うとこんなことができるよ、という紹介です。 CPANで公開されているRedis関連のモジュールも合わせて紹介しています。
Redis自体の注意点 以前Redisを使ったサービスの運用に携わっていたのですが、 そのなかで実際に起きたことを元に、Redisの注意点について書きました。 さいわいサービスが停止するような事故にはありませんでしたが、 メトリックスを眺めながらエンジニア勢でヤバイヤバイ騒いでましたね・・・。 みなさんも気をつけて下さい。
執筆してみての感想 昔から文章を書くのにはだいぶ苦手意識があり、 今回の執筆も非常に苦労しました。 一文の前半を書いた時点で 「今から書こうとしている情報は本当に必要なのか」 「自分の記憶違いで間違った情報なのでは」と不安になり、 色々考えているうちに、何書こうとしてたのかわからなくなるんですよね。 まずは適当に書き上げて、後からちゃんと推敲しよう、 とは思いつつもなかなか進められず・・・。 スループットを上げたい。
細かい表現とかも気になってなかなか進まないので、 こういうの入れて頑張ろうと思います！
 VS Codeでtextlintを使って文章をチェックする gitbookで技術書を書く環境の構築手順  (執筆が進まないと、こういう環境構築に時間をかけてしまうのもよくないと思うんだ・・・)
余談 ところで、Vol.97と第43回ってどっちも素数ですね！ 雑なプログラムを書いて調べてみたところ、 両方素数になるのはVol.83, 第29回以来、7回目(これも素数だ！)。 次はVol.101, 第47回です。 そのときのPerl Hackerは誰になるのでしょうか。楽しみですね！
use warnings; use strict; sub is_prime { my $n = shift; return 0 if $n &amp;lt; 2; my $i = 2; while($i*$i&amp;lt;=$n) { return 0 if $n % $i == 0; $i++; } return 1; } my $i = 1; for my $n(1.</description>
    </item>
    
    <item>
      <title>Redis::Fast 0.19リリースのお知らせ</title>
      <link>https://shogo82148.github.io/blog/2016/12/20/2016-12-20-redis-fast-0-dot-19-released/</link>
      <pubDate>Tue, 20 Dec 2016 22:38:27 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2016/12/20/2016-12-20-redis-fast-0-dot-19-released/</guid>
      <description>Redis::Fast 0.19 をリリースしました。 主な変更点は以下の通りです。
 reconnect_on_error オプションの追加 Sentinelのノード一覧が更新されない不具合の修正 IPv6の実験的サポート  reconnect_on_error オプションの追加 @yoheimutaさんからのプルリクエストです。 今まではネットワークエラーが発生した時のみ再接続処理が走っていましたが、 Redisがエラーを返した場合にも再接続を行うようになります。 マスタースレーブ構成をしているときに、 何らかの原因によりRedis::Fastからのコネクションを維持したまま、 マスターがスレーブに降格してしまった場合に対処するための機能です。 以下のように設定することで、新しいマスターに再接続を行うことが可能になります。
my $r = Redis::Fast-&amp;gt;new( reconnect =&amp;gt; 1, # 0以上で再接続有効 reconnect_on_error =&amp;gt; sub { my ($error, $ret, $command) = @_; if ($error =~ /READONLY You can&amp;#39;t write against a read only slave/) { return 1; # 再接続を行う。次の再接続まで最低1秒空ける } return -1; # 再接続は行わない }, ); Sentinelのノード一覧が更新されない不具合の修正 Redis::FastにはどれかひとつのSentinelノードに接続すると、 他のノードの情報を自動的に収集する機能があります。 この機能が最新のRedisでは動いていなかったので修正しました。 具体的にいつからなのかまでは追ってないのですが、 Redisのバージョン3.0.6から3.2.6の間のどこかで ノード一覧の形式が変わってしまったようです。</description>
    </item>
    
    <item>
      <title>DateTime.pmにうるう秒の修正が入った話</title>
      <link>https://shogo82148.github.io/blog/2016/12/15/2016-12-15-leap-second-in-datetime-dot-pm/</link>
      <pubDate>Thu, 15 Dec 2016 22:17:47 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2016/12/15/2016-12-15-leap-second-in-datetime-dot-pm/</guid>
      <description>こんにちは、DateTime.pm Watcherのいっちーです。 本日面白いパッチがDateTime.pmに取り込まれたので、ご紹介したいと思います。
そのpullreqがこちらです。Closedになっていますが、該当コミットはmasterに取り込まれています。
 The leap second in 2012 was on 2012-07-01 not 2012-06-01. #48   per https://confluence.qps.nl/display/KBE/UTC+to+GPS+Time+Correction the leap second in 2012 was on 2012-07-01 not 2012-06-01. It&amp;rsquo;s is well known that leap seconds only occur directly before Jan 1st or July 1st.
 適当な和訳「2012年に挿入されたうるう秒は2012年6月1日ではなく2012年7月1日です。よく知られているように、今までに挿入されたうるう秒は1月1日と7月1日の直前だけです。」
diff --git a/lib/DateTime/LeapSecond.pm b/lib/DateTime/LeapSecond.pm index 66e1b2b..4a38be2 100644 --- a/lib/DateTime/LeapSecond.pm +++ b/lib/DateTime/LeapSecond.pm @@ -108,7 +108,7 @@ sub _initialize {  1999 Jan. 1 +1 2006 Jan.</description>
    </item>
    
    <item>
      <title>PerlでもGoでも実行できるQuine書いた</title>
      <link>https://shogo82148.github.io/blog/2016/04/06/2016-04-06-ployglot-quine-of-golang-and-perl/</link>
      <pubDate>Wed, 06 Apr 2016 10:07:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2016/04/06/2016-04-06-ployglot-quine-of-golang-and-perl/</guid>
      <description>昨日のPolyglotを元にPerlでもGoでも実行できるQuine書いた。
package main;import(&amp;quot;fmt&amp;quot;);var(q=`printf&#39;package main;import(&amp;quot;fmt&amp;quot;);var(q%c%c%s%c/*%c);sub import{}sub var{$_%cshift%c~s!%c(.*)%c/\*!$1!gr;eval}%c__END__%c&#39;,61,96,$_,96,61,61,61,96,96,10,10;print&amp;lt;DATA&amp;gt;`/*=);sub import{}sub var{$_=shift=~s!`(.*)`/\*!$1!gr;eval} __END__ */);func main(){s:=`package main;import(&amp;quot;fmt&amp;quot;);var(q=%c%s%c/*=);sub import{}sub var{$_=shift=~s!%c(.*)%c/\*!$1!gr;eval} __END__ */);func main(){s:=%c%s%c;fmt.Printf(s,96,q,96,96,96,96,s,96)} `;fmt.Printf(s,96,q,96,96,96,96,s,96)}  Perlで実行してもGoで実行しても自分自身を出力します。</description>
    </item>
    
    <item>
      <title>PerlとGolangで実行できるPolyglot書いてみた</title>
      <link>https://shogo82148.github.io/blog/2016/04/05/2016-04-05-polyglot-of-perl-and-golang/</link>
      <pubDate>Tue, 05 Apr 2016 12:27:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2016/04/05/2016-04-05-polyglot-of-perl-and-golang/</guid>
      <description>Rubyの会社をPerlの会社に変えてしまおう計画。 Golangのフリをして忍び込ませれば行けるのではという話になったので、 GoでもPerlでも実行できるコードを書いてみた。
出来上がったのがこちら。
package main; import (&amp;#34;fmt&amp;#34;); var (s=0/*==); sub import {} sub var { print &amp;#34;Hello macotasu&amp;#34;; } __END__ */) func main() { fmt.Println(&amp;#34;Hello macotasu&amp;#34;) } 一番のポイントはvar (s=0/*==);の行ですね。 Perlで解釈すると正規表現置換s///として解釈され、/*が無視されます。 Goで解釈すると変数sへの代入として解釈され、/*がコメントとして扱われます。
あとはGoのキーワードをPerlが解釈できないので、ちょっと書き方を工夫します。
 package main はGoでもPerlでも似たような意味で解釈されるのでそのまま Goの import, var はPerlで解釈できないので、()を省略せずに書いてPerlの関数呼び出しっぽくする 省略可能なセミコロンをちゃんと書く  GoとPerlのコードは分かれているのでどんな処理でも自由に書くことができますが、 import だけGoでもPerlでも解釈されてしまうというという制限があります。 import するパッケージが一個だけなら問題ないんですが、 複数書く場合は以下のように２個め以降をすべてドットインポートする必要があって男気あふれる感じです。 (Perlでは文字列結合として解釈される。Goではvarのあとにimportかけないっぽいので、ここに押し込むしかない。)
package main; import ( &amp;#34;fmt&amp;#34; . &amp;#34;math&amp;#34; ); var (s=0/*==); sub import {} sub var { print &amp;#34;Hello macotasu&amp;#34;; } __END__ */) func main() { fmt.</description>
    </item>
    
    <item>
      <title>Redisのトランザクション・スクリプト・ランキングを扱うPerlモジュールを公開しました</title>
      <link>https://shogo82148.github.io/blog/2016/03/18/2016-03-18-releaes-redis-modules/</link>
      <pubDate>Fri, 18 Mar 2016 22:16:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2016/03/18/2016-03-18-releaes-redis-modules/</guid>
      <description>以前Redisでスコアを複数設定できるランキングを作ってみたけど、 Githubの肥やしになっていてもあれなので、CPANizeしました。 あわせて、この実装のために作ったユーティリティモジュールも別モジュールとして公開しました。
 Redis::LeaderBoardMulti Redis::Script Redis::Transaction  Redis::LeaderBoardMulti 最初の基準で順位を決められなかった場合の第二基準が欲しいというときに使うモジュールです。 インターフェースがRedis::LeaderBoard互換になるように調整したので、 前回とインターフェースがちょっと変わっています。
se Redis; use Redis::LeaderBoard; my $redis = Redis-&amp;gt;new; my $lb = Redis::LeaderBoardMulti-&amp;gt;new( redis =&amp;gt; $redis, key =&amp;gt; &amp;#39;leader_board:1&amp;#39;, order =&amp;gt; [&amp;#39;asc&amp;#39;, &amp;#39;desc&amp;#39;], # asc/desc, desc as default ); # Redis::LeaderBoardに合わせて複数指定できるようになりました $lb-&amp;gt;set_score( &amp;#39;one&amp;#39; =&amp;gt; [100, time], &amp;#39;two&amp;#39; =&amp;gt; [ 50, time], ); my ($rank, $score, $time) = $lb-&amp;gt;get_rank_with_score(&amp;#39;one&amp;#39;); Redis::LeaderBoard互換なのでそのまま入れ替えられるはずですが、以下のような実装上の制限があります。
 スコアはすべて64bit符号付き整数  Redis::LeaderBoardのスコアは倍精度浮動小数点型なので小数も扱えるが、Redis::LeaderBoardMultiは整数だけ  Redis 2.8.9以降のみで動きます 同順の場合の出現順  Redis::LeaderBoard は ZRANK, ZREVRANK を使い分けているので、orderパラメータによって昇順/降順が変わります Redis::LaederBoardMulti は ZRANK しか使わないので、必ず昇順になります   一応 Lua Script を使わないオプションもそのまま残してありますが、特に理由がない限りデフォルト(Lua Script を使う)で使うといいと思います。 どうしてもロックの範囲が広くなってしまう場合があり、楽観的ロックでは効率が悪いケースがあるためです。</description>
    </item>
    
    <item>
      <title>Redisでスコアを複数設定できるランキングを作ってみた</title>
      <link>https://shogo82148.github.io/blog/2016/02/06/2016-02-06-redis-leader-board-multi/</link>
      <pubDate>Sat, 06 Feb 2016 02:30:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2016/02/06/2016-02-06-redis-leader-board-multi/</guid>
      <description>ランキングを作っているとスコアを複数設定したいことがよくあると思います。 例えば「得点が同じだったら早くその得点を出した人優先」とか「勝ち点が同じだったら得失点差が大きい方優先」とかのように、 最初の基準で順位を決められなかった場合の第二基準が欲しいみたいな場合です。
ランキングを作るのにはRedisのSorted Setを使うのが便利ですが、残念ながらSorted Setはひとつしかスコアを設定できません。 少し前にどうやったら実装できるかと社内チャットで話題に上ったので、試しにRedis::LeaderBoardMulti(仮名)という名前で書いてみました。
 shogo82148/p5-Redis-LeaderBoardMulti  使い方 メソッドの名前はRedis::LeaderBoardにあわせてありますが、 スコアが複数指定できるようになった関係でちょっと変わってます。
use Redis; use Redis::LeaderBoard; my $redis = Redis-&amp;gt;new; my $lb = Redis::LeaderBoardMulti-&amp;gt;new( redis =&amp;gt; $redis, key =&amp;gt; &amp;#39;leader_board:1&amp;#39;, order =&amp;gt; [&amp;#39;asc&amp;#39;, &amp;#39;desc&amp;#39;], # asc/desc, desc as default ); $lb-&amp;gt;set_score(&amp;#39;one&amp;#39; =&amp;gt; 100, time); # 第二基準は時間=得点が同じだったら早くその得点を出した人優先 $lb-&amp;gt;set_score(&amp;#39;two&amp;#39; =&amp;gt; 50, time); my ($rank, $score, $time) = $lb-&amp;gt;get_rank_with_score(&amp;#39;one&amp;#39;); set_scoreの第二引数以降はすべてスコアとして扱われます。(そのためRedis::LeaderBoardと互換性はない) 上の例では「得点が同じだったら早くその得点を出した人優先」になってます。
制限事項 実装の都合により、以下のような制限があります。
 スコアはすべて64bit符号付き整数です  Redis::LeaderBoardのスコアは倍精度浮動小数点型なので小数も扱えるが、Redis::LeaderBoardMultiは整数だけ  Redis 2.8.9以降のみで動きます  実装の仕組み Sorted Setの同じスコアを持つメンバーは辞書順にソートされます(zaddの同じスコアを持つ要素の項を参照)。 例えば以下の様にメンバー「a」「b」「c」を追加すると、必ず「abc」の順番になることが保証されています。</description>
    </item>
    
    <item>
      <title>Redis::Fast 0.17 をリリースしました</title>
      <link>https://shogo82148.github.io/blog/2016/01/23/2016-01-23-redis-fast-0-dot-17-released/</link>
      <pubDate>Sat, 23 Jan 2016 16:20:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2016/01/23/2016-01-23-redis-fast-0-dot-17-released/</guid>
      <description>Redis::Fast 0.17 をリリースしました。 主な変更点は以下のとおりです。
 I/Oの待ち合わせに使うシステムコールをselect(2)からpoll(2)に変更 hiredisをv0.13.3にアップデート  macでテストが終わらない問題がありましたが、この変更によって修正されています。
hiredisはconnect(2)をnonblokingモードで呼び出しています。 nonblockingなので接続が未完了であってもすぐに制御を返し、errnoにEINPROGRESSが設定されます。 この場合、manにあるようにselect(2)で書き込み可能になるのを待つことで、接続完了を検知できます。
 select(2) で書き込み可能になった後に、 getsockopt(2) を使って SOL_SOCKET レベルで SO_ERROR オプションを読み出すこ とにより、 connect() が成功したか、失敗したかを判断できる。
 linuxの場合はこれで上手く動くのですが、macだと何故かselect(2)が永遠に制御を返さない場合があるようです。 接続先が存在しない場合に起こるのですが、制御を返す場合もあるので謎です。
いろいろ調べてはみたのですがselect(2)だとどうやっても上手く動かなかったので、poll(2)に変更しました。 poll(2)変更版でテストしてみると、接続先が存在しない場合にPOLLOUTを返すケースとPOLLHUPを返すケースがあるようです。 どうやらPOLLHUPにあたるイベントが来た時の挙動がlinuxとmacとで違うらしい？ 謎です。</description>
    </item>
    
    <item>
      <title>PerlのDBIx::Class利用上の注意点</title>
      <link>https://shogo82148.github.io/blog/2015/12/17/2015-12-17-dbix-class/</link>
      <pubDate>Thu, 17 Dec 2015 18:35:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/12/17/2015-12-17-dbix-class/</guid>
      <description>この記事は、Perl 5 Advent Calendarの17日目の記事です。
Redis::Fast の reconnect についての中で DBIx::Classのreconnectについても触れています。 DBIx::Classの安全にreconnectionが行えるように考慮されていますが、色々と注意点があります。 reconnection周りで調べてみたので、Advent Calendarの枠を借りてまとめたいと思います。
DBIx::Classとは DBIx::ClassはPerlのO/Rマッピングモジュールです。 テーブル間のリレーションを定義でき、JOIN句の入ったクエリもサポートする等、かなり高機能なモジュールです。 もう僕はJOIN句をDBIx::Class以外で書ける気がしません。 詳しくはtypester先生の解説記事をどうぞ。
 Perl Hackers Hub  第3回　DBIx::Classでデータベース操作（1） 第3回　DBIx::Classでデータベース操作（2） 第3回　DBIx::Classでデータベース操作（3）   サンプル サンプルとしてユーザの所持金を管理する簡単なアプリを作ってみます。 Webアプリとか作るの面倒だったので、コンソールアプリです。
package My::Schema::User { use base &amp;#39;DBIx::Class::Core&amp;#39;; __PACKAGE__-&amp;gt;table(&amp;#39;user&amp;#39;); __PACKAGE__-&amp;gt;add_columns( id =&amp;gt; { data_type =&amp;gt; &amp;#39;INTEGER&amp;#39;, is_nullable =&amp;gt; 0, is_auto_increment =&amp;gt; 1, }, username =&amp;gt; { data_type =&amp;gt; &amp;#39;VARCHAR&amp;#39;, size =&amp;gt; 255, is_nullable =&amp;gt; 0, }, ); __PACKAGE__-&amp;gt;set_primary_key(&amp;#39;id&amp;#39;); # userとmoneyは1対1の関係で、userに対応するmoneyが必ず存在しなければならない __PACKAGE__-&amp;gt;has_one( &amp;#39;money&amp;#39; =&amp;gt; &amp;#39;My::Schema::Money&amp;#39;, { &amp;#39;foreign.</description>
    </item>
    
    <item>
      <title>Perl の DateTime 利用上の注意点</title>
      <link>https://shogo82148.github.io/blog/2015/12/09/2015-12-09-perl-datetime/</link>
      <pubDate>Wed, 09 Dec 2015 00:00:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/12/09/2015-12-09-perl-datetime/</guid>
      <description>この投稿は Perl 5 Advent Calendar 2015 の 9日目の記事です。
Perl の Time::Piece 利用上の注意点 という記事の最後にDateTimeへの言及があったのですが、 DateTimeはDateTimeでいろいろとハマりどころがあるんですよね・・・。 僕も今年いくつか罠にハマりました。ちょうどアドベントカレンダーの季節ですし、この機会にハマりどころをまとめてみることにします。
遅い いろんなところで言われていることですが 遅い です。 試しに代表的な日付を扱うモジュールでベンチをとってみました。 (比較のために時間をとるためのPerlの組み込み関数も入れてあります)
# いろんな形式で今の時間を取得する use Benchmark qw/ cmpthese /; use Time::HiRes (); use Time::Moment; use Time::Piece (); use DateTime; cmpthese 0, { &amp;#39;time&amp;#39; =&amp;gt; sub { time }, &amp;#39;Time::HiRes&amp;#39; =&amp;gt; sub { Time::HiRes::time }, &amp;#39;localtime&amp;#39; =&amp;gt; sub { () = localtime }, &amp;#39;Time::Moment&amp;#39; =&amp;gt; sub { Time::Moment-&amp;gt;now }, &amp;#39;Time::Piece&amp;#39; =&amp;gt; sub { Time::Piece-&amp;gt;localtime }, &amp;#39;DateTime&amp;#39; =&amp;gt; sub { DateTime-&amp;gt;now( time_zone=&amp;gt;&amp;#39;Asia/Tokyo&amp;#39; ) }, }; Rate DateTime Time::Piece Time::Moment localtime Time::HiRes time DateTime 5303/s -- -95% -98% -99% -100% -100% Time::Piece 103765/s 1857% -- -67% -71% -98% -99% Time::Moment 313599/s 5814% 202% -- -11% -93% -98% localtime 354215/s 6580% 241% 13% -- -92% -98% Time::HiRes 4706723/s 88658% 4436% 1401% 1229% -- -72% time 16536995/s 311751% 15837% 5173% 4569% 251% --  それにしてもTime::Moment速いですね。組み込みのlocaltimeと互角とは。</description>
    </item>
    
    <item>
      <title>AnySan::Provider::Slackとape-slackを書いた</title>
      <link>https://shogo82148.github.io/blog/2015/09/28/2015-09-28-anysan-provider-slack-and-ape-slack/</link>
      <pubDate>Mon, 28 Sep 2015 22:11:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/09/28/2015-09-28-anysan-provider-slack-and-ape-slack/</guid>
      <description>先週、今のプロジェクトでのメインのコミュニケーションツールをIRCからSlack切り替えました。 それにともないIRCに済んでいたボットたちもお引越しする必要があったので、 ボットとSlackをつなぐためのライブラリを書きました。
 AnySan::Provider::Slack ape-slack  Perlとgoのボットが住んでいるのでそれぞれの言語で実装してあります。
AnySan::Provider::Slack PerlのAnySan用のモジュールです。
use AnySan; use AnySan::Provider::Slack; my $slack = slack token =&amp;gt; &amp;#39;YOUR SLACK API TOKEN&amp;#39;, channels =&amp;gt; { &amp;#39;general&amp;#39; =&amp;gt; {}, }; $slack-&amp;gt;send_message(&amp;#39;slack message&amp;#39;, channel =&amp;gt; &amp;#39;C024BE91L&amp;#39;); AnySan-&amp;gt;run; AnySanを使うだけでも便利なんですが、 今のプロジェクトではAnySanを対話形式で使いやすくするようにUnazuSanを使っています。 UnazuSanはIRC前提で書かれていて、AnySan::Provider::Slackをインストールしてもそのままは使えません。
UnazuSanを置き換えるもの面倒なので、イベントの名前を書き換えて投げ直すことで、 SlackのメッセージをIRCに見せかける方法をとっています。 またSlackのOutgoing Webhookで@つきのmentionを捕まえるにもあるように、 Slackのメンションは &amp;lt;@U08DGJVJ7&amp;gt;のような形式になってしまい、UnazuSanは自分へのメッセージとして扱ってくれません。 これをUnazuSanが解釈できる形式に置き換えるのがポイントです。
use 5.010; use warnings; use utf8; use Encode qw/encode_utf8/; use UnazuSan; use AnySan; use AnySan::Provider::Slack; my $unazu_san = UnazuSan-&amp;gt;new( host =&amp;gt; &amp;#39;example.com&amp;#39;, password =&amp;gt; &amp;#39;xxxxxxxxxxx&amp;#39;, enable_ssl =&amp;gt; 1, join_channels =&amp;gt; [qw/arcade/], respond_all =&amp;gt; 1, ); my $slack = slack( token =&amp;gt; &amp;#39;YOUR SLACK TOKEN&amp;#39;, channels =&amp;gt; {}, as_user =&amp;gt; 1, ); AnySan-&amp;gt;register_listener( slack =&amp;gt; { event =&amp;gt; &amp;#39;message&amp;#39;, cb =&amp;gt; sub { my $receive = shift; # fake irc privmsg $receive-&amp;gt;{event} = &amp;#39;privmsg&amp;#39;; $receive-&amp;gt;{message} =~ s/&amp;lt;\@xxxxx&amp;gt;:/unazusan:/; AnySan-&amp;gt;broadcast_message($receive); }, } ); $unazu_san-&amp;gt;on_command( help =&amp;gt; sub { my ($receive, @args) = @_; $receive-&amp;gt;reply(&amp;#39;help &amp;#39;.</description>
    </item>
    
    <item>
      <title>テストでも:ok_maopy:したい人へ</title>
      <link>https://shogo82148.github.io/blog/2015/09/19/2015-09-19-ok-macopy/</link>
      <pubDate>Sat, 19 Sep 2015 23:44:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/09/19/2015-09-19-ok-macopy/</guid>
      <description>shogo82148/p5-Acme-OkMacopy  use strict; use Test::More; use Acme::OkMacopy; ok_macopy &amp;#34;macopy is cool&amp;#34;, &amp;#34;ok_macopy&amp;#34;; done_testing; 様子です pic.twitter.com/sA96GmqKmQ
&amp;mdash; トーカナイザの守護霊 (@mackee_w) 2015年9月17日 
:ok_macopy:</description>
    </item>
    
    <item>
      <title>Go言語でPerlのテストを早くする</title>
      <link>https://shogo82148.github.io/blog/2015/09/19/2015-09-19-faster-perl-test-with-go-lang/</link>
      <pubDate>Sat, 19 Sep 2015 21:49:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/09/19/2015-09-19-faster-perl-test-with-go-lang/</guid>
      <description>Test::mysqld::Multiというモジュールを書いてみたみたいな涙ぐましい努力により5分で終わるようになったテストですが、 プロジェクトのコードも増えて人も増えた影響で、 テスト時間が約7分まで伸び、テストのキューに10個近く並んで順番待ちさせられるという状況になってしまいした。
この状況を解決すべく go-prove というものを書いてみたので、そのご紹介です。
proveが遅い理由 proveがテストの結果を読むところがブロッキングI/Oになっているらしく、そのせいで遅くなっているらしいです。
 Perl-Toolchain-Gang/Test-Harness#30  実際に結果読んでいるところはこの辺ですかね。 selectとか使っていてなるべくブロッキングしないような作りにはなっていそうですが、どこかでブロッキングしてしまっているようです。 今のプロジェクトだと32コアのCPUで32並列で動かしてもCPUを100%使い切ることができませんでした。
Shunme ググるとShunmeというプロジェクトでproveの問題を解決しようという試みが行われているようです。
 Shunmeというperl用のテストハーネスモジュールを書き始めました magnolia-k/p5-Shunme  しかし残念ながらproveのプラグイン機構はサポートしておらず、Formatterの指定オプションもないようです。 今のプロジェクトではプラグインでMySQLを立てたり、JUnitでテスト結果をフォーマットしたりということをしているので、そのままは使えなさそう。 ちょっと改造するにはソースコードの理解が大変そうなので断念。 「(逆に遅くなるときも有ります)」というところも気になりますね・・・。
go-prove いろいろテストの実行方法を調べてはみましたが、どの方法も並行処理に苦労している模様。 テストファイル自体はただのPerlのスクリプトなので、実行して集計する部分は別にPerlにこだわる必要ないのでは？ 並行処理といえば今ならGolangでしょ！ってことでproveのGo実装を書いてみました。
 go-prove  例えば以下のようなテストをかいて、
``` perl t/macopy.t use Test::More;
ok &amp;ldquo;macopy&amp;rdquo;;
done_testing;
 go-proveコマンドと実行すると、JUnit形式でテスト結果が出力されます。  $ go-prove 2015/09/19 21:45:44 start t/macopy.t 2015/09/19 21:45:44 finish t/macopy.t      ```
go-prove -j 32とするとgoroutineを32個生成して、32並列でテストを実行してくれます。 I/Oの処理をGolangのランタイムがよしなにやってくれるので、楽ちんです。
また、今のプロジェクトではApp::Prove::Plugin::MySQLPoolを使っているので、それ相当の機能をgo-prove -plugin mysqldで使えるようにしました。 プラグインを有効にするとMySQLサーバを立ち上げて、その接続先情報をGO_PROVE_MYSQLD環境変数に設定してくれます。
実際にプロジェクトのコードで試してみたところ7分かかっていたテストが4分を切るようになりました。 CPUの使用率も100%近くになって、有効活用できているようです。</description>
    </item>
    
    <item>
      <title>PerlからGolangを呼び出す</title>
      <link>https://shogo82148.github.io/blog/2015/08/30/2015-08-30-golang-to-perl-xs-converter/</link>
      <pubDate>Sun, 30 Aug 2015 22:52:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/08/30/2015-08-30-golang-to-perl-xs-converter/</guid>
      <description>GoのコードをPerlから呼び出せるようにするgo2xsを書いてみました。
使い方 Perlから使いたい関数に以下のようにgo2xsで始まるコメントを付けておきます。
``` go hoge package main
//go2xs hello func hello(str string) string { return &amp;ldquo;Hello &amp;rdquo; + str }
 [go2xs](https://github.com/shogo82148/go2xs)をgo getして、xsのグルーコードを作成。 その後通常のPerlモジュールと同じ手順でコンパイルします。 Go 1.5から入ったShared Libraryの機能を使っているのでGo 1.5が必要です。 ``` bash go get https://github.com/shogo82148/go2xs/cli/go2xs go2xs -name hoge hoge.go perl Makefile.PL make  あとは普通に呼び出すだけ。
perl -Mblib -Mhoge -e &#39;print hoge::hello(&amp;quot;World&amp;quot;)&#39; Hello World  制限事項 今はまだ、整数・浮動小数点型・文字列しか扱えません。
あとGoのShared Libraryを複数回読み込むことができないっぽい？ (ref. https://github.com/golang/go/issues/11100 ) ので、go2xsを使ったコードを二つ以上useすると死にます。
FFI::Rawを使う方法 go2xsはGoをShared Libraryとしてコンパイルしているだけなので、go2xsを使わなくても頑張れば呼び出すことができます。 Golang で Shared Library を出力する。で紹介されているこちらのコードで試してみます。
``` go libgofib.</description>
    </item>
    
    <item>
      <title>YAPC::Asia2015へ行ってきた</title>
      <link>https://shogo82148.github.io/blog/2015/08/23/2015-08-23-yapc-asia-2015/</link>
      <pubDate>Sun, 23 Aug 2015 00:48:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/08/23/2015-08-23-yapc-asia-2015/</guid>
      <description>YAPC::Asia2015へ行ってきましました。 Blogを書くまでがYAPCらしいので、簡単に
今年の会場は東京ビッグサイトです。 ▼▼みたいになってるところの中にはじめて潜入してきました。 あの中って会議室なんですね。
去年は毎回立ち見ですごく大変だったけど、今年はかなり会場が広くなったおかけで、 大体席を確保できて楽にトークを聴けました。 しかし会場が東京ビッグサイトであっても、人気トークは立ち見になってしまうのがYAPCのすごいところ・・・。 それでも、前の人の頭でスライドが全く見えないみたいなことはなかったので、広い会場は便利です。
以下、今年見たトークです。
 言語開発の現場 はてなブックマークのトピックページの裏側 技術ブログを書くことについて語るときに僕の語ること  タイトルが9割  世界展開する大規模ウェブサービスのデプロイを支える技術  全サーバで一斉にgit pullするつらい話だった と、思ったら途中からstretcherの話になった  HTTP/2時代のウェブサイト設計  CSSスプライトみたいなファイルを一つにまとめてリクエストを減らす技術はHTTP/2ではオワコンになる 何よりもデータ量を減らすことが大事  【sponsored contents】若手エンジニア達の生存戦略 Google Cloud Platformの謎テクノロジーを掘り下げる  朝寝坊して途中からの参加でした(=_=) Googleのコンテナ技術BorgやGoogleのネットワークについての話  我々はどのように冗長化を失敗したのか MySQLで2億件のシリアルデータと格闘したチューニングの話 データ分析基盤を支える技術  いろいろなツールの比較についてのお話でした なんか色々なオープンソースのソフトウェアを紹介していたけど、「自分で構築しようとするな」とのこと D言語みんな使ってね  Parallelism, Concurrency, and Asynchrony in Perl 6  Perl6では並列・並行・非同期処理が簡単に書けるらしいので、その紹介 Promiseやawaitみたいな他の言語で取り入れられている概念がPerlでも使えるらしい 来年Perl6でドローンが飛んでいるのを期待してます  Profiling &amp;amp; Optimizing in Go  Goのプロファイリングと最適化のデモでした sync.Pool 存在は知っていたけど実際に使っているコード始めて見た気がする。bytes.Bufferの作成に使っていたんだけど、メモリアロケート程度なら同期コストの方が高いのでは〜って思っていた。   改めて見返してみるとPerlについての話がPerl6の並列・並行・非同期処理くらいしかないきがする。 (YAPCのPとは一体)</description>
    </item>
    
    <item>
      <title>Test::mysqld::Multiというモジュールを書いてみた</title>
      <link>https://shogo82148.github.io/blog/2015/06/20/2015-06-20-test-mysqld-multi/</link>
      <pubDate>Sat, 20 Jun 2015 10:41:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/06/20/2015-06-20-test-mysqld-multi/</guid>
      <description>Test::mysqldのインスタンスを一度に大量に作りたい人向けに Test::mysqld::Multiというモジュールを書いてみました。
2016/12/22追記: Test::mysqld::MultiはTest::mysqld 0.20 の一部として取り込まれました (p5-Test::mysqld#13)。 APIは少し変わっているので、詳しくはPODを参照してください。 合わせてApp::Prove::Plugin::MySQLPool 0.06 より、 本記事で紹介した高速化が利用できます。
背景 先日Jenkins EC2 Plugin で Spot Instance を使ってテストを回すというのを、 tkuchikiさんにお願いして僕の関わっているプロジェクトでやっていただきました。 CPUのたくさん載ったインスタンスを安く使えるようになったので、 8並列で動いてたテストを24並列で動かせるようになりました。やった3倍速だ！！！ 9分程かかってたテストが7分で終わるようになりました！！！ あれ・・・思ったほど早くなってない・・・。
ログを眺めているとproveコマンドが立ち上がってから、実際にテストが走り始めるまで数分の時間がありました。 App::Prove::Plugin::MySQLPoolを使っているのですが、 ここで時間がかかっているようです。
App::Prove::Plugin::MySQLPoolはテストの並列度分だけMySQLのインスタンスを立ち上げますが、 一個インスタンスを立ち上げたら、それにアクセスできるようになるまでずっと待っているようです。 MySQLの起動に5秒かかるとして24並列で動かしたら2分かかるわけで無視できない長さになります。
作ったもの n個一度に立ち上げて全部にアクセスできるまで待つ実装にすれば速くなるのでは！ってことでTest::mysqld::Multiというのを書いて、 App::Prove::Plugin::MySQLPoolからそれを使うようにしました。 とりあえずtest-mysql-multiブランチにコミットしてあります。 App::Prove::Plugin::MySQLPoolに取り込んでもらうか別のモジュールとして分離するか、後々のことは未定。 今のプロジェクトで使ってみてちょっとの間様子見してみます。 7分かかってたテストが5分程度で終わるようになったので、効果はあるようです。
ちなみに、並列度が24と半端なのはそれ以上並列度を上げても速くならなかったため。 32コアあるマシンなんだけど使い切れてません。 どこにボトルネックがあるんだろうな・・・。
まとめ プロセス一覧にmysqldが24個並ぶの楽しい</description>
    </item>
    
    <item>
      <title>Perlで文字列の出現回数を調べる</title>
      <link>https://shogo82148.github.io/blog/2015/04/09/2015-04-09-count-substrings-in-perl/</link>
      <pubDate>Thu, 09 Apr 2015 23:28:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2015/04/09/2015-04-09-count-substrings-in-perl/</guid>
      <description>Perlで特定の文字列の出現回数を調べたくなって、調べてみたメモ。
ググるとすぐに見つかった。 perlで指定文字列の出現回数を取得する(正規表現)
 指定文字列の出現回数は正規表現を使って
$count++ while($str =~ m/$pattern/g);
もしくは
$count = (() = $str =~ m/$pattern/g);
 が、一瞬何をやっているのか把握できない・・・。 こういう意味なのかなーって予想はしてみたけど、あってるか一応調査。
whileを使った方法 //g をスカラーコンテキストの中でマッチさせると、 前回マッチした場所を覚えておいてくれて、次のマッチでその場所から検索を再開してくれるらしい。 (Using regular expressions in Perl - perlretut) マッチした場所は pos で取得可能。
my $str = &amp;#34;hoge fuga foo bar&amp;#34;; while ($str =~ m/[a-z]+/g) { say pos $str; } whileを後置にして、ループの回数を数えるようにすれば、最初の方法になる。
ループを使わない方法 これが一番謎だった。
//g をリストコンテキストで評価すると、マッチした文字列がリストになって帰ってくるらしい。 (Quote-Like Operators - perlop)
複数の変数に一括して代入するときに ($foo, $bar) = (1, 2) みたいな書き方をするけど、 () = ... の部分はこれの代入先の変数が一個もないケース。 要するに「リストコンテキストで評価してね」という意味のイディオムみたい。</description>
    </item>
    
    <item>
      <title>Redis::Fast 0.13をリリースしました</title>
      <link>https://shogo82148.github.io/blog/2014/10/16/2014-10-16-redis-fast-0-dot-13-released/</link>
      <pubDate>Thu, 16 Oct 2014 23:51:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2014/10/16/2014-10-16-redis-fast-0-dot-13-released/</guid>
      <description>Redis::Fast 0.13をリリースしました。 主な変更点は以下のとおりです。
 passwordオプションの対応 maxclientsに達した場合に、deep recursion することがある問題の修正 トランザクション内で再接続処理が行われる問題の修正  passwordオプションの対応 今更感のある機能ですね。昔は対応してたんです。 対応してたんですが、Sentinel対応のために接続開始周りをごそっと入れ替えて、そのときに間違ってパスワード認証機能を削除しちゃってたっぽいです(・ω&amp;lt;) なんというかごめんなさい。
実際実装してテストしてみると、認証失敗したときにdouble freeで落ちてちょっとハマりました。 hiredisを使う場合はredisAsyncSetConnectCallbackに指定する関数内で、コネクションを切断するような処理(password認証とか)はしないようにしましょう。
maxclientsに達した場合に、deep recursion することがある問題の修正 Redis::Fastでは、接続処理の中で、コネクションに名前をつけたり、パスワード認証したり、その他独自の処理を実行しています。 この処理の途中でも再接続処理が走ってしまい、 再接続処理の中で再接続処理が実行されて、その再接続処理の中で再接続が&amp;hellip; というような無限ループに突入する場合があります。 maxclientsに達した場合、一度コネクションの確立に成功したあとに接続が切られるので、この無限ループに入ってしまうようです。
接続処理中は再接続処理を行わないようにすることで対応しました。
トランザクション内で再接続処理が行われる問題の修正 Redis::Fast 0.07以降、MULTI-EXECコマンドを遣ったトランザクションの中にいるときは再接続処理が行わないようになっています。 その仕組みを作るにあたって、トランザクションの中にいるか外にいるかを表すフラグをコマンド送信前に更新していました。
 再接続を禁止する MULTI コマンドを送る 結果を受け取る 必要なコマンド発行を行う 再接続を許可する EXECコマンドを実行する 結果を受け取る  しかしこれだと 5 と 6 の間で再接続が起こってしまいます。 EXECコマンドがまだ実行されていないので、ここはまだトランザクションの中ですね。
Redis::Fast 0.13ではフラグの更新はコマンドが成功したときに変更してあります。
 MULTIコマンドを送る 結果を受け取る 再接続を禁止する 必要なコマンド発行を行う EXECコマンドを実行する 結果を受け取る 再接続を許可する  これでトランザクション中に再接続処理が走ることは無いはずです。</description>
    </item>
    
    <item>
      <title>Github::Hooks::ReceiverがX-Hub-Signatureをサポートしました</title>
      <link>https://shogo82148.github.io/blog/2014/09/23/2014-09-23-github-hooks-receiver-supports-x-hub-signature/</link>
      <pubDate>Tue, 23 Sep 2014 00:25:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2014/09/23/2014-09-23-github-hooks-receiver-supports-x-hub-signature/</guid>
      <description>Github::Hooks::ReceiverにX-Hub-SignatureをサポートするPull Requestを送ったら、 速攻取り込まれ、さらにGithubのコミット権とPAUSEのco-maintパーミッションをもらったというお話。
X-Hub-Signature GithubのWebhookは大変便利なんですが、特に対策をしないままだと 他の人にcurlとかで叩かれてしまう可能性があります。 本来であればIPアドレスで制限をかけるべきなんですが、 iptablesの設定とかよくわからないし・・・と思ってGithubのドキュメントを読んでいたら、 もっとお手軽な方法発見。
 Securing your webhooks  GithubからのリクエストにはX-Hub-Signatureというのがついていて、 これを使うとPayloadの検証ができるらしい。 Github::Hooks::Receiverは このヘッダを全くみていないようだったのでPull Requestを送ってみた。
Github::Hooks::Receiver 0.02以降で、以下のようにsecretの指定ができるようになります。
use Github::Hooks::Receiver::Declare; my $receiver = receiver { secret &amp;#39;secret1234&amp;#39;; # Webhookの設定画面のsecretの項目と同じものを入力 on push =&amp;gt; sub { # レポジトリにPushされた時の処理とかをゴニョゴニョ書く }; }; my $psgi = $receiver-&amp;gt;to_app; $receiver-&amp;gt;run; これでsecretを知らない人がリクエストを偽装できなくなるので安心です。 secretはエントロピーが高いほうがいいので ruby -rsecurerandom -e &#39;puts SecureRandom.hex(20)&#39; みたいなコマンド使うといいらしいですよ。
String::Compare::ConstantTime Signatureの比較にはRubyのsecure_compareのような関数を 使ったほうがいいらしい。 Github::Hooks::Receiverでは、そのPerl版のString::Compare::ConstantTimeを使ってみた。 ちょっと引数のチェックに甘いところがあって、segmentation fault場合があったので、こちらにもPull Requestを送っておきました。 Github::Hooks::Receiverは使う前にチェックを入れてあるので、現行バージョンでも問題なく動くはず。
String::Compare::ConstantTimeはXSで書かれたモジュールなんですが、 この手のバグが入り込みやすいのでXS難しいですね。
まとめ  XS怖い Github::Hooks::Receiverにsecretを指定できるようになったので、IP制限がかけられない場合でも安心 でも、可能であればIP制限もしましょうね XS怖い  追記 IP制限について Songmu先生よりコメントをいただきました。</description>
    </item>
    
    <item>
      <title>YAPC::Asia 2014 に行ってきた #yapcasia</title>
      <link>https://shogo82148.github.io/blog/2014/08/31/2014-08-31-yapcasia/</link>
      <pubDate>Sun, 31 Aug 2014 16:02:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2014/08/31/2014-08-31-yapcasia/</guid>
      <description>YAPC::Asia 2014 に参加してきました。 「ブログに書くまでがYAPC」らしいので、メモ書き。
見たトーク  Perl meets Real World 〜ハードウェアと恋に落ちるPerlの使い方〜  デモ中のURLが「localhost」になってたんであれ？って思ったんですが、WebサーバはPC上にあったんですね。RaspberryPi上でPerl動くんじゃなかったんですか！ ネギ振りミククラウド化するって言ってたんで期待してます  Go For Perl Mongers お待たせしました。Perl で BDD を簡単に実践する最高にクールなフレームワークができました DBIx::Class - what is it and what is it good for?  HashRefInflatorの存在を初めて知りました 今関わってるプロジェクトでDBICのRowObject生成コストが問題になってるんで、後で試してみたいです  Scala In Perl Company : Hatena WHERE狙いのキー、ORDER BY狙いのキー Get a kick out of CPAN 初心者が Web エンジニアのコミュニティに触れてみて感じたこと - ゆとりエンジニアの成長戦略
 突然ITインフラを任された人のための…監視設計入門
 半端なPHPDisでPHPerに陰で笑われないためのPerl Monger向け最新PHP事情(5.6対応)
 MacにはPHPが最初から入ってるらしいですよ  モバイルアプリとAPIのありかたを考える2014
 Mobile Application Development for Perl Mongers [ninjinkun x gfx]</description>
    </item>
    
    <item>
      <title>PerlのXS中に起きたシグナルの扱い</title>
      <link>https://shogo82148.github.io/blog/2014/07/05/2014-07-05-signal-in-xs/</link>
      <pubDate>Sat, 05 Jul 2014 11:56:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2014/07/05/2014-07-05-signal-in-xs/</guid>
      <description>Redis::Fast にIssueが来ていたので、 それに関して調査したお話です。
 接続タイムアウトすると double free check に引っかかる brpop みたいな長時間ブロックするコマンド中にシグナルが入ると、最初の1回が無視される  前者はC言語つらいって話で頑張って double free になる条件を探せばいいんですが、 後者はシグナル時のPerlやPOSIX APIの挙動を知らなくと解決できなそう。 そういうわけで、主に後者について調べた結果をまとめておきます。
PERL_ASYNC_CHECKってXS中から呼んでもいいの？ 言いたいことは最初に書いとけって偉い人に言われたので、最初にこの記事の結論を。 「よしななタイミングでPERL_ASYNC_CHECKを呼べばいいっぽい」みたいです。 でも、 ** 「PERL_ASYNC_CHECKってXS中から呼んでもいいの？」 ** という点に確証が持ててないので、 識者のご意見を募集してます！
selectの挙動を調べる Redis::FastはRedisからのレスポンスを待つのにLinuxのselect apiを叩いてます。 ファイルとかが読み書き可能になるまで処理をブロックしてくれるいいやつです。 しかし、select が処理をブロックしている間にシグナルを受信すると、うまく処理ができてないらしい。 そこで割り込み発生時の挙動を確認してみます。
困った時のmanページ(select) をちゃんと読めば書いてありますね。
 エラーならば -1 を返し、 errno にエラーを示す値が設定される;
EINTR シグナルを受信した。
 Redis::Fastはerrnoを特に確認せず、とにかくエラーが発生したらリトライになってたのでダメだったみたいです。 通信にエラーが起きたわけではないので、再接続処理とかみたいな複雑なリトライ処理は必要なく、 単にもう一度selectしなおせば良さそうです。
Perlさんのシグナル処理のタイミング 「割り込みかかったら再度select」っていうふうに修正してみたんですが、 今度はPerlのシグナルハンドラがなかなか呼び出されない！！
use Redis::Fast; $SIG{TERM}= sub { warn &amp;#34;TERM handler called&amp;#34;; }; my $c =-&amp;gt;new(reconnect=&amp;gt;2, every =&amp;gt; 100, server =&amp;gt; &amp;#34;localhost:6379&amp;#34;); $c-&amp;gt;brpop(&amp;#34;a&amp;#34;, 100); # 100秒経ったら諦めて戻ってくる このコードを実行中にSIGTERMを送ると、送った瞬間に&amp;rdquo;TERM handler called&amp;rdquo;と表示されて欲しいのですが、 brpopコマンドが終わるまで実行されない……</description>
    </item>
    
    <item>
      <title>IRCに癒やしボットを入れてみた</title>
      <link>https://shogo82148.github.io/blog/2014/06/04/2014-06-04-irc-healing-bot/</link>
      <pubDate>Wed, 04 Jun 2014 07:37:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2014/06/04/2014-06-04-irc-healing-bot/</guid>
      <description>別チームがIRCに癒やしボットを入れてたので、自分のチームのチャンネルにも入れてみた。
Instagramに登録する InstagramのDeveloperサイトに開発者として登録します。 Authentication のページを見ながら、Server-side (Explicit) Flow を参考にアクセストークンを取得します。
Instagram APIを叩く https://api.instagram.com/v1/tags/$TAGNAME/media/recent?access_token=YOUR_ACCESS_TOKENを叩くと TAGNAMEに関連する画像の情報がJSONで帰ってくるので、 Perlからこのエンドポイントを叩きます。 IRCとのやりとりにはUnazuSanを使いました。
!/usr/bin/env perl use 5.014; use warnings; use strict; use utf8; use Encode qw/encode_utf8/; use Furl; use JSON; use UnazuSan; sub neko { state $data = undef; state $time = 0; if( !$data || time - $time &amp;gt; 60 * 60) { $time = time; my $furl = Furl-&amp;gt;new; my $res = $furl-&amp;gt;get(&amp;#39;https://api.instagram.com/v1/tags/%E7%8C%AB/media/recent?access_token=YOUR_ACCESS_TOKEN&amp;#39;); my $hash = JSON::decode_json($res-&amp;gt;content); $data = $hash-&amp;gt;{data}; } my $media = $data-&amp;gt;[rand(scalar @$data)]; return $media-&amp;gt;{images}{standard_resolution}{url}; } my $unazu_san; my $NICKNAME = &amp;#39;iyashi&amp;#39;; $unazu_san = UnazuSan-&amp;gt;new( host =&amp;gt; &amp;#39;127.</description>
    </item>
    
    <item>
      <title>Redis::Fast 0.07 をリリースしました！</title>
      <link>https://shogo82148.github.io/blog/2014/05/17/2014-05-17-redis-fast-0-dot-07-released/</link>
      <pubDate>Sat, 17 May 2014 16:27:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2014/05/17/2014-05-17-redis-fast-0-dot-07-released/</guid>
      <description>Redis::Fast 0.07 をリリースしました。 現時点での最新バージョンである Redis.pm 1.974 とコンパチブルになります。
主な修正点は以下の通りです
 Redis Sentinel 対応 トランザクション内での再接続禁止 再接続にDB選択し直し  Redis Sentinel 対応 Redis Sentinel というのは自動フェールオーバーの仕組みらしいです。 (ソースはコピペしたきただけで仕組みはあまり理解していない) どんなものかは本家ドキュメントや実際に検証してみた人の記事をご参照ください。
 Redis Sentinel Documentation Redis 2.8 の Sentinel の動きを検証してみた Redis Sentinelを動かしてみた  前から移植作業は進めてたのですが、本家 Redis.pm でもテストがコケたりしてちょっと不安だったのでリリースを見送ってました。 今日 Redis.pm の安定版がリリースされたのでこっちも追従しますよ！！
コネクションを作るときに sentinels を渡すと Redis Sentinel から接続情報を取ってきてくれます。 一緒に reconnect を設定しておいてあげると、Masterに何かあった時に接続情報を再取得→ 自動的に Slave へフェールオーバーしてくれます。
use Redis::Fast; my $redis = Redis::Fast-&amp;gt;new( sentinels =&amp;gt; [ &amp;#39;127.0.0.1:26379&amp;#39; ], service =&amp;gt; &amp;#39;mymaster&amp;#39;, reconnect =&amp;gt; 1, ); トランザクション内での再接続禁止 Redisにも簡単なトランザクション機能があって、 複数の命令を同時に実行することができます。 トランザクション中に再接続が発生するとトランザクションがリセットされてしまうので、 接続前の命令を再投入する必要があるのですが、Redis.</description>
    </item>
    
    <item>
      <title>Redis::Fast 0.06 released</title>
      <link>https://shogo82148.github.io/blog/2014/02/01/2014-02-01-redis-fast-0-dot-06-released/</link>
      <pubDate>Sat, 01 Feb 2014 21:36:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2014/02/01/2014-02-01-redis-fast-0-dot-06-released/</guid>
      <description>こんにちは、もうすぐ17才と100ヶ月を迎えるいっちーです。 今朝、Redis::Fast 0.06をリリースしました。 主な変更点はメモリーリークの修正と、エラー発生時にSegmentation Faltで落ちる問題の修正です。
メモリーリーク Redis::Fastをサブスクライバーモードで動作させると、メモリを無限に食い続ける問題をついに！ついに！修正しました。 原因は、一言で言ってしまえば、Perlのリファレンスカウントの扱いの勉強不足です・・・。
XSの中でPerlのオブジェクトを作るとき、プログラマが手動でリファレンスカウントを制御する必要があります。 とはいうものの、全てのオブジェクトのリファレンスカウントを制御するのは大変なので、 XSには「揮発性」という考え方があります。 sv_2motralを使って変数を揮発性に設定しておけば、よしななタイミングでオブジェクトを解放してくれます。 gfx先生のブログにもあるように、 オブジェクト作成したら原則sv_2motralをつけるようにすれば、 メモリーリークはほとんどなくなるはずです。
SV * s = newSVpv(&amp;#34;Hello World&amp;#34;,0); // Perl の文字列オブジェクト sv_2motral(s) // 揮発性にすることで、使われなくなったら自動的に解放してくれる この「よしななタイミング」をよく理解していなかったのでリークしてました・・・。 XSからオブジェクトへアクセスできなくなったときでないとオブジェクトを解放できないので、 揮発性のオブジェクトが実際に解放されるのは「XSで書かれた関数が終了してPerlに戻るとき」です。 メッセージを待ち続けるwait_for_messages関数は (タイムアウトをしない限り)ずっと終了しないので、 揮発性のオブジェクトを解放するタイミングが一切なかったのです。
不要になったら解放されるよう、揮発性オブジェクトの有効範囲を明示的に指定しました。
sv_2motral(s); ENTER; SAVETMPS; sv_2motral(v); FREETMPS; LEAVE; // v はココで解放される // s は生き残ってる perlcallとかちゃんとドキュメントを読みましょう &amp;gt; 自分
Segmentation Falt 同期的にコマンドを実行してる最中にSIGNAL等で実行が中断されると、 Segmentation Faltが起こる問題を修正しました。 Redis::Fastは同期モードでコマンドを発行したときでも、 hiredisの非同期モードの機能を使って通信しています。 コマンド実行中にエラーが発生すると、 コールバック関数の呼び出しタイミングが変わってしまい、 メモリの確保・解放のタイミングが狂ってしまっていました。
このバグ、試した環境の中ではUbuntu+Perl5.14でしか再現しませんでした。 他の環境ではたまたま解放後もアクセスできてしまって、 正常に動作してしまっていたようです。 嫌なバグだ・・・。
まとめ C言語でメモリ管理するコードは書くべきでない。</description>
    </item>
    
    <item>
      <title>Ark-View-DataTable グラフや表やCSVを簡単に表示したい</title>
      <link>https://shogo82148.github.io/blog/2013/12/07/2013-12-07-ark-view-datatable/</link>
      <pubDate>Sat, 07 Dec 2013 20:11:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2013/12/07/2013-12-07-ark-view-datatable/</guid>
      <description>こんにちは、最近ログの解析をして遊んでいるいっちーです。 解析の結果は最終的にグラフに出すわけなのですが、 先輩方がよく使っているのもあって Google Charts を使ってます。
で、このグラフを他の人に見せると「その元データCSVでちょうだい！」と言われるんです&amp;hellip;。
もちろんcsvを作るなんてこと簡単にできるんですが、 今のプログラムにはグラフ用のテンプレートとHTMLで表出力するためのテンプレートとCSV用のテンプレートがあって、 グラフが追加されるたびにコピペして微妙に書き直し、 という不毛な作業が発生してしまうのです。つらい。
Ark::View::DataTable 使い回しの効かないテンプレートとかなんのためのテンプレートなのか。 データだけ用意してあとはそれぞれのテンプレートに入れるだけとなるのが理想的だよねー、と思い続けて早数ヶ月。 ようやく重い腰を上げて Ark::View::DataTableってのを書きました。
使い方 Data::Google::Visualization::DataTable をレンダリングするための ArkのViewです。
use Ark::View::DataTable; use Data::Google::Visualization::DataTable; sub gvis :Local { my ($self, $c) = @_; my $datatable = Data::Google::Visualization::DataTable-&amp;gt;new(); $datatable-&amp;gt;add_columns( { id =&amp;gt; &amp;#39;x&amp;#39;, label =&amp;gt; &amp;#34;X&amp;#34;, type =&amp;gt; &amp;#39;number&amp;#39; }, { id =&amp;gt; &amp;#39;y&amp;#39;, label =&amp;gt; &amp;#34;Y&amp;#34;, type =&amp;gt; &amp;#39;number&amp;#39; }, ); # 〜〜〜〜正弦波を描きましょう〜〜〜〜 $datatable-&amp;gt;add_rows( map { [$_, sin(2*3.1415926535*$_/500)] } 1.</description>
    </item>
    
    <item>
      <title>ISUCON3の本戦に参加してきた</title>
      <link>https://shogo82148.github.io/blog/2013/11/09/2013-11-09-isucon3/</link>
      <pubDate>Sat, 09 Nov 2013 23:58:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2013/11/09/2013-11-09-isucon3/</guid>
      <description>ISUCON3の予選を何とか通過し、 本戦へと参戦してきました。
大会中の方針とか考えたこととかメモ。
お題  Tw○tter&amp;ndash;likeな画像投稿サービス  ユーザをフォローできる フォローしたユーザが画像を投稿すると、タイムラインに画像が流れる 公開範囲を全員に公開・フォロワーのみに公開・自分だけに公開から選べる  タイムラインはロングポーリングを使ってリアルタイム反映  JSON-APIが用意されていて、Javascriptから叩く  使用できるサーバは5台  画像を扱うお題と聞いて、会場がざわめきました。
MySQLのクエリを見てみる 開始直後、鍵を用意したり、gitのレポジトリを立てたりなんだりした後、 一回目の計測。
topコマンドで走っているプロセスを見ていると、大量のconvertが！！ プロセス名とお題から考えるに、こいつら確実にImage Magickだ・・・。 CPUのほとんどが画像の変換にくわれていたので、 まずは「どこかでキャッシュする」作戦をとることに。 キャッシュするならフロントに近いほうがいいだろうということで、 フロントのnginxでキャッシュする作戦をとることにしました (アクセス制限があるimageは難しいかもしれないけど、全部publicなiconならすぐできるだろうとこのときは思ってました)。
僕はnginxがconvertを駆逐してくれると信じて、MySQLに投げているクエリを中心にPerlのコードを見てました。 役割分担はこんな感じ。
 サーバの設定とか(@mackee_wさん) nginxでキャッシュする設定(@9reさん) コード読む、主にMySQLに投げてるクエリとか(@shogo82148)  毎回、ひどいクエリが仕込まれているようなイメージがあったけど、 今回はそこまでひどくない。 クエリチューニング全然効果なさそうと判断して、次の作戦を考えることにしました。
No Image Magick, use Imager! やっぱり一番のボトルネックは画像変換。 nginxでキャッシュするとはいえ軽いほうがいいよね、ということで、 外部プロセスで実行している画像変換をImagerを使ってPerlと同じプロセスでやる作戦。
Imagerに置き換え後ベンチにかけたら、若干スコアが・・・上がった・・・ような・・・？ しかし、画像が変化していると怒られて、スコアは無効。 画像エラーを修正するコストと、スコアの上がり具合を見て、Image Magickのままにすることにしました。
予選でも同じように外部プロセス起動している部分をPerlのライブラリにしたけど、 その時はあっさり動いた。 あれは外部プロセス起動をやめたらスコア上がると思い込ませるための布石だったんだ・・・。 (今回の場合、プロセスの起動より画像の変換のほうが重いので、スコアが上がらないのは当たり前)
いろいろ諦めてPerl側でファイルキャッシュ Imagerはテストを通らず、nginxの設定キャッシュ設定も上手く動作しなかったので、 Perlでファイルキャッシュする方針に変更。 convertの結果にmvで適当な場所にコピーして保存。 これだけでスコアが5倍くらいに跳ね上がり、一気に上位に浮上！ 最初からやっておくべきだった・・・。 もうちょっと早ければ特別賞もらえたかもしれないのに。
rsync! rsync! ファイルキャッシュの作業をやっている間に、@mackee_wさんがnfsの設定をやってくれたので、 アップロードされたファイルやキャッシュファイルの保存先をnfsに変更。
あとは物量作戦でいくしかないだろうということで、rsyncで他のサーバにコピーして調整を繰り返してた。 (並行してnginxのキャッシュ設定にも再チャレンジしてたけど、nginx力が足りなかった)
最終結果 テストFAILした!</description>
    </item>
    
    <item>
      <title>Redis::NamespaceとRedis::Keyをリリースしました</title>
      <link>https://shogo82148.github.io/blog/2013/10/18/2013-10-18-redis-namespace-and-redis-key/</link>
      <pubDate>Fri, 18 Oct 2013 23:21:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2013/10/18/2013-10-18-redis-namespace-and-redis-key/</guid>
      <description>こんばんは、最近シングルトン恐怖症になっているいっちーです。 Redis::Namespaceと Redis::Keyをリリースしました。
Redis::Namespace 「Redis::NamespaceのPerl版書いた」 で紹介したモジュールをCPANizeしました。 コマンドのキー名に当たる部分に、自動にプレフィックスをつけてくれる賢い奴です。
use Redis; use Redis::Namespace; my $redis = Redis-&amp;gt;new; my $ns = Redis::Namespace-&amp;gt;new(redis =&amp;gt; $redis, namespace =&amp;gt; &amp;#39;fugu&amp;#39;); $ns-&amp;gt;set(&amp;#39;foo&amp;#39;, &amp;#39;bar&amp;#39;); # $redis-&amp;gt;set(&amp;#39;fugu:foo&amp;#39;, &amp;#39;bar&amp;#39;); my $foo = $ns-&amp;gt;get(&amp;#39;foo&amp;#39;); # my $foo = $redis-&amp;gt;get(&amp;#39;fugu:foo&amp;#39;); RedisにはKey-Value Storeなんてかっこいい名前が付いているけど、 結局はシステム全体で使えるグローバル変数なわけです。 グローバル変数は駆逐するべきです。 いちいちプレフィックスつけて名前の衝突を回避するなんて人間のやることとは思えません。
せめてモジュールローカルとか、クラスローカルとかある程度スコープを制限したいですよね。 Redis::Namespaceを使えば簡単に実現できます。
Redis::Key Redis::Key は Redisのキーの簡単なラッパークラスです。 毎回毎回「接続先のRedisサーバ」と「キーの名前」を指定するのは面倒です。 この2つをセットにして、一つのオブジェクトとして扱うことができます。
use Redis; use Redis::Key; my $redis = Redis-&amp;gt;new; my $key = Redis::Key-&amp;gt;new(redis =&amp;gt; $redis, key =&amp;gt; &amp;#39;hoge&amp;#39;); $key-&amp;gt;set(&amp;#39;fugu&amp;#39;); # $redis-&amp;gt;set(&amp;#39;hoge&amp;#39;, &amp;#39;fuga&amp;#39;); $key-&amp;gt;get; # $redis-&amp;gt;get(&amp;#39;hoge&amp;#39;); 普通に使っている限りは他のキーにアクセスすることができなくなるので、 Redis::Keyのオブジェクトを他のクラスに渡す、とかしても安心です。</description>
    </item>
    
    <item>
      <title>Redis::Fastをcpanize＆アップデートしました</title>
      <link>https://shogo82148.github.io/blog/2013/10/13/2013-10-13-cpanize-redis-fast/</link>
      <pubDate>Sun, 13 Oct 2013 22:39:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2013/10/13/2013-10-13-cpanize-redis-fast/</guid>
      <description>Redis::Fastをcpanizeしました！
さらに！早速不具合が見つかったので0.01から0.02にアップデートしました！
CPANに上げてから24時間も経たないうちにpull requestがやってきてCPAN怖いところです。
最初のバージョンである0.01ではタイムアウト処理をちゃんと書いていなかったので、 タイムアウト時に無限ループに陥る不具合がありました。 LinuxとMacとでコネクションを張るのに失敗したときの挙動が違うらしく、 Linuxでは問題なくテストが通るのに、Mac上でのテストでは再現するという面倒バグでした。 さらに面倒なことにRedisの起動のタイミングによって、 Macでもテストが通ったり通らなかったりするという・・・。
主に開発はLinux上でやって、Linux上でしかテスト動かしてなかったので全く気がついていませんでした。 CPANデビューのモジュールがネットワーク関連でXSで少しハードルを上げ過ぎた感じがします。 環境依存な部分が多くてつらいです。
pull requestを送ってくださったsyohexさん、実際にインストールを試みてテストが通らないことを教えてくださったみなさん、ありがとうございました。 アップデートした0.02では、タイムアウト時の処理を少し書きなおして、pull requestも取り込みました。 Mac上でも問題なくテストが通ってインストールできるはずです(きっとね)。</description>
    </item>
    
    <item>
      <title>ISUCON3の予選に参加してきた</title>
      <link>https://shogo82148.github.io/blog/2013/10/07/2013-10-07-isucon3-qualify/</link>
      <pubDate>Mon, 07 Oct 2013 13:03:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2013/10/07/2013-10-07-isucon3-qualify/</guid>
      <description>こんにちは、いつの間にかチームぽわわ2のメンバーになっていたいっちーです。
@9reさんと @mackee_wさんとでISUCON3の予選に参加してきました。 主にアプリの書き換えを担当していたので、やったことを残しておきます。 チーム全体の方針とか役割分担とかはまこぴー先生の#isucon 予選でとりあえず10位だったを参照。
お題 gistみたいなWebアプリ。 社内ISUCONのときと似たようなお題ですね。 違いは&amp;hellip;
 スターは無い Recent Postsのサイドバーが無い代わりに、ページングしてたどっていけるページがある privateな投稿ができる Markdown形式で投稿できて、表示はHTMLでレンダリングされる  詳しくは、れもんさんの#isucon 2013年予選問題の解説などを参照。
やったこと 一言で言えば、Redisにキャッシュするようにしました。
RecentをRedisのリストで管理 Recentの表示で日付順ソートしているのが重たそうだったので、 公開メモのソート結果をあらかじめRedisのリストに入れておく作戦。
RedisのSORTコマンドが高機能で面白いなーって思ってたので使ってみました。 リストにはメモのIDだけ入れておいて、メモの実体は別のキーを参照する、なんてことができます。 このコマンド、SORTって名前なのに「ソートしない」ってオプションあるところがいいですよね！
MySQLがボトルネックになっているのはこれで解消できました。
bin/markdownを使わない＆レンダリング結果をキャッシュ Markdownのレンダリングを外部コマンド叩いてやっていたので、 Text::Markdown::Discountを使ってレンダリングするように変更。 qx{hoge}って記法はじめて見ました。Perlってやつはいろんな書き方があってよくわからないです。
Markdownの文法って亜種が結構あるので、レンダラをかえるのはちょっと怖かったんですが、全く問題なし。 スコアも3000くらい上がってかなり効果がありました。
さらにレンダリング結果をRedisに入れてキャッシュで+1000くらい。
Recentのレンダリング結果をキャッシュ RecentをRedisでさばくようにしたけど、そもそも100要素もあるHTMLのレンダリングそうとう重いはず。 と、いうわけでここもRedisにキャッシュするようにしました。 公開メモが投稿されたらRecent/:pageのキャッシュを全部削除。 Postのたびにキャッシュクリアされるのであんまり効果ないかなーと思っていたけど、わりと効果あったみたい？ (正確なスコアよく見てなかった)
Redis::Fast!! 残り時間も少なくなり時間内にできることも限られれきたので、最後の最後でRedis::Fastを投入。 これで+1000くらい上がったらしい。(正確なスコアよく見てなかった)
s/Redis/Redis::Fast/ するだけの簡単なお仕事の予定が、githubからのインストールに一番手間取った。 cpanfileにgitのレポジトリを書くと(非公式だけど)インストールできるよ！ってどこかで見た気がするけどなかなかうまく行かず、 自分でgit cloneしてそのディレクトリを指定してインストール(したってまこぴー先生が言ってた)。 (hiredis.hが無い！って叫んでいたから、cartonがsubmoduleをうまく処理できていなかったと予想。 非公式の機能に頼るの良くないね。)
できなかったこと  my.cnf？なにそれ美味しいの？ SQLクエリをいじる余裕がなかった  Newer/Olderのクエリが残念なのはわかってたけど、結局いじってない  Nginxでキャッシュしたい 必要なモジュールは事前にCPANにあげておこう。  まとめ 結果は13192.1点で10位でした。 特に問題がなければこのまま予選突破できるはず・・・！
ところで、魔王軍が学生枠を制圧していて恐ろしいですね。 てか、僕らのチームとの差、500点程度しか無いじゃないですか。怖！！！ これ以上の侵攻はなんとしてでも食い止めなければ。</description>
    </item>
    
    <item>
      <title>Redis::Fastってモジュールを書いた</title>
      <link>https://shogo82148.github.io/blog/2013/09/28/2013-09-28-redis-fast/</link>
      <pubDate>Sat, 28 Sep 2013 00:18:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2013/09/28/2013-09-28-redis-fast/</guid>
      <description>hiredisをPerlから扱うためのライブラリとして Redis::hiredisってのがあるけど、 なんだか微妙だって聞いたので自分でPerlのhiredisバインディング書いてみたよ。
 https://github.com/shogo82148/Redis-Fast  (READMEからRedis.pmをそのまま持ってきたことがまるわかりですね。なんとかしよう。)
使い方 Redis.pmと全く同じインターフェースなので、 そのまま置換できる、はず。
use Redis::Fast; my $redis = Redis::Fast-&amp;gt;new; ### synchronize mode $redis-&amp;gt;set(&amp;#39;hoge&amp;#39;, &amp;#39;piyo&amp;#39;); print $redis-&amp;gt;get(&amp;#39;hoge&amp;#39;); # piyo ### asynchronize mode $redis-&amp;gt;get(&amp;#39;hoge&amp;#39;, sub { my ($result, $error) = @_; print $result; # piyo }); $redis-&amp;gt;wait_all_responses; ### pubsub $redis-&amp;gt;publish(&amp;#39;fugu&amp;#39;, &amp;#39;fuga&amp;#39;); $redis-&amp;gt;subscribe(&amp;#39;fugu&amp;#39;, sub { my ($message, $topic, $subscribed_topic) = @_; }); my $timeout = 10; $redis-&amp;gt;wait_for_messages($timeout) while 1; 以前作った、Redis::Namespaceにもそのまま使えます。
use Redis::Fast; use Redis::Namespace; my $redis = Redis::Fast-&amp;gt;new; my $ns = Redis::Namespace(redis =&amp;gt; $redis, namespace =&amp;gt; &amp;#39;fugu&amp;#39;); $ns-&amp;gt;set(&amp;#39;foo&amp;#39;, &amp;#39;bar&amp;#39;); # $redis-&amp;gt;set(&amp;#39;fugu:foo&amp;#39;, &amp;#39;bar&amp;#39;); my $foo = $ns-&amp;gt;get(&amp;#39;foo&amp;#39;); # my $foo = $redis-&amp;gt;get(&amp;#39;fugu:foo&amp;#39;); ベンチマーク Redis.</description>
    </item>
    
    <item>
      <title>YAPCへ行ってきた(二日目)</title>
      <link>https://shogo82148.github.io/blog/2013/09/24/2013-09-24-yapc-second-day/</link>
      <pubDate>Tue, 24 Sep 2013 07:52:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2013/09/24/2013-09-24-yapc-second-day/</guid>
      <description>前回のポストにつづいてYAPC二日目。 聞いたトークの内容を簡単にメモ。
Perl で書く結合テスト 前半はSWET(Software Engineer in Test), TE(Test Engineer)といった業種の話。 後半はテスト手法の分類(誰がする？テストの対象は？方法は？目的は？)について。
スライドはこちら→[Perlで書く結合テスト(]http://ikasama.hateblo.jp/entry/2013/09/22/234521)
これからのPerlプロダクトのかたち 世界一高速な処理系を目指して開発中のgperlと、 その過程でできたツールの紹介。 PerlをLLVMにコンパイルすることがで、高速動作するらしい。 恐ろしい・・・。
Perlは文脈によってトークンの意味が変わってしまうから、トークナイザーを作るのに苦労したとのこと。 (例えば、hoge * fuga とあったときに、*が掛け算なのかブロブなのかわからない) コンパイルの高速化のために文法を工夫しているKuinを見習って欲しいですね。
Emacs実践入門 Perl編 typester先生によるEmacs入門。 PerlCompletion とか helm とか便利そう。 あんまりEmacsカスタマイズできていないので、今度いろいろ入れて遊んでみよう。
Perlでレコメンデーション 登壇者はJubatusのPerlモジュールを書いたりしているらしい。 Jubatus に触ってみようと考え始めてからどれだけの月日が経っただろう・・・ そのうち触ってみます。そのうち。
中規模チャットサービスの運用事例 handlename先生のLobi運用のお話。 今日もcronのメールが迷惑メールフィルタによって闇に葬りさられる悲しいことがあったので、 cronの結果をIRCに飛ばすのとか参考にして何とかしたい。
PhantomJSによる多岐にわたる広告枠の確実な表示テスト 最近の広告はJavascriptを使った遅延読み込みをするので、 ちゃんと表示されるかを静的に判断することができない。 そこで PhantomJS を使ってテストするお話。
フルテストも50msで終わらせたい 〜 FreakOutの取り組み 〜 さすがにフルテストは50msで終わりません。 Ukigumoを使って複数台のサーバでテストを分散実行する取り組みを紹介。
スライド→http://yapcasia.org/2013/talk/show/767463b0-d8fd-11e2-971a-72936aeab6a4
LT 前日にアイデアだけLTで紹介したHTTP::Body::Builderが、別の人の手によって実現されていたのには驚いた。 YAPC恐ろしいところだ・・・。
HUB 懇親会参加しない組だったので、 @sasaplus1 さん, @kazuph さん, @aokcub とHUBで飲み会。 なぜ学内にHUBがあるんだ・・・？
NDS勢やNiigata.pm勢、あと何故かスタッフになっていた @jewel_x12 とも会えて楽しかったです！</description>
    </item>
    
    <item>
      <title>YAPCへ行ってきた(一日目)</title>
      <link>https://shogo82148.github.io/blog/2013/09/20/2013-09-20-yapc-first-day/</link>
      <pubDate>Fri, 20 Sep 2013 21:48:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2013/09/20/2013-09-20-yapc-first-day/</guid>
      <description>YAPCの一日目に行ってきたよ。
いまどきのカジュアルなデータベース関連開発 Songmu先生のセッション。
DBIx::Schema::DSL とか GitDDL::Migrator とかの説明や、 DBのスキーマ設計、Redisの紹介なんかがありました。 自分もMySQLやRedisを触る機会が増えて、DB周りでつらい思いをしたことが何度かあるので (外部キー制約でデッドロック起こしたり、無駄なインデックスを必死に削除したり・・・) 大いに参考に参考にさせていただきます。
スライドはこちらから→いまどきのカジュアルなデータベース関連開発
学術分野におけるPerlの活用例 Perlを使ったアンケートの結果と、PerCUDAの紹介。 GPGPUをPerlのコードで実現しようとのお話。
大規模Perl初心者研修を支える技術 :DeNAさんが行った研修の紹介です。 顔覚えられない、 研修生の状況把握が大変、 信頼関係を作るのが大変 といった問題をどうやって解決したかについてのお話がありました。
トークの中で紹介された本何冊か持っているけど、全然読んでない・・・。 というか研修生みんなこれ読んだんですか。
スライドはこちらから→大規模Perl初心者研修を支える技術
mod_perlの展望とApacheの超絶技巧 最近僕の周辺ではあまり Apache の話題を聞かなくなってしまいましたね。 しかし、その知名度の高さからか、他のオープンソースのプロダクトはダメでも、 Apache はOKという案件があるらしい。 「Apache使いました！」っていうために、mod_perl で代替品を作ろう、というお話。 おそろしい・・・。
スライドはこちらから→mod_perlの展望とApacheの超絶技巧
0から学んだポストモダンPerl ルーティングとかORMはWAFにはいらない。 blessで十分！これぞ、ポスト・モダンPerl！とのことでした。
僕もフルスタックのフレームワークより、 各機能が別になっているほうが好きですね。 (でもblessよりはクラスを扱うためのライブラリ使ったほうがよいと思う) まあ、あんまり大規模なWebアプリ作ったこと無いので、 実際に作ってみると意見が変わるかもしれませんが。
スライドはこちらから→0から学んだポストモダンPerl
Dist::Zilla 英語のトークに紛れ込んでしまい、正直良くわからなかった。 英語能力全く向上していない。
モジュールを作成、テスト、アップロード等の管理をするためのプログラムらしい。 Redis::Namespace でつらい思いをしたので、 次モジュールを作りたくなったら試してみよう。
perl な web application のためのテスト情報 スライドの順番が正しいか、今使っているのは本当にマイクなのかのテストが必要ですね！ 335さん自らテストの必要性を教えてくれました。 「なぜテストが必要か」言葉では語らず行動で示す335さんかっこいい。
Test::Deep は Redis::Namespace のテストでも一部使っていますが、これ便利ですね。 Test::More の is_deeply はちょっと不便だと思っていたので、今後も使っていこうと思います。</description>
    </item>
    
    <item>
      <title>Redis::NamespaceのPerl版書いた</title>
      <link>https://shogo82148.github.io/blog/2013/09/14/2013-09-14-redis-namespace-perl/</link>
      <pubDate>Sat, 14 Sep 2013 18:36:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2013/09/14/2013-09-14-redis-namespace-perl/</guid>
      <description>Redis のキーにプリフィックスつけるの面倒だなー自動的につけてくれないかなーと思い、 調べてみると Ruby に Redis-Namespace というものがあるらしい。 だけども、Perl では探しても見つからなかったので書いてみた。
レポジトリはこちら→Redis::Namespace
使い方 インターフェースは Perl Redis と一緒。 コマンドのキー名に当たる部分に、自動的にプレフィックスをつけてくれる。
use Redis; use Redis::Namespace; my $redis = Redis-&amp;gt;new; my $ns = Redis::Namespace(redis =&amp;gt; $redis, namespace =&amp;gt; &amp;#39;fugu&amp;#39;); $ns-&amp;gt;set(&amp;#39;foo&amp;#39;, &amp;#39;bar&amp;#39;); # $redis-&amp;gt;set(&amp;#39;fugu:foo&amp;#39;, &amp;#39;bar&amp;#39;); my $foo = $ns-&amp;gt;get(&amp;#39;foo&amp;#39;); # my $foo = $redis-&amp;gt;get(&amp;#39;fugu:foo&amp;#39;); 大体のコマンドには対応したつもり。 別のプレフィックスがついたキーには基本的にアクセスできなくなるので、 キー名の管理が少し楽になると思います。
でも、flushdb とか flushall すると全部消えるので気をつけてね！</description>
    </item>
    
    <item>
      <title>Perl の Redis ライブラリを調べた</title>
      <link>https://shogo82148.github.io/blog/2013/08/24/2013-08-24-perl-redis-libraries/</link>
      <pubDate>Sat, 24 Aug 2013 17:51:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2013/08/24/2013-08-24-perl-redis-libraries/</guid>
      <description>最近Redis を使ったコードを書くようになったのですが、 キー名を毎回指定するのがだるいです。 Ruby には redis-objects というのがあって、 Redisのキーをオブジェクトとして扱うことができるようです。 きっと、Perl にも似たようなのあるだろ、って思って調べてみました。
ほしいもの 低レベルなRedisのライブラリはたいていメソッドとRedisのコマンドが一対一対応していて、 次のようなコードになると思います。
``` perl hogehoge.pl $redis-&amp;gt;set(&amp;lsquo;key-name&amp;rsquo;, &amp;lsquo;piyopiyo&amp;rsquo;); $redis-&amp;gt;get(&amp;lsquo;key_name&amp;rsquo;);
 でも、Redisに何か操作をしたいわけじゃなくて、 Redisのキーに対して操作をしたいので、 次のように書けるべきだと思うんです。 ``` perl expected.pl my $key = key($redis, &#39;key-name&#39;); $key-&amp;gt;set(&#39;piyopiyo&#39;); $key-&amp;gt;get();  Redis::Hash, Redis::List Redis::Hashと Redis::Listは Perlのハッシュや配列と同じ操作で Redis にアクセスできるようにするライブラリ。
``` perl Redis::Hash use utf8; use warnings; use strict; use 5.014;
use Redis::Hash;
tie my %my_hash, &amp;lsquo;Redis::Hash&amp;rsquo;, &amp;lsquo;hash_prefix&amp;rsquo;, (server =&amp;gt; &amp;lsquo;localhost:6379&amp;rsquo;);
set hash_prefix:hogehoge piyopiyo set hash_prefix:fugafuga fugufugu $my_hash{hogehoge} = &amp;lsquo;piyopiyo&amp;rsquo;; $my_hash{fugafuga} = &amp;lsquo;fugufugu&amp;rsquo;;</description>
    </item>
    
    <item>
      <title>ランダム抽出アルゴリズムについて考える</title>
      <link>https://shogo82148.github.io/blog/2013/07/13/2013-07-13-random-sample/</link>
      <pubDate>Sat, 13 Jul 2013 22:13:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2013/07/13/2013-07-13-random-sample/</guid>
      <description>数日前に社内IRCで「スマートな非復元抽出の方法はないか」と話題になったので、 ランダムサンプリングのアルゴリズムについて調べたり考えたりしてみた。
復元抽出 非復元抽出の手法って調べてもなかなか出てこない・・・。 ひとまず、復元抽出についてまとめてみましょう。
線形検索 一番簡単な実装方法。 どの区間に入るかを線形検索して求める。 選択肢の個数nとすると計算量はO(n)。
``` perl linear_search_method.pl use strict; use warnings; use List::Util qw(sum);
sub linear_search_method { my $weights = shift; my $num = shift; my $sum = sum @$weights; my $length = @$weights; my @a;
for (1..$num) { my $r = rand($sum); for my $i(0..$length-1) { $r -= $weights-&amp;gt;[$i]; if($r &amp;lt; 0) { push @a, $i; last; } } } return \@a;  }</description>
    </item>
    
    <item>
      <title>Google Cloud Messaging for Chrome を試してみた</title>
      <link>https://shogo82148.github.io/blog/2013/05/15/2013-05-15-google-cloud-messaging-for-chrome/</link>
      <pubDate>Wed, 15 May 2013 11:26:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2013/05/15/2013-05-15-google-cloud-messaging-for-chrome/</guid>
      <description>少し前にGoogle Cloud Messaging for Chrome が発表されました。 Android向けに提供されていた Push 通信の仕組みである GCM の Chrome 版です。 ちょうど GCM for Android に触っていたところだったので、 for Chrome のほうも試してみることにしました。
拡張機能の登録 公式ページの説明にしたがって、 APIを使えるようにします。 GCMはOAuth2.0で認証を行うので、
 クライアントIDを作る Refresh Token を作る  という2ステップが必要。
クライアントIDを作る まず、新しい OAuth2.0 のアプリを作成。 拡張機能をアップロードする予定のGoogleアカウントで以下の作業して Client IDを作ります。
 Google APIs Console にログインする ** Create&amp;hellip; ** メニューから新しいプロジェクトを作成 &amp;ldquo;Services&amp;rdquo; を開いて ** Google Cloud Messaging for Chrome API ** を有効化 &amp;ldquo;API Access&amp;rdquo; を開いて ** Create an OAuth 2.0 cliend ID&amp;hellip; ** というボタンをクリック branding information を適当に入力 &amp;ldquo;Application Type&amp;rdquo; という項目の &amp;ldquo;Web application&amp;rdquo; を選択 &amp;ldquo;Create client ID&amp;rdquo;！！  Client ID と Client Secret が表示されるのでメモしておきましょう。</description>
    </item>
    
  </channel>
</rss>