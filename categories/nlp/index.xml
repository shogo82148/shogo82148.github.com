<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Nlp on Shogo&#39;s Blog</title>
    <link>https://shogo82148.github.io/categories/nlp/</link>
    <description>Recent content in Nlp on Shogo&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <lastBuildDate>Sun, 16 Dec 2012 13:11:00 +0900</lastBuildDate>
    
	<atom:link href="https://shogo82148.github.io/categories/nlp/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>TinySegmenterをLaTeXに移植してみた</title>
      <link>https://shogo82148.github.io/blog/2012/12/16/2012-12-16-tinysegmenter-for-tex/</link>
      <pubDate>Sun, 16 Dec 2012 13:11:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/12/16/2012-12-16-tinysegmenter-for-tex/</guid>
      <description>この記事はTeX &amp;amp; LaTeX Advent Calendarの傘下記事です． 15日はk16.shikanoさんの「TeX がむかついたので実装したけど挫折してる話」, 17日は@egtraさんの「LCDF TypetoolsでOpenTypeフォントを使う(DVIPDFMXで)」です．
neruko3114が参加しているのを見てなんだか楽しそうだったで参加してみました． とはいってもネタも思いつかなったので，過去に作ったものをTeXに移植してみました． ターゲットはTinySegmenter． 以前作ったTinySegmenterMakerでLaTeXを出力できるようになったよ！
使ってみる TinySegmenterMakerのレポジトリをダウンロードするなりgit cloneするなりして 落としてきます． レポジトリに入っているのはモデルファイルとスクリプトだけです． これらを使ってTeXのスタイルファイルを作ります．
$ cd /path/to/TinySegmenterMaker/ $ ./maker tex &amp;lt; RWCP.model カレントディレクトリにtinysegmenter.styができます． TeX から見えるところにおいておきましょう． これを使うソースコードは次のようになります．
\documentclass{jarticle} \usepackage{tinysegmenter} \begin{document} \TinySegmenter{-}{私の名前は中野です} \end{document} platexで処理するとこんな感じに表示されるはず．
私-の-名前-は-中野-です 仕組み TinySegmeneterは元の文章の一部を切り取ってハッシュに入れる動作をしている． でも，LaTeXにはハッシュみたいなデータ構造がないのでコントロールシーケンスで代用． \@ifundefinedで有無を確認し，\csname\endcsnameで置き換え． コントロールシーケンスの一部に日本語を使わないといけないので，日本語LaTeX環境でしか動かない． ただ，一部句点などの扱いが違う？よくわからない．
あとは，文字種の取得が必要なんだけど，ここでも同じことをしてます． すべてのアルファベット・ひらがな・カタカナ・数字について，その文字種をベタ書き． それ以外は全部漢字扱い． そのため，それ以外の文字を使うとオリジナルとは違う結果になるかも．
最後は足し算．これはカウンタを使えば簡単ですね．
応用編 TinySegmenterMakerでは自由にモデルを差し替えることができます． 以前JavaScript版のTinySegmenterを使って， 聞こえますか…自動生成…してみた…よ… ということをしてみました． LaTeXだってできるはず．
聞こえますか… に心に呼びかけるためのモデルファイルが含まれています． これをダウンロードして読み込ませます．
$ ./maker tex &amp;lt; model これを自分のドキュメントに読み込ませてみます．
\documentclass{jarticle} \usepackage{tinysegmenter} \begin{document} (…\TinySegmenter{…}{聞こえますか聞こえますかあなたの心に直接語りかけています}…) \end{document} 私の声が聞こえましたか・・・？</description>
    </item>
    
    <item>
      <title>MeCabをPythonから使う注意点とか</title>
      <link>https://shogo82148.github.io/blog/2012/12/15/2012-12-15-mecab-python/</link>
      <pubDate>Sat, 15 Dec 2012 17:38:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/12/15/2012-12-15-mecab-python/</guid>
      <description>日本語の文章をコンピュータで色々いじるときに， 必ずと言っていいほどよく使うのが形態素解析器． スペースなどの明示的な区切りの無い日本語を単語に分割してくれるツールです． 中でもMeCabが非常に有名で，さまざまなところで使われています．
MeCabはいろいろな言語から呼び出すことができます． 自然言語処理の分野ではPythonが人気のようですね．僕も使っています． しかし，MeCabをPythonから使う場合，注意する点がいくつかあります． そこにハマっている後輩を見かけたので，文章として残しておくことにします． Python2系が対象です(3系はよくわからない)． 注意するのは以下の二点です．
 MeCabに渡す文字列はencode，戻ってきた文字列はdecodeする MeCabに渡した文字列は必ず変数に入れておく  EncodeとDecode Python2系の文字列には，バイト列として扱われる文字列(str)と，Unicodeで表現された文字列(unicode)があります． 日本語を扱う場合，strだといろいろ問題があるので，特に理由がなければunicodeを使うべきです． しかし，MeCabはstrしか受け付けません． そこでMeCabに渡す直前・直後でencode・decodeするようにします．
import MeCab tagger = MeCab.tagger(&amp;#39;-Owakati&amp;#39;) text = u&amp;#39;MeCabで遊んでみよう！&amp;#39; result = tagger.parse(text) # エラー！ encoded_text = text.encode(&amp;#39;utf-8&amp;#39;) # encodeが必要 encoded_result = tagger.parse(text) result = result.decode(&amp;#39;utf-8&amp;#39;) # 必ずdecode &#39;utf-8&#39;の部分は辞書の文字コードに合わせて適宜書き換えてください． デフォルトはeuc-jpですが，utf-8の方が幸せになれると思います．
必ず変数に入れる 次にMeCabの作ったノードに直接アクセスして，品詞情報などを取ってくることを考えます． 適当に書いてみるとこんな感じでしょうか．
import MeCab tagger = MeCab.tagger(&amp;#39;&amp;#39;) text = u&amp;#39;MeCabで遊んでみよう！&amp;#39; node = tagger.parseToNode(text.encode(&amp;#39;utf-8&amp;#39;)) while node: #printはstrを渡す必要があるのでdecodeは不要 print node.surface + &amp;#39;\t&amp;#39; + node.</description>
    </item>
    
    <item>
      <title>TinySegmenterの学習ツールを作ってみた</title>
      <link>https://shogo82148.github.io/blog/2012/11/23/2012-11-23-tinysegmentermaker/</link>
      <pubDate>Fri, 23 Nov 2012 14:37:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/11/23/2012-11-23-tinysegmentermaker/</guid>
      <description>TinySegmenterは工藤さん作のJavaScriptだけで書かれたコンパクトな分かち書きソフトウェアです． わずか20kバイト程度のサイズしかなく，お手軽に使える分かち書きソフトウェアですが， 当たり前のことながら学習データに使った新聞記事以外の文章の精度はイマイチ． 改善しようにも学習用のプログラムが公開されていないのでモデルの修正が大変です．
ないなら作ってしまいましょう！
ダウンロード ソースはgithubで公開しています．cloneするなりzipファイルを落としてくるなりしてください．
 TinySegmenterMaker  学習方法 スペースで分かち書きしたコーパスをあらかじめ準備しておきます． コーパスから分かち書きの情報と素性を取り出します．
$ ./extract &amp;lt; corpus.txt &amp;gt; features.txt AdaBoostを用いて学習します． 新しい弱分類器の分類精度が0.001以下，繰り返し回数が10000回以上となったら学習を終了します．
$ g++ -O3 -o train train.cpp # コンパイル $ ./train -t 0.001 -n 10000 features.txt model # 学習 きちんと分割できるが実際に試してみます．
$ ./segment model 私の名前は中野です 私 の 名前 は 中野 です ライブラリの作成 TinySegmenterは実装が簡単なためいろいろな言語へ移植されています． モデルの更新のたびにそれらへの言語の移植バージョンを作るのは大変です． というわけで，makerコマンドで各種言語用のライブラリを作れます． 学習結果のモデルはライブラリのなかに組み込まれ，ファイル単体で簡単に使用することができます． allを指定することで，対応しているすべての言語向けのライブラリを出力します．
$ ./maker javascript &amp;lt; model $ ./maker perl &amp;lt; model $ ./maker ruby &amp;lt; medel $ .</description>
    </item>
    
    <item>
      <title>PythonでCaboChaを美味しくいただく</title>
      <link>https://shogo82148.github.io/blog/2012/11/01/2012-11-01-cabocha/</link>
      <pubDate>Thu, 01 Nov 2012 23:02:00 +0900</pubDate>
      
      <guid>https://shogo82148.github.io/blog/2012/11/01/2012-11-01-cabocha/</guid>
      <description>日本語構文解析器CaboChaをPythonから使ってみたメモ．
インストール CaboCha自体のインストールは公式のドキュメントを参照． ググれば他の人のレポートも出てくるはず．
CaboChaのソースコードを展開したディレクトリの中の pythonディレクトリにPython-bindingが入ってます． そこに移動した後，管理者権限で以下のコマンドを実行すればインストール完了．
python setup.py install 食べ方 解析結果を文字列出力 python/test.py に書いてあるとおり．
``` python test.py http://code.google.com/p/cabocha/source/browse/trunk/python/test.py #!/usr/bin/python
-- coding: utf-8 -- import CaboCha
c = CaboCha.Parser(&amp;ldquo;&amp;rdquo;); c = CaboCha.Parser()
sentence = &amp;ldquo;太郎はこの本を二郎を見た女性に渡した。&amp;rdquo;
print c.parseToString(sentence)
tree = c.parse(sentence)
print tree.toString(CaboCha.FORMAT_TREE) print tree.toString(CaboCha.FORMAT_LATTICE)
 以下のような結果が得られれば成功． ``` plain &amp;lt;PERSON&amp;gt;太郎&amp;lt;/PERSON&amp;gt;は-----------D この-D | 本を---D | 二郎を-D | 見た-D | 女性に-D 渡した。 EOS &amp;lt;PERSON&amp;gt;太郎&amp;lt;/PERSON&amp;gt;は-----------D この-D | 本を---D | 二郎を-D | 見た-D | 女性に-D 渡した。 EOS * 0 6D 0/1 2.</description>
    </item>
    
  </channel>
</rss>